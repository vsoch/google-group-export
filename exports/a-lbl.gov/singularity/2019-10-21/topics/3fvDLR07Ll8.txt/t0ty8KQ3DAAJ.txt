Date: Wed, 14 Jun 2017 04:50:38 -0700 (PDT)
From: Stefan Kombrink <stefan....@googlemail.com>
To: singularity <singu...@lbl.gov>
Message-Id: <5565bae3-32eb-4df3-b60c-d642371a1261@lbl.gov>
In-Reply-To: <CAApQTTj4AC8dXCObBnSf3KpviyxTMCbtq7G4Auf+SqrTDdOrOw@mail.gmail.com>
References: <cc84e6d1-49ad-416d-8480-78863790f5fd@lbl.gov> <6117a8ba-063e-4799-aeb3-38a2558a0458@lbl.gov>
 <CAKjpbPgtBHN7iNK9tzABD=A-1K8qKPmzHBsBpeSWRiGyFvKdVQ@mail.gmail.com> <b3d1a25d-6e5b-4a47-a2ed-26b5fd144f79@lbl.gov>
 <CAApQTTj4AC8dXCObBnSf3KpviyxTMCbtq7G4Auf+SqrTDdOrOw@mail.gmail.com>
Subject: Re: [Singularity] Re: Is there any way to run mpirun command inside
 container for multi-host system?
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_2419_1777507043.1497441038915"

------=_Part_2419_1777507043.1497441038915
Content-Type: multipart/alternative; 
	boundary="----=_Part_2420_684005060.1497441038915"

------=_Part_2420_684005060.1497441038915
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi Greg,

 I thought about it more:
I also had to bind mount /etc/ssh.
There's a caveat I haven't thought about yet: when ssh is wrapped it is=20
possible to break out running containers just by calling

ssh_orig localhost '/tmp/run_this_code.sh'

Then, sudo and all setuid programs are accessible on the host.
In our case it does not really matter, but it is good to have that in mind!

So maybe I'll first write a tutorial. What are your thoughts on this?

Stefan

Am Dienstag, 13. Juni 2017 17:38:49 UTC+2 schrieb Gregory Kurtzer:
>
> Hi Stefan,
>
> This is an interesting idea, and we might be able to easily include this=
=20
> in a container by a bind mount. Would you be willing to submit and mainta=
in=20
> this in Singularity itself?
>
> Thanks!
>
> On Mon, Jun 12, 2017 at 1:38 PM, 'Stefan Kombrink' via singularity <
> si...@lbl.gov <javascript:>> wrote:
>
>>
>> Here is the wrapper script which replaces ssh:=20
>> https://pastebin.com/vqXXRzb5
>>
>> Am Samstag, 10. Juni 2017 11:17:04 UTC+2 schrieb Guohua Li:
>>>
>>> Really thanks for your reply!=20
>>>
>>> Please post the script when you find it.=20
>>>
>>> Now I'm testing every MPI version which host installed MPI version can=
=20
>>> support much MPI versions inside the container!=20
>>>
>>> Hope your script can solve our problem!
>>>
>>>
>>> =EC=98=81=EC=9B=90=ED=9E=88 =EC=82=B4 =EA=B2=83 =EC=B2=98=EB=9F=BC =EA=
=BF=88=EA=BE=B8=EA=B3=A0 =EB=82=B4=EC=9D=BC =EC=A3=BD=EC=9D=84 =EA=B2=83 =
=EC=B2=98=EB=9F=BC =EC=82=B4=EC=9E=90! =20
>>> This too shall pass away!
>>>
>>> =E2=80=BB =EC=9D=B4=EA=B5=AD=ED=99=94 LI GUOHUA
>>> =E2=80=BB =EA=B1=B4=EA=B5=AD=EB=8C=80=ED=95=99=EA=B5=90 =EB=8C=80=ED=95=
=99=EC=9B=90 =EC=8B=A0=EA=B8=B0=EC=88=A0=EC=9C=B5=ED=95=A9=ED=95=99=EA=B3=
=BC =EB=B0=95=EC=82=AC=EA=B3=BC=EC=A0=95
>>> =E2=80=BB =EC=9C=B5=ED=95=A9 =EC=BB=B4=ED=93=A8=ED=8C=85 =EC=97=B0=EA=
=B5=AC=EC=8B=A4 (IC Lab)
>>> =E2=80=BB iIT, Department of Advanced Technology Fusion, Konkuk Univers=
ity
>>> =E2=80=BB Industry-University Cooperation Bldg. 805
>>> =E2=80=BB KonKuk University, Hwayang-dong, Gwangjin-Gu, Seoul 143-701 S=
outh Korea
>>> =E2=80=BB Cell Phone: +82) 10-3666-8263
>>> =E2=80=BB E-mail: heave...@gmail.com
>>>
>>> 2017-06-10 18:07 GMT+09:00 'Stefan Kombrink' via singularity <
>>> si...@lbl.gov>:
>>>
>>>> I've got some experience on running multi node jobs with mpirun inside=
=20
>>>> the containers.
>>>> Greg is right that it will be difficult to find an general purpose=20
>>>> solution for arbitary HPC systems and software.
>>>> I made it work for two heavily used applications on our cluster one of=
=20
>>>> which used IntelMPI and the other OpenMPI 1.6
>>>> The main thing was to replace /bin/ssh in order to tweak mpirun to wra=
p=20
>>>> "ssh hostname cmd" to "ssh 'singularity ContainerName exec cmd'
>>>> I had to apply some more workarounds to make IB work properly (mainly=
=20
>>>> envvars to configure MPI properly) but essentially the efford was=20
>>>> justifiable.
>>>>
>>>> Sorry cant find the link to the ssh wrapper script right now but I can=
=20
>>>> post it later when you are interested in it. It is really just a few l=
ines=20
>>>> of bash code.
>>>>
>>>> Stefan
>>>>
>>>>
>>>> Am Donnerstag, 8. Juni 2017 15:17:30 UTC+2 schrieb Guohua Li:
>>>>>
>>>>>
>>>>> For our HPC system, really need run mpirun command inside the=20
>>>>> container on multi-host.=20
>>>>>
>>>>> How can we fix the issues?=20
>>>>>
>>>>> In my experience, when I build mpi job on multihost, everytime I=20
>>>>> change the version of MPI inside the container, I have to change the=
=20
>>>>> version of MPI on the host.=20
>>>>>
>>>>> Is there any solution for run mpi command inside the container on=20
>>>>> multi-host system?=20
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --=20
>>>> You received this message because you are subscribed to the Google=20
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send=
=20
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>> --=20
>> You received this message because you are subscribed to the Google Group=
s=20
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n=20
>> email to singu...@lbl.gov <javascript:>.
>>
>
>
>
> --=20
> --
> Gregory M. Kurtzer
> CEO, SingularityWare, LLC.
> Senior Architect, RStor
> Computational Science Advisor, Lawrence Berkeley National Laboratory
>

------=_Part_2420_684005060.1497441038915
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi Greg,<br><br>=C2=A0I thought about it more:<br>I also h=
ad to bind mount /etc/ssh.<br>There&#39;s a caveat I haven&#39;t thought ab=
out yet: when ssh is wrapped it is possible to break out running containers=
 just by calling<br><br>ssh_orig localhost &#39;/tmp/run_this_code.sh&#39;<=
br><br>Then, sudo and all setuid programs are accessible on the host.<br>In=
 our case it does not really matter, but it is good to have that in mind!<b=
r><br>So maybe I&#39;ll first write a tutorial. What are your thoughts on t=
his?<br><br>Stefan<br><br>Am Dienstag, 13. Juni 2017 17:38:49 UTC+2 schrieb=
 Gregory Kurtzer:<blockquote class=3D"gmail_quote" style=3D"margin: 0;margi=
n-left: 0.8ex;border-left: 1px #ccc solid;padding-left: 1ex;"><div dir=3D"l=
tr"><div>Hi Stefan,</div><div><br></div>This is an interesting idea, and we=
 might be able to easily include this in a container by a bind mount. Would=
 you be willing to submit and maintain this in Singularity itself?<div><br>=
</div><div>Thanks!</div></div><div><br><div class=3D"gmail_quote">On Mon, J=
un 12, 2017 at 1:38 PM, &#39;Stefan Kombrink&#39; via singularity <span dir=
=3D"ltr">&lt;<a href=3D"javascript:" target=3D"_blank" gdf-obfuscated-mailt=
o=3D"BrvkQ3KpAgAJ" rel=3D"nofollow" onmousedown=3D"this.href=3D&#39;javascr=
ipt:&#39;;return true;" onclick=3D"this.href=3D&#39;javascript:&#39;;return=
 true;">si...@lbl.gov</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_q=
uote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1e=
x"><div dir=3D"ltr"><br>Here is the wrapper script which replaces ssh: <a h=
ref=3D"https://pastebin.com/vqXXRzb5" target=3D"_blank" rel=3D"nofollow" on=
mousedown=3D"this.href=3D&#39;https://www.google.com/url?q\x3dhttps%3A%2F%2=
Fpastebin.com%2FvqXXRzb5\x26sa\x3dD\x26sntz\x3d1\x26usg\x3dAFQjCNHaQI4svs0t=
xeObI0qVo4Irbe0Elw&#39;;return true;" onclick=3D"this.href=3D&#39;https://w=
ww.google.com/url?q\x3dhttps%3A%2F%2Fpastebin.com%2FvqXXRzb5\x26sa\x3dD\x26=
sntz\x3d1\x26usg\x3dAFQjCNHaQI4svs0txeObI0qVo4Irbe0Elw&#39;;return true;">h=
ttps://pastebin.com/vqXXRzb5</a><span><br><br>Am Samstag, 10. Juni 2017 11:=
17:04 UTC+2 schrieb Guohua Li:</span><blockquote class=3D"gmail_quote" styl=
e=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex=
"><span><div dir=3D"ltr">Really thanks for your reply!=C2=A0<div><br></div>=
<div>Please post the script when you find it.=C2=A0<div><br></div><div>Now =
I&#39;m testing every MPI version which host installed MPI version can supp=
ort much MPI versions inside the container!=C2=A0</div></div><div><br></div=
><div>Hope your script can solve our problem!</div><div><br></div></div></s=
pan><div><br clear=3D"all"><div><div><div dir=3D"ltr"><div><div dir=3D"ltr"=
><div><div dir=3D"ltr"><span><div><span style=3D"color:rgb(182,182,182);fon=
t-family:&#39;Microsoft Yahei&#39;,Arial;text-align:center">=EC=98=81=EC=9B=
=90=ED=9E=88=C2=A0=EC=82=B4=C2=A0=EA=B2=83=C2=A0=EC=B2=98=EB=9F=BC=C2=A0=EA=
=BF=88=EA=BE=B8=EA=B3=A0=C2=A0=EB=82=B4=EC=9D=BC=C2=A0=EC=A3=BD=EC=9D=84=C2=
=A0=EA=B2=83=C2=A0=EC=B2=98=EB=9F=BC=C2=A0=EC=82=B4=EC=9E=90!</span><span s=
tyle=3D"color:rgb(182,182,182);font-family:&#39;Microsoft Yahei&#39;,Arial;=
text-align:center">=C2=A0</span><wbr>=C2=A0</div><div><font color=3D"#99999=
9">This too shall pass away!<br></font><br><font style=3D"background-color:=
rgb(255,255,255)" face=3D"&#39;comic sans ms&#39;, sans-serif" color=3D"#66=
66cc">=E2=80=BB =EC=9D=B4=EA=B5=AD=ED=99=94 LI GUOHUA<br>=E2=80=BB =EA=B1=
=B4=EA=B5=AD=EB=8C=80=ED=95=99=EA=B5=90 =EB=8C=80=ED=95=99=EC=9B=90 =EC=8B=
=A0=EA=B8=B0=EC=88=A0=EC=9C=B5=ED=95=A9=ED=95=99=EA=B3=BC =EB=B0=95=EC=82=
=AC=EA=B3=BC=EC=A0=95</font></div><div><span style=3D"color:rgb(102,102,204=
);font-family:&#39;comic sans ms&#39;,sans-serif;background-color:rgb(255,2=
55,255)">=E2=80=BB</span><font color=3D"#3366ff">=C2=A0</font><font color=
=3D"#6666cc">=EC=9C=B5=ED=95=A9 =EC=BB=B4=ED=93=A8=ED=8C=85 =EC=97=B0=EA=B5=
=AC=EC=8B=A4 (IC Lab)</font><font style=3D"background-color:rgb(255,255,255=
)" face=3D"&#39;comic sans ms&#39;, sans-serif" color=3D"#6666cc"><br>=E2=
=80=BB iIT, Department of Advanced Technology Fusion, Konkuk University<br>=
=E2=80=BB Industry-University Cooperation Bldg. 805</font></div>
</span><div><font style=3D"background-color:rgb(255,255,255)" face=3D"&#39;=
comic sans ms&#39;, sans-serif"><span><font color=3D"#6666cc">=E2=80=BB Kon=
Kuk University, Hwayang-dong, Gwangjin-Gu, Seoul 143-701 South Korea<br>=E2=
=80=BB Cell Phone: <a value=3D"+821036668263">+82) 10-3666-8263</a></font><=
br></span><font color=3D"#9999ff">=E2=80=BB E-mail: heavenkong</font><a sty=
le=3D"color:rgb(153,153,255)" rel=3D"nofollow">...@gmail.com</a></font></di=
v></div></div></div></div></div></div></div>
<br><div class=3D"gmail_quote"><span>2017-06-10 18:07 GMT+09:00 &#39;Stefan=
 Kombrink&#39; via singularity <span dir=3D"ltr">&lt;<a rel=3D"nofollow">si=
...@lbl.gov</a>&gt;</span>:<br></span><blockquote class=3D"gmail_quote" sty=
le=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><span>=
<div dir=3D"ltr">I&#39;ve got some experience on running multi node jobs wi=
th mpirun inside the containers.<br>Greg is right that it will be difficult=
 to find an general purpose solution for arbitary HPC systems and software.=
<br>I made it work for two heavily used applications on our cluster one of =
which used IntelMPI and the other OpenMPI 1.6<br>The main thing was to repl=
ace /bin/ssh in order to tweak mpirun to wrap &quot;ssh hostname cmd&quot; =
to &quot;ssh &#39;singularity ContainerName exec cmd&#39;<br>I had to apply=
 some more workarounds to make IB work properly (mainly envvars to configur=
e MPI properly) but essentially the efford was justifiable.<br><br>Sorry ca=
nt find the link to the ssh wrapper script right now but I can post it late=
r when you are interested in it. It is really just a few lines of bash code=
.<span><font color=3D"#888888"><br><br>Stefan</font></span><div><div><br><b=
r>Am Donnerstag, 8. Juni 2017 15:17:30 UTC+2 schrieb Guohua Li:<blockquote =
class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #=
ccc solid;padding-left:1ex"><div dir=3D"ltr"><br><div><font size=3D"4">For =
our HPC system, really need run mpirun command inside the container on mult=
i-host.=C2=A0</font></div><div><font size=3D"4"><br></font></div><div><font=
 size=3D"4">How can we fix the issues?=C2=A0</font></div><div><font size=3D=
"4"><br></font></div><div><font size=3D"4">In my experience, when I build m=
pi job on multihost, everytime I change the version of MPI inside the conta=
iner, I have to change the version of MPI on the host.=C2=A0</font></div><d=
iv><font size=3D"4"><br></font></div><div><font size=3D"4">Is there any sol=
ution for run mpi=C2=A0command inside the container on multi-host system?=
=C2=A0</font></div><div><font size=3D"4"><br></font></div><div><font size=
=3D"4"><br></font></div><div><font size=3D"4"><br></font></div><div><font s=
ize=3D"4"><br></font></div></div></blockquote></div></div></div></span><div=
><div><span>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br></span>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br></div>
</blockquote></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"javascript:" target=3D"_blank" gdf-obfuscated-mailto=3D"=
BrvkQ3KpAgAJ" rel=3D"nofollow" onmousedown=3D"this.href=3D&#39;javascript:&=
#39;;return true;" onclick=3D"this.href=3D&#39;javascript:&#39;;return true=
;">singularity...@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div><div dir=3D"ltr"><div><div dir=3D"ltr">--<div>Gregory M. Kurtzer</div>=
<div>CEO, SingularityWare, LLC.</div><div>Senior Architect, RStor</div><div=
><span style=3D"font-size:12.8px">Computational Science Advisor, Lawrence B=
erkeley National Laboratory</span><br></div></div></div></div></div>
</div>
</blockquote></div>
------=_Part_2420_684005060.1497441038915--

------=_Part_2419_1777507043.1497441038915--

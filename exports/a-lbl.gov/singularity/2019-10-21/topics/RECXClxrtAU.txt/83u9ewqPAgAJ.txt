X-Received: by 2002:a65:5048:: with SMTP id k8-v6mr6233396pgo.17.1530644925084;
        Tue, 03 Jul 2018 12:08:45 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 2002:aa7:8059:: with SMTP id y25-v6ls4783437pfm.1.gmail; Tue, 03
 Jul 2018 12:08:44 -0700 (PDT)
X-Received: by 2002:a63:943:: with SMTP id 64-v6mr12418833pgj.368.1530644923803;
        Tue, 03 Jul 2018 12:08:43 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1530644923; cv=none;
        d=google.com; s=arc-20160816;
        b=aVY0na10N8YT9BFKFU2hr1eIbYBlqpB9HcVQT14AcWhYIvsuxUhGpWWvdWjQVY5cQN
         gOEuf7TTADMVIdRHl1QMHmgqzl38m2SJrM0T0umimH9tu3MzxqJqK8JKvmZZ+LSEWdyP
         8esXOCqVLtRG5dRE3d45MH0kJDNGYdb1agKkQL2QD3jiwaZVibGKhrfr6vMHmIA++uw6
         CWTqpNf6XtrXCIVLqXA8bkb3Lt6rkzRftMp4o5fF098NDi0JhueRsLHeaRxAx00qn9DS
         dzpPlEDvYfaq51RtDBptfMwZ+HcdBViS30m1BEHtVln7SscTKASlMbsajQ1NkTARK8xf
         sM+A==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:in-reply-to:references:mime-version
         :dkim-signature:arc-authentication-results;
        bh=j6/B15V8HL8J+at9QsItIAZ5b+0nNxdZiRP0Toz11dE=;
        b=UfZ1uOPTeP+I9bRmQNwwCmeSAZ2jG8GE22E+E+CMcBCRiWtC452+BwHd2Y9Xt+Ca4V
         s0otvWInk8JvsV3SqQsUrIMUdWFnB+GDZeIGF/fARibixdJTkabryip5KaQW0HRXS4IN
         ysgecPGpwnGv0hPqNhOfB6XN99U0Qvzeo8GF0HsPomZCXHRGcPjs/2BEDbo/Dwvdyx7Q
         bjewXV7p8SvPwKpNwwtr7EBjNho8x8Gn99hC42yJ3wvH+S3WKsEMo6g4KVW49OclM1q5
         NWxs62Lp/4iwE+Cw9QzdVI2G7nAAcVYNz7dar8KiNByBrHHeOKVb+lF4bmyqsG2UQdMv
         LjHA==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=Tf8DtCDJ;
       spf=pass (google.com: domain of georghi...@gmail.com designates 209.85.208.173 as permitted sender) smtp.mailfrom=georghi...@gmail.com
Return-Path: <georghi...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id z13-v6si1805961pfc.118.2018.07.03.12.08.43
        for <singu...@lbl.gov>;
        Tue, 03 Jul 2018 12:08:43 -0700 (PDT)
Received-SPF: pass (google.com: domain of georghi...@gmail.com designates 209.85.208.173 as permitted sender) client-ip=209.85.208.173;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=Tf8DtCDJ;
       spf=pass (google.com: domain of georghi...@gmail.com designates 209.85.208.173 as permitted sender) smtp.mailfrom=georghi...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2B+BAAKyTtbhq3QVdFQBAUDg1CBDH8og?=
 =?us-ascii?q?3MGUkuCUJA8GYFoBRoClSYUgWMDIwEOgVCBPoE3AoIZITQYAQIBAQIBAQIBEwE?=
 =?us-ascii?q?BAQgLCwgpIwxCDAGBZgUCAwIeglcBAQEBAgEMDgECBgQKDwENDgkLCgMBCwYDA?=
 =?us-ascii?q?gsNIAEJAgIhAQEOAwEFARwOBwQBBwwBBgIEgjRLASiBPgEDDQgFCo0wkAM8iVc?=
 =?us-ascii?q?RgSGBaRYFAReBSoEoBWqCZwoZJg1XV4EyAgYSiDUmgVY/gQ+CEX6CVjcLAQEBA?=
 =?us-ascii?q?QEBgR0MAQ0FAQMGAjUMGoI6glUCh0cNEQgVgTKDHIxQKwmGBoYOb4IcgUBDg0m?=
 =?us-ascii?q?Ca4UgijVPhnYwgRAQay4/GwMMCHCBAYI4CRaBVTAOCYNFaoF6gjCCZoJXAz0wA?=
 =?us-ascii?q?QsEihaECwEBDRcEAymBbQUBAQ?=
X-IronPort-AV: E=Sophos;i="5.51,304,1526367600"; 
   d="scan'208,217";a="28404834"
Received: from mail-lj1-f173.google.com ([209.85.208.173])
  by fe4.lbl.gov with ESMTP; 03 Jul 2018 12:08:39 -0700
Received: by mail-lj1-f173.google.com with SMTP id a17-v6so2395223ljd.8
        for <singu...@lbl.gov>; Tue, 03 Jul 2018 12:08:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to;
        bh=j6/B15V8HL8J+at9QsItIAZ5b+0nNxdZiRP0Toz11dE=;
        b=Tf8DtCDJlZ78C1qYNhD0eCVxYqAW6Z6vXXzy3tUL7bXUkBTslU5DpmPJjEJwj+RkxA
         G0AXB/m5xIQBIUNPLDENVMqMCgs2l5a+mNiS4bSK+YgjuNP+QroHv5TdYnJgZbciJjoS
         LV1dS2ugGNSF1Olx5dtr7F9jjXFDVp7uN3Xim11YBvaIVbSm+ii3zO1ANuToVJFohDSR
         LEzLeud5SyXIwhzXanvgwxqz+x1cAY/aeK44vVC0i1OYD4GIuDKSa3xmYuEYFHRJxtv0
         HM7JlPZoMqxM72SYaoWUDMnh5pYISd2FIGYX83v4ayvmwL211B/afX+H7yForJuHHMTF
         bjQA==
X-Gm-Message-State: APt69E0GeBqwyib4DYNz0zpO+eIIOvkWnA6tsLltP/VnI+YhbIaG7lDn
	BnOBk3YrQnb+ToYtFZy06n07giV60onjCuChXudjxaPt
X-Received: by 2002:a2e:4b01:: with SMTP id y1-v6mr19633035lja.135.1530644918220;
 Tue, 03 Jul 2018 12:08:38 -0700 (PDT)
MIME-Version: 1.0
References: <4d550130-4d54-4d4f-bf9f-a46f34132e96@lbl.gov> <CAJZ53CkoPup6sXotzVLO_toCu2c+rwK-A6Y0+TU277Y9km8N9w@mail.gmail.com>
 <CAM=pu+Jq2HcgVEBoYJ-USVQomnT6=pmd_16UdEpz2nniPQewdw@mail.gmail.com>
 <CADf5cTEmD1BEEg=jQHf2rrK1h+cwPYYqSD3Tz0UKS-RpumNNRA@mail.gmail.com>
 <CAMsq4T1c4vA5Yv6_bWJhpNC=UCze1reP2yPQa2YUtutJRPzQbA@mail.gmail.com>
 <CAM=pu+L-DXgQJ4eSUqSEnriDX9U2+dwOU-e2P2gWFxW3jsPcWQ@mail.gmail.com>
 <CAPqNE2VEL6oOB2NMP89=BxHqQj5k=Mbg2C=7O=oZuRvN5Q-pnQ@mail.gmail.com>
 <CAPqNE2UYU6+k3k6eef49t1gUegbDRSAD5XyDAf28bQWEBKjCqg@mail.gmail.com>
 <CAM=pu++GTFfSA5riN7F7KmLzGR=U-TdbX1C9hJzD9x=-h-M_cw@mail.gmail.com>
 <CAMsq4T2BrK5ro0wuLdELmOTOeEgafW_OZ7c=s7QERA4K5_atwg@mail.gmail.com>
 <CAM=pu++W=8VQDYNfUbZhhNHtEHpYGXRgYre6_Aj_hPafHmr_DQ@mail.gmail.com>
 <CAM=pu+Jg+k=YZninbi8Wf4b-BVoW4R536rqAFJn6su_o-+0wOA@mail.gmail.com>
 <CAM=pu+JRrCB0+Xc+A9ogXvDbdqqkqzjsZwOhy3n7-WNH-ZV3tg@mail.gmail.com> <CAJZ53C=88GZCGuw-=uMkMwQiPTt5Qm6j2rkBAhW+p_EjfY484g@mail.gmail.com>
In-Reply-To: <CAJZ53C=88GZCGuw-=uMkMwQiPTt5Qm6j2rkBAhW+p_EjfY484g@mail.gmail.com>
From: Georg Hildebrand <georghi...@gmail.com>
Date: Tue, 3 Jul 2018 21:08:01 +0200
Message-ID: <CAJaZQ0hNGzoAZTgEamHXrtWHPxTDwhJwnc7Gay6m6BcLibGnhQ@mail.gmail.com>
Subject: Re: [Singularity] Research data and containers
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="000000000000a0bcdd05701d0aa4"

--000000000000a0bcdd05701d0aa4
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

Hey Dominique,

You may want to checkout these projects:

https://github.com/quiltdata version and deploy management for data. The
concept i like is that they tokenize the data in a merkle tree.

There is also the nexus project (quite old and driven by a astro science
community, not sure how actively its developed currently).
http://download.nexusformat.org/doc/html/examples/index.html


Viele Gr=C3=BC=C3=9Fe
Georg


Am Di., 3. Juli 2018 um 17:24 Uhr schrieb Brandon Barker <
brando...@cornell.edu>:

> Sorry for the short reply earlier. Here is the service I was referring to=
:
> https://codeocean.com/
> Of course, there can be costs: https://codeocean.com/plans
>
>
> On Thu, Jun 28, 2018 at 6:47 AM, v <vso...@gmail.com> wrote:
>
>> Oh, and Chris (@chrisfilo on GitHub) wrote a nice article about data
>> sharing:
>>
>>
>> https://medium.com/@ChrisFiloG/liberating-data-an-interview-with-john-io=
annidis-a71262047f17
>>
>> Good insights :)
>>
>> On Thu, Jun 28, 2018, 3:38 AM v <vso...@gmail.com> wrote:
>>
>>> There's also the interplanetary filesystem (peer to peer) idea...
>>>
>>> https://ipfs.io/
>>>
>>> But not sure that is taking feet yet?
>>>
>>> On Thu, Jun 28, 2018 at 3:37 AM v <vso...@gmail.com> wrote:
>>>
>>>> Figure out some model where you get some yuuuge company to host it via
>>>> cloud storage, then mount the data easily as an instance. Grab the ana=
lysis
>>>> container (and be sudo if you like, it's your cloud node to be
>>>> irresponsible with) and run-all-the-things.
>>>>
>>>> And get your credit card bill after forgetting about the GPU node(s)
>>>> over the weekend, cry softly, have a snack, feel better :)
>>>>
>>>> In all seriousness, this is a non-trivial problem. Someone has to pay
>>>> for storage! It's not even a one time thing, it's a long term commitme=
nt to
>>>> management of the data and access / tooling around it..
>>>>
>>>> On Thu, Jun 28, 2018 at 3:31 AM Maxime Hebrard <
>>>> maxime...@gmail.com> wrote:
>>>>
>>>>> but that is the point ...
>>>>> to say "yes, I ran the pipeline with your data, and can verify what
>>>>> you claimed in the paper, I have replicated the result."
>>>>> we need a way to get the hand on the original dataset
>>>>>
>>>>> well my personal problem is not really on "dataset" per se but more
>>>>> with references data
>>>>> like reference genome / indexes / annotation files
>>>>> that are Huge and hard to manage :-/
>>>>>
>>>>> I could point to public repo for that, but still it is a pain for the
>>>>> user to download (or let the container download for him) this huge
>>>>> files :-/
>>>>>
>>>>> looking for a "better solution" ...
>>>>>
>>>>>
>>>>>
>>>>> On Thu, Jun 28, 2018 at 6:08 PM, v <vso...@gmail.com> wrote:
>>>>> > All the cool kids are signing things these days!
>>>>> >
>>>>> https://docs.docker.com/engine/security/trust/content_trust/#image-ta=
gs-and-content-trust
>>>>> > :P
>>>>> >
>>>>> > Dataset signing, especially for these fantastic "actually large"
>>>>> datasets,
>>>>> > seems to be taken with the same importance for reproducibility as
>>>>> the tools
>>>>> > that go into the anayses. To play devil's advocate, given that we
>>>>> want to
>>>>> > prove some phenomena, wouldn't we want to be able to show the same
>>>>> (or
>>>>> > comparable within some range of confidence) result across different
>>>>> > datasets? It doesn't strengthen the hypothsis to do the same thing
>>>>> again on
>>>>> > the exact same data, it strengthens the confidence in the
>>>>> reproducibility of
>>>>> > the pipeline (two separate things). So perhaps a small bit of data
>>>>> could be
>>>>> > stored with the container to validate the pipeline, but then new
>>>>> samples
>>>>> > encouraged to show if the hypothsis holds?
>>>>> >
>>>>> > And I'm probably off here, but I think the sharing of datasets is
>>>>> less about
>>>>> > "run it again on exactly the same data" but more about "share the
>>>>> data so we
>>>>> > can all learn from it and increase overall N for better power." A
>>>>> culture of
>>>>> > data sharing, along with validation of method + published result,
>>>>> also
>>>>> > allows for checks and balances ("yes, I ran the pipeline with your
>>>>> data, and
>>>>> > can verify what you claimed in the paper, I have replicated the
>>>>> result."
>>>>> >
>>>>> > On Thu, Jun 28, 2018 at 12:20 AM 'John Hearns' via singularity
>>>>> > <singu...@lbl.gov> wrote:
>>>>> >>
>>>>> >> Chris Hines mentions signing of tool packages.  In danger of
>>>>> crossing the
>>>>> >> streams, I am an enthusiast for the Julia language.
>>>>> >> the new Pkg3 infrastructure for Julia, which is the default packag=
e
>>>>> >> manager now, implements UUIDs for packages
>>>>> >> https://github.com/JuliaLang/Juleps/blob/master/Pkg3.md#registries
>>>>> >>
>>>>> >> On 28 June 2018 at 09:15, John Hearns <hea...@googlemail.com>
>>>>> wrote:
>>>>> >>>
>>>>> >>> I think this a very, very interesting topic.  Please allow me to
>>>>> explore
>>>>> >>> and hopefully bring out some responses?
>>>>> >>>
>>>>> >>> Are we talking about large public datasets here - for instance I
>>>>> worked
>>>>> >>> on a CERN experiment (ahem) many years ago.
>>>>> >>> One hopes that huge, public datasets do not change. For instance
>>>>> if I
>>>>> >>> went back to analyze what was tagged at the time with a run numbe=
r
>>>>> and an
>>>>> >>> event number I hope I would get the same data.
>>>>> >>> OK, it is clear that some large institutiosn worldwide will store
>>>>> that
>>>>> >>> data. And that bitrot or the scarcity of the tape drives to read
>>>>> the data
>>>>> >>> has not rendered it beyond recovery.
>>>>> >>>
>>>>> >>> I also worked with the JASMIN project in the UK, where several
>>>>> institutes
>>>>> >>> have banded together to create a central data store for climate
>>>>> modelling.
>>>>> >>> Again large public datasets.
>>>>> >>>
>>>>> >>> I also worked in Formula 1 with CFD engineers, and managed over a
>>>>> >>> petabyte of data from CFD studies. Those studies were catalogued
>>>>> by year and
>>>>> >>> then case number.
>>>>> >>> Again, we assume that the data is held on tape somewhere and if
>>>>> you ind
>>>>> >>> the correctly named directory you will get the same data back.
>>>>> >>>
>>>>> >>> I guess here we are talking about reproducibility. So we have a
>>>>> >>> Singularity container, which is signed, and captures the packages
>>>>> and
>>>>> >>> libraries needed to run that analysis.
>>>>> >>> We also have to have the same data available to run on.  Do we
>>>>> need to
>>>>> >>> physically keep that data 'beside' the container? Maybe, for
>>>>> certain data
>>>>> >>> and certain values of 'not too large'.
>>>>> >>> but how about analyses of (say) CERN or JASMIN data? Is it enough
>>>>> to make
>>>>> >>> a pointer towards those datasets somehow?
>>>>> >>> I would say URL's or URIs here, but we have seen how the Web is
>>>>> dynamic
>>>>> >>> and sites disappear and links change.
>>>>> >>>
>>>>> >>>
>>>>> >>> Its worth saying that in the UK there is a lot of effort in this
>>>>> space.
>>>>> >>> The Research Councils there mandated that if they fund research
>>>>> the data
>>>>> >>> must be retained for N years (I forget N)
>>>>> >>> So many Universities now have specific services for research data=
,
>>>>> for
>>>>> >>> instance:
>>>>> >>> http://www.ucl.ac.uk/research-it-services/research-data-service
>>>>> >>> https://www.ukdataservice.ac.uk/
>>>>> >>>
>>>>> >>> Arkivum https://arkivum.com/ works closely with the UK academic
>>>>> network
>>>>> >>> to provide large data storage. I just found this blog on their
>>>>> website -
>>>>> >>> well worth reading.
>>>>> >>>
>>>>> >>>
>>>>> https://arkivum.com/articles/blog-series-part-1-four-economic-factors=
-make-cost-nothing-expensive-something/
>>>>> >>>
>>>>> >>>
>>>>> https://arkivum.com/pharma/blog-series-part-4-final-economic-fallacy-=
long-term-data-temporarily-dynamic-path-dependent/
>>>>> >>>
>>>>> >>>
>>>>> >>> To end up, I guess what we are aiming towards is an S3 compatible
>>>>> storage
>>>>> >>> bucket, whether this is hosted in-house, by Amazon or by a
>>>>> compatible
>>>>> >>> provider.
>>>>> >>> Such a bucket would have to be locked, and signed.  Ideas??
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>>
>>>>> >>> On 28 June 2018 at 03:44, v <vso...@gmail.com> wrote:
>>>>> >>>>
>>>>> >>>> Your description of the different components is on point.
>>>>> >>>>
>>>>> >>>> Finding hosting for large data is, and will continue to be,
>>>>> always one
>>>>> >>>> of the biggest problems. It's expensive. Someone has to pay for
>>>>> it. Nobody
>>>>> >>>> will do it for you for free. We are lucky to have things like
>>>>> Github repos,
>>>>> >>>> Google Drive, Dropbox, that gives some (mediocre) access to smal=
l
>>>>> data. For
>>>>> >>>> large data, everyone is pretty much on their own. Most academics
>>>>> have a
>>>>> >>>> university that provides some sort of web space / library data
>>>>> archive, and
>>>>> >>>> if you are publishing, some journals will support it too -->
>>>>> >>>> https://www.nature.com/sdata/policies/repositories. I try to
>>>>> figure out
>>>>> >>>> hacks to get everything hosted, for free, in version control, bu=
t
>>>>> that
>>>>> >>>> breaks when anything gets large.
>>>>> >>>>
>>>>> >>>> The entity that manages a data respository, if this is a thing,
>>>>> must
>>>>> >>>> have incentive to do it. The datasets have to bring in money in
>>>>> some way, or
>>>>> >>>> someone has to value it enough to pay for it. That's sort of wha=
t
>>>>> most
>>>>> >>>> things come down to, unfortunately.
>>>>> >>>>
>>>>> >>>>
>>>>> >>>> On Wed, Jun 27, 2018 at 6:38 PM Maxime Hebrard
>>>>> >>>> <maxime...@gmail.com> wrote:
>>>>> >>>>>
>>>>> >>>>> I start to use singularity / containers and obviously I ran int=
o
>>>>> the
>>>>> >>>>> same question ...
>>>>> >>>>>
>>>>> >>>>> a half solution that I found by exploring existing solution
>>>>> (thanks to
>>>>> >>>>> nf-core and SciLifeLab to share their workflow / containers) is
>>>>> ( as
>>>>> >>>>> far I understand ):
>>>>> >>>>>
>>>>> >>>>> the container encapsulate only the sorftware.
>>>>> >>>>> the data are store in external repositories.
>>>>> >>>>>
>>>>> >>>>> the user receive the container.
>>>>> >>>>>
>>>>> >>>>> case 1:
>>>>> >>>>> the user download the data by himself and point his files to th=
e
>>>>> >>>>> container
>>>>> >>>>> the container use local files as resources
>>>>> >>>>> pros:
>>>>> >>>>>  * the container is slim
>>>>> >>>>>  * user can store the data on machine A (data server) and run t=
he
>>>>> >>>>> software on machine B (analyse server)
>>>>> >>>>> cons:
>>>>> >>>>> * user is involved in downloading the right data
>>>>> >>>>>
>>>>> >>>>> case 2:
>>>>> >>>>> the user do not have the data
>>>>> >>>>> the container download the data from the external repository
>>>>> >>>>> the container use the data it just download
>>>>> >>>>> pro:
>>>>> >>>>> * the container manage everything
>>>>> >>>>> cons:
>>>>> >>>>> * the step of downloading the data require bandwith + disk spac=
e
>>>>> =3D
>>>>> >>>>> time and resources
>>>>> >>>>>
>>>>> >>>>> a general worry for both scenarii is:
>>>>> >>>>> who manage the data repository ? can we ensure the version of
>>>>> the data
>>>>> >>>>> package will be maintain ?
>>>>> >>>>>
>>>>> >>>>> Waiting for your feedback ;)
>>>>> >>>>> Maxime
>>>>> >>>>>
>>>>> >>>>> On Thu, Jun 28, 2018 at 8:15 AM, 'Chris Hines' via singularity
>>>>> >>>>> <singu...@lbl.gov> wrote:
>>>>> >>>>> > To quote 90's band "The Offspring" IMHO "You gotta keep 'em
>>>>> >>>>> > separated"
>>>>> >>>>> >
>>>>> >>>>> > Personally I think this is a larger question: How do we (as
>>>>> research
>>>>> >>>>> > software engineers, or whatever you would like to call us
>>>>> today)
>>>>> >>>>> > catalog and
>>>>> >>>>> > attach references (DOI's I guess) to larger data sets. Does i=
t
>>>>> make
>>>>> >>>>> > sense to
>>>>> >>>>> > mksquashfs or tar.bz2? What if they are already in a single
>>>>> hdf5
>>>>> >>>>> > file? And
>>>>> >>>>> > what about the output data set? we obviously want that to lan=
d
>>>>> >>>>> > outside the
>>>>> >>>>> > computational container, but how should we package the output
>>>>> so it
>>>>> >>>>> > can be
>>>>> >>>>> > referenced directly? How do we make that whole thing
>>>>> discoverable and
>>>>> >>>>> > encourage researchers to attach sufficient metadata to make i=
t
>>>>> >>>>> > searchable?
>>>>> >>>>> >
>>>>> >>>>> > I'm wondering if part of the solution is some sort of "meta
>>>>> >>>>> > container" that
>>>>> >>>>> > downloads a set of versioned data with specific checksums, an=
d
>>>>> a
>>>>> >>>>> > versioned
>>>>> >>>>> > tool container with a specific checksum, and attaches them in=
 a
>>>>> >>>>> > reproducible
>>>>> >>>>> > way.
>>>>> >>>>> >
>>>>> >>>>> > To address Dominque's question directly: I'd keep the
>>>>> >>>>> > "semi-separated".
>>>>> >>>>> > Whatever your researchers use for
>>>>> archiving/cataloging/managing their
>>>>> >>>>> > data
>>>>> >>>>> > sets, keep that in place and add the singularity container to
>>>>> the
>>>>> >>>>> > data set
>>>>> >>>>> > (rather than adding the data set to the singularity container=
).
>>>>> >>>>> >
>>>>> >>>>> > Regards,
>>>>> >>>>> > --
>>>>> >>>>> > Chris.
>>>>> >>>>> > Monash eResearch Centre, Monash University, Australia
>>>>> >>>>> >
>>>>> >>>>> > On Thu, 28 Jun 2018 at 01:19, v <vso...@gmail.com> wrote:
>>>>> >>>>> >>
>>>>> >>>>> >> If you are making containers with singularity (and using
>>>>> Squashfs
>>>>> >>>>> >> anyway)
>>>>> >>>>> >> it wouldn't be so nutty to just compress with mksquashfs and
>>>>> then
>>>>> >>>>> >> mount
>>>>> >>>>> >> where needed - I did this with a huge dataset and it worked
>>>>> pretty
>>>>> >>>>> >> nicely
>>>>> >>>>> >> :_) It relies on FUSE then and all the issues around that,
>>>>> but it's
>>>>> >>>>> >> an
>>>>> >>>>> >> option!
>>>>> >>>>> >>
>>>>> >>>>> >> This is good showing of how use use mksquashfs (it's really
>>>>> >>>>> >> simple,actually!) -->
>>>>> >>>>> >> http://tldp.org/HOWTO/SquashFS-HOWTO/creatingandusing.html
>>>>> >>>>> >> And then mount -->
>>>>> >>>>> >> https://vsoch.github.io/datasets/2018/zenodo/#mount-with-sud=
o
>>>>> >>>>> >>
>>>>> >>>>> >> On Wed, Jun 27, 2018 at 8:14 AM Brandon Barker
>>>>> >>>>> >> <brando...@cornell.edu> wrote:
>>>>> >>>>> >>>
>>>>> >>>>> >>> I seem to recall code ocean may have explored this idea.
>>>>> Sorry I
>>>>> >>>>> >>> can't
>>>>> >>>>> >>> say more, at the moment.
>>>>> >>>>> >>>
>>>>> >>>>> >>> On Wed, Jun 27, 2018, 8:50 AM Dominique Hansen
>>>>> >>>>> >>> <dominiqu...@gmail.com> wrote:
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Hello everyone,
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> I am seeking for tips and experience on how to handle
>>>>> research
>>>>> >>>>> >>>> data,
>>>>> >>>>> >>>> especially bigger sets of data (inside the GB range), in
>>>>> >>>>> >>>> combination with
>>>>> >>>>> >>>> containers.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> I am a student assistant working in the IT department of a
>>>>> >>>>> >>>> research
>>>>> >>>>> >>>> institute. And I am involved in building the infrastructur=
e
>>>>> for
>>>>> >>>>> >>>> singularity
>>>>> >>>>> >>>> containerization and introducing researchers to the
>>>>> technology. We
>>>>> >>>>> >>>> have
>>>>> >>>>> >>>> already build a few base images containing frequently used
>>>>> tools.
>>>>> >>>>> >>>> Recently a
>>>>> >>>>> >>>> research group approached us, wishing to integrate data,
>>>>> they
>>>>> >>>>> >>>> created for
>>>>> >>>>> >>>> one tool, into a container with the tool. The data takes u=
p
>>>>> >>>>> >>>> several GB of
>>>>> >>>>> >>>> disk space and we are unsure how to handle this and simila=
r
>>>>> future
>>>>> >>>>> >>>> use
>>>>> >>>>> >>>> cases.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Does anyone have a set of best practices or is there an
>>>>> intended
>>>>> >>>>> >>>> way to
>>>>> >>>>> >>>> use singularity with big research data?
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> The options we considered are:
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Moving the data into the container at build time.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Pro:
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Keeps the whole thing mobile
>>>>> >>>>> >>>> Keeps work away from the researchers
>>>>> >>>>> >>>> Can be referenced as a single entity in a publication.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Con:
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Where would you store such big containers, especially
>>>>> several of
>>>>> >>>>> >>>> them?
>>>>> >>>>> >>>> What would happen, if separate versions of the tool are
>>>>> needed?
>>>>> >>>>> >>>> Keep the
>>>>> >>>>> >>>> old and accumulate redundant data? Delete the old and risk
>>>>> >>>>> >>>> reproducibility
>>>>> >>>>> >>>> problems? (Maybe container Apps can be used to minimize
>>>>> this.)
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Let the researchers mount the data into the container at
>>>>> startup.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Pro:
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Keeps the containers slimmer, the tools more modular.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Con:
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Adds to the workload and the things the researchers have t=
o
>>>>> keep
>>>>> >>>>> >>>> track
>>>>> >>>>> >>>> of.
>>>>> >>>>> >>>> Spreads the parts needed for reproduction over at least tw=
o
>>>>> >>>>> >>>> points.
>>>>> >>>>> >>>> Hampers mobility.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Mounting during early phases and publish with a container,
>>>>> >>>>> >>>> containing
>>>>> >>>>> >>>> the data.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Pro:
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Reduces amount of containers with redundant and deprecated
>>>>> data.
>>>>> >>>>> >>>> Makes reproduction of results easier after publication.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Con:
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Ads to the workload.
>>>>> >>>>> >>>> When is the point when its time to "freeze" the data insid=
e
>>>>> the
>>>>> >>>>> >>>> container?
>>>>> >>>>> >>>> Storage of the container is still problematic.
>>>>> >>>>> >>>> Might introduce reproducibility problems, since you change
>>>>> the
>>>>> >>>>> >>>> original
>>>>> >>>>> >>>> container to put the data into it.
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Are there any recommendations from experience?
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> Thank you and best regards,
>>>>> >>>>> >>>> Dominique
>>>>> >>>>> >>>>
>>>>> >>>>> >>>> --
>>>>> >>>>> >>>> You received this message because you are subscribed to th=
e
>>>>> Google
>>>>> >>>>> >>>> Groups "singularity" group.
>>>>> >>>>> >>>> To unsubscribe from this group and stop receiving emails
>>>>> from it,
>>>>> >>>>> >>>> send
>>>>> >>>>> >>>> an email to singu...@lbl.gov.
>>>>> >>>>> >>>
>>>>> >>>>> >>> --
>>>>> >>>>> >>> You received this message because you are subscribed to the
>>>>> Google
>>>>> >>>>> >>> Groups
>>>>> >>>>> >>> "singularity" group.
>>>>> >>>>> >>> To unsubscribe from this group and stop receiving emails
>>>>> from it,
>>>>> >>>>> >>> send an
>>>>> >>>>> >>> email to singu...@lbl.gov.
>>>>> >>>>> >>>
>>>>> >>>>> >>> --
>>>>> >>>>> >>> Vanessa Villamia Sochat
>>>>> >>>>> >>> Stanford University '16
>>>>> >>>>> >>> (603) 321-0676
>>>>> >>>>> >>
>>>>> >>>>> >> --
>>>>> >>>>> >> You received this message because you are subscribed to the
>>>>> Google
>>>>> >>>>> >> Groups
>>>>> >>>>> >> "singularity" group.
>>>>> >>>>> >> To unsubscribe from this group and stop receiving emails fro=
m
>>>>> it,
>>>>> >>>>> >> send an
>>>>> >>>>> >> email to singu...@lbl.gov.
>>>>> >>>>> >
>>>>> >>>>> > --
>>>>> >>>>> > You received this message because you are subscribed to the
>>>>> Google
>>>>> >>>>> > Groups
>>>>> >>>>> > "singularity" group.
>>>>> >>>>> > To unsubscribe from this group and stop receiving emails from
>>>>> it,
>>>>> >>>>> > send an
>>>>> >>>>> > email to singu...@lbl.gov.
>>>>> >>>>>
>>>>> >>>>> --
>>>>> >>>>> You received this message because you are subscribed to the
>>>>> Google
>>>>> >>>>> Groups "singularity" group.
>>>>> >>>>> To unsubscribe from this group and stop receiving emails from
>>>>> it, send
>>>>> >>>>> an email to singu...@lbl.gov.
>>>>> >>>>
>>>>> >>>>
>>>>> >>>>
>>>>> >>>> --
>>>>> >>>> Vanessa Villamia Sochat
>>>>> >>>> Stanford University '16
>>>>> >>>> (603) 321-0676
>>>>> >>>>
>>>>> >>>> --
>>>>> >>>> You received this message because you are subscribed to the Goog=
le
>>>>> >>>> Groups "singularity" group.
>>>>> >>>> To unsubscribe from this group and stop receiving emails from it=
,
>>>>> send
>>>>> >>>> an email to singu...@lbl.gov.
>>>>> >>>
>>>>> >>>
>>>>> >>
>>>>> >> --
>>>>> >> You received this message because you are subscribed to the Google
>>>>> Groups
>>>>> >> "singularity" group.
>>>>> >> To unsubscribe from this group and stop receiving emails from it,
>>>>> send an
>>>>> >> email to singu...@lbl.gov.
>>>>> >>
>>>>> >> --
>>>>> >> Vanessa Villamia Sochat
>>>>> >> Stanford University '16
>>>>> >> (603) 321-0676
>>>>> >
>>>>> > --
>>>>> > You received this message because you are subscribed to the Google
>>>>> Groups
>>>>> > "singularity" group.
>>>>> > To unsubscribe from this group and stop receiving emails from it,
>>>>> send an
>>>>> > email to singu...@lbl.gov.
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, sen=
d
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>> --
>>>>> Vanessa Villamia Sochat
>>>>> Stanford University '16
>>>>> (603) 321-0676
>>>>>
>>>>> --
>>>>> Vanessa Villamia Sochat
>>>>> Stanford University '16
>>>>> (603) 321-0676
>>>>>
>>>> --
>> You received this message because you are subscribed to the Google Group=
s
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n
>> email to singu...@lbl.gov.
>>
>
>
>
> --
> Brandon E. Barker
> http://www.cac.cornell.edu/barker/
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--000000000000a0bcdd05701d0aa4
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hey Dominique,=C2=A0<div><br></div><div>You may want to ch=
eckout these projects:<br></div><div><br></div><div><a href=3D"https://gith=
ub.com/quiltdata">https://github.com/quiltdata</a> version and deploy manag=
ement for data. The concept i like is that they tokenize the data in a merk=
le tree.=C2=A0</div><div><br></div><div>There is also the nexus project (qu=
ite old and driven by a astro science community, not sure how actively its =
developed currently).=C2=A0</div><div><a href=3D"http://download.nexusforma=
t.org/doc/html/examples/index.html">http://download.nexusformat.org/doc/htm=
l/examples/index.html</a><br></div><div><div><div dir=3D"ltr" class=3D"gmai=
l_signature"><div dir=3D"ltr"><br><div><br></div><div>Viele Gr=C3=BC=C3=9Fe=
=C2=A0</div><div>Georg</div></div></div></div><br></div></div><br><div clas=
s=3D"gmail_quote"><div dir=3D"ltr">Am Di., 3. Juli 2018 um 17:24=C2=A0Uhr s=
chrieb Brandon Barker &lt;<a href=3D"mailto:brando...@cornell.edu">brando..=
.@cornell.edu</a>&gt;:<br></div><blockquote class=3D"gmail_quote" style=3D"=
margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"=
ltr"><div>Sorry for the short reply earlier. Here is the service I was refe=
rring to: <a href=3D"https://codeocean.com/" target=3D"_blank">https://code=
ocean.com/</a></div><div>Of course, there can be costs: <a href=3D"https://=
codeocean.com/plans" target=3D"_blank">https://codeocean.com/plans</a><br><=
/div><br></div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On=
 Thu, Jun 28, 2018 at 6:47 AM, v <span dir=3D"ltr">&lt;<a href=3D"mailto:vs=
o...@gmail.com" target=3D"_blank">vso...@gmail.com</a>&gt;</span> wrote:<br=
><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1=
px #ccc solid;padding-left:1ex"><div dir=3D"auto">Oh, and Chris (@chrisfilo=
 on GitHub) wrote a nice article about data sharing:<div dir=3D"auto"><br><=
/div><div dir=3D"auto"><a href=3D"https://medium.com/@ChrisFiloG/liberating=
-data-an-interview-with-john-ioannidis-a71262047f17" target=3D"_blank">http=
s://medium.com/@ChrisFiloG/liberating-data-an-interview-with-john-ioannidis=
-a71262047f17</a><br></div><div dir=3D"auto"><br></div><div dir=3D"auto">Go=
od insights :)</div></div><div class=3D"m_-2128201603505309756HOEnZb"><div =
class=3D"m_-2128201603505309756h5"><br><div class=3D"gmail_quote"><div dir=
=3D"ltr">On Thu, Jun 28, 2018, 3:38 AM v &lt;<a href=3D"mailto:vso...@gmail=
.com" target=3D"_blank">vso...@gmail.com</a>&gt; wrote:<br></div><blockquot=
e class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc sol=
id;padding-left:1ex"><div dir=3D"ltr">There&#39;s also the interplanetary f=
ilesystem (peer to peer) idea...<div><br></div><div><a href=3D"https://ipfs=
.io/" rel=3D"noreferrer" target=3D"_blank">https://ipfs.io/</a><br></div><d=
iv><br></div><div>But not sure that is taking feet yet?</div></div><br><div=
 class=3D"gmail_quote"><div dir=3D"ltr">On Thu, Jun 28, 2018 at 3:37 AM v &=
lt;<a href=3D"mailto:vso...@gmail.com" rel=3D"noreferrer" target=3D"_blank"=
>vso...@gmail.com</a>&gt; wrote:<br></div><blockquote class=3D"gmail_quote"=
 style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><d=
iv dir=3D"ltr">Figure out some model where you get some yuuuge company to h=
ost it via cloud storage, then mount the data easily as an instance. Grab t=
he analysis container (and be sudo if you like, it&#39;s your cloud node to=
 be irresponsible with) and run-all-the-things.<div><br></div><div>And get =
your credit card bill after forgetting about the GPU node(s) over the weeke=
nd, cry softly, have a snack, feel better :)</div><div><br></div><div>In al=
l seriousness, this is a non-trivial problem. Someone has to pay for storag=
e! It&#39;s not even a one time thing, it&#39;s a long term commitment to m=
anagement of the data and access / tooling around it..=C2=A0</div></div><br=
><div class=3D"gmail_quote"><div dir=3D"ltr">On Thu, Jun 28, 2018 at 3:31 A=
M Maxime Hebrard &lt;<a href=3D"mailto:maxime...@gmail.com" rel=3D"noreferr=
er" target=3D"_blank">maxime...@gmail.com</a>&gt; wrote:<br></div><blockquo=
te class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc so=
lid;padding-left:1ex">but that is the point ...<br>
to say &quot;yes, I ran the pipeline with your data, and can verify what<br=
>
you claimed in the paper, I have replicated the result.&quot;<br>
we need a way to get the hand on the original dataset<br>
<br>
well my personal problem is not really on &quot;dataset&quot; per se but mo=
re<br>
with references data<br>
like reference genome / indexes / annotation files<br>
that are Huge and hard to manage :-/<br>
<br>
I could point to public repo for that, but still it is a pain for the<br>
user to download (or let the container download for him) this huge<br>
files :-/<br>
<br>
looking for a &quot;better solution&quot; ...<br>
<br>
<br>
<br>
On Thu, Jun 28, 2018 at 6:08 PM, v &lt;<a href=3D"mailto:vso...@gmail.com" =
rel=3D"noreferrer" target=3D"_blank">vso...@gmail.com</a>&gt; wrote:<br>
&gt; All the cool kids are signing things these days!<br>
&gt; <a href=3D"https://docs.docker.com/engine/security/trust/content_trust=
/#image-tags-and-content-trust" rel=3D"noreferrer noreferrer" target=3D"_bl=
ank">https://docs.docker.com/engine/security/trust/content_trust/#image-tag=
s-and-content-trust</a><br>
&gt; :P<br>
&gt;<br>
&gt; Dataset signing, especially for these fantastic &quot;actually large&q=
uot; datasets,<br>
&gt; seems to be taken with the same importance for reproducibility as the =
tools<br>
&gt; that go into the anayses. To play devil&#39;s advocate, given that we =
want to<br>
&gt; prove some phenomena, wouldn&#39;t we want to be able to show the same=
 (or<br>
&gt; comparable within some range of confidence) result across different<br=
>
&gt; datasets? It doesn&#39;t strengthen the hypothsis to do the same thing=
 again on<br>
&gt; the exact same data, it strengthens the confidence in the reproducibil=
ity of<br>
&gt; the pipeline (two separate things). So perhaps a small bit of data cou=
ld be<br>
&gt; stored with the container to validate the pipeline, but then new sampl=
es<br>
&gt; encouraged to show if the hypothsis holds?<br>
&gt;<br>
&gt; And I&#39;m probably off here, but I think the sharing of datasets is =
less about<br>
&gt; &quot;run it again on exactly the same data&quot; but more about &quot=
;share the data so we<br>
&gt; can all learn from it and increase overall N for better power.&quot; A=
 culture of<br>
&gt; data sharing, along with validation of method + published result, also=
<br>
&gt; allows for checks and balances (&quot;yes, I ran the pipeline with you=
r data, and<br>
&gt; can verify what you claimed in the paper, I have replicated the result=
.&quot;<br>
&gt;<br>
&gt; On Thu, Jun 28, 2018 at 12:20 AM &#39;John Hearns&#39; via singularity=
<br>
&gt; &lt;<a href=3D"mailto:singu...@lbl.gov" rel=3D"noreferrer" target=3D"_=
blank">singu...@lbl.gov</a>&gt; wrote:<br>
&gt;&gt;<br>
&gt;&gt; Chris Hines mentions signing of tool packages.=C2=A0 In danger of =
crossing the<br>
&gt;&gt; streams, I am an enthusiast for the Julia language.<br>
&gt;&gt; the new Pkg3 infrastructure for Julia, which is the default packag=
e<br>
&gt;&gt; manager now, implements UUIDs for packages<br>
&gt;&gt; <a href=3D"https://github.com/JuliaLang/Juleps/blob/master/Pkg3.md=
#registries" rel=3D"noreferrer noreferrer" target=3D"_blank">https://github=
.com/JuliaLang/Juleps/blob/master/Pkg3.md#registries</a><br>
&gt;&gt;<br>
&gt;&gt; On 28 June 2018 at 09:15, John Hearns &lt;<a href=3D"mailto:hea...=
@googlemail.com" rel=3D"noreferrer" target=3D"_blank">hea...@googlemail.com=
</a>&gt; wrote:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I think this a very, very interesting topic.=C2=A0 Please allo=
w me to explore<br>
&gt;&gt;&gt; and hopefully bring out some responses?<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Are we talking about large public datasets here - for instance=
 I worked<br>
&gt;&gt;&gt; on a CERN experiment (ahem) many years ago.<br>
&gt;&gt;&gt; One hopes that huge, public datasets do not change. For instan=
ce if I<br>
&gt;&gt;&gt; went back to analyze what was tagged at the time with a run nu=
mber and an<br>
&gt;&gt;&gt; event number I hope I would get the same data.<br>
&gt;&gt;&gt; OK, it is clear that some large institutiosn worldwide will st=
ore that<br>
&gt;&gt;&gt; data. And that bitrot or the scarcity of the tape drives to re=
ad the data<br>
&gt;&gt;&gt; has not rendered it beyond recovery.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I also worked with the JASMIN project in the UK, where several=
 institutes<br>
&gt;&gt;&gt; have banded together to create a central data store for climat=
e modelling.<br>
&gt;&gt;&gt; Again large public datasets.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I also worked in Formula 1 with CFD engineers, and managed ove=
r a<br>
&gt;&gt;&gt; petabyte of data from CFD studies. Those studies were catalogu=
ed by year and<br>
&gt;&gt;&gt; then case number.<br>
&gt;&gt;&gt; Again, we assume that the data is held on tape somewhere and i=
f you ind<br>
&gt;&gt;&gt; the correctly named directory you will get the same data back.=
<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I guess here we are talking about reproducibility. So we have =
a<br>
&gt;&gt;&gt; Singularity container, which is signed, and captures the packa=
ges and<br>
&gt;&gt;&gt; libraries needed to run that analysis.<br>
&gt;&gt;&gt; We also have to have the same data available to run on.=C2=A0 =
Do we need to<br>
&gt;&gt;&gt; physically keep that data &#39;beside&#39; the container? Mayb=
e, for certain data<br>
&gt;&gt;&gt; and certain values of &#39;not too large&#39;.<br>
&gt;&gt;&gt; but how about analyses of (say) CERN or JASMIN data? Is it eno=
ugh to make<br>
&gt;&gt;&gt; a pointer towards those datasets somehow?<br>
&gt;&gt;&gt; I would say URL&#39;s or URIs here, but we have seen how the W=
eb is dynamic<br>
&gt;&gt;&gt; and sites disappear and links change.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Its worth saying that in the UK there is a lot of effort in th=
is space.<br>
&gt;&gt;&gt; The Research Councils there mandated that if they fund researc=
h the data<br>
&gt;&gt;&gt; must be retained for N years (I forget N)<br>
&gt;&gt;&gt; So many Universities now have specific services for research d=
ata, for<br>
&gt;&gt;&gt; instance:<br>
&gt;&gt;&gt; <a href=3D"http://www.ucl.ac.uk/research-it-services/research-=
data-service" rel=3D"noreferrer noreferrer" target=3D"_blank">http://www.uc=
l.ac.uk/research-it-services/research-data-service</a><br>
&gt;&gt;&gt; <a href=3D"https://www.ukdataservice.ac.uk/" rel=3D"noreferrer=
 noreferrer" target=3D"_blank">https://www.ukdataservice.ac.uk/</a><br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Arkivum <a href=3D"https://arkivum.com/" rel=3D"noreferrer nor=
eferrer" target=3D"_blank">https://arkivum.com/</a> works closely with the =
UK academic network<br>
&gt;&gt;&gt; to provide large data storage. I just found this blog on their=
 website -<br>
&gt;&gt;&gt; well worth reading.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; <a href=3D"https://arkivum.com/articles/blog-series-part-1-fou=
r-economic-factors-make-cost-nothing-expensive-something/" rel=3D"noreferre=
r noreferrer" target=3D"_blank">https://arkivum.com/articles/blog-series-pa=
rt-1-four-economic-factors-make-cost-nothing-expensive-something/</a><br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; <a href=3D"https://arkivum.com/pharma/blog-series-part-4-final=
-economic-fallacy-long-term-data-temporarily-dynamic-path-dependent/" rel=
=3D"noreferrer noreferrer" target=3D"_blank">https://arkivum.com/pharma/blo=
g-series-part-4-final-economic-fallacy-long-term-data-temporarily-dynamic-p=
ath-dependent/</a><br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; To end up, I guess what we are aiming towards is an S3 compati=
ble storage<br>
&gt;&gt;&gt; bucket, whether this is hosted in-house, by Amazon or by a com=
patible<br>
&gt;&gt;&gt; provider.<br>
&gt;&gt;&gt; Such a bucket would have to be locked, and signed.=C2=A0 Ideas=
??<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; On 28 June 2018 at 03:44, v &lt;<a href=3D"mailto:vso...@gmail=
.com" rel=3D"noreferrer" target=3D"_blank">vso...@gmail.com</a>&gt; wrote:<=
br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Your description of the different components is on point.<=
br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Finding hosting for large data is, and will continue to be=
, always one<br>
&gt;&gt;&gt;&gt; of the biggest problems. It&#39;s expensive. Someone has t=
o pay for it. Nobody<br>
&gt;&gt;&gt;&gt; will do it for you for free. We are lucky to have things l=
ike Github repos,<br>
&gt;&gt;&gt;&gt; Google Drive, Dropbox, that gives some (mediocre) access t=
o small data. For<br>
&gt;&gt;&gt;&gt; large data, everyone is pretty much on their own. Most aca=
demics have a<br>
&gt;&gt;&gt;&gt; university that provides some sort of web space / library =
data archive, and<br>
&gt;&gt;&gt;&gt; if you are publishing, some journals will support it too -=
-&gt;<br>
&gt;&gt;&gt;&gt; <a href=3D"https://www.nature.com/sdata/policies/repositor=
ies" rel=3D"noreferrer noreferrer" target=3D"_blank">https://www.nature.com=
/sdata/policies/repositories</a>. I try to figure out<br>
&gt;&gt;&gt;&gt; hacks to get everything hosted, for free, in version contr=
ol, but that<br>
&gt;&gt;&gt;&gt; breaks when anything gets large.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; The entity that manages a data respository, if this is a t=
hing, must<br>
&gt;&gt;&gt;&gt; have incentive to do it. The datasets have to bring in mon=
ey in some way, or<br>
&gt;&gt;&gt;&gt; someone has to value it enough to pay for it. That&#39;s s=
ort of what most<br>
&gt;&gt;&gt;&gt; things come down to, unfortunately.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; On Wed, Jun 27, 2018 at 6:38 PM Maxime Hebrard<br>
&gt;&gt;&gt;&gt; &lt;<a href=3D"mailto:maxime...@gmail.com" rel=3D"noreferr=
er" target=3D"_blank">maxime...@gmail.com</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; I start to use singularity / containers and obviously =
I ran into the<br>
&gt;&gt;&gt;&gt;&gt; same question ...<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; a half solution that I found by exploring existing sol=
ution (thanks to<br>
&gt;&gt;&gt;&gt;&gt; nf-core and SciLifeLab to share their workflow / conta=
iners) is ( as<br>
&gt;&gt;&gt;&gt;&gt; far I understand ):<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; the container encapsulate only the sorftware.<br>
&gt;&gt;&gt;&gt;&gt; the data are store in external repositories.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; the user receive the container.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; case 1:<br>
&gt;&gt;&gt;&gt;&gt; the user download the data by himself and point his fi=
les to the<br>
&gt;&gt;&gt;&gt;&gt; container<br>
&gt;&gt;&gt;&gt;&gt; the container use local files as resources<br>
&gt;&gt;&gt;&gt;&gt; pros:<br>
&gt;&gt;&gt;&gt;&gt;=C2=A0 * the container is slim<br>
&gt;&gt;&gt;&gt;&gt;=C2=A0 * user can store the data on machine A (data ser=
ver) and run the<br>
&gt;&gt;&gt;&gt;&gt; software on machine B (analyse server)<br>
&gt;&gt;&gt;&gt;&gt; cons:<br>
&gt;&gt;&gt;&gt;&gt; * user is involved in downloading the right data<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; case 2:<br>
&gt;&gt;&gt;&gt;&gt; the user do not have the data<br>
&gt;&gt;&gt;&gt;&gt; the container download the data from the external repo=
sitory<br>
&gt;&gt;&gt;&gt;&gt; the container use the data it just download<br>
&gt;&gt;&gt;&gt;&gt; pro:<br>
&gt;&gt;&gt;&gt;&gt; * the container manage everything<br>
&gt;&gt;&gt;&gt;&gt; cons:<br>
&gt;&gt;&gt;&gt;&gt; * the step of downloading the data require bandwith + =
disk space =3D<br>
&gt;&gt;&gt;&gt;&gt; time and resources<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; a general worry for both scenarii is:<br>
&gt;&gt;&gt;&gt;&gt; who manage the data repository ? can we ensure the ver=
sion of the data<br>
&gt;&gt;&gt;&gt;&gt; package will be maintain ?<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; Waiting for your feedback ;)<br>
&gt;&gt;&gt;&gt;&gt; Maxime<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; On Thu, Jun 28, 2018 at 8:15 AM, &#39;Chris Hines&#39;=
 via singularity<br>
&gt;&gt;&gt;&gt;&gt; &lt;<a href=3D"mailto:singu...@lbl.gov" rel=3D"norefer=
rer" target=3D"_blank">singu...@lbl.gov</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt; &gt; To quote 90&#39;s band &quot;The Offspring&quot; =
IMHO &quot;You gotta keep &#39;em<br>
&gt;&gt;&gt;&gt;&gt; &gt; separated&quot;<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; Personally I think this is a larger question: How=
 do we (as research<br>
&gt;&gt;&gt;&gt;&gt; &gt; software engineers, or whatever you would like to=
 call us today)<br>
&gt;&gt;&gt;&gt;&gt; &gt; catalog and<br>
&gt;&gt;&gt;&gt;&gt; &gt; attach references (DOI&#39;s I guess) to larger d=
ata sets. Does it make<br>
&gt;&gt;&gt;&gt;&gt; &gt; sense to<br>
&gt;&gt;&gt;&gt;&gt; &gt; mksquashfs or tar.bz2? What if they are already i=
n a single hdf5<br>
&gt;&gt;&gt;&gt;&gt; &gt; file? And<br>
&gt;&gt;&gt;&gt;&gt; &gt; what about the output data set? we obviously want=
 that to land<br>
&gt;&gt;&gt;&gt;&gt; &gt; outside the<br>
&gt;&gt;&gt;&gt;&gt; &gt; computational container, but how should we packag=
e the output so it<br>
&gt;&gt;&gt;&gt;&gt; &gt; can be<br>
&gt;&gt;&gt;&gt;&gt; &gt; referenced directly? How do we make that whole th=
ing discoverable and<br>
&gt;&gt;&gt;&gt;&gt; &gt; encourage researchers to attach sufficient metada=
ta to make it<br>
&gt;&gt;&gt;&gt;&gt; &gt; searchable?<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; I&#39;m wondering if part of the solution is some=
 sort of &quot;meta<br>
&gt;&gt;&gt;&gt;&gt; &gt; container&quot; that<br>
&gt;&gt;&gt;&gt;&gt; &gt; downloads a set of versioned data with specific c=
hecksums, and a<br>
&gt;&gt;&gt;&gt;&gt; &gt; versioned<br>
&gt;&gt;&gt;&gt;&gt; &gt; tool container with a specific checksum, and atta=
ches them in a<br>
&gt;&gt;&gt;&gt;&gt; &gt; reproducible<br>
&gt;&gt;&gt;&gt;&gt; &gt; way.<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; To address Dominque&#39;s question directly: I&#3=
9;d keep the<br>
&gt;&gt;&gt;&gt;&gt; &gt; &quot;semi-separated&quot;.<br>
&gt;&gt;&gt;&gt;&gt; &gt; Whatever your researchers use for archiving/catal=
oging/managing their<br>
&gt;&gt;&gt;&gt;&gt; &gt; data<br>
&gt;&gt;&gt;&gt;&gt; &gt; sets, keep that in place and add the singularity =
container to the<br>
&gt;&gt;&gt;&gt;&gt; &gt; data set<br>
&gt;&gt;&gt;&gt;&gt; &gt; (rather than adding the data set to the singulari=
ty container).<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; Regards,<br>
&gt;&gt;&gt;&gt;&gt; &gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt; Chris.<br>
&gt;&gt;&gt;&gt;&gt; &gt; Monash eResearch Centre, Monash University, Austr=
alia<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; On Thu, 28 Jun 2018 at 01:19, v &lt;<a href=3D"ma=
ilto:vso...@gmail.com" rel=3D"noreferrer" target=3D"_blank">vso...@gmail.co=
m</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; If you are making containers with singularity=
 (and using Squashfs<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; anyway)<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; it wouldn&#39;t be so nutty to just compress =
with mksquashfs and then<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; mount<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; where needed - I did this with a huge dataset=
 and it worked pretty<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; nicely<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; :_) It relies on FUSE then and all the issues=
 around that, but it&#39;s<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; an<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; option!<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; This is good showing of how use use mksquashf=
s (it&#39;s really<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; simple,actually!) --&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; <a href=3D"http://tldp.org/HOWTO/SquashFS-HOW=
TO/creatingandusing.html" rel=3D"noreferrer noreferrer" target=3D"_blank">h=
ttp://tldp.org/HOWTO/SquashFS-HOWTO/creatingandusing.html</a><br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; And then mount --&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; <a href=3D"https://vsoch.github.io/datasets/2=
018/zenodo/#mount-with-sudo" rel=3D"noreferrer noreferrer" target=3D"_blank=
">https://vsoch.github.io/datasets/2018/zenodo/#mount-with-sudo</a><br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; On Wed, Jun 27, 2018 at 8:14 AM Brandon Barke=
r<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; &lt;<a href=3D"mailto:brando...@cornell.edu" =
rel=3D"noreferrer" target=3D"_blank">brando...@cornell.edu</a>&gt; wrote:<b=
r>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; I seem to recall code ocean may have expl=
ored this idea. Sorry I<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; can&#39;t<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; say more, at the moment.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; On Wed, Jun 27, 2018, 8:50 AM Dominique H=
ansen<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; &lt;<a href=3D"mailto:dominiqu...@gmail.c=
om" rel=3D"noreferrer" target=3D"_blank">dominiqu...@gmail.com</a>&gt; wrot=
e:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Hello everyone,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; I am seeking for tips and experience =
on how to handle research<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; data,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; especially bigger sets of data (insid=
e the GB range), in<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; combination with<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; containers.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; I am a student assistant working in t=
he IT department of a<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; research<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; institute. And I am involved in build=
ing the infrastructure for<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; singularity<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; containerization and introducing rese=
archers to the technology. We<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; have<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; already build a few base images conta=
ining frequently used tools.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Recently a<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; research group approached us, wishing=
 to integrate data, they<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; created for<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; one tool, into a container with the t=
ool. The data takes up<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; several GB of<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; disk space and we are unsure how to h=
andle this and similar future<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; use<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; cases.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Does anyone have a set of best practi=
ces or is there an intended<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; way to<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; use singularity with big research dat=
a?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; The options we considered are:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Moving the data into the container at=
 build time.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Keeps the whole thing mobile<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Keeps work away from the researchers<=
br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Can be referenced as a single entity =
in a publication.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Where would you store such big contai=
ners, especially several of<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; them?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; What would happen, if separate versio=
ns of the tool are needed?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Keep the<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; old and accumulate redundant data? De=
lete the old and risk<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; reproducibility<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; problems? (Maybe container Apps can b=
e used to minimize this.)<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Let the researchers mount the data in=
to the container at startup.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Keeps the containers slimmer, the too=
ls more modular.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Adds to the workload and the things t=
he researchers have to keep<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; track<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; of.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Spreads the parts needed for reproduc=
tion over at least two<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; points.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Hampers mobility.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Mounting during early phases and publ=
ish with a container,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; containing<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; the data.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Reduces amount of containers with red=
undant and deprecated=C2=A0 data.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Makes reproduction of results easier =
after publication.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Ads to the workload.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; When is the point when its time to &q=
uot;freeze&quot; the data inside the<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; container?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Storage of the container is still pro=
blematic.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Might introduce reproducibility probl=
ems, since you change the<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; original<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; container to put the data into it.<br=
>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Are there any recommendations from ex=
perience?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Thank you and best regards,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Dominique<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; You received this message because you=
 are subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.=
<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; To unsubscribe from this group and st=
op receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; send<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; an email to <a href=3D"mailto:singula=
rity%...@lbl.gov" rel=3D"noreferrer" target=3D"_blank">singu...@lbl.gov</a>=
.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; You received this message because you are=
 subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; Groups<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; To unsubscribe from this group and stop r=
eceiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; send an<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; email to <a href=3D"mailto:singularity%..=
.@lbl.gov" rel=3D"noreferrer" target=3D"_blank">singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; Vanessa Villamia Sochat<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; Stanford University &#39;16<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; (603) 321-0676<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; You received this message because you are sub=
scribed to the Google<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; Groups<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; To unsubscribe from this group and stop recei=
ving emails from it,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; send an<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; email to <a href=3D"mailto:singularity%...@lb=
l.gov" rel=3D"noreferrer" target=3D"_blank">singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt; You received this message because you are subscri=
bed to the Google<br>
&gt;&gt;&gt;&gt;&gt; &gt; Groups<br>
&gt;&gt;&gt;&gt;&gt; &gt; &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; &gt; To unsubscribe from this group and stop receiving=
 emails from it,<br>
&gt;&gt;&gt;&gt;&gt; &gt; send an<br>
&gt;&gt;&gt;&gt;&gt; &gt; email to <a href=3D"mailto:singularity%...@lbl.go=
v" rel=3D"noreferrer" target=3D"_blank">singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; You received this message because you are subscribed t=
o the Google<br>
&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emai=
ls from it, send<br>
&gt;&gt;&gt;&gt;&gt; an email to <a href=3D"mailto:singularity%...@lbl.gov"=
 rel=3D"noreferrer" target=3D"_blank">singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt; Vanessa Villamia Sochat<br>
&gt;&gt;&gt;&gt; Stanford University &#39;16<br>
&gt;&gt;&gt;&gt; (603) 321-0676<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt; You received this message because you are subscribed to th=
e Google<br>
&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emails f=
rom it, send<br>
&gt;&gt;&gt;&gt; an email to <a href=3D"mailto:singularity%...@lbl.gov" rel=
=3D"noreferrer" target=3D"_blank">singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; You received this message because you are subscribed to the Google=
 Groups<br>
&gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt; To unsubscribe from this group and stop receiving emails from it, =
send an<br>
&gt;&gt; email to <a href=3D"mailto:singularity%...@lbl.gov" rel=3D"norefer=
rer" target=3D"_blank">singu...@lbl.gov</a>.<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; Vanessa Villamia Sochat<br>
&gt;&gt; Stanford University &#39;16<br>
&gt;&gt; (603) 321-0676<br>
&gt;<br>
&gt; --<br>
&gt; You received this message because you are subscribed to the Google Gro=
ups<br>
&gt; &quot;singularity&quot; group.<br>
&gt; To unsubscribe from this group and stop receiving emails from it, send=
 an<br>
&gt; email to <a href=3D"mailto:singularity%...@lbl.gov" rel=3D"noreferrer"=
 target=3D"_blank">singu...@lbl.gov</a>.<br>
<br>
-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singularity%...@lbl.gov" rel=3D"noreferrer" targe=
t=3D"_blank">singu...@lbl.gov</a>.<br clear=3D"all"><div><br></div>-- <br><=
div dir=3D"ltr" class=3D"m_-2128201603505309756m_4101311823605881321m_92223=
56217056320682m_1012473880129367663gmail_signature" data-smartmail=3D"gmail=
_signature"><div class=3D"m_-2128201603505309756m_4101311823605881321m_9222=
356217056320682m_1012473880129367663gmail_signature" data-smartmail=3D"gmai=
l_signature">Vanessa Villamia Sochat<br>Stanford University &#39;16<br><div=
><div><div>(603) 321-0676<br clear=3D"all"><div><br></div>-- <br><div dir=
=3D"ltr" class=3D"m_-2128201603505309756m_4101311823605881321m_922235621705=
6320682gmail_signature" data-smartmail=3D"gmail_signature"><div class=3D"m_=
-2128201603505309756m_4101311823605881321m_9222356217056320682gmail_signatu=
re" data-smartmail=3D"gmail_signature">Vanessa Villamia Sochat<br>Stanford =
University &#39;16<br><div><div><div>(603) 321-0676</div></div></div></div>=
</div></div></div></div></div></div></blockquote></div></blockquote></div>
</blockquote></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><br>-- <br><div class=
=3D"m_-2128201603505309756gmail_signature" data-smartmail=3D"gmail_signatur=
e"><div dir=3D"ltr">Brandon E. Barker<br><a href=3D"http://www.cac.cornell.=
edu/barker/" target=3D"_blank">http://www.cac.cornell.edu/barker/</a><br></=
div></div>
</div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</blockquote></div>

--000000000000a0bcdd05701d0aa4--

X-Received: by 2002:a62:4747:: with SMTP id u68mr2979730pfa.45.1551477689980;
        Fri, 01 Mar 2019 14:01:29 -0800 (PST)
X-BeenThere: singularity@lbl.gov
Received: by 2002:a63:6b06:: with SMTP id g6ls3854664pgc.7.gmail; Fri, 01 Mar
 2019 14:01:28 -0800 (PST)
X-Received: by 2002:a65:4b83:: with SMTP id t3mr6968690pgq.417.1551477688694;
        Fri, 01 Mar 2019 14:01:28 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1551477688; cv=none;
        d=google.com; s=arc-20160816;
        b=LwMCNDsSOry7YzqwMq7cGnOUJ+tgX7pIjqmz+gULUmkWM5RQsT8nqpiktUf6MaZSRC
         hrKQRfsh+DrQJIgzvYePMs9dC1kG7K5IYhyMzb1/pUVv10oOQd3PrsAr+SN3rJD8NsId
         0JgB6mSfs518nPFZw6c7G66QAfj67ZLt0FcBj4mpmcQps1VgSZzjAPjdDkJX6aJGzymk
         AOXbjrexYRPxcTtX8JTb/odzviZT7ure9IXKUuqqXugQ8mzxnWDW6fBNaSlYiLw8CXBf
         3KqG+BKGvriSd+AU7L4NtcPiQTSDrNjKL0IzGm9lWky+w8nrZySr+RJ2zOL3yugud4Ha
         DZ/A==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:in-reply-to:references:mime-version
         :dkim-signature;
        bh=Te2R7zkM+4LcKywBxA2d2q0egxKhWB0rkosHRxgG9UA=;
        b=pOmV5fp7iC27ge2IIbzBQq3SH4R9hdhYboN4Xb0Bifgf+HRVATq8qHYoI3t+ipqnNF
         b2809WGK0Ponq79mXDESi8QMgyCU+3YGh+VbEPzqy5ss9IeeRhv5JyD2HHTHOLlI5+Hp
         MAmhU1AsRafTWHlkVOY3tNByBGA49MvZu1EW5NFepaVf2vFCoUPr+0YcDmOwc1MWEDzK
         bqtUO+9qvUAmTfjvqbA434ke3t51i7H11Y72rejjyGLw6zUWAdP09Yy2tC0VyU5kWi9f
         TYgLr9VhnydVgVv26CwZxza/kQKidSUUytMZMJR02ifDCMOcXuusOqupzAaylfxMCsxl
         FAsA==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=mP6Czilu;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.166.45 as permitted sender) smtp.mailfrom=vso...@gmail.com
Return-Path: <vso...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [131.243.228.52])
        by mx.google.com with ESMTP id u10si20716286pgh.255.2019.03.01.14.01.28
        for <singu...@lbl.gov>;
        Fri, 01 Mar 2019 14:01:28 -0800 (PST)
Received-SPF: pass (google.com: domain of vso...@gmail.com designates 209.85.166.45 as permitted sender) client-ip=209.85.166.45;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=mP6Czilu;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.166.45 as permitted sender) smtp.mailfrom=vso...@gmail.com
X-Ironport-SBRS: 2.7
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2GqAgCnqnlcfy2mVdFhA4NyUQFAUDMnh?=
 =?us-ascii?q?AiBHYJej2mUO4cxPCsQg3gQNgKEIiI4EgEDAQEDAQMCAQECEAEBCQsLCCclDII?=
 =?us-ascii?q?6DC4ETTsDAQEBAQEBAQEBJAEBAQEBAQEBAQEBAQEBARoCDSBEBiMdARseAwwGB?=
 =?us-ascii?q?Qs3AgIhAQERAQUBHBmDIgEmAYE1AQMVBQqfUjyJXRqBJoESBQEXgnkFhDoKGSc?=
 =?us-ascii?q?NX4E3AgEFEow5F4F/gRGCFFAugldHAgKBOBM1DBqCQ4I1IgKJf4ZggQaRYjMJh?=
 =?us-ascii?q?0OHb4M9GYF0iSmIBJA6gS6LLzCBCjOBeHAVOzGCBwEBATETggMXE4M4gmSIDSQ?=
 =?us-ascii?q?wAY51ASUEgiMBAQ?=
X-IronPort-AV: E=Sophos;i="5.58,429,1544515200"; 
   d="scan'208,217";a="145574747"
Received: from mail-io1-f45.google.com ([209.85.166.45])
  by fe3.lbl.gov with ESMTP; 01 Mar 2019 14:01:22 -0800
Received: by mail-io1-f45.google.com with SMTP id y6so20802963ioq.10
        for <singu...@lbl.gov>; Fri, 01 Mar 2019 14:01:22 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to;
        bh=Te2R7zkM+4LcKywBxA2d2q0egxKhWB0rkosHRxgG9UA=;
        b=mP6CziluYo0VcmOlxmgVoSrynrXwzJ39I37lB9dKRo2x43+oZDkhMfH6MRGQR2wuZI
         jh/YGNtSVUKrivmpGo02XfHuzjple+pUp8I7msZbbMCnoD9Tj33eLhLf/pUs5GXz34fx
         Vhkd5akxvwwXCT3qX02lQDQ3nC5eAk1Zh1M80OZUCXdeW1C/ysrDdPadoS9HvL0Pa1AF
         Deb2C4bubUwkjaHJ13LnGOMXBbhjITyy6tw2goqVfiBDJZIduI9urABmTHTUHPDCUcXs
         i7aCRYpRdUHBUVt3RtsMd767OD/jZ2+TjyWNRcXBpcqS1ZuRkT8hBGwuSHHaPVtT9PaD
         0big==
X-Gm-Message-State: APjAAAVCSEk8V6uftTXhU4QPcOceYA+GI4twMpgU2Dm3tMDr1u4by7/2
	Np3z0rBRKNJBcCP1EAZuYKDcaxaeUGBrJJ0CDsa7pAt8
X-Received: by 2002:a5e:d612:: with SMTP id w18mr3952255iom.71.1551477680520;
 Fri, 01 Mar 2019 14:01:20 -0800 (PST)
MIME-Version: 1.0
References: <a94c4768-8cd7-43aa-8bb9-b21b3ccf950c@lbl.gov> <CAApQTTh9E=oNwfTLFmjmH6rAXDH2Q+X29D0Ur_Y3VMXvGvsDtg@mail.gmail.com>
 <710b4b5e-f209-41da-bfcb-c19043201fa4@lbl.gov> <CAM=pu++geyfoQ+HWGtWVOStYfuH3+b49VLSk6zwQS0pH7V_WCA@mail.gmail.com>
 <54a4fb06-9c3c-46f0-bcf8-7d788fb7d381@lbl.gov> <CAM=pu+K3LpHL-MbQ==RMumDX7_gADoui=MBmRmTmeGc7JxPn_w@mail.gmail.com>
 <a347f411-2d39-472c-bd5f-d1401eb3fa97@lbl.gov> <CAM=pu+KYDYz_-d3FcxERd_0nRjaFbGAstQaM+gvudJObTW-qjw@mail.gmail.com>
In-Reply-To: <CAM=pu+KYDYz_-d3FcxERd_0nRjaFbGAstQaM+gvudJObTW-qjw@mail.gmail.com>
From: v <vso...@gmail.com>
Date: Fri, 1 Mar 2019 17:01:09 -0500
Message-ID: <CAM=pu+JnUZM51H9-KOLNF2=h-+1P8fcoGpgaw3cKeJofnxA4dw@mail.gmail.com>
Subject: Re: [Singularity] Singularity image download syncronization during
 multiple job startup
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="0000000000000643b705830f8cc2"

--0000000000000643b705830f8cc2
Content-Type: text/plain; charset="UTF-8"

So how can we do better? We have to think of the scope of Singularity
itself - it should be optimized to run / otherwise interact with
containers. Adding layers that it knows how to interact with a wide range
of storage APIs is out of scope. What *is* in scope is asking for more
general support to pull from a registry that conforms to OCI (the
distribution specification). In that Singularity does support pulling a
general web address, if you are just trying to download blobs, that should
work. (e.g., try this:

$ singularity run
https://57-167740989-gh.circle-artifacts.com/0/singularity-containers/vanessa/fortune/latest/bffb06f1d12ed52d62d51c60c46d1bfeba4530eb0ee563e2d3734e7a954537ce.sif

That's just a blob. So if you have something in storage that doesn't
conform to the distribution spec, and also doesn't have an https address,
you have to write some custom wrapper to retrieve the object (akin to
sregistry client, this is what I was trying to provide) If it does have an
https address you still need (likely) some special script to map a
container URI to an https address. So could we fix everything with the
distribution-spec? Not yet, really. The missing piece is that OCI doesn't
let you (yet) define custom content types - because a client would need to
know to pull a layer, find that it's SIF, and just download (and not
decompress to build an image). But that seems like "the right way" to go
about it, to me. The static registry I threw together had a (quick) example
of this, try:

curl
> https://singularityhub.github.io/registry-org/singularityhub/busybox/manifests/latest/


So what would be a logical path to get Singularity to support *all the
places?* Something like:

 - distribution spec allows for custom media types
 - Singularity (still) conforms to OCI and learns to read the content type,
and know when a container binary is being pulled (no extraction necessary)
 - Registries that conform to OCI have containers pushed with the correct
content type
 - Singularity pulls them. :)

In this case, an s3:// address, or anything not https, would just be a
known type. The details need to be thought out with respect to a content
type (sif) versus a storage type (s3 object vs https on some filesystem)
but these are details - the important thing is that this would all be part
of the specification, and Singularity could choose to support the types
that it needs. I suspect it would be a list argument in the config :)

But I think, if Singularity is going as strongly OCI as it has been, this
approach would be preferred. This way, you don't need to "hard code" some
custom API endpoint into Singularity. We have some faith in the standard to
be adopted.

The above is related to just pulling your containers. The next issue you
bring up is harder, and that's workflows. Workflows that work seamlessly
between cloud and HPC is an even bigger thing. You can take on some
specific workflow manager that works across HPC and cloud (e.g., Cromwell,
Nextflow, maybe Snakemake) but then you are adding layers of messy config
files and this huge scary thing that the workflow manager might go away and
you are screwed. You've probably noticed that there is no
"singularity-compose" akin to docker-compose, or any easy way to
orchestrate services. I'd be surprised if Sylabs isn't working on something
like this. Kubernetes is great, but it doesn't solve the HPC problem. While
I don't want to state that any of those examples are a good way to go for
across regions and compute, I will say that we would theoretically want a
tool that has mappings across places. And also abstracts the crapton of
configuration files away from the user. I guess only time will tell what
that tool turns out to be.

/crawls back into dinosaur cave




Is this a problem of

On Fri, Mar 1, 2019 at 4:35 PM v <vso...@gmail.com> wrote:

>
>>>
>> Yes, that PR enables singularity to check the local cache for shub
>> downloads. This feature was missing. But even with that fix, if two tasks
>> are released to the same node nearly simultaneously and the required
>> container is not in the cache, the first task starts the download to the
>> cache, but the second task just sees the file name in the cache and tries
>> to run it.  If the download was sufficiently fast, this would be less of an
>> issue. If it is cached, it is not an issue.
>>
>> If the idea here is that you are downloading the (final) file name to the
> cache, I don't think this is the correct way to go about it. Usually the
> file should be downloaded with some temporary extension, and then renamed
> (moved) at the end only when it's whole and complete. It is the case that
> the container might be downloaded by two nodes at the same time - but if
> the check is done for the file existing right before the move operation,
> there shouldn't be any sort of attempt by one process to use a partially
> downloaded from another. At worst, a few started the downloaded, one wins,
> and everyone else just removes theirs with the temporary extension.
>
> The metrics are cool, and as I would expect.
>
>
>> I don't have a problem with the wrapper doing the pull. It is the corner
>> case where one download is currently running while another job starts
>> trying to use the same image on the same node. Some of this may be our own
>> fault because we moved the singularity cache out of ${HOME} and into a
>> shared local directory. We did this because 1) the GPFS home directory on
>> the compute nodes is very limited - Only to be used to create your compute
>> environment and is read-only on the compute/gpu nodes.  2) By using a
>> shared cache, we reduce the amount of local storage used for image caching.
>> I would just have to figure out a synchronization method to hold jobs if
>> the image is being actively downloaded. The wrapper could do that.
>>
>> I'm not sure why caching wasn't implemented in the way I've been
> accustomed to, with renaming after lots of checks. I believe this is called
> downloading atomically? I implemented a simple function
> <https://github.com/sylabs/singularity/blob/vault/release-2.6/libexec/python/base.py#L352>
> for the original Singularity (when it had python) and we would want to add
> to that one more check that the file doesn't exist before renaming it.
>
> I don't think you'd need the lock file if you did something like that, but
> others can correct me. What you don't want to do is stream/download into
> your final container... distaster.
>
> So, I guess my next question would be, Does Singularity itself support
>> pulling from and object store directly using an S3 or Swift client? I know
>> it handles docker/OCI, Singularity Library, Singularity Hub, and local file
>> system paths. That would probably the be better fit overall instead of
>> moving to a share file system. The transition to a public cloud would be
>> easier with the container store being in object storage.
>>
>> This would be very good to see, I agree :) I've been trying to provide
> this support with Singularity Registry Client, but it's just a wrapper.
>
>
> --
> Vanessa Villamia Sochat
> Stanford University '16
> (603) 321-0676
>


-- 
Vanessa Villamia Sochat
Stanford University '16
(603) 321-0676

--0000000000000643b705830f8cc2
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr">So how can we do better?=
 We have to think of the scope of Singularity itself - it should be optimiz=
ed to run / otherwise interact with containers. Adding layers that it knows=
 how to interact with a wide range of storage APIs is out of scope. What <i=
>is</i>=C2=A0in scope is asking for more general support to pull from a reg=
istry that conforms to OCI (the distribution specification). In that Singul=
arity does support pulling a general web address, if you are just trying to=
 download blobs, that should work. (e.g., try this:<div><br></div><div><div=
>$ singularity run <a href=3D"https://57-167740989-gh.circle-artifacts.com/=
0/singularity-containers/vanessa/fortune/latest/bffb06f1d12ed52d62d51c60c46=
d1bfeba4530eb0ee563e2d3734e7a954537ce.sif">https://57-167740989-gh.circle-a=
rtifacts.com/0/singularity-containers/vanessa/fortune/latest/bffb06f1d12ed5=
2d62d51c60c46d1bfeba4530eb0ee563e2d3734e7a954537ce.sif</a></div><div><br></=
div><div>That&#39;s just a blob. So if you have something in storage that d=
oesn&#39;t conform to the distribution spec, and also doesn&#39;t have an h=
ttps address, you have to write some custom wrapper to retrieve the object =
(akin to sregistry client, this is what I was trying to provide) If it does=
 have an https address you still need (likely) some special script to map a=
 container URI to an https address. So could we fix everything with the dis=
tribution-spec? Not yet, really. The missing piece is that OCI doesn&#39;t =
let you (yet) define custom content types - because a client would need to =
know to pull a layer, find that it&#39;s SIF, and just download (and not de=
compress to build an image). But that seems like &quot;the right way&quot; =
to go about it, to me. The static registry I threw together had a (quick) e=
xample of this, try:</div><div><br></div><blockquote class=3D"gmail_quote" =
style=3D"margin:0px 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);pa=
dding-left:1ex">curl <a href=3D"https://singularityhub.github.io/registry-o=
rg/singularityhub/busybox/manifests/latest/">https://singularityhub.github.=
io/registry-org/singularityhub/busybox/manifests/latest/</a></blockquote><d=
iv><br></div><div>So what would be a logical path to get Singularity to sup=
port *all the places?* Something like:</div><div><br></div><div>=C2=A0- dis=
tribution spec allows for custom media types</div><div>=C2=A0- Singularity =
(still) conforms to OCI and learns to read the content type, and know when =
a container binary is being pulled (no extraction necessary)</div><div>=C2=
=A0- Registries that conform to OCI have containers pushed with the correct=
 content type</div><div>=C2=A0- Singularity pulls them. :)</div><div><br></=
div><div>In this case, an s3:// address, or anything not https, would just =
be a known type. The details need to be thought out with respect to a conte=
nt type (sif) versus a storage type (s3 object vs https on some filesystem)=
 but these are details - the important thing is that this would all be part=
 of the specification, and Singularity could choose to support the types th=
at it needs. I suspect it would be a list argument in the config :)</div><d=
iv><br></div><div>But I think, if Singularity is going as strongly OCI as i=
t has been, this approach would be preferred. This way, you don&#39;t need =
to &quot;hard code&quot; some custom API endpoint into Singularity. We have=
 some faith in the standard to be adopted.</div><div><br></div><div>The abo=
ve is related to just pulling your containers. The next issue you bring up =
is harder, and that&#39;s workflows. Workflows that work seamlessly between=
 cloud and HPC is an even bigger thing. You can take on some specific workf=
low manager that works across HPC and cloud (e.g., Cromwell, Nextflow, mayb=
e Snakemake) but then you are adding layers of messy config files and this =
huge scary thing that the workflow manager might go away and you are screwe=
d. You&#39;ve probably noticed that there is no &quot;singularity-compose&q=
uot; akin to docker-compose, or any easy way to orchestrate services. I&#39=
;d be surprised if Sylabs isn&#39;t working on something like this. Kuberne=
tes is great, but it doesn&#39;t solve the HPC problem. While I don&#39;t w=
ant to state that any of those examples are a good way to go for across reg=
ions and compute, I will say that we would theoretically want a tool that h=
as mappings across places. And also abstracts the crapton of configuration =
files away from the user. I guess only time will tell what that tool turns =
out to be.</div><div><br></div><div>/crawls back into dinosaur cave</div><d=
iv><br></div><div><br></div><div><br></div><div><br><div>Is this a problem =
of</div></div></div></div></div></div><br><div class=3D"gmail_quote"><div d=
ir=3D"ltr" class=3D"gmail_attr">On Fri, Mar 1, 2019 at 4:35 PM v &lt;<a hre=
f=3D"mailto:vso...@gmail.com">vso...@gmail.com</a>&gt; wrote:<br></div><blo=
ckquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left=
:1px solid rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"><div class=
=3D"gmail_quote"><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px =
0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"><div dir=
=3D"ltr"><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8e=
x;border-left:1px solid rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"=
><div class=3D"gmail_quote"><div>=C2=A0</div></div></div></blockquote><div>=
Yes, that PR enables singularity to check the local cache for shub download=
s. This feature was missing. But even with that fix, if two tasks are relea=
sed to the same node nearly simultaneously and the required container is no=
t in the cache, the first task starts the download to the cache, but the se=
cond task just sees the file name in the cache and tries to run it.=C2=A0 I=
f the download was sufficiently fast, this would be less of an issue. If it=
 is cached, it is not an issue.<br><br></div></div></blockquote><div>If the=
 idea here is that you are downloading the (final) file name to the cache, =
I don&#39;t think this is the correct way to go about it. Usually the file =
should be downloaded with some temporary extension, and then renamed (moved=
) at the end only when it&#39;s whole and complete. It is the case that the=
 container might be downloaded by two nodes at the same time - but if the c=
heck is done for the file existing right before the move operation, there s=
houldn&#39;t be any sort of attempt by one process to use a partially downl=
oaded from another. At worst, a few started the downloaded, one wins, and e=
veryone else just removes theirs with the temporary extension.</div><div><b=
r></div><div>The metrics are cool, and as I would expect.</div><div>=C2=A0<=
br></div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8e=
x;border-left:1px solid rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"=
><div>I don&#39;t have a problem with the wrapper doing the pull. It is the=
 corner case where one download is currently running while another job star=
ts trying to use the same image on the same node. Some of this may be our o=
wn fault because we moved the singularity cache out of ${HOME} and into a s=
hared local directory. We did this because 1) the GPFS home directory on th=
e compute nodes is very limited - Only to be used to create your compute en=
vironment and is read-only on the compute/gpu nodes.=C2=A0 2) By using a sh=
ared cache, we reduce the amount of local storage used for image caching. I=
 would just have to figure out a synchronization method to hold jobs if the=
 image is being actively downloaded. The wrapper could do that.=C2=A0 <br><=
br></div></div></blockquote><div>I&#39;m not sure why caching wasn&#39;t im=
plemented in the way I&#39;ve been accustomed to, with renaming after lots =
of checks. I believe this is called downloading atomically? I implemented a=
 <a href=3D"https://github.com/sylabs/singularity/blob/vault/release-2.6/li=
bexec/python/base.py#L352" target=3D"_blank">simple function</a> for the or=
iginal Singularity (when it had python) and we would want to add to that on=
e more check that the file doesn&#39;t exist before renaming it.</div><div>=
=C2=A0</div><div>I don&#39;t think you&#39;d need the lock file if you did =
something like that, but others can correct me. What you don&#39;t want to =
do is stream/download into your final container... distaster.</div><div><br=
></div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;=
border-left:1px solid rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"><=
div>So, I guess my next question would be, Does Singularity itself support =
pulling from and object store directly using an S3 or Swift client? I know =
it handles docker/OCI, Singularity Library, Singularity Hub, and local file=
 system paths. That would probably the be better fit overall instead of mov=
ing to a share file system. The transition to a public cloud would be easie=
r with the container store being in object storage.<br><br></div></div></bl=
ockquote><div>This would be very good to see, I agree :) I&#39;ve been tryi=
ng to provide this support with Singularity Registry Client, but it&#39;s j=
ust a wrapper.</div><div><br></div></div><div><br></div>-- <br><div dir=3D"=
ltr" class=3D"gmail-m_-6673075336180344150gmail_signature">Vanessa Villamia=
 Sochat<br>Stanford University &#39;16<br><div><div><div>(603) 321-0676</di=
v></div></div></div></div>
</blockquote></div><br clear=3D"all"><div><br></div>-- <br><div dir=3D"ltr"=
 class=3D"gmail_signature">Vanessa Villamia Sochat<br>Stanford University &=
#39;16<br><div><div><div>(603) 321-0676</div></div></div></div>

--0000000000000643b705830f8cc2--

X-Received: by 10.98.28.201 with SMTP id c192mr39935510pfc.7.1467813636884;
        Wed, 06 Jul 2016 07:00:36 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.149.197 with SMTP id x188ls96061iod.7.gmail; Wed, 06 Jul
 2016 07:00:36 -0700 (PDT)
X-Received: by 10.98.30.199 with SMTP id e190mr42646061pfe.146.1467813636220;
        Wed, 06 Jul 2016 07:00:36 -0700 (PDT)
Return-Path: <gmku...@lbl.gov>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTPS id l3si4331045paz.169.2016.07.06.07.00.36
        for <singu...@lbl.gov>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Wed, 06 Jul 2016 07:00:36 -0700 (PDT)
Received-SPF: pass (google.com: domain of gmku...@lbl.gov designates 209.85.215.72 as permitted sender) client-ip=209.85.215.72;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of gmku...@lbl.gov designates 209.85.215.72 as permitted sender) smtp.mailfrom=gmku...@lbl.gov
X-Ironport-SBRS: 2.2
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2CgAACvDn1XekjXVdFdgnCBJG0PBoM2gQyjXYRzjBCBdx6FegKBIgc4FAEBAQEBAQESAQEJCwwIISQLhEwBAQQBEggJKxkSBQsJAgsNIAoCAiEBDwMBBQELEQYIBwQBGgIEAYd0Aw8IBY8Nj0KBMT4xizuLNA2EMQEBAQEBAQEDAQEBAQEBAQEbBAsFimSCQ4FPEQEGgxeCWgWIEwdfhX8+hCOFBjQBhgiGLoIQgWpOhAiIaogXhjQSHoEPDw+CPhyBbBwyB4c2gTUBAQE
X-IronPort-AV: E=Sophos;i="5.28,319,1464678000"; 
   d="scan'208,217";a="28814891"
Received: from mail-lf0-f72.google.com ([209.85.215.72])
  by fe4.lbl.gov with ESMTP; 06 Jul 2016 07:00:33 -0700
Received: by mail-lf0-f72.google.com with SMTP id g18so158904793lfg.2
        for <singu...@lbl.gov>; Wed, 06 Jul 2016 07:00:33 -0700 (PDT)
X-Gm-Message-State: ALyK8tI6XCFjLXXaZCr/60Qy+L/tWmv959dKHTJvfxBJHZeiubWLOQ14mXK377Rmd5MKlrXR3QoS1AjvIoB2ulMNb7zKMppXi4C1oJRRA+VBw7EWFeC7UHRJ0elEWZPxu1eZlw2GebpfwiUP7eQ/6pPzfCc=
X-Received: by 10.25.19.74 with SMTP id j71mr4771791lfi.44.1467813631672;
        Wed, 06 Jul 2016 07:00:31 -0700 (PDT)
MIME-Version: 1.0
X-Received: by 10.25.19.74 with SMTP id j71mr4771787lfi.44.1467813631271; Wed,
 06 Jul 2016 07:00:31 -0700 (PDT)
Received: by 10.25.214.158 with HTTP; Wed, 6 Jul 2016 07:00:30 -0700 (PDT)
In-Reply-To: <e8eb3fb2-05cc-4f5e-bbab-91da877b6e1c@lbl.gov>
References: <6247ec64-6881-4978-82a0-f7d6e24039e9@lbl.gov>
	<CAN7etTx+2ETq_aarfJfez_p4YzoNJ49zwO2CQe=KRwSSZkuR5Q@mail.gmail.com>
	<3998ac67-7f95-475d-ac75-ceb562e19e3b@lbl.gov>
	<CAN7etTwNG_1G9YuuTQZWSE3SKZjXqNjt8bsZFrVQBJC8_1-mAw@mail.gmail.com>
	<1403bcbe-c615-4417-a629-f95568b75ee7@lbl.gov>
	<CAN7etTwnpqqbiF=PAqZKDY0yDtyqJGVg2N3x2_-RHFvd6+Qh8Q@mail.gmail.com>
	<054d2758-0acd-48f0-a9bd-b0d52ce02f38@lbl.gov>
	<613ECCC0-A9C9-42D0-9C26-36695C612DA4@open-mpi.org>
	<007b47f4-0aea-42dc-b871-d653bb7a67a1@lbl.gov>
	<CAN7etTxOGqMfyg_C2AWisRWCCs2RKkM91s6SbWTcjYb3X5_Aew@mail.gmail.com>
	<15574850-11a7-4317-b784-26631fad4f29@lbl.gov>
	<e8eb3fb2-05cc-4f5e-bbab-91da877b6e1c@lbl.gov>
Date: Wed, 6 Jul 2016 07:00:30 -0700
Message-ID: <CAN7etTy8-xQ5ATWaKxrUCi=AH+QHv8ddjTeG7P2XrikSAh2pug@mail.gmail.com>
Subject: Re: [Singularity] Communication between singularity containers
From: "Gregory M. Kurtzer" <gmku...@lbl.gov>
To: "singu...@lbl.gov" <singu...@lbl.gov>
Cc: "r...@open-mpi.org" <r...@open-mpi.org>
Content-Type: multipart/alternative; boundary=001a11406b3616c0790536f7fee2

--001a11406b3616c0790536f7fee2
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi,

/run/user is associated with the Singularity container?

Can you show me the output of 'losetup -a' please?

Why are you are running it with sudo, you should not need to.

It is weird, isn't -n a synonym for -np and if so, shouldn't it executing 1
process on the given node? It seems like it is doing more.

Lastly, what version of Singularity is this? If from Git master when did
you do the last pull? Can you try this in debug mode and with a
simple binary for testing:

$ mpirun -n 1 singularity -d exec /mnt/glusterfs/singularity/nasmpi-1.img
true

And send that output please.


On Wednesday, July 6, 2016, Raimon Bosch <raimo...@gmail.com> wrote:

>
> When I do "df -h" I see the singularity container still mounted. Maybe I
> need to run a command to unmount it:
>
> > df -h
> Filesystem                 Size  Used Avail Use% Mounted on
> ****
> tmpfs                      3.2G     0  3.2G   0% /run/user/1006
> ****
>
> El mi=C3=A9rcoles, 6 de julio de 2016, 10:25:24 (UTC+2), Raimon Bosch esc=
ribi=C3=B3:
>>
>>
>> Hi Gregory,
>>
>> It fails depending on your environment. In my Ubuntu 14.04 it worked
>> fine, but in this instance of Debian jessie I get the following:
>>
>> > ERROR: Failed to associate image to loop: Device or resource busy
>>
>> Maybe is because we are using a glusterfs shared disk to keep the
>> containers?
>>
>> Here you have the entire output:
>>
>> > sudo mpirun -n 1 singularity exec
>> /mnt/glusterfs/singularity/nasmpi-1.img /trace.sh
>> /NPB/NPB3.3-MPI/bin/bt.C.4 : -n 1 singularity exec
>> /mnt/glusterfs/singularity/nasmpi-2.img /trace.sh
>> /NPB/NPB3.3-MPI/bin/bt.C.4 : -n 1 singularity exec
>> /mnt/glusterfs/singularity/nasmpi-3.img /trace.sh
>> /NPB/NPB3.3-MPI/bin/bt.C.4 : -n 1 singularity exec
>> /mnt/glusterfs/singularity/nasmpi-4.img /trace.sh /NPB/NPB3.3-MPI/bin/bt=
.C.4
>> ERROR: Failed to associate image to loop: Device or resource busy
>> ERROR: Failed to associate image to loop: Device or resource busy
>> /bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8=
)
>> ERROR: Failed to associate image to loop: Device or resource busy
>> ------------------------------------------------------------------------=
--
>> mpirun has exited due to process rank 2 with PID 63416 on
>> node bscgrid30 exiting improperly. There are two reasons this could occu=
r:
>>
>> 1. this process did not call "init" before exiting, but others in
>> the job did. This can cause a job to hang indefinitely while it waits
>> for all processes to call "init". By rule, if one process calls "init",
>> then ALL processes must call "init" prior to termination.
>>
>> 2. this process called "init", but exited without calling "finalize".
>> By rule, all processes that call "init" MUST call "finalize" prior to
>> exiting or it will be considered an "abnormal termination"
>>
>> This may have caused other processes in the application to be
>> terminated by signals sent by mpirun (as reported here).
>> ------------------------------------------------------------------------=
--
>>
>> Thanks in advance,
>>
>> El martes, 5 de julio de 2016, 18:21:48 (UTC+2), Gregory M. Kurtzer
>> escribi=C3=B3:
>>>
>>> Hi Raimon,
>>>
>>> I am confused as to what the issue is that you are having. Singularity
>>> supports running both across nodes as well as multiple processes per no=
de
>>> in any number of containers. Can you paste your command and the error y=
ou
>>> are getting, maybe that will help.
>>>
>>> Thanks!
>>>
>>>
>>>
>>> On Tue, Jul 5, 2016 at 8:25 AM, Raimon Bosch <rai...@gmail.com>
>>> wrote:
>>>
>>>>
>>>> That solution does not work with nas/mpi benchmark. That's because
>>>> bt.C.16 expects 16 processes. When you split processes it throws an
>>>> exception because number of processes is lower than 16.
>>>>
>>>> I am still trying to figure out how to do this. Let me know if you hav=
e
>>>> any suggestion.
>>>>
>>>> Cheers,
>>>>
>>>> El jueves, 23 de junio de 2016, 15:09:13 (UTC+2), Ralph Castain
>>>> escribi=C3=B3:
>>>>>
>>>>> I think you are misunderstanding the basic nature of the Singularity
>>>>> =E2=80=9Ccontainer=E2=80=9D. It=E2=80=99s just a file system overlay.=
 So =E2=80=9Csharing=E2=80=9D a container is
>>>>> no different than running on a node where the procs all see the same =
file
>>>>> system. Thus, having multiple containers that are identical makes no =
sense
>>>>> - it=E2=80=99s all the same file system.
>>>>>
>>>>> Now if you want to run different containers (e.g., with different
>>>>> libraries or OS in them), then you would use mpirun=E2=80=99s MPMD sy=
ntax - for
>>>>> example:
>>>>>
>>>>> mpirun -n 1 <container1> : -n 1 <container2>
>>>>>
>>>>> HTH
>>>>> Ralph
>>>>>
>>>>> On Jun 23, 2016, at 1:53 AM, Raimon Bosch <rai...@gmail.com> wrote:
>>>>>
>>>>>
>>>>> One last question: What if I want to execute more than one container
>>>>> in the same host? With this technique I am bounded always to the same
>>>>> container. One of our experiments was based in measuring performance =
of
>>>>> several containers working in parallel in the same node. Also we had
>>>>> experiments with N containers per host in a multihost environment.
>>>>>
>>>>> El mi=C3=A9rcoles, 22 de junio de 2016, 16:41:58 (UTC+2), Gregory M.
>>>>> Kurtzer escribi=C3=B3:
>>>>>>
>>>>>> Hi Raimon,
>>>>>>
>>>>>> Sorry I wasn't clear. I am not yet at my computer and thinking while
>>>>>> typing on an iPhone hinders my mental processes. Lol
>>>>>>
>>>>>> If I understand your example properly, you have a docker or VM
>>>>>> infrastructure already set up and you are invoking the mpirun comman=
ds from
>>>>>> within the virtual environment. Singularity works on a very differen=
t
>>>>>> premis because integrating a virtual cluster into an existing cluste=
r and
>>>>>> scheduling system is a mess.
>>>>>>
>>>>>> So starting from the physical nodes, which already have access to al=
l
>>>>>> other nodes in the cluster, and already scheduled properly, and in d=
irect
>>>>>> access to optimized hardware and file systems.... You call mpirun.
>>>>>>
>>>>>> The mpirun command will take the standard format as you illustrated
>>>>>> with the following change to call Singularity inline:
>>>>>>
>>>>>> $ mpirun -np 4 --hostfile hosts.txt singularity exec ~/container.img
>>>>>> trace.sh bt.C.4
>>>>>>
>>>>>> This assumes the following:
>>>>>>
>>>>>> 1. The container image which contains the program's you want to run
>>>>>> is at ~/container.img and accessible at this path on all nodes refer=
enced
>>>>>> in hosts.txt
>>>>>> 2. The hosts.txt references other physical nodes you want to run on
>>>>>> 3. The executables trace.sh and bt.C.4 are both inside the container
>>>>>> and in a standard path
>>>>>>
>>>>>> In this case we are performing one execution and MPI + singularity i=
s
>>>>>> managing all of the communication between processes, nodes and conta=
iners.
>>>>>> Also it is now using any optimized hardware (eg. Infiniband) and exi=
sting
>>>>>> high performance file systems (which should not be accessible via a
>>>>>> virtualized or Docker'ized cluster for security reasons).
>>>>>>
>>>>>> This way is actually MUCH simpler then what you are proposing becaus=
e
>>>>>> there is no need to manage any virtual nodes, virtual networks, or r=
esource
>>>>>> manager hacks. It really is as easy as just running any other MPI pr=
ocess
>>>>>> on an existing cluster.
>>>>>>
>>>>>> Hope that helps better!
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Wednesday, June 22, 2016, Raimon Bosch <rai...@gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> Hi Gregory,
>>>>>>>
>>>>>>> I'm not sure if I would achieve the same with your commands. In an
>>>>>>> environment based on dockers or virtual machines we would do someth=
ing like
>>>>>>> this [non applicable to Singularity]:
>>>>>>>
>>>>>>> > cd $OPEN_MPI/bin && mpirun -np 4 --hostfile hosts.txt ./trace.sh
>>>>>>> ./bt.C.4
>>>>>>>
>>>>>>> where hosts.txt* is:
>>>>>>>
>>>>>>> >vm-ip-01-on-*host01* slots=3D2
>>>>>>> >vm-ip-01-on-*host02* slots=3D2
>>>>>>>
>>>>>>> * vm-ip-XX-on-hostXX are IPs i.e. 172.100.60.XX
>>>>>>>
>>>>>>> and trace.sh is:
>>>>>>>
>>>>>>> >#!/bin/bash
>>>>>>> >
>>>>>>> >export EXTRAE_HOME=3D/opt/extrae/
>>>>>>> >export EXTRAE_CONFIG_FILE=3D/extrae.xml
>>>>>>> >export LD_PRELOAD=3D${EXTRAE_HOME}/lib/libmpitrace.so
>>>>>>> >
>>>>>>> >## Run the desired program
>>>>>>> >$*
>>>>>>>
>>>>>>> As you see we only perform one execution and OpenMPI transparently
>>>>>>> manages communication between containers or virtual machines. This =
command
>>>>>>> would work well rather VMs are on the same host or not.
>>>>>>>
>>>>>>> What I understand from your response is that now we should execute
>>>>>>> OpenMPI on each host and then merge results manually. I don't know =
yet how
>>>>>>> to do this merge step or if it is any way to centralize everything =
like I
>>>>>>> would do with VMs.
>>>>>>>
>>>>>>> Thanks in advance,
>>>>>>>
>>>>>>> El mi=C3=A9rcoles, 22 de junio de 2016, 14:42:54 (UTC+2), Gregory M=
.
>>>>>>> Kurtzer escribi=C3=B3:
>>>>>>>>
>>>>>>>> Hi Raimon,
>>>>>>>>
>>>>>>>> The quick answer is you have mpirun handle that as you would
>>>>>>>> normally where the container file lives on a shared file system:
>>>>>>>>
>>>>>>>> $ mpirun singularity exec ~/container.img mpi_prog_in_container
>>>>>>>>
>>>>>>>> Let the MPI outside the container launch the singularity container
>>>>>>>> on each host as it would normally launch any MPI program. Then it =
will call
>>>>>>>> Singulairty and Singularity will launch the MPI program inside the
>>>>>>>> container on each of your hosts/servers.
>>>>>>>>
>>>>>>>> Hope that helps!
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> On Wednesday, June 22, 2016, Raimon Bosch <rai...@gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>>>
>>>>>>>>> Hi Gregory,
>>>>>>>>>
>>>>>>>>> Thank you for your answer. One of our experiments needs to run
>>>>>>>>> OpenMPI among several servers. This means that we should put one =
of our
>>>>>>>>> containers in host01, another in host02 and another in host03 and=
 collect
>>>>>>>>> the results.
>>>>>>>>>
>>>>>>>>> How can I do this execution in parallel if I need to communicate
>>>>>>>>> with more than one server?
>>>>>>>>>
>>>>>>>>> El martes, 21 de junio de 2016, 16:51:03 (UTC+2), Gregory M.
>>>>>>>>> Kurtzer escribi=C3=B3:
>>>>>>>>>>
>>>>>>>>>> Hi Raimon,
>>>>>>>>>>
>>>>>>>>>> The communication model of a Singularity container is very
>>>>>>>>>> different from that of a Docker implementation. This is because =
Docker for
>>>>>>>>>> all practical purposes emulates a virtual machine as each contai=
ner has
>>>>>>>>>> it's own IP address and thus it's own ssh server. It also carrie=
s its own
>>>>>>>>>> set of complexities, for example networks need to be segregated/=
VLan'ed,
>>>>>>>>>> DNS/host resolution needs to be dynamic and passed down to the c=
ontainers
>>>>>>>>>> (so they can reach each other), ssh daemons and other process ru=
nning
>>>>>>>>>> inside the containers, management via an existing scheduling sys=
tem, and
>>>>>>>>>> the list goes on and on.
>>>>>>>>>>
>>>>>>>>>> Think of it this way, Singularity does not do any of that... It
>>>>>>>>>> runs a program within the container as if it were running on the=
 host
>>>>>>>>>> itself, so to communicate between containers is as easy as commu=
nicating
>>>>>>>>>> between programs. So for MPI, it would happen with the MPI on th=
e physical
>>>>>>>>>> host (outside the container) invoking the container subsystem wh=
ich then
>>>>>>>>>> invokes the MPI programs within the container and the MPI progra=
ms within
>>>>>>>>>> the container communicate back to the MPI (orted) outside the co=
ntainer on
>>>>>>>>>> the host to get access to the host resources. In this model all =
available
>>>>>>>>>> resources and infrastructure can be leveraged at full bandwidth =
by the
>>>>>>>>>> contained processes and all of the aforementioned complexities a=
kin to
>>>>>>>>>> running on a virtualized mini-cluster are circumvented.
>>>>>>>>>>
>>>>>>>>>> There is additional information I have written at:
>>>>>>>>>>
>>>>>>>>>> http://singularity.lbl.gov/#hpc
>>>>>>>>>>
>>>>>>>>>> That page is still coming along, and needs more information stil=
l
>>>>>>>>>> but if you have any questions, comments or change proposals plea=
se let us
>>>>>>>>>> know!
>>>>>>>>>>
>>>>>>>>>> Thanks and hope that helps!
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On Tue, Jun 21, 2016 at 7:37 AM, Raimon Bosch <
>>>>>>>>>> rai...@gmail.com> wrote:
>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>>
>>>>>>>>>>> Hi,
>>>>>>>>>>>
>>>>>>>>>>> We are trying to run experiments using singularity containers.
>>>>>>>>>>> The idea is to run OpenMPI among several containers and check p=
erformance
>>>>>>>>>>> results.
>>>>>>>>>>>
>>>>>>>>>>> How can I communicate with another container? In docker this is
>>>>>>>>>>> clear because every container gets an assigned IP and you can p=
ing there,
>>>>>>>>>>> but what is the situation in the case of singularity? Is it pos=
sible to
>>>>>>>>>>> assign an IP to each container? Can I connect via ssh to them?
>>>>>>>>>>>
>>>>>>>>>>> Thanks in advance,
>>>>>>>>>>>
>>>>>>>>>>> --
>>>>>>>>>>> You received this message because you are subscribed to the
>>>>>>>>>>> Google Groups "singularity" group.
>>>>>>>>>>> To unsubscribe from this group and stop receiving emails from
>>>>>>>>>>> it, send an email to singu...@lbl.gov.
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> --
>>>>>>>>>> Gregory M. Kurtzer
>>>>>>>>>> High Performance Computing Services (HPCS)
>>>>>>>>>> University of California
>>>>>>>>>> Lawrence Berkeley National Laboratory
>>>>>>>>>> One Cyclotron Road, Berkeley, CA 94720
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> You received this message because you are subscribed to the Googl=
e
>>>>>>>>> Groups "singularity" group.
>>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> Gregory M. Kurtzer
>>>>>>>> High Performance Computing Services (HPCS)
>>>>>>>> University of California
>>>>>>>> Lawrence Berkeley National Laboratory
>>>>>>>> One Cyclotron Road, Berkeley, CA 94720
>>>>>>>>
>>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Gregory M. Kurtzer
>>>>>> High Performance Computing Services (HPCS)
>>>>>> University of California
>>>>>> Lawrence Berkeley National Laboratory
>>>>>> One Cyclotron Road, Berkeley, CA 94720
>>>>>>
>>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, sen=
d
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>>
>>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>>
>>>
>>> --
>>> Gregory M. Kurtzer
>>> High Performance Computing Services (HPCS)
>>> University of California
>>> Lawrence Berkeley National Laboratory
>>> One Cyclotron Road, Berkeley, CA 94720
>>>
>> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov
> <javascript:_e(%7B%7D,'cvml','singularity%...@lbl.gov');>.
>


--=20
Gregory M. Kurtzer
High Performance Computing Services (HPCS)
University of California
Lawrence Berkeley National Laboratory
One Cyclotron Road, Berkeley, CA 94720

--001a11406b3616c0790536f7fee2
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi,=C2=A0<div><br></div><div>/run/user is associated with the Singularity c=
ontainer?</div><div><br></div><div>Can you show me the output of &#39;loset=
up -a&#39; please?</div><div><br></div><div>Why are=C2=A0<span></span>you a=
re running it with sudo, you should not need to.</div><div><br></div><div>I=
t is weird, isn&#39;t -n a synonym for -np and if so, shouldn&#39;t it exec=
uting 1 process on the given node? It seems like it is doing more.=C2=A0</d=
iv><div><br></div><div>Lastly, what version of Singularity is this? If from=
 Git=C2=A0master when did you do the last pull? Can you try this in debug m=
ode and with a simple=C2=A0binary for testing:</div><div><br></div><div>$=
=C2=A0<font size=3D"2"><span style=3D"background-color:rgba(255,255,255,0)"=
>mpirun -n 1 singularity -d=C2=A0exec=C2=A0/mnt/glusterfs/singularity/nasmp=
i-1.img=C2=A0</span></font><span style=3D"background-color:rgba(255,255,255=
,0);font-size:small">true</span></div><div><span style=3D"background-color:=
rgba(255,255,255,0);font-size:small"><br></span></div><div>And send that ou=
tput please.=C2=A0</div><div><br></div><div><br>On Wednesday, July 6, 2016,=
 Raimon Bosch &lt;<a href=3D"mailto:raimo...@gmail.com">raimo...@gmail.com<=
/a>&gt; wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .=
8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr"><br>When =
I do &quot;df -h&quot; I see the singularity container still mounted. Maybe=
 I need to run a command to unmount it:<br><br>&gt; df -h<br>Filesystem=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 Size=C2=A0 Used Avail Use% Mounted on<br>****<br>tmpfs=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3.2G=C2=A0=C2=A0=C2=A0=
=C2=A0 0=C2=A0 3.2G=C2=A0=C2=A0 0% /run/user/1006<br>****<br><br>El mi=C3=
=A9rcoles, 6 de julio de 2016, 10:25:24 (UTC+2), Raimon Bosch  escribi=C3=
=B3:<blockquote class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;b=
order-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr"><br>Hi Gregory=
,<br><br>It fails depending on your environment. In my Ubuntu 14.04 it work=
ed fine, but in this instance of Debian jessie I get the following:<br><br>=
&gt; ERROR: Failed to associate image to loop: Device or resource busy<br><=
br>Maybe is because we are using a glusterfs shared disk to keep the contai=
ners?<br><br>Here you have the entire output:<br><br>&gt; sudo mpirun -n 1 =
singularity exec /mnt/glusterfs/singularity/nasmpi-1.img /trace.sh /NPB/NPB=
3.3-MPI/bin/bt.C.4 : -n 1 singularity exec /mnt/glusterfs/singularity/nasmp=
i-2.img /trace.sh /NPB/NPB3.3-MPI/bin/bt.C.4 : -n 1 singularity exec /mnt/g=
lusterfs/singularity/nasmpi-3.img /trace.sh /NPB/NPB3.3-MPI/bin/bt.C.4 : -n=
 1 singularity exec /mnt/glusterfs/singularity/nasmpi-4.img /trace.sh /NPB/=
NPB3.3-MPI/bin/bt.C.4<br>ERROR: Failed to associate image to loop: Device o=
r resource busy<br>ERROR: Failed to associate image to loop: Device or reso=
urce busy<br>/bin/bash: warning: setlocale: LC_ALL: cannot change locale (e=
n_US.UTF-8)<br>ERROR: Failed to associate image to loop: Device or resource=
 busy<br>------------------------------------------------------------------=
--------<br>mpirun has exited due to process rank 2 with PID 63416 on<br>no=
de bscgrid30 exiting improperly. There are two reasons this could occur:<br=
><br>1. this process did not call &quot;init&quot; before exiting, but othe=
rs in<br>the job did. This can cause a job to hang indefinitely while it wa=
its<br>for all processes to call &quot;init&quot;. By rule, if one process =
calls &quot;init&quot;,<br>then ALL processes must call &quot;init&quot; pr=
ior to termination.<br><br>2. this process called &quot;init&quot;, but exi=
ted without calling &quot;finalize&quot;.<br>By rule, all processes that ca=
ll &quot;init&quot; MUST call &quot;finalize&quot; prior to<br>exiting or i=
t will be considered an &quot;abnormal termination&quot;<br><br>This may ha=
ve caused other processes in the application to be<br>terminated by signals=
 sent by mpirun (as reported here).<br>------------------------------------=
--------------------------------------<br><br>Thanks in advance,<br><br>El =
martes, 5 de julio de 2016, 18:21:48 (UTC+2), Gregory M. Kurtzer  escribi=
=C3=B3:<blockquote class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8e=
x;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Raimon,<=
div><br></div><div>I am confused as to what the issue is that you are havin=
g. Singularity supports running both across nodes as well as multiple proce=
sses per node in any number of containers. Can you paste your command and t=
he error you are getting, maybe that will help.</div><div><br></div><div>Th=
anks!</div><div><br></div><div><br></div></div><div><br><div class=3D"gmail=
_quote">On Tue, Jul 5, 2016 at 8:25 AM, Raimon Bosch <span dir=3D"ltr">&lt;=
<a rel=3D"nofollow">rai...@gmail.com</a>&gt;</span> wrote:<br><blockquote c=
lass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;=
padding-left:1ex"><div dir=3D"ltr"><br>That solution does not work with nas=
/mpi benchmark. That&#39;s because bt.C.16 expects 16 processes. When you s=
plit processes it throws an exception because number of processes is lower =
than 16. <br><br>I am still trying to figure out how to do this. Let me kno=
w if you have any suggestion.<br><br>Cheers,<span><br><br>El jueves, 23 de =
junio de 2016, 15:09:13 (UTC+2), Ralph Castain  escribi=C3=B3:</span><block=
quote class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left=
:1px #ccc solid;padding-left:1ex"><div style=3D"word-wrap:break-word"><span=
><div>I think you are misunderstanding the basic nature of the Singularity =
=E2=80=9Ccontainer=E2=80=9D. It=E2=80=99s just a file system overlay. So =
=E2=80=9Csharing=E2=80=9D a container is no different than running on a nod=
e where the procs all see the same file system. Thus, having multiple conta=
iners that are identical makes no sense - it=E2=80=99s all the same file sy=
stem.</div><div><br></div><div>Now if you want to run different containers =
(e.g., with different libraries or OS in them), then you would use mpirun=
=E2=80=99s MPMD syntax - for example:</div><div><br></div><div>mpirun -n 1 =
&lt;container1&gt; : -n 1 &lt;container2&gt;</div><div><br></div><div>HTH</=
div><div>Ralph</div></span><div><br><blockquote type=3D"cite"><div><div><di=
v>On Jun 23, 2016, at 1:53 AM, Raimon Bosch &lt;<a rel=3D"nofollow">rai...@=
gmail.com</a>&gt; wrote:</div><br></div></div><div><div><div><div dir=3D"lt=
r" style=3D"font-family:Helvetica;font-size:12px;font-style:normal;font-wei=
ght:normal;letter-spacing:normal;text-align:start;text-indent:0px;text-tran=
sform:none;white-space:normal;word-spacing:0px"><br>One last question: What=
 if I want to execute more than one container in the same host? With this t=
echnique I am bounded always to the same container. One of our experiments =
was based in measuring performance of several containers working in paralle=
l in the same node. Also we had experiments with N containers per host in a=
 multihost environment.<br><br>El mi=C3=A9rcoles, 22 de junio de 2016, 16:4=
1:58 (UTC+2), Gregory M. Kurtzer escribi=C3=B3:<blockquote class=3D"gmail_q=
uote" style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-c=
olor:rgb(204,204,204);border-left-style:solid;padding-left:1ex">Hi Raimon,<=
div><br></div><div>Sorry I wasn&#39;t clear. I am not yet at my computer an=
d thinking while typing on an iPhone hinders my mental processes. Lol</div>=
<div><br></div><div>If I understand your example properly, you have a docke=
r or VM infrastructure already set up and you are invoking the mpirun comma=
nds from within the virtual environment. Singularity works on a very differ=
ent premis because integrating a virtual cluster into an existing cluster a=
nd scheduling system is a mess.</div><div><br></div><div>So starting from t=
he physical nodes, which already have access to all other nodes in the clus=
ter, and already scheduled properly, and in direct access to optimized hard=
ware and file systems.... You call mpirun.=C2=A0</div><div><br></div><div>T=
he mpirun command will take the standard format as you illustrated with the=
 following change to call Singularity inline:</div><div><br></div><div>$ mp=
irun -np 4 --hostfile hosts.txt singularity exec ~/container.img trace.sh b=
t.C.4</div><div><br></div><div>This assumes the following:</div><div><br></=
div><div>1. The container image which contains the program&#39;s you want t=
o run is at ~/container.img and accessible at this path=C2=A0on all nodes r=
eferenced in hosts.txt</div><div>2. The hosts.txt references other physical=
 nodes you want to run on</div><div>3. The executables trace.sh and bt.C.4 =
are both inside the container and in a standard path</div><br><div>In this =
case we are performing one execution and MPI + singularity is managing all =
of the communication between processes, nodes and containers. Also it is no=
w using any optimized hardware (eg. Infiniband)=C2=A0and existing high perf=
ormance=C2=A0file systems (which should not be accessible via a virtualized=
 or Docker&#39;ized=C2=A0cluster for security reasons).</div><div><br></div=
><div>This way is actually MUCH simpler then what you are proposing because=
 there is no need to manage any virtual nodes, virtual networks, or resourc=
e manager hacks. It really is as easy as just running any other MPI=C2=A0pr=
ocess on an existing cluster.=C2=A0</div><div><br></div><div>Hope that help=
s better!</div><div><br></div><div><span></span><br><br>On Wednesday, June =
22, 2016, Raimon Bosch &lt;<a rel=3D"nofollow">raimon...@</a><a href=3D"htt=
p://gmail.com/" rel=3D"nofollow" target=3D"_blank">gmail.com</a>&gt; wrote:=
<br><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;bor=
der-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:sol=
id;padding-left:1ex"><div dir=3D"ltr"><br><br>Hi Gregory,<br><br>I&#39;m no=
t sure if I would achieve the same with your commands. In an environment ba=
sed on dockers or virtual machines we would do something like this [non app=
licable to Singularity]:<br><br>&gt; cd $OPEN_MPI/bin &amp;&amp; mpirun -np=
 4 --hostfile hosts.txt ./trace.sh ./bt.C.4<br><br>where hosts.txt* is:<br>=
<br>&gt;vm-ip-01-on-<b>host01</b><span>=C2=A0</span>slots=3D2<br>&gt;vm-ip-=
01-on-<b>host02</b><span>=C2=A0</span>slots=3D2<br><br>* vm-ip-XX-on-hostXX=
<b><span>=C2=A0</span></b>are IPs i.e. 172.100.60.XX<br><br>and trace.sh is=
:<br><br>&gt;#!/bin/bash<br>&gt;<br>&gt;export EXTRAE_HOME=3D/opt/extrae/<b=
r>&gt;export EXTRAE_CONFIG_FILE=3D/extrae.xml<br>&gt;export LD_PRELOAD=3D${=
EXTRAE_HOME}/lib/libmpitrace.so<br>&gt;<br>&gt;## Run the desired program<b=
r>&gt;$*<br><br>As you see we only perform one execution and OpenMPI transp=
arently manages communication between containers or virtual machines. This =
command would work well rather VMs are on the same host or not.<br><br>What=
 I understand from your response is that now we should execute OpenMPI on e=
ach host and then merge results manually. I don&#39;t know yet how to do th=
is merge step or if it is any way to centralize everything like I would do =
with VMs.<br><br>Thanks in advance,<br><br>El mi=C3=A9rcoles, 22 de junio d=
e 2016, 14:42:54 (UTC+2), Gregory M. Kurtzer escribi=C3=B3:<blockquote clas=
s=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;b=
order-left-color:rgb(204,204,204);border-left-style:solid;padding-left:1ex"=
>Hi Raimon,<div><br></div><div>The quick answer is you have mpirun handle t=
hat as you would normally where the container file lives on a shared file s=
ystem:</div><div><br></div><div>$ mpirun singularity exec ~/container.img m=
pi_prog_in_container</div><div><br></div><div>Let the MPI outside the conta=
iner launch the singularity container on each host as it would normally lau=
nch any MPI program. Then it will call Singulairty and Singularity will lau=
nch the MPI program inside the container on each of your hosts/servers.=C2=
=A0</div><div><br></div><div>Hope that helps!</div><div><br></div><div><spa=
n></span><br><br>On Wednesday, June 22, 2016, Raimon Bosch &lt;<a rel=3D"no=
follow">rai...@gmail.com</a>&gt; wrote:<br><blockquote class=3D"gmail_quote=
" style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-color=
:rgb(204,204,204);border-left-style:solid;padding-left:1ex"><div dir=3D"ltr=
"><br>Hi Gregory,<br><br>Thank you for your answer. One of our experiments =
needs to run OpenMPI among several servers. This means that we should put o=
ne of our containers in host01, another in host02 and another in host03 and=
 collect the results.<span>=C2=A0</span><br><br>How can I do this execution=
 in parallel if I need to communicate with more than one server?<br><br>El =
martes, 21 de junio de 2016, 16:51:03 (UTC+2), Gregory M. Kurtzer escribi=
=C3=B3:<blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;=
border-left-width:1px;border-left-color:rgb(204,204,204);border-left-style:=
solid;padding-left:1ex"><div dir=3D"ltr">Hi Raimon,<div><br></div><div>The =
communication model of a Singularity container is very different from that =
of a Docker implementation. This is because Docker for all practical purpos=
es emulates a virtual machine as each container has it&#39;s own IP address=
 and thus it&#39;s own ssh server. It also carries its own set of complexit=
ies, for example networks need to be segregated/VLan&#39;ed, DNS/host resol=
ution needs to be dynamic and passed down to the containers (so they can re=
ach each other), ssh daemons and other process running inside the container=
s, management via an existing scheduling system, and the list goes on and o=
n.</div><div><br></div><div>Think of it this way, Singularity does not do a=
ny of that... It runs a program within the container as if it were running =
on the host itself, so to communicate between containers is as easy as comm=
unicating between programs. So for MPI, it would happen with the MPI on the=
 physical host (outside the container) invoking the container subsystem whi=
ch then invokes the MPI programs within the container and the MPI programs =
within the container communicate back to the MPI (orted) outside the contai=
ner on the host to get access to the host resources. In this model all avai=
lable resources and infrastructure can be leveraged at full bandwidth by th=
e contained processes and all of the aforementioned complexities akin to ru=
nning on a virtualized mini-cluster are circumvented.</div><div><br></div><=
div>There is additional information I have written at:</div><div><br></div>=
<div><a href=3D"http://singularity.lbl.gov/#hpc" rel=3D"nofollow" target=3D=
"_blank">http://singularity.lbl.gov/#hpc</a><br></div><div><br></div><div>T=
hat page is still coming along, and needs more information still but if you=
 have any questions, comments or change proposals please let us know!</div>=
<div><br></div><div>Thanks and hope that helps!</div><div><br></div><div><b=
r></div></div><div><br><div class=3D"gmail_quote">On Tue, Jun 21, 2016 at 7=
:37 AM, Raimon Bosch<span>=C2=A0</span><span dir=3D"ltr">&lt;<a rel=3D"nofo=
llow">rai...@gmail.com</a>&gt;</span><span>=C2=A0</span>wrote:<br><blockquo=
te class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left-widt=
h:1px;border-left-color:rgb(204,204,204);border-left-style:solid;padding-le=
ft:1ex"><div dir=3D"ltr"><br><br>Hi,<br><br>We are trying to run experiment=
s using singularity containers. The idea is to run OpenMPI among several co=
ntainers and check performance results.<span>=C2=A0</span><br><br>How can I=
 communicate with another container? In docker this is clear because every =
container gets an assigned IP and you can ping there, but what is the situa=
tion in the case of singularity? Is it possible to assign an IP to each con=
tainer? Can I connect via ssh to them?<br><br>Thanks in advance,<span><font=
 color=3D"#888888"><br></font></span></div><span><font color=3D"#888888"><d=
iv><br></div>--<span>=C2=A0</span><br>You received this message because you=
 are subscribed to the Google Groups &quot;singularity&quot; group.<br>To u=
nsubscribe from this group and stop receiving emails from it, send an email=
 to<span>=C2=A0</span><a rel=3D"nofollow">singu...@lbl.gov</a>.<br></font><=
/span></blockquote></div><br><br clear=3D"all"><div><br></div>--<span>=C2=
=A0</span><br><div><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>High Perform=
ance Computing Services (HPCS)<br>University of California<br>Lawrence Berk=
eley National Laboratory<br>One Cyclotron Road, Berkeley, CA 94720</div></d=
iv></div></div></blockquote></div><div><br></div>--<span>=C2=A0</span><br>Y=
ou received this message because you are subscribed to the Google Groups &q=
uot;singularity&quot; group.<br>To unsubscribe from this group and stop rec=
eiving emails from it, send an email to<span>=C2=A0</span><a>singu...@lbl.g=
ov</a>.<br></blockquote></div><br><br>--<span>=C2=A0</span><br><div dir=3D"=
ltr"><div>Gregory M. Kurtzer<br>High Performance Computing Services (HPCS)<=
br>University of California<br>Lawrence Berkeley National Laboratory<br>One=
 Cyclotron Road, Berkeley, CA 94720</div></div><br></blockquote></div><div>=
<br></div>--<span>=C2=A0</span><br>You received this message because you ar=
e subscribed to the Google Groups &quot;singularity&quot; group.<br>To unsu=
bscribe from this group and stop receiving emails from it, send an email to=
<span>=C2=A0</span><a>singu...@lbl.gov</a>.<br></blockquote></div><br><br>-=
-<span>=C2=A0</span><br><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>High Pe=
rformance Computing Services (HPCS)<br>University of California<br>Lawrence=
 Berkeley National Laboratory<br>One Cyclotron Road, Berkeley, CA 94720</di=
v></div><br></blockquote></div><div style=3D"font-family:Helvetica;font-siz=
e:12px;font-style:normal;font-weight:normal;letter-spacing:normal;text-alig=
n:start;text-indent:0px;text-transform:none;white-space:normal;word-spacing=
:0px"><br></div><span style=3D"font-family:Helvetica;font-size:12px;font-st=
yle:normal;font-weight:normal;letter-spacing:normal;text-align:start;text-i=
ndent:0px;text-transform:none;white-space:normal;word-spacing:0px;float:non=
e;display:inline!important">--<span>=C2=A0</span></span><br style=3D"font-f=
amily:Helvetica;font-size:12px;font-style:normal;font-weight:normal;letter-=
spacing:normal;text-align:start;text-indent:0px;text-transform:none;white-s=
pace:normal;word-spacing:0px"><span style=3D"font-family:Helvetica;font-siz=
e:12px;font-style:normal;font-weight:normal;letter-spacing:normal;text-alig=
n:start;text-indent:0px;text-transform:none;white-space:normal;word-spacing=
:0px;float:none;display:inline!important">You received this message because=
 you are subscribed to the Google Groups &quot;singularity&quot; group.</sp=
an><br style=3D"font-family:Helvetica;font-size:12px;font-style:normal;font=
-weight:normal;letter-spacing:normal;text-align:start;text-indent:0px;text-=
transform:none;white-space:normal;word-spacing:0px"></div></div><span style=
=3D"font-family:Helvetica;font-size:12px;font-style:normal;font-weight:norm=
al;letter-spacing:normal;text-align:start;text-indent:0px;text-transform:no=
ne;white-space:normal;word-spacing:0px;float:none;display:inline!important"=
>To unsubscribe from this group and stop receiving emails from it, send an =
email to<span>=C2=A0</span></span><a style=3D"font-family:Helvetica;font-si=
ze:12px;font-style:normal;font-weight:normal;letter-spacing:normal;text-ali=
gn:start;text-indent:0px;text-transform:none;white-space:normal;word-spacin=
g:0px" rel=3D"nofollow">singu...@lbl.gov</a><span style=3D"font-family:Helv=
etica;font-size:12px;font-style:normal;font-weight:normal;letter-spacing:no=
rmal;text-align:start;text-indent:0px;text-transform:none;white-space:norma=
l;word-spacing:0px;float:none;display:inline!important">.</span></div></blo=
ckquote></div><br></div></blockquote></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>High Performance Computing=
 Services (HPCS)<br>University of California<br>Lawrence Berkeley National =
Laboratory<br>One Cyclotron Road, Berkeley, CA 94720</div></div></div>
</div>
</blockquote></div></blockquote></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"javascript:_e(%7B%7D,&#39;cvml&#39;,&#39;singularity...@=
lbl.gov&#39;);" target=3D"_blank">singu...@lbl.gov</a>.<br>
</blockquote></div><br><br>-- <br><div dir=3D"ltr"><div>Gregory M. Kurtzer<=
br>High Performance Computing Services (HPCS)<br>University of California<b=
r>Lawrence Berkeley National Laboratory<br>One Cyclotron Road, Berkeley, CA=
 94720</div></div><br>

--001a11406b3616c0790536f7fee2--

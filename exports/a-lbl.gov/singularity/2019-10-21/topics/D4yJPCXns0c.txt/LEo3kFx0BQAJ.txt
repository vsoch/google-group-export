X-Received: by 2002:a62:d5c2:: with SMTP id d185mr1780935pfg.123.1542149307718;
        Tue, 13 Nov 2018 14:48:27 -0800 (PST)
X-BeenThere: singularity@lbl.gov
Received: by 2002:a17:902:1:: with SMTP id 1-v6ls4848892pla.12.gmail; Tue, 13
 Nov 2018 14:48:26 -0800 (PST)
X-Received: by 2002:a17:902:2c03:: with SMTP id m3mr3261643plb.6.1542149306566;
        Tue, 13 Nov 2018 14:48:26 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1542149306; cv=none;
        d=google.com; s=arc-20160816;
        b=E46YjxrRec6aAicHrV4buidTpiIu0jCAaJXWTVRylW7jDlgcXqD7HcuOJwG73sSg0n
         kmMa46m2iooowqJp+RE7yvqmisoCH1sMT10aztXPAwp7wTlpwAgIkX4yfy2pRj0adAGB
         KMdXRfQVaflmlB+3sr+FWouvqQUsGR/xr/miU2H5zdwxzX1HCT3oqsQ+16ChW9nXPWRt
         orkD7SKA+/81SkejcEOQmraAPsiPzWcIllDH2ZA18HdKO6RHkdcoBhqByaR3QcPGYE6B
         +oJaVuVCzYaQt7l4MfDU5DfKLREzlSAacScJbX+GZ/kKSw2aFZT8txp380blh+7QBUSD
         WhIw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:in-reply-to:references:mime-version
         :dkim-signature;
        bh=I4IJOg0JCN7Jkpaj1IGWc0dbWHPdURLMIqjbOYwLlLQ=;
        b=oCMIo1o9baLpTCGqTELHjSPajHyzcbAuFatMNEbeMMAksNsa9dPnd7bKvu9mPSyobT
         kcO4Em7G8se4M+AjpepHcY/0RZecsIF9l4ZaEodR3YiyGEDa/Z3QOxPb+Sqm0EHgvjJW
         BoMyXZCSJ3huJeth6HkrJSLMQ2EOBx4/Qp2jn+vC0YwiRYAI3Z1POliIIcQ+DAcPfqNk
         vpmSPgWcF6jk+wQtEhhI0IGfNU32qyPUtk2OEdu2SPy6rq7L47etIg9kk9q0VHNpUUzV
         3hb945deXFbgxKTUtiUxSCHEKIKJgMAq9RUdT0uHZBOiLRfPnSJROlpRM+Y6It4hUggZ
         TnTQ==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=tJGrNt2g;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.166.178 as permitted sender) smtp.mailfrom=vso...@gmail.com
Return-Path: <vso...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id r12si21285755pgf.22.2018.11.13.14.48.26
        for <singu...@lbl.gov>;
        Tue, 13 Nov 2018 14:48:26 -0800 (PST)
Received-SPF: pass (google.com: domain of vso...@gmail.com designates 209.85.166.178 as permitted sender) client-ip=209.85.166.178;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=tJGrNt2g;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.166.178 as permitted sender) smtp.mailfrom=vso...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2E/AwB4U+tbhrKmVdFgA4NygQ9PMyeDc?=
 =?us-ascii?q?gaBHYJekieRYYVogSs7JQEKC4N4RgKDPSI4FgEDAQECAQECAQECEAEBAQgLCwg?=
 =?us-ascii?q?pIwyCNgUCAxoHBQRLOzABAQEBAQEBAQEBAQEBAQEaAg0gQwEBAQECASMEGQEND?=
 =?us-ascii?q?h4DAQsGAwILDSoCAiEBAQ4DAQUBHA4HBAEHDAcCBIMAASgBgT8BAw0IBQqNNZA?=
 =?us-ascii?q?HPIsNfBYFAReCdwWBMQGDCwoZJw1agTcCAQUSi3AXgX+BEYIUfoJWRQKBGxMBD?=
 =?us-ascii?q?AYBCQI1DBqCPYJXAo97jwYnLgmGd4cAgysYkHONKIEHgwCGPzCBOVYNI3FwFTs?=
 =?us-ascii?q?xgjuCNYNTinAkMBCLHQ4XMIF3AQE?=
X-IronPort-AV: E=Sophos;i="5.56,230,1539673200"; 
   d="scan'208,217";a="42422699"
Received: from mail-it1-f178.google.com ([209.85.166.178])
  by fe4.lbl.gov with ESMTP; 13 Nov 2018 14:48:24 -0800
Received: by mail-it1-f178.google.com with SMTP id a205-v6so15424438itd.4
        for <singu...@lbl.gov>; Tue, 13 Nov 2018 14:48:24 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to;
        bh=I4IJOg0JCN7Jkpaj1IGWc0dbWHPdURLMIqjbOYwLlLQ=;
        b=tJGrNt2gu/tfp3zyiBL2xrmgmB55FdCLUR1qalop/Ho1hhZVsX69LDghjFk40K6Jay
         QEwnTK1NGPpf0HWDQDO/K7dTljeq0IRzTxbkxmvGd0+Hq68dR3wNJTiDVS6MYH8WwIva
         TyGql0pVYOEeMJMZKjM+gtuDXq73mBOvT+sslXwsGfrVxbxzkqvHs/VXzyua2x1KPHLG
         c6iBsjI3ofeIkXddZGGIzahJqP1ohLOGVNxMJPpBz//jMQubsesAZKT6MP/yPfROeT4K
         q4jVMgATsW6EitEy7FHDGCWDmCgGra/wu+C1tc19cLVBOj4F3IhF4OH3JVIi4S5KGi3b
         Ly5A==
X-Gm-Message-State: AGRZ1gLehVKpkyTlcfqzzvv6Md9oYY/qDsPN5ms1d1SzBTy/2S50ArgL
	he7hbC869Hyr3mEpq/uHCEDNpdzwK3ibH2HMs+1CpT9w
X-Received: by 2002:a24:dac7:: with SMTP id z190-v6mr4798543itg.87.1542149304069;
 Tue, 13 Nov 2018 14:48:24 -0800 (PST)
MIME-Version: 1.0
References: <f7003a30-6d9a-4df1-a1dc-9d9ec5912580@lbl.gov> <CAM=pu+LEGC2fh2Z=vT_TeryF+rck1i5Y2nJ+6RyGkznx=pmFgQ@mail.gmail.com>
In-Reply-To: <CAM=pu+LEGC2fh2Z=vT_TeryF+rck1i5Y2nJ+6RyGkznx=pmFgQ@mail.gmail.com>
From: v <vso...@gmail.com>
Date: Tue, 13 Nov 2018 17:48:12 -0500
Message-ID: <CAM=pu+JYSujdu7M16RSEXggpdeMhbM7BaZmx6_vXDiLti5sZHA@mail.gmail.com>
Subject: Re: [Singularity] Sregistry serving performance tweaks
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="00000000000075b5a4057a939db3"

--00000000000075b5a4057a939db3
Content-Type: text/plain; charset="UTF-8"

If anyone wants to pick up this discussion (and wants to link with work in
issues) I have brought it up several times, the most recent of which is an
issue here --> https://github.com/singularityhub/sregistry/issues/160 This
list is okay too, although it's better (imho) to have discussion for a code
base sort of "packaged" with it (a la Github).

On Tue, Nov 13, 2018 at 3:57 PM v <vso...@gmail.com> wrote:

> I think the performance issues for scaling are logical given that we have
> a single nginx, uwgi application, and file system storage. Typically when
> you scale these "apps" in some kind of cloud or cluster, you are generating
> several instances of the components that scale with demand. For Singularity
> Hub, for example, we don't rely on a filesystem to serve images, we use an
> object storage API that the registry server can easily direct the user to.
> The web interface doesn't need to do much other than provide a human
> friendly interface to that. You are right that tweaking the config will
> only take you so far - you would actually need to mimic a container cluster
> and somehow deploy more than one set of servers for accessing the same
> database and filesystem. This sounds messy to me.
>
> I think what we should do here is to put our heads together and think
> about how the images can better be served at scale, for Singularity
> Registry Server. This comes down to the kind of file storage (or object
> storage) that you are able to use. For each solution we can make a storage
> plugin. For example, you could weigh the costs and benefits of using Google
> Storage, and then your "upload" to the registry would be to push there.
> That's how SingularityHub rolls :) For the user (you) it would come down to
> enabling the plugin, and exporting some credential as a secret. That's
> probably it :)
>
> And when I say "we can make" I mean "I" - I would be happy to implement
> these for you - you can rely on this dinosaur! What I'd want to do is get a
> solid description of your (and the community needs) so the SRegistry server
> can be all that it needs to be!)
>
> Best,
>
> Vanessa
>
> On Tue, Nov 13, 2018 at 3:39 PM Mike Moore <wxdu...@gmail.com> wrote:
>
>> Hi everyone,
>>
>>   Our POC with sregistry has been moving along well.  I am trying to
>> address reliability issues when running multiple simultaneous pulls from
>> sregistry.  I would see timeouts and disconnects on the compute node side
>> when trying to run only 5 simultaneous pulls.  With changes to the number
>> of processes and worker threads in the nginx and sregistry uwsgi
>> containers, I have been able to resolve these timeouts for the most part.
>> What I am running into is a significant throughput limit on a per-pull
>> basis.  So, here is a little background on our POC infrastructure.
>>
>> Sregistry is running in a virtual machine with 16 GB of RAM and 8 Cores.
>> The VM is running CentOS 7, hosted by KVM hypervisor, on a HP Blade with 2
>> x 2.2GHz AMD Opteron 6174 (12 Core) processors.  Due to limitations in the
>> network hardware, the hypervisor has a 6 Gbit Ethernet connection out to
>> our network. The VM's disk is a single qcow2 image running on a GPFS file
>> system.  The disk will provide easily 100+MB/s of throughput.
>>
>> The problem I am having is that there is something throttling the ability
>> for sregistry to push the container image out to the clients. For a single
>> client pull of a 1.5GB image, I only see about ~32MB/s of throughput (256
>> Mbit/s).  With multiple simultaneous pulls, I can get up to about 230-240
>> MB/s sustained (2+ Gbit/s).  Using dstat to monitor cpu, disk, network, and
>> interrupts, I have ruled out the disk and CPU being a limit.  CPU
>> utilization for the single pull cases is almost nothing, and when really
>> cranking (at least 40+ simultaneous pulls) it is busy, but nothing is
>> blocked on disk IO.  There is no disk activity that I can see.  It appears
>> that everything is being served from memory.
>>
>> I first thought this was an issue with the network configuration so I ran
>> iperf between the VM and the compute nodes to test the throughput. I get
>> between 4-5 Gbit/s throughput between the VM to the compute nodes. So next,
>> I shelled into the containers to see if the docker proxy between the
>> container network and the outside world was causing problems. Using the
>> uwsgi container, I can get again 4-5 Gbit/s throughput.  So it is not the
>> proxy causing the limit.
>>
>> If I understand the traffic flow I am seeing using "docker stats",  when
>> singularity pulls from sregistry, the traffic flow looks like
>>
>>        uwsgi/sregistry container------->nginx container------>docker
>> proxy------>VM eth0------->network------>compute node--->singularity client
>>
>> The nginx container has a lot of traffic coming and going as everything
>> does go through it.
>>
>> I am at a loss as where to look next to improve performance.  Here is
>> what I have done so far:
>>
>> In uwsgi.ini, I replaced the original processes and threads with the
>> following settings:
>> http-timeout = 3600000
>> socket-timeout = 120
>> processes = 128
>> threads = 1
>> ignore-sigpipe = true
>> ignore-write-errors = true
>> disable-write-exception = true
>>
>> In nginx, I made the following changes:
>> Upped worker_processes to 32, but keeping it lower didn't make an
>> appreciable difference.
>> Disabled access logging
>> Upped worker_connections from 1024 to 2048
>> Added settings to do asynchronous IO, disabled sendfile.
>>
>> I still see the occasional failure on a pull, and I think that is because
>> the registry isn't pushing data out as fast as it could.  Does anyone have
>> any further suggestions on settings to try to relieve the bottleneck(s)?
>>
>> Thank you
>> -Mike
>>
>> --
>> You received this message because you are subscribed to the Google Groups
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to singu...@lbl.gov.
>>
>
>
> --
> Vanessa Villamia Sochat
> Stanford University '16
> (603) 321-0676
>


-- 
Vanessa Villamia Sochat
Stanford University '16
(603) 321-0676

--00000000000075b5a4057a939db3
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div dir=3D"ltr">If anyone wants to pick up this discussio=
n (and wants to link with work in issues) I have brought it up several time=
s, the most recent of which is an issue here --&gt;=C2=A0<a href=3D"https:/=
/github.com/singularityhub/sregistry/issues/160">https://github.com/singula=
rityhub/sregistry/issues/160</a> This list is okay too, although it&#39;s b=
etter (imho) to have discussion for a code base sort of &quot;packaged&quot=
; with it (a la Github).</div></div><br><div class=3D"gmail_quote"><div dir=
=3D"ltr">On Tue, Nov 13, 2018 at 3:57 PM v &lt;<a href=3D"mailto:vso...@gma=
il.com">vso...@gmail.com</a>&gt; wrote:<br></div><blockquote class=3D"gmail=
_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:=
1ex"><div dir=3D"ltr">I think the performance issues for scaling are logica=
l given that we have a single nginx, uwgi application, and file system stor=
age. Typically when you scale these &quot;apps&quot; in some kind of cloud =
or cluster, you are generating several instances of the components that sca=
le with demand. For Singularity Hub, for example, we don&#39;t rely on a fi=
lesystem to serve images, we use an object storage API that the registry se=
rver can easily direct the user to. The web interface doesn&#39;t need to d=
o much other than provide a human friendly interface to that. You are right=
 that tweaking the config will only take you so far - you would actually ne=
ed to mimic a container cluster and somehow deploy more than one set of ser=
vers for accessing the same database and filesystem. This sounds messy to m=
e.<div><br></div><div>I think what we should do here is to put our heads to=
gether and think about how the images can better be served at scale, for Si=
ngularity Registry Server. This comes down to the kind of file storage (or =
object storage) that you are able to use. For each solution we can make a s=
torage plugin. For example, you could weigh the costs and benefits of using=
 Google Storage, and then your &quot;upload&quot; to the registry would be =
to push there. That&#39;s how SingularityHub rolls :) For the user (you) it=
 would come down to enabling the plugin, and exporting some credential as a=
 secret. That&#39;s probably it :)</div><div><br></div><div>And when I say =
&quot;we can make&quot; I mean &quot;I&quot; - I would be happy to implemen=
t these for you - you can rely on this dinosaur! What I&#39;d want to do is=
 get a solid description of your (and the community needs) so the SRegistry=
 server can be all that it needs to be!)</div><div><br></div><div>Best,</di=
v><div><br></div><div>Vanessa</div></div><br><div class=3D"gmail_quote"><di=
v dir=3D"ltr">On Tue, Nov 13, 2018 at 3:39 PM Mike Moore &lt;<a href=3D"mai=
lto:wxdu...@gmail.com" target=3D"_blank">wxdu...@gmail.com</a>&gt; wrote:<b=
r></div><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border=
-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi everyone,<br><br=
>=C2=A0 Our POC with sregistry has been moving along well.=C2=A0 I am tryin=
g to address reliability issues when running multiple simultaneous pulls fr=
om sregistry.=C2=A0 I would see timeouts and disconnects on the compute nod=
e side when trying to run only 5 simultaneous pulls.=C2=A0 With changes to =
the number of processes and worker threads in the nginx and sregistry uwsgi=
 containers, I have been able to resolve these timeouts for the most part.=
=C2=A0 What I am running into is a significant throughput limit on a per-pu=
ll basis.=C2=A0 So, here is a little background on our POC infrastructure.=
=C2=A0 <br><br>Sregistry is running in a virtual machine with 16 GB of RAM =
and 8 Cores.=C2=A0 The VM is running CentOS 7, hosted by KVM hypervisor, on=
 a HP Blade with 2 x 2.2GHz AMD Opteron 6174 (12 Core) processors.=C2=A0 Du=
e to limitations in the network hardware, the hypervisor has a 6 Gbit Ether=
net connection out to our network. The VM&#39;s disk is a single qcow2 imag=
e running on a GPFS file system.=C2=A0 The disk will provide easily 100+MB/=
s of throughput.=C2=A0 <br><br>The problem I am having is that there is som=
ething throttling the ability for sregistry to push the container image out=
 to the clients. For a single client pull of a 1.5GB image, I only see abou=
t ~32MB/s of throughput (256 Mbit/s).=C2=A0 With multiple simultaneous pull=
s, I can get up to about 230-240 MB/s sustained (2+ Gbit/s).=C2=A0 Using ds=
tat to monitor cpu, disk, network, and interrupts, I have ruled out the dis=
k and CPU being a limit.=C2=A0 CPU utilization for the single pull cases is=
 almost nothing, and when really cranking (at least 40+ simultaneous pulls)=
 it is busy, but nothing is blocked on disk IO.=C2=A0 There is no disk acti=
vity that I can see.=C2=A0 It appears that everything is being served from =
memory. <br><br>I first thought this was an issue with the network configur=
ation so I ran iperf between the VM and the compute nodes to test the throu=
ghput. I get between 4-5 Gbit/s throughput between the VM to the compute no=
des. So next, I shelled into the containers to see if the docker proxy betw=
een the container network and the outside world was causing problems. Using=
 the uwsgi container, I can get again 4-5 Gbit/s throughput.=C2=A0 So it is=
 not the proxy causing the limit.<br><br>If I understand the traffic flow I=
 am seeing using &quot;docker stats&quot;,=C2=A0 when singularity pulls fro=
m sregistry, the traffic flow looks like<br><br>=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0 uwsgi/sregistry container-------&gt;nginx container------&gt;dock=
er proxy------&gt;VM eth0-------&gt;network------&gt;compute node---&gt;sin=
gularity client<br><br>The nginx container has a lot of traffic coming and =
going as everything does go through it. <br><br>I am at a loss as where to =
look next to improve performance.=C2=A0 Here is what I have done so far:<br=
><br>In uwsgi.ini, I replaced the original processes and threads with the f=
ollowing settings:<br>http-timeout =3D 3600000<br>socket-timeout =3D 120<br=
>processes =3D 128<br>threads =3D 1<br>ignore-sigpipe =3D true<br>ignore-wr=
ite-errors =3D true<br>disable-write-exception =3D true<br><br>In nginx, I =
made the following changes:<br>Upped worker_processes to 32, but keeping it=
 lower didn&#39;t make an appreciable difference.<br>Disabled access loggin=
g<br>Upped worker_connections from 1024 to 2048<br>Added settings to do asy=
nchronous IO, disabled sendfile.<br><br>I still see the occasional failure =
on a pull, and I think that is because the registry isn&#39;t pushing data =
out as fast as it could.=C2=A0 Does anyone have any further suggestions on =
settings to try to relieve the bottleneck(s)?<br><br>Thank you<br>-Mike<br>=
<br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</blockquote></div><br clear=3D"all"><div><br></div>-- <br><div dir=3D"ltr"=
 class=3D"m_8017014714064823084gmail_signature" data-smartmail=3D"gmail_sig=
nature">Vanessa Villamia Sochat<br>Stanford University &#39;16<br><div><div=
><div>(603) 321-0676</div></div></div></div>
</blockquote></div><br clear=3D"all"><div><br></div>-- <br><div dir=3D"ltr"=
 class=3D"gmail_signature" data-smartmail=3D"gmail_signature">Vanessa Villa=
mia Sochat<br>Stanford University &#39;16<br><div><div><div>(603) 321-0676<=
/div></div></div></div>

--00000000000075b5a4057a939db3--

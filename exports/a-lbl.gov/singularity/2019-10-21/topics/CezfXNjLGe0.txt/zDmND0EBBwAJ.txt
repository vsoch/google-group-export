X-Received: by 10.157.31.16 with SMTP id x16mr52577564otd.19.1470151788147;
        Tue, 02 Aug 2016 08:29:48 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.139.135 with SMTP id n129ls5115568iod.6.gmail; Tue, 02 Aug
 2016 08:29:47 -0700 (PDT)
X-Received: by 10.98.38.4 with SMTP id m4mr106781761pfm.47.1470151787572;
        Tue, 02 Aug 2016 08:29:47 -0700 (PDT)
Return-Path: <nathan...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id xl3si3542616pab.117.2016.08.02.08.29.47
        for <singu...@lbl.gov>;
        Tue, 02 Aug 2016 08:29:47 -0700 (PDT)
Received-SPF: pass (google.com: domain of nathan...@gmail.com designates 209.85.220.178 as permitted sender) client-ip=209.85.220.178;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of nathan...@gmail.com designates 209.85.220.178 as permitted sender) smtp.mailfrom=nathan...@gmail.com
X-Ironport-SBRS: 2.7
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2FCAQCcu6BXf7LcVdFdhBt8gz+BDKNAiS2GfHaBPUAmgWxUgicBgQ8CJYEbOBQBAQEBAQEBAw8BAQkLCwkXMYJTOQoGKwEBAQEBAQEBAQEBAQEBAQEaAisEFgsbAQEEARIIAQgdAQ0OHgMBCwYFCw0gAQkCAiECDgMBBQEcDgcEARoCBAGHdAEDDwgFCaJYgTI+MYs7gWqCWgWGTgoZJw1Ug0ABAQEBAQUBAQEBAQEBAQEBARQCBhCIEoFSgQOCQ4FPEQEcGYJoK4IvBYYMghEHYIUSC4EphCaFDzSGGII4RIJzQ4I1gWsXN4cMDiOFSYgrhAWCODCBDw8PgkgcgWhSAQEBAQOGdIE2AQEB
X-IPAS-Result: A2FCAQCcu6BXf7LcVdFdhBt8gz+BDKNAiS2GfHaBPUAmgWxUgicBgQ8CJYEbOBQBAQEBAQEBAw8BAQkLCwkXMYJTOQoGKwEBAQEBAQEBAQEBAQEBAQEaAisEFgsbAQEEARIIAQgdAQ0OHgMBCwYFCw0gAQkCAiECDgMBBQEcDgcEARoCBAGHdAEDDwgFCaJYgTI+MYs7gWqCWgWGTgoZJw1Ug0ABAQEBAQUBAQEBAQEBAQEBARQCBhCIEoFSgQOCQ4FPEQEcGYJoK4IvBYYMghEHYIUSC4EphCaFDzSGGII4RIJzQ4I1gWsXN4cMDiOFSYgrhAWCODCBDw8PgkgcgWhSAQEBAQOGdIE2AQEB
X-IronPort-AV: E=Sophos;i="5.28,461,1464678000"; 
   d="scan'208,217";a="31386827"
Received: from mail-qk0-f178.google.com ([209.85.220.178])
  by fe4.lbl.gov with ESMTP; 02 Aug 2016 08:29:44 -0700
Received: by mail-qk0-f178.google.com with SMTP id v123so45161994qkh.3
        for <singu...@lbl.gov>; Tue, 02 Aug 2016 08:29:44 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=from:content-transfer-encoding:mime-version:subject:message-id:date
         :references:in-reply-to:to;
        bh=gwQ4q19xhIe2Pna43JTnoQTtvA3P4+FxGZHhGAs0zUE=;
        b=nfxBjVIcVyt1o7IiLR/GTWzPlV1fmI5Iu5pQYaAMIg/vr1sW18ZfeehREn0oBNBI6v
         my1gJ/Boufi5lkXRjaWKA2r2KBiqBLoUPtczBePKL8y23dVj+LnbhUkBDSQZQgwpsAKB
         f5C5OyhOa822J1HK2ZIjFhQmJhq2p206q4n+A7bHsi+C3AOIBtNU45+3mN6IZlTxqCY8
         oaqrcVdNXDszGsN5uPqu9wp+qkQLFd8sPKFvbzwlIu0WzKOFMoHqAjv1CEMWQwvWPTV+
         jd0vLGmG3+IjWo+IRMMr8MHWh5ijNI7qM/MkJ5wqegmX751zKkCZw13j3iIk0umKfNku
         z1xA==
X-Gm-Message-State: AEkooutFs45wHRg1mJGhlzsGDE5ZBxV1aTCGlugkOX/fh2YPkPn0f0amqR0juVed+NaXsg==
X-Received: by 10.55.73.148 with SMTP id w142mr78697910qka.77.1470151783101;
        Tue, 02 Aug 2016 08:29:43 -0700 (PDT)
Return-Path: <nathan...@gmail.com>
Received: from [172.26.120.242] (nat-130-132-173-155.central.yale.edu. [130.132.173.155])
        by smtp.gmail.com with ESMTPSA id u57sm1612450qta.20.2016.08.02.08.29.42
        for <singu...@lbl.gov>
        (version=TLS1 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
        Tue, 02 Aug 2016 08:29:42 -0700 (PDT)
From: Nathan Lin <nathan...@gmail.com>
Content-Type: multipart/alternative;
	boundary=Apple-Mail-AFF726B9-603A-4719-BDB5-C331E483A79C
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (1.0)
Subject: Re: [Singularity] How to use GPU in singularity?
Message-Id: <AAC7A4FE-6EF8-45FB-839C-4792CE1797F2@gmail.com>
Date: Tue, 2 Aug 2016 11:29:41 -0400
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
 <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov> <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
 <CAA8GL6BdE1TRBaPD-oM7qcj8QK1cBsmJsUzYyrvkRPBP9CX+hQ@mail.gmail.com>
 <CAMfmYehdPLtiouQqMGqOx4ZbEXFbbPRL5QOxsP_vQo0us1QLuA@mail.gmail.com>
 <B927B7F6-3CFB-452D-92AB-866F9B8024E4@gmail.com> <CAMfmYeiSvcReO4jvSGJkavnex64wGZ8Phxva2kAxJ7pcp48YiA@mail.gmail.com>
 <CAMfmYeiaTxVQSNqwprHe5ckcDHPcJXy3imdepiRL+KkDh12TCQ@mail.gmail.com>
 <65CD778F-6CD1-4DB4-9668-4D89839B7053@gmail.com> <CAMfmYeg_pnJcyKGetK7WVChToaWCgGYH-nrYY9v=2+RSkuWZuQ@mail.gmail.com>
 <C5AE54CB-2BA1-4E59-88FC-D20224A46086@gmail.com> <CAMfmYeg2rR9-U-zyviCeDXRt_QgKv_K0p9pf-+qgoGPQAjxjXA@mail.gmail.com>
 <95039222-908B-4AE8-8844-551646C9733C@gmail.com> <CAA8GL6ATuT+zMyD9zrW5GBH3Br8bm8=RvjKm1PNAGbKGF3psMw@mail.gmail.com>
 <CAMfmYejEioybKBLNSv36dd7ma-Z1hatfssvFUOGiuehBZbk-Ug@mail.gmail.com>
 <CA+3XN_KmaVuaKqOCbCvocOrw0qghQZq3kiBh1S6T2NKyTgpDTA@mail.gmail.com>
 <CAMfmYeiia1H27LL8q72LgrsgBV8PF8+QL03DK922PVM6WO0FDg@mail.gmail.com>
 <CA+3XN_Lb6DT4zNfuzTdbL276SsKUumResXsheJ0P9UK1j8KTMA@mail.gmail.com>
 <CAN7etTzJOy=mqZFfFY=4+W_DnMN2c_3G8tdqNM91Gy0qdrqXCA@mail.gmail.com>
 <CAMfmYeiTxZUEjiBx43R4hHWDTx_PvH+VQsx27P+QYmjsoihYaA@mail.gmail.com> <CAN7etTxU9wiVg+0KH+1cX+FmAmSkD65xORjubSzv4heOknYPww@mail.gmail.com>
In-Reply-To: <CAN7etTxU9wiVg+0KH+1cX+FmAmSkD65xORjubSzv4heOknYPww@mail.gmail.com>
To: singularity@lbl.gov
X-Mailer: iPhone Mail (13G34)

--Apple-Mail-AFF726B9-603A-4719-BDB5-C331E483A79C
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: quoted-printable

Hi,

From my experiences, attempting to use the NVIDIA drivers on the host was n=
ot the most successful approach. Although first of all, I think it is impor=
tant to distinguish between the CUDA drivers and the NVIDIA drivers. This i=
s made more confusing because the CUDA toolkit wants to install its own ver=
sion of the NVIDIA drivers, but the point is the CUDA drivers are relativel=
y portable while the NVIDIA drivers are not so much.=20

The errors I ran into with the NVIDIA driver (specifically the library libc=
uda.so.352.63) was that there seemed to be a difference between the version=
 of the library that was installed on the cluster and the version of the li=
brary I got from extracting the library without installing the driver (usin=
g the --extract-only option). I think this has to do with the fact that som=
ething is actually compiled when you install the driver, but the point is t=
hat the two versions of the library have different dependencies. And it see=
ms that the version on the cluster depends on some libraries that are insta=
lled on the cluster. Although I did not mess with my singularity install (w=
ith bind path and such) there didn't seem like a good resolution for this b=
ecause the reason we are using singularity is precisely because we want our=
 image to have a newer version of lib.c. Thus, the ability for our image to=
 get the libraries it needs from the host computer is pretty much nonexiste=
nt. Instead, I've set up my image to have multiple version numbers of the l=
ibcuda.so library, and depending on the host machine, the image adds the ap=
propriate driver to LD_LIBRARY_PATH. This isn't the greatest solution, but =
it was the best I could think of.=20

I hope that was helpful, and good luck!

Best,
Nathan

> On Aug 2, 2016, at 11:05 AM, Gregory M. Kurtzer <gmku...@lbl.gov> wrote:
>=20
>=20
>> On Tue, Aug 2, 2016 at 7:58 AM, Igor Yakushin <igor...@gmail.com> wrote:
>> Hi Greg,
>> I got an impression that Nathan was saying that you cannot just copy hos=
t NVIDIA drivers.
>=20
> I'm not sure how "copy-able" the drivers are, but I have the impression t=
hey are compiled against an older version of libC so they should be relativ=
ely portable... I think this is how Nvidia-docker works.
> =20
>> Did I misunderstand it? How do you use "bind path"? Is it a feature of S=
ingularity?
>=20
> "bind path" is in your configuration file (singularity.conf) and will bin=
d files/directories outside the container to inside.
>=20
> =20
>> Also, would this solution be portable? Do you mean that this "bind path"=
 happens dynamically as long as the host has some NVIDIA driver and would w=
ork with any version without having to rebuild the container?
>=20
> That would be the idea yes. It should be as portable as Nvidia's solution=
 (as I understand it) lol. Maybe someone else has more information on this =
who can chime in.
> =20
>> Thank you,
>=20
> My pleasure!
> =20
>> Igor
>>=20
>>> On Tue, Aug 2, 2016 at 9:35 AM, Gregory M. Kurtzer <gmku...@lbl.gov> wr=
ote:
>>> I think the best way of doing this is to have the host provide the CUDA=
 drivers that properly match the kernel drivers that it has installed on th=
e host to a directory. Then use "bind path" to link in those drivers into t=
he container and set the LD_LIBRARY_PATH in /etc/singularity/init to match =
that directory.=20
>>>=20
>>> This feature will be MUCH better when we will be able to link in arbitr=
ary directories into the containers without having to rely on the bind poin=
t existing.=20
>>>=20
>>> Greg
>>>=20
>>>=20
>>>=20
>>>> On Monday, August 1, 2016, Bernard Li <ber...@vanhpc.org> wrote:
>>>> Hi Igor:
>>>>=20
>>>> 352.39 and Tesla K80.
>>>>=20
>>>> Thanks,
>>>>=20
>>>> Bernard
>>>>=20
>>>> On Mon, Aug 1, 2016 at 10:21 PM, Igor Yakushin <igor...@gmail.com> wro=
te:
>>>> > Hi Bernard,
>>>> > What nvidia driver version is on your host?  What card model?
>>>> > Thank you,
>>>> > Igor
>>>> >
>>>> >
>>>> > On Aug 1, 2016 11:55 PM, "Bernard Li" <ber...@vanhpc.org> wrote:
>>>> >>
>>>> >> Hey Igor:
>>>> >>
>>>> >> If you can make the tensorflow Singularity container available, I'd=
 like
>>>> >> to try that out on our cluster.
>>>> >>
>>>> >> Thanks,
>>>> >>
>>>> >> Bernard
>>>> >>
>>>> >> On Monday, 1 August 2016, Igor Yakushin <igor...@gmail.com> wrote:
>>>> >>>
>>>> >>> Hi Nathan,
>>>> >>> The main problem was that if you try to install cuda, it would by =
default
>>>> >>> install driver as well that might be of different version than the=
 driver
>>>> >>> installed with NVIDIA*.run file. So when installing cuda, use an o=
ption not
>>>> >>> to install the driver. It is much easier to find NVIDIA*.run file =
of the
>>>> >>> version you need than cuda*.run with the right driver.  When downl=
oading
>>>> >>> NVIDIA*.run, pay attention that you are asking for Tesla card (if =
that's
>>>> >>> what you have). Consumer cards have different driver (I do not rem=
ember if
>>>> >>> it is reflected in the file name but I suspect not, because I made=
 this
>>>> >>> mistake).
>>>> >>> Thank you,
>>>> >>> Igor
>>>> >>>
>>>> >>>
>>>> >>> On Mon, Aug 1, 2016 at 8:56 AM, Nathan Lin <nathan...@gmail.com>
>>>> >>> wrote:
>>>> >>>>
>>>> >>>> That's great to hear Igor! What ended up being the problem?
>>>> >>>>
>>>> >>>> On Mon, Aug 1, 2016 at 1:43 AM, Rick Wagner <richard...@gmail.com=
>
>>>> >>>> wrote:
>>>> >>>>>
>>>> >>>>> Igor,
>>>> >>>>>
>>>> >>>>> If you had a chance to post your definition file or the steps yo=
u took,
>>>> >>>>> I know several of us would appreciate it. Getting TensorFlow run=
ning on
>>>> >>>>> CentOS was a huge effort for our support staff. And that's just =
one of many
>>>> >>>>> GPU-enabled applications.
>>>> >>>>>
>>>> >>>>> --Rick
>>>> >>>>>
>>>> >>>>> On Jul 31, 2016, at 10:20 PM, Igor Yakushin <igor...@gmail.com>
>>>> >>>>> wrote:
>>>> >>>>>
>>>> >>>>> Thank you, Nathan. It finally works!
>>>> >>>>>
>>>> >>>>> On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin <nathan...@gmail.com=
>
>>>> >>>>> wrote:
>>>> >>>>>>
>>>> >>>>>> Yes I do
>>>> >>>>>>
>>>> >>>>>> On Jul 31, 2016, at 5:03 PM, Igor Yakushin <igor...@gmail.com>
>>>> >>>>>> wrote:
>>>> >>>>>>
>>>> >>>>>> Nathan,
>>>> >>>>>> When you import tensorflow in python, does it tell you what cud=
a
>>>> >>>>>> libraries it is loading or not?
>>>> >>>>>> Do you see these messages:
>>>> >>>>>> =3D=3D=3D=3D=3D=3D
>>>> >>>>>> >>> import tensorflow as tf
>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully op=
ened
>>>> >>>>>> CUDA library libcublas.so locally
>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully op=
ened
>>>> >>>>>> CUDA library libcudnn.so locally
>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully op=
ened
>>>> >>>>>> CUDA library libcufft.so locally
>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully op=
ened
>>>> >>>>>> CUDA library libcuda.so locally
>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully op=
ened
>>>> >>>>>> CUDA library libcurand.so locally
>>>> >>>>>> =3D=3D=3D=3D=3D=3D
>>>> >>>>>> Thank you,
>>>> >>>>>> Igor
>>>> >>>>>>
>>>> >>>>>> On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin <nathan...@gmail.co=
m>
>>>> >>>>>> wrote:
>>>> >>>>>>>
>>>> >>>>>>> Hi Igor,
>>>> >>>>>>>
>>>> >>>>>>> In regards to your first questions, the OS/drivers of your bui=
lding
>>>> >>>>>>> computer should not matter. I built an Ubuntu 14.04 image on m=
y RHEL 7 box
>>>> >>>>>>> for our RHEL 6 cluster. I'm not sure that the toolkit is that =
version
>>>> >>>>>>> specific, my image seems to work fine and it's running 353.63.=
 There is one
>>>> >>>>>>> thing that I do that may be helpful. I read it somewhere onlin=
e and am not
>>>> >>>>>>> actually sure if it does anything, but I've included it in my =
image
>>>> >>>>>>> definitions just in case. Apparently there is something about =
initializing
>>>> >>>>>>> the CUDA Toolkit. As part of my definition file I run 'make' o=
n the CUDA
>>>> >>>>>>> sample 'deviceQuery'. Maybe that will help?
>>>> >>>>>>>
>>>> >>>>>>> Best,
>>>> >>>>>>> Nathan
>>>> >>>>>>>
>>>> >>>>>>> On Jul 31, 2016, at 1:51 PM, Igor Yakushin <igor...@gmail.com>
>>>> >>>>>>> wrote:
>>>> >>>>>>>
>>>> >>>>>>> Hi Nathan,
>>>> >>>>>>> I got a little bit further: nvidia-smi is working now but tens=
orflow
>>>> >>>>>>> still complains:
>>>> >>>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>> >>>>>>>
>>>> >>>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>> >>>>>>> Singularity/ubuntu_14.04.img> nvidia-smi
>>>> >>>>>>> Sun Jul 31 17:33:44 2016
>>>> >>>>>>> +------------------------------------------------------+
>>>> >>>>>>> | NVIDIA-SMI 352.55     Driver Version: 352.55         |
>>>> >>>>>>>
>>>> >>>>>>> |-------------------------------+----------------------+------=
----------------+
>>>> >>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volat=
ile
>>>> >>>>>>> Uncorr. ECC |
>>>> >>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-U=
til
>>>> >>>>>>> Compute M. |
>>>> >>>>>>>
>>>> >>>>>>> |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D|
>>>> >>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>>>> >>>>>>> 0 |
>>>> >>>>>>> | N/A   45C    P0    79W / 235W |    158MiB / 11519MiB |     4=
5%
>>>> >>>>>>> Default |
>>>> >>>>>>>
>>>> >>>>>>> +-------------------------------+----------------------+------=
----------------+
>>>> >>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>>>> >>>>>>> 0 |
>>>> >>>>>>> | N/A   23C    P8    18W / 235W |     61MiB / 11519MiB |      =
0%
>>>> >>>>>>> Default |
>>>> >>>>>>>
>>>> >>>>>>> +-------------------------------+----------------------+------=
----------------+
>>>> >>>>>>>
>>>> >>>>>>>
>>>> >>>>>>> +-------------------------------------------------------------=
----------------+
>>>> >>>>>>> | Processes:
>>>> >>>>>>> GPU Memory |
>>>> >>>>>>> |  GPU       PID  Type  Process name
>>>> >>>>>>> Usage      |
>>>> >>>>>>>
>>>> >>>>>>> |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D|
>>>> >>>>>>>
>>>> >>>>>>> +-------------------------------------------------------------=
----------------+
>>>> >>>>>>> Singularity/ubuntu_14.04.img> python
>>>> >>>>>>> Python 2.7.6 (default, Mar 22 2014, 22:59:56)
>>>> >>>>>>> [GCC 4.8.2] on linux2
>>>> >>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>> >>>>>>> information.
>>>> >>>>>>> >>> import tensorflow
>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully o=
pened
>>>> >>>>>>> CUDA library libcublas.so locally
>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully o=
pened
>>>> >>>>>>> CUDA library libcudnn.so locally
>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully o=
pened
>>>> >>>>>>> CUDA library libcufft.so locally
>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully o=
pened
>>>> >>>>>>> CUDA library libcuda.so.1 locally
>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully o=
pened
>>>> >>>>>>> CUDA library libcurand.so locally
>>>> >>>>>>> >>> ss =3D tensorflow.Session()
>>>> >>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed c=
all to
>>>> >>>>>>> cuInit: CUDA_ERROR_NO_DEVICE
>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] ret=
rieving
>>>> >>>>>>> CUDA diagnostic information for host: midway-l34-02
>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hos=
tname:
>>>> >>>>>>> midway-l34-02
>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] lib=
cuda
>>>> >>>>>>> reported version is: 352.93.0
>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] dri=
ver
>>>> >>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Ker=
nel Module
>>>> >>>>>>> 352.55  Thu Oct  8 15:18:00 PDT 2015
>>>> >>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (G=
CC)
>>>> >>>>>>> """
>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] ker=
nel
>>>> >>>>>>> reported version is: 352.55.0
>>>> >>>>>>> E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:296] ker=
nel
>>>> >>>>>>> version 352.55.0 does not match DSO version 352.93.0 -- cannot=
 find working
>>>> >>>>>>> devices in this configuration
>>>> >>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU de=
vices
>>>> >>>>>>> available on machine.
>>>> >>>>>>> >>>
>>>> >>>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>> >>>>>>> As far as I understand the problem is that cuda-7.5 was built =
or
>>>> >>>>>>> relies on nvidia 352.93 while I have NVIDIA driver 352.55 both=
 on the host
>>>> >>>>>>> and container. So far I could not find cuda-7.5 built with 352=
.55.
>>>> >>>>>>> cuda-7.5 has stabs directory in which there is libcuda.so. The
>>>> >>>>>>> problem is probably coming from there. However, I doubt I can =
just replace
>>>> >>>>>>> libcuda.so in the stubs directory by a different version or tu=
rn it into
>>>> >>>>>>> symbolic link to a different version in the driver? Because it=
s size is much
>>>> >>>>>>> smaller than the size of the real libcuda.so in the driver. So=
 I suspect, it
>>>> >>>>>>> is really only some kind of interface to the real library?
>>>> >>>>>>>
>>>> >>>>>>> Thank you,
>>>> >>>>>>> Igor
>>>> >>>>>>>
>>>> >>>>>>>
>>>> >>>>>>> On Sun, Jul 31, 2016 at 9:36 AM, Igor Yakushin <igor...@gmail.=
com>
>>>> >>>>>>> wrote:
>>>> >>>>>>>>
>>>> >>>>>>>> Hi Nathan,
>>>> >>>>>>>> When installing cuda libraries and tensorflow into the singul=
arity
>>>> >>>>>>>> image, is it important to be on the same host with the same v=
ersion of
>>>> >>>>>>>> CUDA/OS on which you are going to run later?
>>>> >>>>>>>> I do not have root on the machine I am going to run later and
>>>> >>>>>>>> prepare the image on a different machine with a different ver=
sion of nvidia
>>>> >>>>>>>> driver and a different flavor of Linux.
>>>> >>>>>>>> Thank you,
>>>> >>>>>>>> Igor
>>>> >>>>>>>>
>>>> >>>>>>>>
>>>> >>>>>>>> On Sun, Jul 31, 2016 at 8:39 AM, Nathan Lin
>>>> >>>>>>>> <nathan...@gmail.com> wrote:
>>>> >>>>>>>>>
>>>> >>>>>>>>> Hi Igor,
>>>> >>>>>>>>>
>>>> >>>>>>>>> I don't necessarily have a great answer for you. If seems li=
ke you
>>>> >>>>>>>>> are doing everything right, yet it is still not working. In =
my case, yes
>>>> >>>>>>>>> nvidia-smi as well as TensorFlow both work correctly. I feel=
 like your error
>>>> >>>>>>>>> still has to do with the version of libcuda.so you are using=
. Notice how
>>>> >>>>>>>>> Python seems to correctly load libcuda.so, yet there is late=
r an error that
>>>> >>>>>>>>> is unable to find libcuda.so. My first suspicion is that the=
re is still a
>>>> >>>>>>>>> version mismatch between the drivers installed on the image =
and on the host.
>>>> >>>>>>>>> If you are sure that is not true, it may be possible that th=
e version of the
>>>> >>>>>>>>> driver that is installed on the machine isn't new enough for=
 the GPU. That
>>>> >>>>>>>>> actually occurred on our cluster, and after a sysadmin updat=
ed the driver,
>>>> >>>>>>>>> it worked. Barring that I am not too sure. Maybe if you prov=
ide me with the
>>>> >>>>>>>>> full details of your installation (the versions of the packa=
ges that you
>>>> >>>>>>>>> have installed, the OS of your image and host), I might be a=
ble to think
>>>> >>>>>>>>> about something, but my suspicion is that the driver version=
 on your host
>>>> >>>>>>>>> machine may not be new enough.
>>>> >>>>>>>>>
>>>> >>>>>>>>> Best,
>>>> >>>>>>>>> Nathan
>>>> >>>>>>>>>
>>>> >>>>>>>>> On Jul 31, 2016, at 12:17 AM, Igor Yakushin <igor...@gmail.c=
om>
>>>> >>>>>>>>> wrote:
>>>> >>>>>>>>>
>>>> >>>>>>>>> Hi Nathan,
>>>> >>>>>>>>>
>>>> >>>>>>>>> I have found exactly the same version of NVIDIA driver and
>>>> >>>>>>>>> extracted from it the libraries and nvidia executables and c=
opied them in
>>>> >>>>>>>>> /usr/lib64/nvidia and /usr/bin and created the corresponding=
 symbolic links.
>>>> >>>>>>>>> However, I still cannot use GPU inside singularity: nvidia-s=
mi says "GPU
>>>> >>>>>>>>> access blocked by the operating system" (does it work in you=
r case?) and
>>>> >>>>>>>>> when tensorflow session starts it also complains that "No GP=
U devices
>>>> >>>>>>>>> available on machine". However, notice that tensorflow seems=
 to think that a
>>>> >>>>>>>>> different version of NVIDIA driver is used. Not sure where i=
t is coming
>>>> >>>>>>>>> from. The machine on which the image was built has version 3=
61.42
>>>> >>>>>>>>>
>>>> >>>>>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>> >>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>> >>>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>> >>>>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>> >>>>>>>>> information.
>>>> >>>>>>>>> >>> import tensorflow
>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened
>>>> >>>>>>>>> CUDA library libcublas.so locally
>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened
>>>> >>>>>>>>> CUDA library libcudnn.so locally
>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened
>>>> >>>>>>>>> CUDA library libcufft.so locally
>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened
>>>> >>>>>>>>> CUDA library libcuda.so locally
>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened
>>>> >>>>>>>>> CUDA library libcurand.so locally
>>>> >>>>>>>>> >>> ss =3D tensorflow.Session()
>>>> >>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed=
 call
>>>> >>>>>>>>> to cuInit: CUDA_ERROR_UNKNOWN
>>>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>> >>>>>>>>> retrieving CUDA diagnostic information for host: midway230
>>>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>>>> >>>>>>>>> hostname: midway230
>>>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] l=
ibcuda
>>>> >>>>>>>>> reported version is: Not found: was unable to find libcuda.s=
o DSO loaded
>>>> >>>>>>>>> into this program
>>>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] d=
river
>>>> >>>>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 K=
ernel Module
>>>> >>>>>>>>> 352.55  Thu Oct  8 15:18:00 PDT 2015
>>>> >>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) =
(GCC)
>>>> >>>>>>>>> """
>>>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] k=
ernel
>>>> >>>>>>>>> reported version is: 352.55.0
>>>> >>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU =
devices
>>>> >>>>>>>>> available on machine.
>>>> >>>>>>>>> >>>
>>>> >>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>> >>>>>>>>> Failed to initialize NVML: GPU access blocked by the operati=
ng
>>>> >>>>>>>>> system
>>>> >>>>>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>> >>>>>>>>>
>>>> >>>>>>>>> Thank you,
>>>> >>>>>>>>> Igor
>>>> >>>>>>>>>
>>>> >>>>>>>>>
>>>> >>>>>>>>> On Thu, Jul 28, 2016 at 9:34 PM, Nathan Lin
>>>> >>>>>>>>> <nathan...@gmail.com> wrote:
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> I am not sure how to find the correct driver version, but f=
rom my
>>>> >>>>>>>>>> testing, the version must match exactly. I will admit that =
I have had
>>>> >>>>>>>>>> problems finding specific versions of the driver from NVIDI=
A's website. I
>>>> >>>>>>>>>> had to ask a sysadmin for the installer that they used. In =
order to extract
>>>> >>>>>>>>>> the files, you need to use the --extract-only option. For i=
nstance, you will
>>>> >>>>>>>>>> have to run something like ' sh /NVIDIA-Linux-x86_64-352.63=
.run
>>>> >>>>>>>>>> --extract-only'/ . You will then be given a directory with =
all the libraries
>>>> >>>>>>>>>> that would have been installed. You will need to copy the l=
ibcuda.so.###.##
>>>> >>>>>>>>>> library (and you can copy any NVIDIA executables that you w=
ant such as
>>>> >>>>>>>>>> nvidia-smi). Good luck!
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> On Thu, Jul 28, 2016 at 8:51 PM, Igor <igor...@gmail.com> w=
rote:
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> I mean I am using this file from NVIDIA website
>>>> >>>>>>>>>>> cuda_7.5.18_linux.run to install the driver, opengl, cuda.=
 Driver
>>>> >>>>>>>>>>> installation fails, cuda succeeds.
>>>> >>>>>>>>>>> Also, when I run
>>>> >>>>>>>>>>> sh cuda_7.5.18_linux.run
>>>> >>>>>>>>>>> I am offered to install the driver version 352.39 while on=
 the
>>>> >>>>>>>>>>> host it is 346.47. I cannot upgrade the host. Any idea whe=
re I can get
>>>> >>>>>>>>>>> 346.17?
>>>> >>>>>>>>>>> I tried using the same link just substitute 18 for somethi=
ng else
>>>> >>>>>>>>>>> but have not found the files:
>>>> >>>>>>>>>>> wget
>>>> >>>>>>>>>>> http://developer.download.nvidia.com/compute/cuda/7.5/Prod=
/local_installers/cuda_7.5.1X_linux.run
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote=
:
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> Hi Nathan,
>>>> >>>>>>>>>>>> When I try to install the driver by running NVIDIA*.run s=
cript
>>>> >>>>>>>>>>>> inside the image, it fails, probably because it tries to =
modify kernel that
>>>> >>>>>>>>>>>> belongs to host?
>>>> >>>>>>>>>>>> How do I extract just libcuda.so.345.67 without installin=
g the
>>>> >>>>>>>>>>>> driver (which is obviously problematic) and why would cop=
ying the library
>>>> >>>>>>>>>>>> from the host would not work?
>>>> >>>>>>>>>>>> Thank you,
>>>> >>>>>>>>>>>> Igor
>>>> >>>>>>>>>>>>
>>>> >>>>>>>>>>>> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Li=
n
>>>> >>>>>>>>>>>> wrote:
>>>> >>>>>>>>>>>>>
>>>> >>>>>>>>>>>>> Also if you are using the binary installation of TensorF=
low you
>>>> >>>>>>>>>>>>> need CUDA toolkit 7.5 and cuDNN v4. These only need to b=
e installed on our
>>>> >>>>>>>>>>>>> image. As I mentioned earlier you will need the libcuda.=
so.###.## library on
>>>> >>>>>>>>>>>>> your image. It is very important that this is the same v=
ersion of the NVIDIA
>>>> >>>>>>>>>>>>> driver as you have on your nose (seemingly 346.67 for yo=
u). I should've have
>>>> >>>>>>>>>>>>> also mentioned that you want the libcuda.so.345.67 libra=
ry that you get from
>>>> >>>>>>>>>>>>> extracting the NVIDIA installer. It will not work if you=
 try to copy the
>>>> >>>>>>>>>>>>> libcuda.so library that from you node.
>>>> >>>>>>>>>>>>>
>>>> >>>>>>>>>>>>> Let me know if you have any more questions.
>>>> >>>>>>>>>>>>>
>>>> >>>>>>>>>>>>> Best,
>>>> >>>>>>>>>>>>> Nathan
>>>> >>>>>>>>>>>>>
>>>> >>>>>>>>>>>>> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com=
>
>>>> >>>>>>>>>>>>> wrote:
>>>> >>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>> Hello,
>>>> >>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>> Yes you are correct. The NVIDIA driver must be installe=
d on
>>>> >>>>>>>>>>>>>> your image as well. However, you honestly only need the=
 libcuda.so.###.##
>>>> >>>>>>>>>>>>>> library and the appropriate links for that library. Onc=
e you have those
>>>> >>>>>>>>>>>>>> installed in your image, it should work.
>>>> >>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>> Best,
>>>> >>>>>>>>>>>>>> Nathan
>>>> >>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>> On Thursday, July 28, 2016, Igor <igor...@gmail.com> wr=
ote:
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> Hi All,
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> I am trying to use GPU-enabled tensorflow and it canno=
t find
>>>> >>>>>>>>>>>>>>> GPU card from inside the container.
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> On the host:
>>>> >>>>>>>>>>>>>>> $ lspci | grep -i nvidia
>>>> >>>>>>>>>>>>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Te=
sla
>>>> >>>>>>>>>>>>>>> K40m] (rev a1)
>>>> >>>>>>>>>>>>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Te=
sla
>>>> >>>>>>>>>>>>>>> K40m] (rev a1)
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> $ nvidia-smi
>>>> >>>>>>>>>>>>>>> Thu Jul 28 19:01:42 2016
>>>> >>>>>>>>>>>>>>> +-----------------------------------------------------=
-+
>>>> >>>>>>>>>>>>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47        =
 |
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> |-------------------------------+---------------------=
-+----------------------+
>>>> >>>>>>>>>>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A=
 |
>>>> >>>>>>>>>>>>>>> Volatile Uncorr. ECC |
>>>> >>>>>>>>>>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage=
 |
>>>> >>>>>>>>>>>>>>> GPU-Util  Compute M. |
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|
>>>> >>>>>>>>>>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off=
 |
>>>> >>>>>>>>>>>>>>> 0 |
>>>> >>>>>>>>>>>>>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB=
 |
>>>> >>>>>>>>>>>>>>> 0%      Default |
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> +-------------------------------+---------------------=
-+----------------------+
>>>> >>>>>>>>>>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off=
 |
>>>> >>>>>>>>>>>>>>> 0 |
>>>> >>>>>>>>>>>>>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB=
 |
>>>> >>>>>>>>>>>>>>> 0%      Default |
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> +-------------------------------+---------------------=
-+----------------------+
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> +-----------------------------------------------------=
------------------------+
>>>> >>>>>>>>>>>>>>> | Processes:
>>>> >>>>>>>>>>>>>>> GPU Memory |
>>>> >>>>>>>>>>>>>>> |  GPU       PID  Type  Process name
>>>> >>>>>>>>>>>>>>> Usage      |
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|
>>>> >>>>>>>>>>>>>>> |    0     11671    G   /usr/bin/X
>>>> >>>>>>>>>>>>>>> 9MiB |
>>>> >>>>>>>>>>>>>>> |    1     11671    G   /usr/bin/X
>>>> >>>>>>>>>>>>>>> 3MiB |
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> Inside singularity:
>>>> >>>>>>>>>>>>>>> $ singularity shell
>>>> >>>>>>>>>>>>>>> /software/src/singularity_images/tensorflow_0.9.img
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia
>>>> >>>>>>>>>>>>>>> bash: lspci: command not found
>>>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>> >>>>>>>>>>>>>>> bash: nvidia-smi: command not found
>>>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> python
>>>> >>>>>>>>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>> >>>>>>>>>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>> >>>>>>>>>>>>>>> Type "help", "copyright", "credits" or "license" for m=
ore
>>>> >>>>>>>>>>>>>>> information.
>>>> >>>>>>>>>>>>>>> >>> import tensorflow as tf
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] succes=
sfully
>>>> >>>>>>>>>>>>>>> opened CUDA library libcublas.so locally
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] succes=
sfully
>>>> >>>>>>>>>>>>>>> opened CUDA library libcudnn.so locally
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] succes=
sfully
>>>> >>>>>>>>>>>>>>> opened CUDA library libcufft.so locally
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] succes=
sfully
>>>> >>>>>>>>>>>>>>> opened CUDA library libcuda.so locally
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] succes=
sfully
>>>> >>>>>>>>>>>>>>> opened CUDA library libcurand.so locally
>>>> >>>>>>>>>>>>>>> >>> sess =3D tf.Session()
>>>> >>>>>>>>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] =
failed
>>>> >>>>>>>>>>>>>>> call to cuInit: CUDA_ERROR_UNKNOWN
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:=
153]
>>>> >>>>>>>>>>>>>>> retrieving CUDA diagnostic information for host: midwa=
y-l34-01
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:=
160]
>>>> >>>>>>>>>>>>>>> hostname: midway-l34-01
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:=
185]
>>>> >>>>>>>>>>>>>>> libcuda reported version is: Not found: was unable to =
find libcuda.so DSO
>>>> >>>>>>>>>>>>>>> loaded into this program
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:=
347]
>>>> >>>>>>>>>>>>>>> driver version file contents: """NVRM version: NVIDIA =
UNIX x86_64 Kernel
>>>> >>>>>>>>>>>>>>> Module  346.47  Thu Feb 19 18:56:03 PST 2015
>>>> >>>>>>>>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.=
7-11)
>>>> >>>>>>>>>>>>>>> (GCC)
>>>> >>>>>>>>>>>>>>> """
>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:=
189]
>>>> >>>>>>>>>>>>>>> kernel reported version is: 346.47.0
>>>> >>>>>>>>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] N=
o GPU
>>>> >>>>>>>>>>>>>>> devices available on machine.
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> Must there be nvidia driver installed inside the conta=
iner?
>>>> >>>>>>>>>>>>>>> Outside? The container shares the same kernel with the=
 host and nvidia
>>>> >>>>>>>>>>>>>>> kernel module needs to be loaded... How this is handle=
d? Any requirements on
>>>> >>>>>>>>>>>>>>> nvidia driver and cuda versions inside and outside of =
the container?
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> Thank you,
>>>> >>>>>>>>>>>>>>> Igor
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>>
>>>> >>>>>>>>>>>>>>> --
>>>> >>>>>>>>>>>>>>> You received this message because you are subscribed t=
o the
>>>> >>>>>>>>>>>>>>> Google Groups "singularity" group.
>>>> >>>>>>>>>>>>>>> To unsubscribe from this group and stop receiving emai=
ls from
>>>> >>>>>>>>>>>>>>> it, send an email to singu...@lbl.gov.
>>>> >>>>>>>>>>>
>>>> >>>>>>>>>>> --
>>>> >>>>>>>>>>> You received this message because you are subscribed to th=
e
>>>> >>>>>>>>>>> Google Groups "singularity" group.
>>>> >>>>>>>>>>> To unsubscribe from this group and stop receiving emails f=
rom it,
>>>> >>>>>>>>>>> send an email to singu...@lbl.gov.
>>>> >>>>>>>>>>
>>>> >>>>>>>>>>
>>>> >>>>>>>>>> --
>>>> >>>>>>>>>> You received this message because you are subscribed to the=
 Google
>>>> >>>>>>>>>> Groups "singularity" group.
>>>> >>>>>>>>>> To unsubscribe from this group and stop receiving emails fr=
om it,
>>>> >>>>>>>>>> send an email to singu...@lbl.gov.
>>>> >>>>>>>>>
>>>> >>>>>>>>>
>>>> >>>>>>>>> --
>>>> >>>>>>>>> You received this message because you are subscribed to the =
Google
>>>> >>>>>>>>> Groups "singularity" group.
>>>> >>>>>>>>> To unsubscribe from this group and stop receiving emails fro=
m it,
>>>> >>>>>>>>> send an email to singu...@lbl.gov.
>>>> >>>>>>>>>
>>>> >>>>>>>>> --
>>>> >>>>>>>>> You received this message because you are subscribed to the =
Google
>>>> >>>>>>>>> Groups "singularity" group.
>>>> >>>>>>>>> To unsubscribe from this group and stop receiving emails fro=
m it,
>>>> >>>>>>>>> send an email to singu...@lbl.gov.
>>>> >>>>>>>>
>>>> >>>>>>>>
>>>> >>>>>>>
>>>> >>>>>>> --
>>>> >>>>>>> You received this message because you are subscribed to the Go=
ogle
>>>> >>>>>>> Groups "singularity" group.
>>>> >>>>>>> To unsubscribe from this group and stop receiving emails from =
it,
>>>> >>>>>>> send an email to singu...@lbl.gov.
>>>> >>>>>>>
>>>> >>>>>>> --
>>>> >>>>>>> You received this message because you are subscribed to the Go=
ogle
>>>> >>>>>>> Groups "singularity" group.
>>>> >>>>>>> To unsubscribe from this group and stop receiving emails from =
it,
>>>> >>>>>>> send an email to singu...@lbl.gov.
>>>> >>>>>>
>>>> >>>>>>
>>>> >>>>>> --
>>>> >>>>>> You received this message because you are subscribed to the Goo=
gle
>>>> >>>>>> Groups "singularity" group.
>>>> >>>>>> To unsubscribe from this group and stop receiving emails from i=
t, send
>>>> >>>>>> an email to singu...@lbl.gov.
>>>> >>>>>>
>>>> >>>>>> --
>>>> >>>>>> You received this message because you are subscribed to the Goo=
gle
>>>> >>>>>> Groups "singularity" group.
>>>> >>>>>> To unsubscribe from this group and stop receiving emails from i=
t, send
>>>> >>>>>> an email to singu...@lbl.gov.
>>>> >>>>>
>>>> >>>>>
>>>> >>>>> --
>>>> >>>>> You received this message because you are subscribed to the Goog=
le
>>>> >>>>> Groups "singularity" group.
>>>> >>>>> To unsubscribe from this group and stop receiving emails from it=
, send
>>>> >>>>> an email to singu...@lbl.gov.
>>>> >>>>>
>>>> >>>>> --
>>>> >>>>> You received this message because you are subscribed to the Goog=
le
>>>> >>>>> Groups "singularity" group.
>>>> >>>>> To unsubscribe from this group and stop receiving emails from it=
, send
>>>> >>>>> an email to singu...@lbl.gov.
>>>> >>>>
>>>> >>>>
>>>> >>>> --
>>>> >>>> You received this message because you are subscribed to the Googl=
e
>>>> >>>> Groups "singularity" group.
>>>> >>>> To unsubscribe from this group and stop receiving emails from it,=
 send
>>>> >>>> an email to singu...@lbl.gov.
>>>> >>>
>>>> >>>
>>>> >>> --
>>>> >>> You received this message because you are subscribed to the Google=
 Groups
>>>> >>> "singularity" group.
>>>> >>> To unsubscribe from this group and stop receiving emails from it, =
send an
>>>> >>> email to singu...@lbl.gov.
>>>> >>
>>>> >> --
>>>> >> You received this message because you are subscribed to the Google =
Groups
>>>> >> "singularity" group.
>>>> >> To unsubscribe from this group and stop receiving emails from it, s=
end an
>>>> >> email to singu...@lbl.gov.
>>>> >
>>>> > --
>>>> > You received this message because you are subscribed to the Google G=
roups
>>>> > "singularity" group.
>>>> > To unsubscribe from this group and stop receiving emails from it, se=
nd an
>>>> > email to singu...@lbl.gov.
>>>>=20
>>>> --
>>>> You received this message because you are subscribed to the Google Gro=
ups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send=
 an email to singu...@lbl.gov.
>>>=20
>>>=20
>>> --=20
>>> Gregory M. Kurtzer
>>> High Performance Computing Services (HPCS)
>>> University of California
>>> Lawrence Berkeley National Laboratory
>>> One Cyclotron Road, Berkeley, CA 94720
>>>=20
>>> --=20
>>> You received this message because you are subscribed to the Google Grou=
ps "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send =
an email to singu...@lbl.gov.
>>=20
>> --=20
>> You received this message because you are subscribed to the Google Group=
s "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n email to singu...@lbl.gov.
>=20
>=20
>=20
> --=20
> Gregory M. Kurtzer
> High Performance Computing Services (HPCS)
> University of California
> Lawrence Berkeley National Laboratory
> One Cyclotron Road, Berkeley, CA 94720
> --=20
> You received this message because you are subscribed to the Google Groups=
 "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an=
 email to singu...@lbl.gov.

--Apple-Mail-AFF726B9-603A-4719-BDB5-C331E483A79C
Content-Type: text/html;
	charset=utf-8
Content-Transfer-Encoding: quoted-printable

<html><head><meta http-equiv=3D"content-type" content=3D"text/html; charset=
=3Dutf-8"></head><body dir=3D"auto"><div></div><div>Hi,</div><div><br></div=
><div>From my experiences, attempting to use the NVIDIA drivers on the host=
 was not the most successful approach. Although first of all, I think it is=
 important to distinguish between the CUDA drivers and the NVIDIA drivers. =
This is made more confusing because the CUDA toolkit wants to install its o=
wn version of the NVIDIA drivers, but the point is the CUDA drivers are rel=
atively portable while the NVIDIA drivers are not so much.&nbsp;</div><div>=
<br></div><div>The errors I ran into with the NVIDIA driver (specifically t=
he library libcuda.so.352.63) was that there seemed to be a difference betw=
een the version of the library that was installed on the cluster and the ve=
rsion of the library I got from extracting the library without installing t=
he driver (using the --extract-only option). I think this has to do with th=
e fact that something is actually compiled when you install the driver, but=
 the point is that the two versions of the library have different dependenc=
ies. And it seems that the version on the cluster depends on some libraries=
 that are installed on the cluster. Although I did not mess with my singula=
rity install (with bind path and such) there didn't seem like a good resolu=
tion for this because the reason we are using singularity is precisely beca=
use we want our image to have a newer version of lib.c. Thus, the ability f=
or our image to get the libraries it needs from the host computer is pretty=
 much nonexistent. Instead, I've set up my image to have multiple version n=
umbers of the libcuda.so library, and depending on the host machine, the im=
age adds the appropriate driver to LD_LIBRARY_PATH. This isn't the greatest=
 solution, but it was the best I could think of.&nbsp;</div><div><br></div>=
<div>I hope that was helpful, and good luck!</div><div><br></div><div>Best,=
</div><div>Nathan</div><div><br>On Aug 2, 2016, at 11:05 AM, Gregory M. Kur=
tzer &lt;<a href=3D"mailto:gmku...@lbl.gov">gmku...@lbl.gov</a>&gt; wrote:<=
br><br></div><blockquote type=3D"cite"><div><div dir=3D"ltr"><div><br></div=
><div class=3D"gmail_extra"><div class=3D"gmail_quote">On Tue, Aug 2, 2016 =
at 7:58 AM, Igor Yakushin <span dir=3D"ltr">&lt;<a href=3D"mailto:igor...@g=
mail.com" target=3D"_blank">igor...@gmail.com</a>&gt;</span> wrote:<br><blo=
ckquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left=
-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);paddi=
ng-left:1ex"><div dir=3D"ltr">Hi Greg,<div>I got an impression that Nathan =
was saying that you cannot just copy host NVIDIA drivers. </div></div></blo=
ckquote><div><br></div><div><div>I'm not sure how "copy-able" the drivers a=
re, but I have the impression they are compiled against an older version of=
 libC so they should be relatively portable... I think this is how Nvidia-d=
ocker works.</div></div><div>&nbsp;</div><blockquote class=3D"gmail_quote" =
style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:s=
olid;border-left-color:rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr">=
<div>Did I misunderstand it? How do you use "bind path"? Is it a feature of=
 Singularity?</div></div></blockquote><div><br></div><div><div>"bind path" =
is in your configuration file (singularity.conf) and will bind files/direct=
ories outside the container to inside.</div></div><div><br></div><div>&nbsp=
;</div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;=
border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204=
,204);padding-left:1ex"><div dir=3D"ltr"><div>Also, would this solution be =
portable? Do you mean that this "bind path" happens dynamically as long as =
the host has some NVIDIA driver and would work with any version without hav=
ing to rebuild the container?</div></div></blockquote><div><br></div><div>T=
hat would be the idea yes. It should be as portable as Nvidia's solution (a=
s I understand it) lol. Maybe someone else has more information on this who=
 can chime in.</div><div>&nbsp;</div><blockquote class=3D"gmail_quote" styl=
e=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid=
;border-left-color:rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"><div=
>Thank you,</div></div></blockquote><div><br></div><div>My pleasure!</div><=
div>&nbsp;</div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0=
px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rg=
b(204,204,204);padding-left:1ex"><div dir=3D"ltr"><div>Igor</div></div><div=
 class=3D"gmail-HOEnZb"><div class=3D"gmail-h5"><div class=3D"gmail_extra">=
<br><div class=3D"gmail_quote">On Tue, Aug 2, 2016 at 9:35 AM, Gregory M. K=
urtzer <span dir=3D"ltr">&lt;<a href=3D"mailto:gmku...@lbl.gov" target=3D"_=
blank">gmku...@lbl.gov</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_=
quote" style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-=
style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">I think th=
e best way of doing this is to have the host provide the CUDA drivers that =
properly match the kernel drivers that it has installed on the host to a di=
rectory. Then use&nbsp;"bind path" to link in&nbsp;those drivers into the c=
ontainer and set the LD_LIBRARY_PATH in /etc/singularity/init to match that=
 directory.&nbsp;<div><br></div><div>This feature will be MUCH better when =
we will be able to link in arbitrary directories into the containers withou=
t having to rely on the bind point existing.&nbsp;</div><div><br></div>Greg=
<div><div><div><br></div><div><span></span><br><div><br>On Monday, August 1=
, 2016, Bernard Li &lt;<a href=3D"mailto:ber...@vanhpc.org" target=3D"_blan=
k">ber...@vanhpc.org</a>&gt; wrote:<br><blockquote class=3D"gmail_quote" st=
yle=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:sol=
id;border-left-color:rgb(204,204,204);padding-left:1ex">Hi Igor:<br>
<br>
352.39 and Tesla K80.<br>
<br>
Thanks,<br>
<br>
Bernard<br>
<br>
On Mon, Aug 1, 2016 at 10:21 PM, Igor Yakushin &lt;<a>igor...@gmail.com</a>=
&gt; wrote:<br>
&gt; Hi Bernard,<br>
&gt; What nvidia driver version is on your host?&nbsp; What card model?<br>
&gt; Thank you,<br>
&gt; Igor<br>
&gt;<br>
&gt;<br>
&gt; On Aug 1, 2016 11:55 PM, "Bernard Li" &lt;<a>ber...@vanhpc.org</a>&gt;=
 wrote:<br>
&gt;&gt;<br>
&gt;&gt; Hey Igor:<br>
&gt;&gt;<br>
&gt;&gt; If you can make the tensorflow Singularity container available, I'=
d like<br>
&gt;&gt; to try that out on our cluster.<br>
&gt;&gt;<br>
&gt;&gt; Thanks,<br>
&gt;&gt;<br>
&gt;&gt; Bernard<br>
&gt;&gt;<br>
&gt;&gt; On Monday, 1 August 2016, Igor Yakushin &lt;<a>igor...@gmail.com</=
a>&gt; wrote:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt; The main problem was that if you try to install cuda, it would=
 by default<br>
&gt;&gt;&gt; install driver as well that might be of different version than=
 the driver<br>
&gt;&gt;&gt; installed with NVIDIA*.run file. So when installing cuda, use =
an option not<br>
&gt;&gt;&gt; to install the driver. It is much easier to find NVIDIA*.run f=
ile of the<br>
&gt;&gt;&gt; version you need than cuda*.run with the right driver.&nbsp; W=
hen downloading<br>
&gt;&gt;&gt; NVIDIA*.run, pay attention that you are asking for Tesla card =
(if that's<br>
&gt;&gt;&gt; what you have). Consumer cards have different driver (I do not=
 remember if<br>
&gt;&gt;&gt; it is reflected in the file name but I suspect not, because I =
made this<br>
&gt;&gt;&gt; mistake).<br>
&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; On Mon, Aug 1, 2016 at 8:56 AM, Nathan Lin &lt;<a>nathan...@gm=
ail.com</a>&gt;<br>
&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; That's great to hear Igor! What ended up being the problem=
?<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; On Mon, Aug 1, 2016 at 1:43 AM, Rick Wagner &lt;<a>richard=
...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; Igor,<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; If you had a chance to post your definition file or th=
e steps you took,<br>
&gt;&gt;&gt;&gt;&gt; I know several of us would appreciate it. Getting Tens=
orFlow running on<br>
&gt;&gt;&gt;&gt;&gt; CentOS was a huge effort for our support staff. And th=
at's just one of many<br>
&gt;&gt;&gt;&gt;&gt; GPU-enabled applications.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --Rick<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; On Jul 31, 2016, at 10:20 PM, Igor Yakushin &lt;<a>igo=
r...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; Thank you, Nathan. It finally works!<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin &lt;<a>nat=
han...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; Yes I do<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; On Jul 31, 2016, at 5:03 PM, Igor Yakushin &lt;<a>=
igor...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt; When you import tensorflow in python, does it tell=
 you what cuda<br>
&gt;&gt;&gt;&gt;&gt;&gt; libraries it is loading or not?<br>
&gt;&gt;&gt;&gt;&gt;&gt; Do you see these messages:<br>
&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; import tensorflow as tf<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcublas.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcudnn.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcufft.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcuda.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcurand.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin &lt;<a=
>nathan...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Igor,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; In regards to your first questions, the OS/dri=
vers of your building<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; computer should not matter. I built an Ubuntu =
14.04 image on my RHEL 7 box<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; for our RHEL 6 cluster. I'm not sure that the =
toolkit is that version<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; specific, my image seems to work fine and it's=
 running 353.63. There is one<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; thing that I do that may be helpful. I read it=
 somewhere online and am not<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; actually sure if it does anything, but I've in=
cluded it in my image<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; definitions just in case. Apparently there is =
something about initializing<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; the CUDA Toolkit. As part of my definition fil=
e I run 'make' on the CUDA<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; sample 'deviceQuery'. Maybe that will help?<br=
>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Best,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Nathan<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Jul 31, 2016, at 1:51 PM, Igor Yakushin &lt=
;<a>igor...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I got a little bit further: nvidia-smi is work=
ing now but tensorflow<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; still complains:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/ubuntu_14.04.img&gt; nvidia-smi<br=
>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Sun Jul 31 17:33:44 2016<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +---------------------------------------------=
---------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | NVIDIA-SMI 352.55&nbsp; &nbsp; &nbsp;Driver =
Version: 352.55&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |-------------------------------+-------------=
---------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | GPU&nbsp; Name&nbsp; &nbsp; &nbsp; &nbsp; Pe=
rsistence-M| Bus-Id&nbsp; &nbsp; &nbsp; &nbsp; Disp.A | Volatile<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Uncorr. ECC |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | Fan&nbsp; Temp&nbsp; Perf&nbsp; Pwr:Usage/Ca=
p|&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Memory-Usage | GPU-Util<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Compute M. |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |&nbsp; &nbsp;0&nbsp; Tesla K40m&nbsp; &nbsp; =
&nbsp; &nbsp; &nbsp; Off&nbsp; | 0000:20:00.0&nbsp; &nbsp; &nbsp;Off |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | N/A&nbsp; &nbsp;45C&nbsp; &nbsp; P0&nbsp; &n=
bsp; 79W / 235W |&nbsp; &nbsp; 158MiB / 11519MiB |&nbsp; &nbsp; &nbsp;45%<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Default |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------------------------+-------------=
---------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |&nbsp; &nbsp;1&nbsp; Tesla K40m&nbsp; &nbsp; =
&nbsp; &nbsp; &nbsp; Off&nbsp; | 0000:8B:00.0&nbsp; &nbsp; &nbsp;Off |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | N/A&nbsp; &nbsp;23C&nbsp; &nbsp; P8&nbsp; &n=
bsp; 18W / 235W |&nbsp; &nbsp; &nbsp;61MiB / 11519MiB |&nbsp; &nbsp; &nbsp;=
 0%<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Default |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------------------------+-------------=
---------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +---------------------------------------------=
--------------------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | Processes:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; GPU Memory |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |&nbsp; GPU&nbsp; &nbsp; &nbsp; &nbsp;PID&nbsp=
; Type&nbsp; Process name<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Usage&nbsp; &nbsp; &nbsp; |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +---------------------------------------------=
--------------------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/ubuntu_14.04.img&gt; python<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Python 2.7.6 (default, Mar 22 2014, 22:59:56)<=
br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; [GCC 4.8.2] on linux2<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Type "help", "copyright", "credits" or "licens=
e" for more<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; information.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; import tensorflow<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcublas.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcudnn.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcufft.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcuda.so.1 locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcurand.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; ss =3D tensorflow.Session()<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; E tensorflow/stream_executor/cuda/cuda_driver.=
cc:491] failed call to<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; cuInit: CUDA_ERROR_NO_DEVICE<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:153] retrieving<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA diagnostic information for host: midway-l=
34-02<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:160] hostname:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; midway-l34-02<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:185] libcuda<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; reported version is: 352.93.0<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:356] driver<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; version file contents: """NVRM version: NVIDIA=
 UNIX x86_64 Kernel Module<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 352.55&nbsp; Thu Oct&nbsp; 8 15:18:00 PDT 2015=
<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; GCC version:&nbsp; gcc version 4.4.7 20120313 =
(Red Hat 4.4.7-16) (GCC)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; """<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:189] kernel<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; reported version is: 352.55.0<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; E tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:296] kernel<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; version 352.55.0 does not match DSO version 35=
2.93.0 -- cannot find working<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; devices in this configuration<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/core/common_runtime/gpu/gpu_init.=
cc:81] No GPU devices<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; available on machine.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; As far as I understand the problem is that cud=
a-7.5 was built or<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; relies on nvidia 352.93 while I have NVIDIA dr=
iver 352.55 both on the host<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; and container. So far I could not find cuda-7.=
5 built with 352.55.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; cuda-7.5 has stabs directory in which there is=
 libcuda.so. The<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; problem is probably coming from there. However=
, I doubt I can just replace<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; libcuda.so in the stubs directory by a differe=
nt version or turn it into<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; symbolic link to a different version in the dr=
iver? Because its size is much<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; smaller than the size of the real libcuda.so i=
n the driver. So I suspect, it<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; is really only some kind of interface to the r=
eal library?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Sun, Jul 31, 2016 at 9:36 AM, Igor Yakushin=
 &lt;<a>igor...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; When installing cuda libraries and tensorf=
low into the singularity<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; image, is it important to be on the same h=
ost with the same version of<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA/OS on which you are going to run late=
r?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I do not have root on the machine I am goi=
ng to run later and<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; prepare the image on a different machine w=
ith a different version of nvidia<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver and a different flavor of Linux.<br=
>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Sun, Jul 31, 2016 at 8:39 AM, Nathan Li=
n<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;<a>nathan...@gmail.com</a>&gt; wrote:<=
br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Igor,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I don't necessarily have a great answe=
r for you. If seems like you<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; are doing everything right, yet it is =
still not working. In my case, yes<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; nvidia-smi as well as TensorFlow both =
work correctly. I feel like your error<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; still has to do with the version of li=
bcuda.so you are using. Notice how<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Python seems to correctly load libcuda=
.so, yet there is later an error that<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; is unable to find libcuda.so. My first=
 suspicion is that there is still a<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; version mismatch between the drivers i=
nstalled on the image and on the host.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; If you are sure that is not true, it m=
ay be possible that the version of the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver that is installed on the machin=
e isn't new enough for the GPU. That<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; actually occurred on our cluster, and =
after a sysadmin updated the driver,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; it worked. Barring that I am not too s=
ure. Maybe if you provide me with the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; full details of your installation (the=
 versions of the packages that you<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; have installed, the OS of your image a=
nd host), I might be able to think<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; about something, but my suspicion is t=
hat the driver version on your host<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; machine may not be new enough.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Best,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Nathan<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Jul 31, 2016, at 12:17 AM, Igor Yak=
ushin &lt;<a>igor...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I have found exactly the same version =
of NVIDIA driver and<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; extracted from it the libraries and nv=
idia executables and copied them in<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; /usr/lib64/nvidia and /usr/bin and cre=
ated the corresponding symbolic links.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; However, I still cannot use GPU inside=
 singularity: nvidia-smi says "GPU<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; access blocked by the operating system=
" (does it work in your case?) and<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; when tensorflow session starts it also=
 complains that "No GPU devices<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; available on machine". However, notice=
 that tensorflow seems to think that a<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; different version of NVIDIA driver is =
used. Not sure where it is coming<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; from. The machine on which the image w=
as built has version 361.42<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Python 2.7.12 (default, Jul&nbsp; 1 20=
16, 15:12:24)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; [GCC 5.4.0 20160609] on linux2<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Type "help", "copyright", "credits" or=
 "license" for more<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; information.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; import tensorflow<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcublas.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcudnn.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcufft.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcuda.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcurand.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; ss =3D tensorflow.Session=
()<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; E tensorflow/stream_executor/cuda/cuda=
_driver.cc:491] failed call<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; to cuInit: CUDA_ERROR_UNKNOWN<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:153]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; retrieving CUDA diagnostic information=
 for host: midway230<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:160]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; hostname: midway230<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:185] libcuda<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; reported version is: Not found: was un=
able to find libcuda.so DSO loaded<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; into this program<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:347] driver<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; version file contents: """NVRM version=
: NVIDIA UNIX x86_64 Kernel Module<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 352.55&nbsp; Thu Oct&nbsp; 8 15:18:00 =
PDT 2015<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GCC version:&nbsp; gcc version 4.4.7 2=
0120313 (Red Hat 4.4.7-16) (GCC)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; """<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:189] kernel<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; reported version is: 352.55.0<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/core/common_runtime/gpu/g=
pu_init.cc:81] No GPU devices<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; available on machine.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/tensorflow_0.9.img&gt; nvi=
dia-smi<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Failed to initialize NVML: GPU access =
blocked by the operating<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; system<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thu, Jul 28, 2016 at 9:34 PM, Natha=
n Lin<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;<a>nathan...@gmail.com</a>&gt; wro=
te:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I am not sure how to find the corr=
ect driver version, but from my<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; testing, the version must match ex=
actly. I will admit that I have had<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; problems finding specific versions=
 of the driver from NVIDIA's website. I<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; had to ask a sysadmin for the inst=
aller that they used. In order to extract<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; the files, you need to use the --e=
xtract-only option. For instance, you will<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; have to run something like ' sh /N=
VIDIA-Linux-x86_64-352.63.run<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --extract-only'/ . You will then b=
e given a directory with all the libraries<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; that would have been installed. Yo=
u will need to copy the libcuda.so.###.##<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; library (and you can copy any NVID=
IA executables that you want such as<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; nvidia-smi). Good luck!<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thu, Jul 28, 2016 at 8:51 PM, I=
gor &lt;<a>igor...@gmail.com</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I mean I am using this file fr=
om NVIDIA website<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; cuda_7.5.18_linux.run to insta=
ll the driver, opengl, cuda. Driver<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; installation fails, cuda succe=
eds.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Also, when I run<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; sh cuda_7.5.18_linux.run<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I am offered to install the dr=
iver version 352.39 while on the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; host it is 346.47. I cannot up=
grade the host. Any idea where I can get<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 346.17?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tried using the same link ju=
st substitute 18 for something else<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; but have not found the files:<=
br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; wget<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; <a href=3D"http://developer.do=
wnload.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.=
run" target=3D"_blank">http://developer.download.nvidia.com/compute/cuda/7.=
5/Prod/local_installers/cuda_7.5.1X_linux.run</a><br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thursday, July 28, 2016 at =
7:34:55 PM UTC-5, Igor wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; When I try to install the =
driver by running NVIDIA*.run script<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; inside the image, it fails=
, probably because it tries to modify kernel that<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; belongs to host?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; How do I extract just libc=
uda.so.345.67 without installing the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver (which is obviously=
 problematic) and why would copying the library<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; from the host would not wo=
rk?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thursday, July 28, 2016=
 at 7:18:26 PM UTC-5, Nathan Lin<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Also if you are using =
the binary installation of TensorFlow you<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; need CUDA toolkit 7.5 =
and cuDNN v4. These only need to be installed on our<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; image. As I mentioned =
earlier you will need the libcuda.so.###.## library on<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; your image. It is very=
 important that this is the same version of the NVIDIA<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver as you have on =
your nose (seemingly 346.67 for you). I should've have<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; also mentioned that yo=
u want the libcuda.so.345.67 library that you get from<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; extracting the NVIDIA =
installer. It will not work if you try to copy the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; libcuda.so library tha=
t from you node.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Let me know if you hav=
e any more questions.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Best,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Nathan<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thursday, July 28, =
2016, Nathan Lin &lt;<a>nat...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hello,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Yes you are correc=
t. The NVIDIA driver must be installed on<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; your image as well=
. However, you honestly only need the libcuda.so.###.##<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; library and the ap=
propriate links for that library. Once you have those<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; installed in your =
image, it should work.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Best,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Nathan<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thursday, July =
28, 2016, Igor &lt;<a>igor...@gmail.com</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi All,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I am trying to=
 use GPU-enabled tensorflow and it cannot find<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GPU card from =
inside the container.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On the host:<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; $ lspci | grep=
 -i nvidia<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 20:00.0 3D con=
troller: NVIDIA Corporation GK110BGL [Tesla<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; K40m] (rev a1)=
<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 8b:00.0 3D con=
troller: NVIDIA Corporation GK110BGL [Tesla<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; K40m] (rev a1)=
<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; $ nvidia-smi<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thu Jul 28 19:=
01:42 2016<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------=
-----------------------------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | NVIDIA-SMI 3=
46.47&nbsp; &nbsp; &nbsp;Driver Version: 346.47&nbsp; &nbsp; &nbsp; &nbsp; =
&nbsp;|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |-------------=
------------------+----------------------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | GPU&nbsp; Na=
me&nbsp; &nbsp; &nbsp; &nbsp; Persistence-M| Bus-Id&nbsp; &nbsp; &nbsp; &nb=
sp; Disp.A |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Volatile Uncor=
r. ECC |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | Fan&nbsp; Te=
mp&nbsp; Perf&nbsp; Pwr:Usage/Cap|&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Memory-=
Usage |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GPU-Util&nbsp;=
 Compute M. |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |&nbsp; &nbsp;=
0&nbsp; Tesla K40m&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Off&nbsp; | 0000:20:00=
.0&nbsp; &nbsp; &nbsp;Off |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | N/A&nbsp; &n=
bsp;30C&nbsp; &nbsp; P8&nbsp; &nbsp; 20W / 235W |&nbsp; &nbsp; &nbsp;66MiB =
/ 11519MiB |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0%&nbsp; &nbsp=
; &nbsp; Default |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------=
------------------+----------------------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |&nbsp; &nbsp;=
1&nbsp; Tesla K40m&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Off&nbsp; | 0000:8B:00=
.0&nbsp; &nbsp; &nbsp;Off |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | N/A&nbsp; &n=
bsp;26C&nbsp; &nbsp; P8&nbsp; &nbsp; 19W / 235W |&nbsp; &nbsp; &nbsp;60MiB =
/ 11519MiB |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0%&nbsp; &nbsp=
; &nbsp; Default |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------=
------------------+----------------------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------=
----------------------------------------------------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | Processes:<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GPU Memory |<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |&nbsp; GPU&nb=
sp; &nbsp; &nbsp; &nbsp;PID&nbsp; Type&nbsp; Process name<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Usage&nbsp; &n=
bsp; &nbsp; |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |&nbsp; &nbsp;=
 0&nbsp; &nbsp; &nbsp;11671&nbsp; &nbsp; G&nbsp; &nbsp;/usr/bin/X<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 9MiB |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |&nbsp; &nbsp;=
 1&nbsp; &nbsp; &nbsp;11671&nbsp; &nbsp; G&nbsp; &nbsp;/usr/bin/X<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 3MiB |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Inside singula=
rity:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; $ singularity =
shell<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; /software/src/=
singularity_images/tensorflow_0.9.img<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/te=
nsorflow_0.9.img&gt; lspci | grep -i nvidia<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; bash: lspci: c=
ommand not found<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/te=
nsorflow_0.9.img&gt; nvidia-smi<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; bash: nvidia-s=
mi: command not found<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/te=
nsorflow_0.9.img&gt; python<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Python 2.7.12 =
(default, Jul&nbsp; 1 2016, 15:12:24)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; [GCC 5.4.0 201=
60609] on linux2<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Type "help", "=
copyright", "credits" or "license" for more<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; information.<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; i=
mport tensorflow as tf<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcublas.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcudnn.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcufft.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcuda.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcurand.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; s=
ess =3D tf.Session()<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; E tensorflow/s=
tream_executor/cuda/cuda_driver.cc:491] failed<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; call to cuInit=
: CUDA_ERROR_UNKNOWN<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:153]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; retrieving CUD=
A diagnostic information for host: midway-l34-01<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:160]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; hostname: midw=
ay-l34-01<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:185]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; libcuda report=
ed version is: Not found: was unable to find libcuda.so DSO<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; loaded into th=
is program<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:347]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver version=
 file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Module&nbsp; 3=
46.47&nbsp; Thu Feb 19 18:56:03 PST 2015<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GCC version:&n=
bsp; gcc version 4.4.7 20120313 (Red Hat 4.4.7-11)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; (GCC)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; """<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:189]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; kernel reporte=
d version is: 346.47.0<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/c=
ore/common_runtime/gpu/gpu_init.cc:81] No GPU<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; devices availa=
ble on machine.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Must there be =
nvidia driver installed inside the container?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Outside? The c=
ontainer shares the same kernel with the host and nvidia<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; kernel module =
needs to be loaded... How this is handled? Any requirements on<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; nvidia driver =
and cuda versions inside and outside of the container?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received t=
his message because you are subscribed to the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Google Groups =
"singularity" group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe=
 from this group and stop receiving emails from<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; it, send an em=
ail to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message beca=
use you are subscribed to the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Google Groups "singularity" gr=
oup.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group=
 and stop receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@l=
bl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because =
you are subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and=
 stop receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.g=
ov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you =
are subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and sto=
p receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.gov</=
a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you =
are subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and sto=
p receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.gov</=
a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you are subs=
cribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiv=
ing emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you are subs=
cribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiv=
ing emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you are subscrib=
ed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving =
emails from it, send<br>
&gt;&gt;&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you are subscrib=
ed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving =
emails from it, send<br>
&gt;&gt;&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; You received this message because you are subscribed t=
o the Google<br>
&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emai=
ls from it, send<br>
&gt;&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; You received this message because you are subscribed t=
o the Google<br>
&gt;&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emai=
ls from it, send<br>
&gt;&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt; You received this message because you are subscribed to th=
e Google<br>
&gt;&gt;&gt;&gt; Groups "singularity" group.<br>
&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emails f=
rom it, send<br>
&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; --<br>
&gt;&gt;&gt; You received this message because you are subscribed to the Go=
ogle Groups<br>
&gt;&gt;&gt; "singularity" group.<br>
&gt;&gt;&gt; To unsubscribe from this group and stop receiving emails from =
it, send an<br>
&gt;&gt;&gt; email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; You received this message because you are subscribed to the Google=
 Groups<br>
&gt;&gt; "singularity" group.<br>
&gt;&gt; To unsubscribe from this group and stop receiving emails from it, =
send an<br>
&gt;&gt; email to <a>singu...@lbl.gov</a>.<br>
&gt;<br>
&gt; --<br>
&gt; You received this message because you are subscribed to the Google Gro=
ups<br>
&gt; "singularity" group.<br>
&gt; To unsubscribe from this group and stop receiving emails from it, send=
 an<br>
&gt; email to <a>singu...@lbl.gov</a>.<br>
<br>
--<br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singu...@lbl.gov</a>.<br>
</blockquote></div></div><br><br></div></div><span>-- <br><div dir=3D"ltr">=
<div>Gregory M. Kurtzer<br>High Performance Computing Services (HPCS)<br>Un=
iversity of California<br>Lawrence Berkeley National Laboratory<br>One Cycl=
otron Road, Berkeley, CA 94720</div></div><br>

<p></p></span><div><div>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div class=3D"gmail_signature"><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>=
High Performance Computing Services (HPCS)<br>University of California<br>L=
awrence Berkeley National Laboratory<br>One Cyclotron Road, Berkeley, CA 94=
720</div></div></div>
</div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov">singu...@lbl.gov</a>.<br>
</div></blockquote></body></html>
--Apple-Mail-AFF726B9-603A-4719-BDB5-C331E483A79C--

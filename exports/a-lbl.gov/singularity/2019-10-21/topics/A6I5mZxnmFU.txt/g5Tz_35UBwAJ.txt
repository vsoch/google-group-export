X-Received: by 2002:a63:6e87:: with SMTP id j129-v6mr3340905pgc.83.1526667269523;
        Fri, 18 May 2018 11:14:29 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 2002:a17:902:9a4c:: with SMTP id x12-v6ls3275562plv.0.gmail; Fri,
 18 May 2018 11:14:28 -0700 (PDT)
X-Received: by 2002:a17:902:bb07:: with SMTP id l7-v6mr10660497pls.128.1526667268531;
        Fri, 18 May 2018 11:14:28 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1526667268; cv=none;
        d=google.com; s=arc-20160816;
        b=zQXRMr6yk3d8eVcPnWlOwROkCvGzW5aB0HUhspoNnMIH3wOYnqgsVnl/4j+IwBNNoa
         CyJjhE+Fxry2FNTbe/15xFiMYSeaQPs1JRYG6EubPNULid5+0uFa3BScmCY8DnI/bAZq
         L01H5Ed3x+JE81ZF5Khpx/c/2qtZzYx0GRPFNYiEg2TQzWXN3DCaIdGJMoiO2mws6eNV
         eBuBGiCb+gveMpAxzNwIOZyTzMb9odDRS5XJq1IiLBd8/9GsDShyZU76rhRvfqFkZXim
         lyWbT3Nro1O8uD6GTIKhxkVygNWPbXOG2d1Xplx5QMB4SbUBhD0f41fEj6PoCLj/J2+R
         fF7Q==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:references:in-reply-to:mime-version
         :dkim-signature:arc-authentication-results;
        bh=kzYxZ+vpzQ9C3W4d3tCB7rVTrZRs4NjJ9g3sMdRe3H4=;
        b=MwJnYDtbsxC9OTsaSeiZn6peYIkefIbNpGt01pvSavQMJNmiprVd4UarUzd6ZSRgjU
         e4ob680YrR5uKPhvnR75SfbEMs+H1uSnioY3DnKpXKlfw2zJYdbS6OJlw1Zo2o+f7oPu
         Taoh5MuISf9BDXW1sjdh7CfJtLZcOQ0I6IJXT1/Ue5jipE6XMfSPoKBpuqUof43y8kxJ
         DdR+L+M63fwqIwOMo6TfIvHQet1V9R66mCXJpgolvBakUG0lAFn5lmur0bYbqWSfXE3W
         k8rLp6FhF3r4CHurIlWvFgv+uMdPiOABuDRYcFV3XxULL8pV89O5zthL89xr+R/oD/Xz
         Y6aA==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=LZiMKHEu;
       spf=pass (google.com: domain of jason...@gmail.com designates 209.85.220.177 as permitted sender) smtp.mailfrom=jason...@gmail.com
Return-Path: <jason...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id h7-v6si6313524pgc.14.2018.05.18.11.14.28
        for <singu...@lbl.gov>;
        Fri, 18 May 2018 11:14:28 -0700 (PDT)
Received-SPF: pass (google.com: domain of jason...@gmail.com designates 209.85.220.177 as permitted sender) client-ip=209.85.220.177;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=LZiMKHEu;
       spf=pass (google.com: domain of jason...@gmail.com designates 209.85.220.177 as permitted sender) smtp.mailfrom=jason...@gmail.com
X-Ironport-SBRS: 3.5
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2GKAgCrFv9ah7HcVdFcGgEBAQEBAgEBA?=
 =?us-ascii?q?QEIAQEBAYMYgQx9KINuBoNthBeMeYF5gQ+TNhSBDgMYOyMNCYFJgi9GAoISITQ?=
 =?us-ascii?q?YAQIBAQEBAQECAQECEAEBAQgNCQgoIwyCNQUCAwIeBQRLJgUBMAEBAQEBAQEBA?=
 =?us-ascii?q?QEfAgwhQwEBAQQjHQENDh4DDAYFCwYDAQEBAQICJgICIQEBDgMBBQELCQgOBwQ?=
 =?us-ascii?q?BBxUEgwICKIE+AQMVBQqcbTyLBYF/BQEXgnAFg08KGSYNVFeCHwIBBRJ3hyyBV?=
 =?us-ascii?q?D+BD4JeLoJPQgEBgSUIARIBgx+CVAKHYIUkiwUXLAcCgWeEA4Vugn+MfYlfSoQ?=
 =?us-ascii?q?HgjgwgQQcbC5xMxojUDGCEoIUGoNOinAhMAEPjTlHgXABAQ?=
X-IronPort-AV: E=Sophos;i="5.49,415,1520924400"; 
   d="scan'208";a="23661353"
Received: from mail-qk0-f177.google.com ([209.85.220.177])
  by fe4.lbl.gov with ESMTP; 18 May 2018 11:14:26 -0700
Received: by mail-qk0-f177.google.com with SMTP id l132-v6so7156675qke.3
        for <singu...@lbl.gov>; Fri, 18 May 2018 11:14:26 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=kzYxZ+vpzQ9C3W4d3tCB7rVTrZRs4NjJ9g3sMdRe3H4=;
        b=LZiMKHEuyvAJWVsgRferdwMgXn661on0vj+uXt/PmPHTcu97HQyOC1AuqZksT72YxE
         zEZQWxCowe854qHoR/0PFfN/o+nAb2FD+jPCvg/HPsj7fIxmKKZTUrFVsrhuzGDxzfQa
         cxd9XxmQVXxcXGO5Oe3O+OmIlcS6zWf1cSR20Wl1ufUY01XkhWxzG74J3YhY5zWCeEYc
         GF0lpEdbYc3onK+gjtiFeOu+v1p3O33Tke5M/rfMoZFUrFGY2BiUzpROoNUdKsv1YWST
         AUXMJPDA9qR+2flMhf4mNKPpjW0TVFxF4rbmCoqbAhGWfOeVoVYticI8cMtv9lUIzw+e
         3QcA==
X-Gm-Message-State: ALKqPwfHe4EECSfbApr9Re2Ve0o5ojOA1XZ+hEBgkWh8ovUI6EWBGajR
	GO/9wp+JVilttAWZXt6j357Hm0Jqib010wHyKfFm9BWo
X-Received: by 2002:a37:82c6:: with SMTP id e189-v6mr9307474qkd.322.1526667265926;
 Fri, 18 May 2018 11:14:25 -0700 (PDT)
MIME-Version: 1.0
Received: by 2002:ac8:3368:0:0:0:0:0 with HTTP; Fri, 18 May 2018 11:14:25
 -0700 (PDT)
In-Reply-To: <CAB6eJZ+6PDjs3POSQPNoLdaMys5d7iYDYcUeQFpMyzJ6DEP31w@mail.gmail.com>
References: <167671ff-657d-4560-a35f-87091223fe29@lbl.gov> <B58197C146EC324AA00A2A07DC082602C2CBA0C3@XMAIL-MBX-BT1.AD.UCSD.EDU>
 <CAB6eJZ+6PDjs3POSQPNoLdaMys5d7iYDYcUeQFpMyzJ6DEP31w@mail.gmail.com>
From: Jason Stover <jason...@gmail.com>
Date: Fri, 18 May 2018 13:14:25 -0500
Message-ID: <CAGfAqt_SyMw8CqJxb8DjbnfTfsAj__eXOrJvKPCzJzsEuQcnvg@mail.gmail.com>
Subject: Re: [Singularity] Running an mpi program with mvapitch
To: singularity@lbl.gov
Content-Type: text/plain; charset="UTF-8"

Hi George,

  Can you run it from inside the container? For example:

    singularity exec
/data/zakigf/candle/swift-hypervisor-horovod-mvapich.simg mpiexec -n 1
mpi-pi.o

-J


On Fri, May 18, 2018 at 12:56 PM, George Zaki <georg...@gmail.com> wrote:
> Thanks Marty
>
> Below are the values I got, any obvious mismatch? I git this working fine
> with OpenMPI.
>
> Here is also what I try to run:
>
> singularity exec /data/zakigf/candle/swift-hypervisor-horovod-mvapich.simg
> mpicc mpi-pi.c -o  mpi-pi.o
>
> [zakigf@cn2360 mpi-example]$ mpiexec -n 1 singularity exec
> /data/zakigf/candle/swift-hypervisor-horovod-mvapich.simg mpi-pi.o
>
> Then I kill after no response:
>
> ^C[mpiexec@cn2360] Sending Ctrl-C to processes as requested
>
> [mpiexec@cn2360] Press Ctrl-C again to force abort
>
> [mpiexec@cn2360] HYDU_sock_write (utils/sock/sock.c:286): write error (Bad
> file descriptor)
>
> [mpiexec@cn2360] HYD_pmcd_pmiserv_send_signal (pm/pmiserv/pmiserv_cb.c:169):
> unable to write data to proxy
>
> [mpiexec@cn2360] ui_cmd_cb (pm/pmiserv/pmiserv_pmci.c:79): unable to send
> signal downstream
>
> [mpiexec@cn2360] HYDT_dmxu_poll_wait_for_event
> (tools/demux/demux_poll.c:76): callback returned error status
>
> [mpiexec@cn2360] HYD_pmci_wait_for_completion
> (pm/pmiserv/pmiserv_pmci.c:198): error waiting for event
>
> [mpiexec@cn2360] main (ui/mpich/mpiexec.c:344): process manager error
> waiting for completion
>
>
> Now about the versions:
>
> Singularity: Invoking an interactive shell within container...
>
>
> Singularity swift-hypervisor-horovod-mvapich.simg:~> mpiexec --version
>
> HYDRA build details:
>
>     Version:                                 3.1.4
>
>     Release Date:                            Wed Sep  7 14:33:43 EDT 2016
>
>     CC:                              gcc
>
>     CXX:                             g++
>
>     F77:                             gfortran
>
>     F90:                             gfortran
>
>     Configure options:                       '--disable-option-checking'
> '--prefix=NONE' '--cache-file=/dev/null' '--srcdir=.' 'CC=gcc' 'CFLAGS=
> -DNDEBUG -DNVALGRIND -O2' 'LDFLAGS=-L/lib -L/lib -L/lib -Wl,-rpath,/lib
> -L/lib -Wl,-rpath,/lib -L/lib -L/lib' 'LIBS=-libmad -libumad -libverbs -ldl
> -lrt -lm -lpthread ' 'CPPFLAGS= -I/tmp/mvapich2-2.2/src/mpl/include
> -I/tmp/mvapich2-2.2/src/mpl/include -I/tmp/mvapich2-2.2/src/openpa/src
> -I/tmp/mvapich2-2.2/src/openpa/src -D_REENTRANT
> -I/tmp/mvapich2-2.2/src/mpi/romio/include -I/include -I/include -I/include
> -I/include'
>
>     Process Manager:                         pmi
>
>     Launchers available:                     ssh rsh fork slurm ll lsf sge
> manual persist
>
>     Topology libraries available:            hwloc
>
>     Resource management kernels available:   user slurm ll lsf sge pbs
> cobalt
>
>     Checkpointing libraries available:
>
>     Demux engines available:                 poll select
>
> Singularity swift-hypervisor-horovod-mvapich.simg:~> gcc --version
>
> gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
>
> Copyright (C) 2015 Free Software Foundation, Inc.
>
> This is free software; see the source for copying conditions.  There is NO
>
> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>
>
> Singularity swift-hypervisor-horovod-mvapich.simg:~> exit
>
> exit
>
>
> [zakigf@cn2360 ~]$ ml mvapich2/2.2/gcc-5.3.0
>
> [+] Loading mvapich2 2.2 for GCC 5.3.0
>
> [zakigf@cn2360 ~]$ gcc --version
>
> gcc (GCC) 4.4.7 20120313 (Red Hat 4.4.7-17)
>
> Copyright (C) 2010 Free Software Foundation, Inc.
>
> This is free software; see the source for copying conditions.  There is NO
>
> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
>
>
> [zakigf@cn2360 ~]$ mpiexec --version
>
> HYDRA build details:
>
>     Version:                                 3.1.4
>
>     Release Date:                            Wed Sep  7 14:33:43 EDT 2016
>
>     CC:                              /usr/local/GCC/5.3.0/bin/gcc
>
>     CXX:                             /usr/local/GCC/5.3.0/bin/g++
>
>     F77:                             /usr/local/GCC/5.3.0/bin/gfortran
>
>     F90:                             /usr/local/GCC/5.3.0/bin/gfortran
>
>     Configure options:                       '--disable-option-checking'
> '--prefix=/usr/local/MVAPICH2/2.2/gcc-5.3.0'
> '--with-slurm-lib=/usr/local/slurm/lib'
> '--with-slurm-include=/usr/local/slurm/include' '--enable-debug=none'
> '--enable-timing=runtime' 'CC=/usr/local/GCC/5.3.0/bin/gcc'
> 'CXX=/usr/local/GCC/5.3.0/bin/g++' 'FC=/usr/local/GCC/5.3.0/bin/gfortran'
> 'F77=/usr/local/GCC/5.3.0/bin/gfortran' '--cache-file=/dev/null'
> '--srcdir=.' 'CFLAGS= -DNDEBUG -DNVALGRIND -O2' 'LDFLAGS=-L/lib -L/lib
> -L/lib -Wl,-rpath,/lib -L/lib -Wl,-rpath,/lib -L/lib -L/lib' 'LIBS=-libmad
> -libumad -libverbs -ldl -lrt -lm -lpthread ' 'CPPFLAGS=
> -I/usr/local/src/mvapich2/mvapich2-2.2/src/mpl/include
> -I/usr/local/src/mvapich2/mvapich2-2.2/src/mpl/include
> -I/usr/local/src/mvapich2/mvapich2-2.2/src/openpa/src
> -I/usr/local/src/mvapich2/mvapich2-2.2/src/openpa/src -D_REENTRANT
> -I/usr/local/src/mvapich2/mvapich2-2.2/src/mpi/romio/include -I/include
> -I/include -I/include -I/include'
>
>     Process Manager:                         pmi
>
>     Launchers available:                     ssh rsh fork slurm ll lsf sge
> manual persist
>
>     Topology libraries available:            hwloc
>
>     Resource management kernels available:   user slurm ll lsf sge pbs
> cobalt
>
>     Checkpointing libraries available:
>
>     Demux engines available:                 poll select
>
>
> On Fri, May 18, 2018 at 1:31 PM Kandes, Martin <mka...@sdsc.edu> wrote:
>>
>> Hi George,
>>
>> I run with different gcc compiler versions inside and outside my MPI
>> containers. So I would be surprised if that is the issue here. I'm not sure
>> I have a good recommendation of where to start debugging your problem. But I
>> might start by double checking the MPI versions match inside and outside the
>> container. e.g. see [1].
>>
>> Marty
>>
>> [1]
>>
>> [mkandes@comet-ln3 ~]$ srun --partition=debug --pty --nodes=1
>> --ntasks-per-node=24 -t 00:30:00 --wait=0 --export=ALL /bin/bash
>> srun: job 16364303 queued and waiting for resources
>> srun: job 16364303 has been allocated resources
>> [mkandes@comet-14-06 ~]$ cd /scratch/mkandes/16364303/
>> [mkandes@comet-14-06 16364303]$ cp
>> /oasis/scratch/comet/mkandes/temp_project/singularity/images/ubuntu-mvapich2.img
>> ./
>> [mkandes@comet-14-06 16364303]$ module purge
>> [mkandes@comet-14-06 16364303]$ module load gnu
>> [mkandes@comet-14-06 16364303]$ module load mvapich2_ib
>> [mkandes@comet-14-06 16364303]$ module list
>> Currently Loaded Modulefiles:
>>   1) gnu/4.9.2         2) mvapich2_ib/2.1
>> [mkandes@comet-14-06 16364303]$ module load singularity
>> [mkandes@comet-14-06 16364303]$ gcc --version
>> gcc (GCC) 4.9.2
>> Copyright (C) 2014 Free Software Foundation, Inc.
>> This is free software; see the source for copying conditions.  There is NO
>> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR
>> PURPOSE.
>>
>> [mkandes@comet-14-06 16364303]$ mpirun --version
>> HYDRA build details:
>>     Version:                                 3.1.4
>>     Release Date:                            Thu Apr  2 17:15:15 EDT 2015
>>     CC:                              gcc  -fPIC -O3
>>     CXX:                             g++  -fPIC -O3
>>     F77:                             gfortran -fPIC -O3
>>     F90:                             gfortran -fPIC -O3
>>     Configure options:                       '--disable-option-checking'
>> '--prefix=/opt/mvapich2/gnu/ib' '--enable-shared' '--enable-sharedlibs=gcc'
>> '--with-hwloc' '--enable-f77' '--enable-fc' '--enable-hybrid'
>> '--with-ib-include=/usr/include/infiniband' '--with-ib-libpath=/usr/lib64'
>> '--enable-fast=O3'
>> '--with-limic2=/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/../..//cache/build-limic'
>> '--with-slurm=/usr/lib64/slurm' '--with-file-system=lustre' 'CC=gcc'
>> 'CFLAGS=-fPIC -O3 -O3' 'CXX=g++' 'CXXFLAGS=-fPIC -O3 -O3' 'FC=gfortran'
>> 'FCFLAGS=-fPIC -O3 -O3' 'F77=gfortran' 'FFLAGS=-L/usr/lib64 -L/lib -L/lib
>> -fPIC -O3 -O3' '--cache-file=/dev/null' '--srcdir=.' 'LDFLAGS=-L/usr/lib64
>> -L/lib -L/lib -L/lib -Wl,-rpath,/lib -L/lib -Wl,-rpath,/lib -L/usr/lib64
>> -L/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/../..//cache/build-limic/lib
>> -L/lib -L/lib' 'LIBS=-libmad -lrdmacm -libumad -libverbs -ldl -lrt -llimic2
>> -lm -lpthread ' 'CPPFLAGS=-I/usr/include/infiniband
>> -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/mpl/include
>> -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/mpl/include
>> -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/openpa/src
>> -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/openpa/src
>> -D_REENTRANT
>> -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/mpi/romio/include
>> -I/include -I/include -I/usr/include/infiniband
>> -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/../..//cache/build-limic/include
>> -I/include -I/include'
>>     Process Manager:                         pmi
>>     Launchers available:                     ssh rsh fork slurm ll lsf sge
>> manual persist
>>     Topology libraries available:            hwloc
>>     Resource management kernels available:   user slurm ll lsf sge pbs
>> cobalt
>>     Checkpointing libraries available:
>>     Demux engines available:                 poll select
>> [mkandes@comet-14-06 16364303]$ singularity shell ubuntu-mvapich2.img
>> Singularity: Invoking an interactive shell within container...
>>
>> Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303> gcc --version
>> gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
>> Copyright (C) 2015 Free Software Foundation, Inc.
>> This is free software; see the source for copying conditions.  There is NO
>> warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR
>> PURPOSE.
>>
>> Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303> mpirun
>> --version
>> HYDRA build details:
>>     Version:                                 3.1.4
>>     Release Date:                            Thu Apr  2 17:15:15 EDT 2015
>>     CC:                              gcc
>>     CXX:                             g++
>>     F77:                             gfortran
>>     F90:                             gfortran
>>     Configure options:                       '--disable-option-checking'
>> '--prefix=/opt/mvapich2' '--cache-file=/dev/null' '--srcdir=.' 'CC=gcc'
>> 'CFLAGS= -DNDEBUG -DNVALGRIND -O2' 'LDFLAGS=-L/lib -L/lib -L/lib
>> -Wl,-rpath,/lib -L/lib -Wl,-rpath,/lib -L/lib -L/lib' 'LIBS=-libmad -lrdmacm
>> -libumad -libverbs -ldl -lrt -lm -lpthread ' 'CPPFLAGS=
>> -I/tmp/mvapich2-2.1/src/mpl/include -I/tmp/mvapich2-2.1/src/mpl/include
>> -I/tmp/mvapich2-2.1/src/openpa/src -I/tmp/mvapich2-2.1/src/openpa/src
>> -D_REENTRANT -I/tmp/mvapich2-2.1/src/mpi/romio/include -I/include -I/include
>> -I/include -I/include'
>>     Process Manager:                         pmi
>>     Launchers available:                     ssh rsh fork slurm ll lsf sge
>> manual persist
>>     Topology libraries available:            hwloc
>>     Resource management kernels available:   user slurm ll lsf sge pbs
>> cobalt
>>     Checkpointing libraries available:
>>     Demux engines available:                 poll select
>> Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303>
>>
>>
>> ________________________________
>> From: George Zaki [georg...@gmail.com]
>> Sent: Friday, May 18, 2018 6:48 AM
>> To: singularity
>> Subject: [Singularity] Running an mpi program with mvapitch
>>
>> Hi singularity team,
>>
>>
>> I would like to run an MPI program in a singularity container. The program
>> is compiled using mvapicth2.2 using a gcc version 5.4.
>>
>>
>> I can see that my cluster has a compiled version of mvapitch2.2 with gcc
>> 5.3
>>
>>
>> When I run:
>>
>>
>> mpiexe -n 1 singularity exec /path/to/sing/image ./mpi-pi.o
>>
>> the call does not return.
>>
>>
>>
>> Does the gcc version has to be exactly the same? I tried the switch the
>> compiler in this image:
>>
>>
>> BootStrap: docker
>> From: nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04
>>
>>
>> However when gcc 5.3 is used the mvapitch does not build correctly.
>>
>>
>> If that's the problem, Is there a preferred method of switching gcc
>> version in this container singularity container?
>>
>>
>> Thanks,
>> George
>>
>> --
>> You received this message because you are subscribed to the Google Groups
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to singu...@lbl.gov.
>>
>> --
>> You received this message because you are subscribed to a topic in the
>> Google Groups "singularity" group.
>> To unsubscribe from this topic, visit
>> https://groups.google.com/a/lbl.gov/d/topic/singularity/A6I5mZxnmFU/unsubscribe.
>> To unsubscribe from this group and all its topics, send an email to
>> singu...@lbl.gov.
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.

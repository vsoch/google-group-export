X-Received: by 10.237.46.3 with SMTP id j3mr52974254qtd.2.1470154101891;
        Tue, 02 Aug 2016 09:08:21 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.142.77 with SMTP id q74ls4628727iod.23.gmail; Tue, 02 Aug
 2016 09:08:21 -0700 (PDT)
X-Received: by 10.66.101.41 with SMTP id fd9mr106404783pab.108.1470154101220;
        Tue, 02 Aug 2016 09:08:21 -0700 (PDT)
Return-Path: <gmku...@lbl.gov>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id sc6si3651480pac.196.2016.08.02.09.08.20
        for <singu...@lbl.gov>;
        Tue, 02 Aug 2016 09:08:21 -0700 (PDT)
Received-SPF: pass (google.com: domain of gmku...@lbl.gov designates 74.125.82.72 as permitted sender) client-ip=74.125.82.72;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of gmku...@lbl.gov designates 74.125.82.72 as permitted sender) smtp.mailfrom=gmku...@lbl.gov
X-Ironport-SBRS: 1.6
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2HIAQB9xKBXdEhSfUpdhBt8B4M4gQyjRIR7iy52gT1AJoFsVIInAYEPAoE5BzgUAQEBAQEBAQMPAQoLFBcxglM5CjEBAQEBAQEBAQEBAQEBAQEBGgIvFgsbAQEEARIIAQgrMAsJAgsNIAEJAgIhAQ8DAQUBHAYIBwQBGgIEAYd1Aw8IBQmTKI9EgTI+MYs7i2MNhBQLAQEBASIQiWSBA4JDgU8RAYMdgloFhgyCEQdghRILaj+EJoUPNAGGF4I4RIJzQ4I1gWsXN4c9hUmIK4QFgjgSHoEPDw+CSByBbBwyAQEBAQOGdIE2AQEB
X-IPAS-Result: A2HIAQB9xKBXdEhSfUpdhBt8B4M4gQyjRIR7iy52gT1AJoFsVIInAYEPAoE5BzgUAQEBAQEBAQMPAQoLFBcxglM5CjEBAQEBAQEBAQEBAQEBAQEBGgIvFgsbAQEEARIIAQgrMAsJAgsNIAEJAgIhAQ8DAQUBHAYIBwQBGgIEAYd1Aw8IBQmTKI9EgTI+MYs7i2MNhBQLAQEBASIQiWSBA4JDgU8RAYMdgloFhgyCEQdghRILaj+EJoUPNAGGF4I4RIJzQ4I1gWsXN4c9hUmIK4QFgjgSHoEPDw+CSByBbBwyAQEBAQOGdIE2AQEB
X-IronPort-AV: E=Sophos;i="5.28,461,1464678000"; 
   d="scan'208,217";a="32062864"
Received: from mail-wm0-f72.google.com ([74.125.82.72])
  by fe3.lbl.gov with ESMTP; 02 Aug 2016 09:08:16 -0700
Received: by mail-wm0-f72.google.com with SMTP id p129so106990255wmp.3
        for <singu...@lbl.gov>; Tue, 02 Aug 2016 09:08:16 -0700 (PDT)
X-Gm-Message-State: AEkoout+5YcSiy5V8EOOVX9yL4pIHcSt2nfQhIJ7P+0SnSyoo9lxjED7wgO0IlbZFyvY7vHd7OTtVJ2dRT9hFkeCxucPMvcGKgMNV6+BzN9y9Ydcmc07oZqKft5gLOtBNSR3WVLKje0t09/YklFk2TLaAmU=
X-Received: by 10.25.156.77 with SMTP id f74mr22609283lfe.51.1470154095775;
        Tue, 02 Aug 2016 09:08:15 -0700 (PDT)
X-Received: by 10.25.156.77 with SMTP id f74mr22609269lfe.51.1470154095233;
 Tue, 02 Aug 2016 09:08:15 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.214.141 with HTTP; Tue, 2 Aug 2016 09:08:13 -0700 (PDT)
In-Reply-To: <CAA8GL6D2CnOWS+7BDYHQ=H=-JG0TRSrwnL3C3MX5Mcnr1avggQ@mail.gmail.com>
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
 <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov> <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
 <CAA8GL6BdE1TRBaPD-oM7qcj8QK1cBsmJsUzYyrvkRPBP9CX+hQ@mail.gmail.com>
 <CAMfmYehdPLtiouQqMGqOx4ZbEXFbbPRL5QOxsP_vQo0us1QLuA@mail.gmail.com>
 <B927B7F6-3CFB-452D-92AB-866F9B8024E4@gmail.com> <CAMfmYeiSvcReO4jvSGJkavnex64wGZ8Phxva2kAxJ7pcp48YiA@mail.gmail.com>
 <CAMfmYeiaTxVQSNqwprHe5ckcDHPcJXy3imdepiRL+KkDh12TCQ@mail.gmail.com>
 <65CD778F-6CD1-4DB4-9668-4D89839B7053@gmail.com> <CAMfmYeg_pnJcyKGetK7WVChToaWCgGYH-nrYY9v=2+RSkuWZuQ@mail.gmail.com>
 <C5AE54CB-2BA1-4E59-88FC-D20224A46086@gmail.com> <CAMfmYeg2rR9-U-zyviCeDXRt_QgKv_K0p9pf-+qgoGPQAjxjXA@mail.gmail.com>
 <95039222-908B-4AE8-8844-551646C9733C@gmail.com> <CAA8GL6ATuT+zMyD9zrW5GBH3Br8bm8=RvjKm1PNAGbKGF3psMw@mail.gmail.com>
 <CAMfmYejEioybKBLNSv36dd7ma-Z1hatfssvFUOGiuehBZbk-Ug@mail.gmail.com>
 <CA+3XN_KmaVuaKqOCbCvocOrw0qghQZq3kiBh1S6T2NKyTgpDTA@mail.gmail.com>
 <CAMfmYeiia1H27LL8q72LgrsgBV8PF8+QL03DK922PVM6WO0FDg@mail.gmail.com>
 <CA+3XN_Lb6DT4zNfuzTdbL276SsKUumResXsheJ0P9UK1j8KTMA@mail.gmail.com>
 <CAN7etTzJOy=mqZFfFY=4+W_DnMN2c_3G8tdqNM91Gy0qdrqXCA@mail.gmail.com>
 <CAMfmYeiTxZUEjiBx43R4hHWDTx_PvH+VQsx27P+QYmjsoihYaA@mail.gmail.com>
 <CAN7etTxU9wiVg+0KH+1cX+FmAmSkD65xORjubSzv4heOknYPww@mail.gmail.com>
 <AAC7A4FE-6EF8-45FB-839C-4792CE1797F2@gmail.com> <CAMfmYeii6BtEQ1W_HrTwcbRMVMD6j0C534-F9jtbzSP1UDCfgw@mail.gmail.com>
 <CAA8GL6Aa87tX730i96z2VPtU=_EM1kPHWiq+HzyPR+tL7KyaBA@mail.gmail.com>
 <CAA8GL6B1TYrwOfp=C7Ay06hHXZS2X86tm5XugksumdsBCa-0dQ@mail.gmail.com> <CAA8GL6D2CnOWS+7BDYHQ=H=-JG0TRSrwnL3C3MX5Mcnr1avggQ@mail.gmail.com>
From: "Gregory M. Kurtzer" <gmku...@lbl.gov>
Date: Tue, 2 Aug 2016 09:08:13 -0700
Message-ID: <CAN7etTyp76TOBZC2U4uOamTP6ocoDipq1vb-B4LKyWnY7RMSqg@mail.gmail.com>
Subject: Re: [Singularity] How to use GPU in singularity?
To: singularity <singu...@lbl.gov>
Content-Type: multipart/alternative; boundary=001a114114a09c98ee053918ec59

--001a114114a09c98ee053918ec59
Content-Type: text/plain; charset=UTF-8

On Tue, Aug 2, 2016 at 8:52 AM, Nathan Lin <nathan...@gmail.com> wrote:

> Hi Greg,
>
> Sorry for this email, just saw your recent reply. Can you tell me a bit
> more about the /environment file? That seems like it would definitely solve
> one of my major issues I've been running into. Should it be formatted
> similar to a standard bash profile file?
>

Containers built/bootstrapped with Singularity v2.1 (or newer) will have
the file /environment which will get sourced automatically when invoking
the container. You are correct, you can format it similar to your standard
bash/shell profile script. In order to be portable, just make sure you
follow Bourne semantics (not Bash) so don't do anything fancy. lol

Hope that helps!

Greg



>
> Thanks!
> Nathan
>
> On Tue, Aug 2, 2016 at 11:50 AM, Nathan Lin <nathan...@gmail.com>
> wrote:
>
>> Hi Greg,
>>
>> I think that something along the line of what you brainstormed would
>> work, but it would probably require that the image and the host computer
>> are using the same version of lib.c. At this point, I just can't seem to
>> think about a different way to get around the inherent different in the
>> dependencies of the two versions of the library. But I'm also not familiar
>> with this kind of stuff (I've really only been working with Linux and
>> containers this summer), so maybe there is a solution out there!
>>
>> Best,
>> Nathan
>>
>> On Tue, Aug 2, 2016 at 11:46 AM, Nathan Lin <nathan...@gmail.com>
>> wrote:
>>
>>> Hi Igor,
>>>
>>> Sorry I was going to include this detail, but I was typing on my phone
>>> and got lazy. The setting of LD_LIBRARY_PATH is not really automatic. On
>>> our clusters, we have modules and basically when we load the TensorFlow
>>> module, it parses the /lib folder for the correct NVIDIA driver version for
>>> the computer and stores it as a variable. Then, part of my runscript sets
>>> LD_LIBRARY_PATH to include the path to the driver I installed on the image.
>>> Not the most elegant solution, but it works. On our cluster, we are trying
>>> to have the image be as similar to a python interpreter as possible, so
>>> using runscripts works well for us.
>>>
>>> Best,
>>> Nathan
>>>
>>> On Tue, Aug 2, 2016 at 11:39 AM, Igor Yakushin <igor...@gmail.com>
>>> wrote:
>>>
>>>> Nathan,
>>>> Considering that singularity ignores $HOME/.bashrc and in version 2.1
>>>> gives you sh, not bash, by default, how do you make singularity set
>>>> LD_LIBRARY_PATH automatically? Do you wrap bash or is there some other
>>>> hooks? On my cluster different nodes have different versions of nvidia
>>>> driver and different tesla cards. So it would be useful for an image to be
>>>> able to automatically set LD_LIBRARY_PATH and PATH to point to the correct
>>>> version of the driver.
>>>> Thank you,
>>>> Igor
>>>>
>>>> On Tue, Aug 2, 2016 at 10:29 AM, Nathan Lin <nathan...@gmail.com>
>>>> wrote:
>>>>
>>>>> Hi,
>>>>>
>>>>> From my experiences, attempting to use the NVIDIA drivers on the host
>>>>> was not the most successful approach. Although first of all, I think it is
>>>>> important to distinguish between the CUDA drivers and the NVIDIA drivers.
>>>>> This is made more confusing because the CUDA toolkit wants to install its
>>>>> own version of the NVIDIA drivers, but the point is the CUDA drivers are
>>>>> relatively portable while the NVIDIA drivers are not so much.
>>>>>
>>>>> The errors I ran into with the NVIDIA driver (specifically the library
>>>>> libcuda.so.352.63) was that there seemed to be a difference between the
>>>>> version of the library that was installed on the cluster and the version of
>>>>> the library I got from extracting the library without installing the driver
>>>>> (using the --extract-only option). I think this has to do with the fact
>>>>> that something is actually compiled when you install the driver, but the
>>>>> point is that the two versions of the library have different dependencies.
>>>>> And it seems that the version on the cluster depends on some libraries that
>>>>> are installed on the cluster. Although I did not mess with my singularity
>>>>> install (with bind path and such) there didn't seem like a good resolution
>>>>> for this because the reason we are using singularity is precisely because
>>>>> we want our image to have a newer version of lib.c. Thus, the ability for
>>>>> our image to get the libraries it needs from the host computer is pretty
>>>>> much nonexistent. Instead, I've set up my image to have multiple version
>>>>> numbers of the libcuda.so library, and depending on the host machine, the
>>>>> image adds the appropriate driver to LD_LIBRARY_PATH. This isn't the
>>>>> greatest solution, but it was the best I could think of.
>>>>>
>>>>> I hope that was helpful, and good luck!
>>>>>
>>>>> Best,
>>>>> Nathan
>>>>>
>>>>> On Aug 2, 2016, at 11:05 AM, Gregory M. Kurtzer <gmku...@lbl.gov>
>>>>> wrote:
>>>>>
>>>>>
>>>>> On Tue, Aug 2, 2016 at 7:58 AM, Igor Yakushin <igor...@gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Greg,
>>>>>> I got an impression that Nathan was saying that you cannot just copy
>>>>>> host NVIDIA drivers.
>>>>>>
>>>>>
>>>>> I'm not sure how "copy-able" the drivers are, but I have the
>>>>> impression they are compiled against an older version of libC so they
>>>>> should be relatively portable... I think this is how Nvidia-docker works.
>>>>>
>>>>>
>>>>>> Did I misunderstand it? How do you use "bind path"? Is it a feature
>>>>>> of Singularity?
>>>>>>
>>>>>
>>>>> "bind path" is in your configuration file (singularity.conf) and will
>>>>> bind files/directories outside the container to inside.
>>>>>
>>>>>
>>>>>
>>>>>> Also, would this solution be portable? Do you mean that this "bind
>>>>>> path" happens dynamically as long as the host has some NVIDIA driver and
>>>>>> would work with any version without having to rebuild the container?
>>>>>>
>>>>>
>>>>> That would be the idea yes. It should be as portable as Nvidia's
>>>>> solution (as I understand it) lol. Maybe someone else has more information
>>>>> on this who can chime in.
>>>>>
>>>>>
>>>>>> Thank you,
>>>>>>
>>>>>
>>>>> My pleasure!
>>>>>
>>>>>
>>>>>> Igor
>>>>>>
>>>>>> On Tue, Aug 2, 2016 at 9:35 AM, Gregory M. Kurtzer <gmku...@lbl.gov
>>>>>> > wrote:
>>>>>>
>>>>>>> I think the best way of doing this is to have the host provide the
>>>>>>> CUDA drivers that properly match the kernel drivers that it has installed
>>>>>>> on the host to a directory. Then use "bind path" to link in those drivers
>>>>>>> into the container and set the LD_LIBRARY_PATH in /etc/singularity/init to
>>>>>>> match that directory.
>>>>>>>
>>>>>>> This feature will be MUCH better when we will be able to link in
>>>>>>> arbitrary directories into the containers without having to rely on the
>>>>>>> bind point existing.
>>>>>>>
>>>>>>> Greg
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Monday, August 1, 2016, Bernard Li <ber...@vanhpc.org> wrote:
>>>>>>>
>>>>>>>> Hi Igor:
>>>>>>>>
>>>>>>>> 352.39 and Tesla K80.
>>>>>>>>
>>>>>>>> Thanks,
>>>>>>>>
>>>>>>>> Bernard
>>>>>>>>
>>>>>>>> On Mon, Aug 1, 2016 at 10:21 PM, Igor Yakushin <igor...@gmail.com>
>>>>>>>> wrote:
>>>>>>>> > Hi Bernard,
>>>>>>>> > What nvidia driver version is on your host?  What card model?
>>>>>>>> > Thank you,
>>>>>>>> > Igor
>>>>>>>> >
>>>>>>>> >
>>>>>>>> > On Aug 1, 2016 11:55 PM, "Bernard Li" <ber...@vanhpc.org> wrote:
>>>>>>>> >>
>>>>>>>> >> Hey Igor:
>>>>>>>> >>
>>>>>>>> >> If you can make the tensorflow Singularity container available,
>>>>>>>> I'd like
>>>>>>>> >> to try that out on our cluster.
>>>>>>>> >>
>>>>>>>> >> Thanks,
>>>>>>>> >>
>>>>>>>> >> Bernard
>>>>>>>> >>
>>>>>>>> >> On Monday, 1 August 2016, Igor Yakushin <igor...@gmail.com>
>>>>>>>> wrote:
>>>>>>>> >>>
>>>>>>>> >>> Hi Nathan,
>>>>>>>> >>> The main problem was that if you try to install cuda, it would
>>>>>>>> by default
>>>>>>>> >>> install driver as well that might be of different version than
>>>>>>>> the driver
>>>>>>>> >>> installed with NVIDIA*.run file. So when installing cuda, use
>>>>>>>> an option not
>>>>>>>> >>> to install the driver. It is much easier to find NVIDIA*.run
>>>>>>>> file of the
>>>>>>>> >>> version you need than cuda*.run with the right driver.  When
>>>>>>>> downloading
>>>>>>>> >>> NVIDIA*.run, pay attention that you are asking for Tesla card
>>>>>>>> (if that's
>>>>>>>> >>> what you have). Consumer cards have different driver (I do not
>>>>>>>> remember if
>>>>>>>> >>> it is reflected in the file name but I suspect not, because I
>>>>>>>> made this
>>>>>>>> >>> mistake).
>>>>>>>> >>> Thank you,
>>>>>>>> >>> Igor
>>>>>>>> >>>
>>>>>>>> >>>
>>>>>>>> >>> On Mon, Aug 1, 2016 at 8:56 AM, Nathan Lin <
>>>>>>>> nathan...@gmail.com>
>>>>>>>> >>> wrote:
>>>>>>>> >>>>
>>>>>>>> >>>> That's great to hear Igor! What ended up being the problem?
>>>>>>>> >>>>
>>>>>>>> >>>> On Mon, Aug 1, 2016 at 1:43 AM, Rick Wagner <
>>>>>>>> richard...@gmail.com>
>>>>>>>> >>>> wrote:
>>>>>>>> >>>>>
>>>>>>>> >>>>> Igor,
>>>>>>>> >>>>>
>>>>>>>> >>>>> If you had a chance to post your definition file or the steps
>>>>>>>> you took,
>>>>>>>> >>>>> I know several of us would appreciate it. Getting TensorFlow
>>>>>>>> running on
>>>>>>>> >>>>> CentOS was a huge effort for our support staff. And that's
>>>>>>>> just one of many
>>>>>>>> >>>>> GPU-enabled applications.
>>>>>>>> >>>>>
>>>>>>>> >>>>> --Rick
>>>>>>>> >>>>>
>>>>>>>> >>>>> On Jul 31, 2016, at 10:20 PM, Igor Yakushin <
>>>>>>>> igor...@gmail.com>
>>>>>>>> >>>>> wrote:
>>>>>>>> >>>>>
>>>>>>>> >>>>> Thank you, Nathan. It finally works!
>>>>>>>> >>>>>
>>>>>>>> >>>>> On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin <
>>>>>>>> nathan...@gmail.com>
>>>>>>>> >>>>> wrote:
>>>>>>>> >>>>>>
>>>>>>>> >>>>>> Yes I do
>>>>>>>> >>>>>>
>>>>>>>> >>>>>> On Jul 31, 2016, at 5:03 PM, Igor Yakushin <
>>>>>>>> igor...@gmail.com>
>>>>>>>> >>>>>> wrote:
>>>>>>>> >>>>>>
>>>>>>>> >>>>>> Nathan,
>>>>>>>> >>>>>> When you import tensorflow in python, does it tell you what
>>>>>>>> cuda
>>>>>>>> >>>>>> libraries it is loading or not?
>>>>>>>> >>>>>> Do you see these messages:
>>>>>>>> >>>>>> ======
>>>>>>>> >>>>>> >>> import tensorflow as tf
>>>>>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened
>>>>>>>> >>>>>> CUDA library libcublas.so locally
>>>>>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened
>>>>>>>> >>>>>> CUDA library libcudnn.so locally
>>>>>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened
>>>>>>>> >>>>>> CUDA library libcufft.so locally
>>>>>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened
>>>>>>>> >>>>>> CUDA library libcuda.so locally
>>>>>>>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened
>>>>>>>> >>>>>> CUDA library libcurand.so locally
>>>>>>>> >>>>>> ======
>>>>>>>> >>>>>> Thank you,
>>>>>>>> >>>>>> Igor
>>>>>>>> >>>>>>
>>>>>>>> >>>>>> On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin <
>>>>>>>> nathan...@gmail.com>
>>>>>>>> >>>>>> wrote:
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> Hi Igor,
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> In regards to your first questions, the OS/drivers of your
>>>>>>>> building
>>>>>>>> >>>>>>> computer should not matter. I built an Ubuntu 14.04 image
>>>>>>>> on my RHEL 7 box
>>>>>>>> >>>>>>> for our RHEL 6 cluster. I'm not sure that the toolkit is
>>>>>>>> that version
>>>>>>>> >>>>>>> specific, my image seems to work fine and it's running
>>>>>>>> 353.63. There is one
>>>>>>>> >>>>>>> thing that I do that may be helpful. I read it somewhere
>>>>>>>> online and am not
>>>>>>>> >>>>>>> actually sure if it does anything, but I've included it in
>>>>>>>> my image
>>>>>>>> >>>>>>> definitions just in case. Apparently there is something
>>>>>>>> about initializing
>>>>>>>> >>>>>>> the CUDA Toolkit. As part of my definition file I run
>>>>>>>> 'make' on the CUDA
>>>>>>>> >>>>>>> sample 'deviceQuery'. Maybe that will help?
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> Best,
>>>>>>>> >>>>>>> Nathan
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> On Jul 31, 2016, at 1:51 PM, Igor Yakushin <
>>>>>>>> igor...@gmail.com>
>>>>>>>> >>>>>>> wrote:
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> Hi Nathan,
>>>>>>>> >>>>>>> I got a little bit further: nvidia-smi is working now but
>>>>>>>> tensorflow
>>>>>>>> >>>>>>> still complains:
>>>>>>>> >>>>>>> =========
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> =========
>>>>>>>> >>>>>>> Singularity/ubuntu_14.04.img> nvidia-smi
>>>>>>>> >>>>>>> Sun Jul 31 17:33:44 2016
>>>>>>>> >>>>>>> +------------------------------------------------------+
>>>>>>>> >>>>>>> | NVIDIA-SMI 352.55     Driver Version: 352.55         |
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> |-------------------------------+----------------------+----------------------+
>>>>>>>> >>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A |
>>>>>>>> Volatile
>>>>>>>> >>>>>>> Uncorr. ECC |
>>>>>>>> >>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage |
>>>>>>>> GPU-Util
>>>>>>>> >>>>>>> Compute M. |
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> |===============================+======================+======================|
>>>>>>>> >>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>>>>>>>> >>>>>>> 0 |
>>>>>>>> >>>>>>> | N/A   45C    P0    79W / 235W |    158MiB / 11519MiB |
>>>>>>>>  45%
>>>>>>>> >>>>>>> Default |
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>> >>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>>>>>>>> >>>>>>> 0 |
>>>>>>>> >>>>>>> | N/A   23C    P8    18W / 235W |     61MiB / 11519MiB |
>>>>>>>>   0%
>>>>>>>> >>>>>>> Default |
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> +-----------------------------------------------------------------------------+
>>>>>>>> >>>>>>> | Processes:
>>>>>>>> >>>>>>> GPU Memory |
>>>>>>>> >>>>>>> |  GPU       PID  Type  Process name
>>>>>>>> >>>>>>> Usage      |
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> |=============================================================================|
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> +-----------------------------------------------------------------------------+
>>>>>>>> >>>>>>> Singularity/ubuntu_14.04.img> python
>>>>>>>> >>>>>>> Python 2.7.6 (default, Mar 22 2014, 22:59:56)
>>>>>>>> >>>>>>> [GCC 4.8.2] on linux2
>>>>>>>> >>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>>>>>> >>>>>>> information.
>>>>>>>> >>>>>>> >>> import tensorflow
>>>>>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>> CUDA library libcublas.so locally
>>>>>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>> CUDA library libcudnn.so locally
>>>>>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>> CUDA library libcufft.so locally
>>>>>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>> CUDA library libcuda.so.1 locally
>>>>>>>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>> CUDA library libcurand.so locally
>>>>>>>> >>>>>>> >>> ss = tensorflow.Session()
>>>>>>>> >>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491]
>>>>>>>> failed call to
>>>>>>>> >>>>>>> cuInit: CUDA_ERROR_NO_DEVICE
>>>>>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>>>> retrieving
>>>>>>>> >>>>>>> CUDA diagnostic information for host: midway-l34-02
>>>>>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>>>>>>>> hostname:
>>>>>>>> >>>>>>> midway-l34-02
>>>>>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185]
>>>>>>>> libcuda
>>>>>>>> >>>>>>> reported version is: 352.93.0
>>>>>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356]
>>>>>>>> driver
>>>>>>>> >>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64
>>>>>>>> Kernel Module
>>>>>>>> >>>>>>> 352.55  Thu Oct  8 15:18:00 PDT 2015
>>>>>>>> >>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16)
>>>>>>>> (GCC)
>>>>>>>> >>>>>>> """
>>>>>>>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189]
>>>>>>>> kernel
>>>>>>>> >>>>>>> reported version is: 352.55.0
>>>>>>>> >>>>>>> E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:296]
>>>>>>>> kernel
>>>>>>>> >>>>>>> version 352.55.0 does not match DSO version 352.93.0 --
>>>>>>>> cannot find working
>>>>>>>> >>>>>>> devices in this configuration
>>>>>>>> >>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU
>>>>>>>> devices
>>>>>>>> >>>>>>> available on machine.
>>>>>>>> >>>>>>> >>>
>>>>>>>> >>>>>>> =================
>>>>>>>> >>>>>>> As far as I understand the problem is that cuda-7.5 was
>>>>>>>> built or
>>>>>>>> >>>>>>> relies on nvidia 352.93 while I have NVIDIA driver 352.55
>>>>>>>> both on the host
>>>>>>>> >>>>>>> and container. So far I could not find cuda-7.5 built with
>>>>>>>> 352.55.
>>>>>>>> >>>>>>> cuda-7.5 has stabs directory in which there is libcuda.so.
>>>>>>>> The
>>>>>>>> >>>>>>> problem is probably coming from there. However, I doubt I
>>>>>>>> can just replace
>>>>>>>> >>>>>>> libcuda.so in the stubs directory by a different version or
>>>>>>>> turn it into
>>>>>>>> >>>>>>> symbolic link to a different version in the driver? Because
>>>>>>>> its size is much
>>>>>>>> >>>>>>> smaller than the size of the real libcuda.so in the driver.
>>>>>>>> So I suspect, it
>>>>>>>> >>>>>>> is really only some kind of interface to the real library?
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> Thank you,
>>>>>>>> >>>>>>> Igor
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> On Sun, Jul 31, 2016 at 9:36 AM, Igor Yakushin <
>>>>>>>> igor...@gmail.com>
>>>>>>>> >>>>>>> wrote:
>>>>>>>> >>>>>>>>
>>>>>>>> >>>>>>>> Hi Nathan,
>>>>>>>> >>>>>>>> When installing cuda libraries and tensorflow into the
>>>>>>>> singularity
>>>>>>>> >>>>>>>> image, is it important to be on the same host with the
>>>>>>>> same version of
>>>>>>>> >>>>>>>> CUDA/OS on which you are going to run later?
>>>>>>>> >>>>>>>> I do not have root on the machine I am going to run later
>>>>>>>> and
>>>>>>>> >>>>>>>> prepare the image on a different machine with a different
>>>>>>>> version of nvidia
>>>>>>>> >>>>>>>> driver and a different flavor of Linux.
>>>>>>>> >>>>>>>> Thank you,
>>>>>>>> >>>>>>>> Igor
>>>>>>>> >>>>>>>>
>>>>>>>> >>>>>>>>
>>>>>>>> >>>>>>>> On Sun, Jul 31, 2016 at 8:39 AM, Nathan Lin
>>>>>>>> >>>>>>>> <nathan...@gmail.com> wrote:
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> Hi Igor,
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> I don't necessarily have a great answer for you. If seems
>>>>>>>> like you
>>>>>>>> >>>>>>>>> are doing everything right, yet it is still not working.
>>>>>>>> In my case, yes
>>>>>>>> >>>>>>>>> nvidia-smi as well as TensorFlow both work correctly. I
>>>>>>>> feel like your error
>>>>>>>> >>>>>>>>> still has to do with the version of libcuda.so you are
>>>>>>>> using. Notice how
>>>>>>>> >>>>>>>>> Python seems to correctly load libcuda.so, yet there is
>>>>>>>> later an error that
>>>>>>>> >>>>>>>>> is unable to find libcuda.so. My first suspicion is that
>>>>>>>> there is still a
>>>>>>>> >>>>>>>>> version mismatch between the drivers installed on the
>>>>>>>> image and on the host.
>>>>>>>> >>>>>>>>> If you are sure that is not true, it may be possible that
>>>>>>>> the version of the
>>>>>>>> >>>>>>>>> driver that is installed on the machine isn't new enough
>>>>>>>> for the GPU. That
>>>>>>>> >>>>>>>>> actually occurred on our cluster, and after a sysadmin
>>>>>>>> updated the driver,
>>>>>>>> >>>>>>>>> it worked. Barring that I am not too sure. Maybe if you
>>>>>>>> provide me with the
>>>>>>>> >>>>>>>>> full details of your installation (the versions of the
>>>>>>>> packages that you
>>>>>>>> >>>>>>>>> have installed, the OS of your image and host), I might
>>>>>>>> be able to think
>>>>>>>> >>>>>>>>> about something, but my suspicion is that the driver
>>>>>>>> version on your host
>>>>>>>> >>>>>>>>> machine may not be new enough.
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> Best,
>>>>>>>> >>>>>>>>> Nathan
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> On Jul 31, 2016, at 12:17 AM, Igor Yakushin <
>>>>>>>> igor...@gmail.com>
>>>>>>>> >>>>>>>>> wrote:
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> Hi Nathan,
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> I have found exactly the same version of NVIDIA driver and
>>>>>>>> >>>>>>>>> extracted from it the libraries and nvidia executables
>>>>>>>> and copied them in
>>>>>>>> >>>>>>>>> /usr/lib64/nvidia and /usr/bin and created the
>>>>>>>> corresponding symbolic links.
>>>>>>>> >>>>>>>>> However, I still cannot use GPU inside singularity:
>>>>>>>> nvidia-smi says "GPU
>>>>>>>> >>>>>>>>> access blocked by the operating system" (does it work in
>>>>>>>> your case?) and
>>>>>>>> >>>>>>>>> when tensorflow session starts it also complains that "No
>>>>>>>> GPU devices
>>>>>>>> >>>>>>>>> available on machine". However, notice that tensorflow
>>>>>>>> seems to think that a
>>>>>>>> >>>>>>>>> different version of NVIDIA driver is used. Not sure
>>>>>>>> where it is coming
>>>>>>>> >>>>>>>>> from. The machine on which the image was built has
>>>>>>>> version 361.42
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> ============
>>>>>>>> >>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>>>>>> >>>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>>>>>> >>>>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>>>>>> >>>>>>>>> information.
>>>>>>>> >>>>>>>>> >>> import tensorflow
>>>>>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>>>> CUDA library libcublas.so locally
>>>>>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>>>> CUDA library libcudnn.so locally
>>>>>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>>>> CUDA library libcufft.so locally
>>>>>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>>>> CUDA library libcuda.so locally
>>>>>>>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully opened
>>>>>>>> >>>>>>>>> CUDA library libcurand.so locally
>>>>>>>> >>>>>>>>> >>> ss = tensorflow.Session()
>>>>>>>> >>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491]
>>>>>>>> failed call
>>>>>>>> >>>>>>>>> to cuInit: CUDA_ERROR_UNKNOWN
>>>>>>>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>>>> >>>>>>>>> retrieving CUDA diagnostic information for host: midway230
>>>>>>>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>>>>>>>> >>>>>>>>> hostname: midway230
>>>>>>>> >>>>>>>>> I
>>>>>>>> tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
>>>>>>>> >>>>>>>>> reported version is: Not found: was unable to find
>>>>>>>> libcuda.so DSO loaded
>>>>>>>> >>>>>>>>> into this program
>>>>>>>> >>>>>>>>> I
>>>>>>>> tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver
>>>>>>>> >>>>>>>>> version file contents: """NVRM version: NVIDIA UNIX
>>>>>>>> x86_64 Kernel Module
>>>>>>>> >>>>>>>>> 352.55  Thu Oct  8 15:18:00 PDT 2015
>>>>>>>> >>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat
>>>>>>>> 4.4.7-16) (GCC)
>>>>>>>> >>>>>>>>> """
>>>>>>>> >>>>>>>>> I
>>>>>>>> tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel
>>>>>>>> >>>>>>>>> reported version is: 352.55.0
>>>>>>>> >>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No
>>>>>>>> GPU devices
>>>>>>>> >>>>>>>>> available on machine.
>>>>>>>> >>>>>>>>> >>>
>>>>>>>> >>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>>>>>> >>>>>>>>> Failed to initialize NVML: GPU access blocked by the
>>>>>>>> operating
>>>>>>>> >>>>>>>>> system
>>>>>>>> >>>>>>>>> ===========
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> Thank you,
>>>>>>>> >>>>>>>>> Igor
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> On Thu, Jul 28, 2016 at 9:34 PM, Nathan Lin
>>>>>>>> >>>>>>>>> <nathan...@gmail.com> wrote:
>>>>>>>> >>>>>>>>>>
>>>>>>>> >>>>>>>>>> I am not sure how to find the correct driver version,
>>>>>>>> but from my
>>>>>>>> >>>>>>>>>> testing, the version must match exactly. I will admit
>>>>>>>> that I have had
>>>>>>>> >>>>>>>>>> problems finding specific versions of the driver from
>>>>>>>> NVIDIA's website. I
>>>>>>>> >>>>>>>>>> had to ask a sysadmin for the installer that they used.
>>>>>>>> In order to extract
>>>>>>>> >>>>>>>>>> the files, you need to use the --extract-only option.
>>>>>>>> For instance, you will
>>>>>>>> >>>>>>>>>> have to run something like ' sh
>>>>>>>> /NVIDIA-Linux-x86_64-352.63.run
>>>>>>>> >>>>>>>>>> --extract-only'/ . You will then be given a directory
>>>>>>>> with all the libraries
>>>>>>>> >>>>>>>>>> that would have been installed. You will need to copy
>>>>>>>> the libcuda.so.###.##
>>>>>>>> >>>>>>>>>> library (and you can copy any NVIDIA executables that
>>>>>>>> you want such as
>>>>>>>> >>>>>>>>>> nvidia-smi). Good luck!
>>>>>>>> >>>>>>>>>>
>>>>>>>> >>>>>>>>>> On Thu, Jul 28, 2016 at 8:51 PM, Igor <
>>>>>>>> igor...@gmail.com> wrote:
>>>>>>>> >>>>>>>>>>>
>>>>>>>> >>>>>>>>>>> I mean I am using this file from NVIDIA website
>>>>>>>> >>>>>>>>>>> cuda_7.5.18_linux.run to install the driver, opengl,
>>>>>>>> cuda. Driver
>>>>>>>> >>>>>>>>>>> installation fails, cuda succeeds.
>>>>>>>> >>>>>>>>>>> Also, when I run
>>>>>>>> >>>>>>>>>>> sh cuda_7.5.18_linux.run
>>>>>>>> >>>>>>>>>>> I am offered to install the driver version 352.39 while
>>>>>>>> on the
>>>>>>>> >>>>>>>>>>> host it is 346.47. I cannot upgrade the host. Any idea
>>>>>>>> where I can get
>>>>>>>> >>>>>>>>>>> 346.17?
>>>>>>>> >>>>>>>>>>> I tried using the same link just substitute 18 for
>>>>>>>> something else
>>>>>>>> >>>>>>>>>>> but have not found the files:
>>>>>>>> >>>>>>>>>>> wget
>>>>>>>> >>>>>>>>>>>
>>>>>>>> http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run
>>>>>>>> >>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>
>>>>>>>> >>>>>>>>>>> On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor
>>>>>>>> wrote:
>>>>>>>> >>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>> Hi Nathan,
>>>>>>>> >>>>>>>>>>>> When I try to install the driver by running
>>>>>>>> NVIDIA*.run script
>>>>>>>> >>>>>>>>>>>> inside the image, it fails, probably because it tries
>>>>>>>> to modify kernel that
>>>>>>>> >>>>>>>>>>>> belongs to host?
>>>>>>>> >>>>>>>>>>>> How do I extract just libcuda.so.345.67 without
>>>>>>>> installing the
>>>>>>>> >>>>>>>>>>>> driver (which is obviously problematic) and why would
>>>>>>>> copying the library
>>>>>>>> >>>>>>>>>>>> from the host would not work?
>>>>>>>> >>>>>>>>>>>> Thank you,
>>>>>>>> >>>>>>>>>>>> Igor
>>>>>>>> >>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan
>>>>>>>> Lin
>>>>>>>> >>>>>>>>>>>> wrote:
>>>>>>>> >>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>> Also if you are using the binary installation of
>>>>>>>> TensorFlow you
>>>>>>>> >>>>>>>>>>>>> need CUDA toolkit 7.5 and cuDNN v4. These only need
>>>>>>>> to be installed on our
>>>>>>>> >>>>>>>>>>>>> image. As I mentioned earlier you will need the
>>>>>>>> libcuda.so.###.## library on
>>>>>>>> >>>>>>>>>>>>> your image. It is very important that this is the
>>>>>>>> same version of the NVIDIA
>>>>>>>> >>>>>>>>>>>>> driver as you have on your nose (seemingly 346.67 for
>>>>>>>> you). I should've have
>>>>>>>> >>>>>>>>>>>>> also mentioned that you want the libcuda.so.345.67
>>>>>>>> library that you get from
>>>>>>>> >>>>>>>>>>>>> extracting the NVIDIA installer. It will not work if
>>>>>>>> you try to copy the
>>>>>>>> >>>>>>>>>>>>> libcuda.so library that from you node.
>>>>>>>> >>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>> Let me know if you have any more questions.
>>>>>>>> >>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>> Best,
>>>>>>>> >>>>>>>>>>>>> Nathan
>>>>>>>> >>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>> On Thursday, July 28, 2016, Nathan Lin <
>>>>>>>> nat...@gmail.com>
>>>>>>>> >>>>>>>>>>>>> wrote:
>>>>>>>> >>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>> Hello,
>>>>>>>> >>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>> Yes you are correct. The NVIDIA driver must be
>>>>>>>> installed on
>>>>>>>> >>>>>>>>>>>>>> your image as well. However, you honestly only need
>>>>>>>> the libcuda.so.###.##
>>>>>>>> >>>>>>>>>>>>>> library and the appropriate links for that library.
>>>>>>>> Once you have those
>>>>>>>> >>>>>>>>>>>>>> installed in your image, it should work.
>>>>>>>> >>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>> Best,
>>>>>>>> >>>>>>>>>>>>>> Nathan
>>>>>>>> >>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>> On Thursday, July 28, 2016, Igor <
>>>>>>>> igor...@gmail.com> wrote:
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> Hi All,
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> I am trying to use GPU-enabled tensorflow and it
>>>>>>>> cannot find
>>>>>>>> >>>>>>>>>>>>>>> GPU card from inside the container.
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> On the host:
>>>>>>>> >>>>>>>>>>>>>>> $ lspci | grep -i nvidia
>>>>>>>> >>>>>>>>>>>>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL
>>>>>>>> [Tesla
>>>>>>>> >>>>>>>>>>>>>>> K40m] (rev a1)
>>>>>>>> >>>>>>>>>>>>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL
>>>>>>>> [Tesla
>>>>>>>> >>>>>>>>>>>>>>> K40m] (rev a1)
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> $ nvidia-smi
>>>>>>>> >>>>>>>>>>>>>>> Thu Jul 28 19:01:42 2016
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> +------------------------------------------------------+
>>>>>>>> >>>>>>>>>>>>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47
>>>>>>>>    |
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> |-------------------------------+----------------------+----------------------+
>>>>>>>> >>>>>>>>>>>>>>> | GPU  Name        Persistence-M| Bus-Id
>>>>>>>> Disp.A |
>>>>>>>> >>>>>>>>>>>>>>> Volatile Uncorr. ECC |
>>>>>>>> >>>>>>>>>>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|
>>>>>>>>  Memory-Usage |
>>>>>>>> >>>>>>>>>>>>>>> GPU-Util  Compute M. |
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> |===============================+======================+======================|
>>>>>>>> >>>>>>>>>>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0
>>>>>>>>  Off |
>>>>>>>> >>>>>>>>>>>>>>> 0 |
>>>>>>>> >>>>>>>>>>>>>>> | N/A   30C    P8    20W / 235W |     66MiB /
>>>>>>>> 11519MiB |
>>>>>>>> >>>>>>>>>>>>>>> 0%      Default |
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>> >>>>>>>>>>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0
>>>>>>>>  Off |
>>>>>>>> >>>>>>>>>>>>>>> 0 |
>>>>>>>> >>>>>>>>>>>>>>> | N/A   26C    P8    19W / 235W |     60MiB /
>>>>>>>> 11519MiB |
>>>>>>>> >>>>>>>>>>>>>>> 0%      Default |
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> +-----------------------------------------------------------------------------+
>>>>>>>> >>>>>>>>>>>>>>> | Processes:
>>>>>>>> >>>>>>>>>>>>>>> GPU Memory |
>>>>>>>> >>>>>>>>>>>>>>> |  GPU       PID  Type  Process name
>>>>>>>> >>>>>>>>>>>>>>> Usage      |
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> |=============================================================================|
>>>>>>>> >>>>>>>>>>>>>>> |    0     11671    G   /usr/bin/X
>>>>>>>> >>>>>>>>>>>>>>> 9MiB |
>>>>>>>> >>>>>>>>>>>>>>> |    1     11671    G   /usr/bin/X
>>>>>>>> >>>>>>>>>>>>>>> 3MiB |
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> Inside singularity:
>>>>>>>> >>>>>>>>>>>>>>> $ singularity shell
>>>>>>>> >>>>>>>>>>>>>>> /software/src/singularity_images/tensorflow_0.9.img
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> lspci | grep -i
>>>>>>>> nvidia
>>>>>>>> >>>>>>>>>>>>>>> bash: lspci: command not found
>>>>>>>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>>>>>> >>>>>>>>>>>>>>> bash: nvidia-smi: command not found
>>>>>>>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> python
>>>>>>>> >>>>>>>>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>>>>>> >>>>>>>>>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>>>>>> >>>>>>>>>>>>>>> Type "help", "copyright", "credits" or "license"
>>>>>>>> for more
>>>>>>>> >>>>>>>>>>>>>>> information.
>>>>>>>> >>>>>>>>>>>>>>> >>> import tensorflow as tf
>>>>>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully
>>>>>>>> >>>>>>>>>>>>>>> opened CUDA library libcublas.so locally
>>>>>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully
>>>>>>>> >>>>>>>>>>>>>>> opened CUDA library libcudnn.so locally
>>>>>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully
>>>>>>>> >>>>>>>>>>>>>>> opened CUDA library libcufft.so locally
>>>>>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully
>>>>>>>> >>>>>>>>>>>>>>> opened CUDA library libcuda.so locally
>>>>>>>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>>>>>>>> successfully
>>>>>>>> >>>>>>>>>>>>>>> opened CUDA library libcurand.so locally
>>>>>>>> >>>>>>>>>>>>>>> >>> sess = tf.Session()
>>>>>>>> >>>>>>>>>>>>>>> E
>>>>>>>> tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed
>>>>>>>> >>>>>>>>>>>>>>> call to cuInit: CUDA_ERROR_UNKNOWN
>>>>>>>> >>>>>>>>>>>>>>> I
>>>>>>>> tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>>>> >>>>>>>>>>>>>>> retrieving CUDA diagnostic information for host:
>>>>>>>> midway-l34-01
>>>>>>>> >>>>>>>>>>>>>>> I
>>>>>>>> tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>>>>>>>> >>>>>>>>>>>>>>> hostname: midway-l34-01
>>>>>>>> >>>>>>>>>>>>>>> I
>>>>>>>> tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185]
>>>>>>>> >>>>>>>>>>>>>>> libcuda reported version is: Not found: was unable
>>>>>>>> to find libcuda.so DSO
>>>>>>>> >>>>>>>>>>>>>>> loaded into this program
>>>>>>>> >>>>>>>>>>>>>>> I
>>>>>>>> tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347]
>>>>>>>> >>>>>>>>>>>>>>> driver version file contents: """NVRM version:
>>>>>>>> NVIDIA UNIX x86_64 Kernel
>>>>>>>> >>>>>>>>>>>>>>> Module  346.47  Thu Feb 19 18:56:03 PST 2015
>>>>>>>> >>>>>>>>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat
>>>>>>>> 4.4.7-11)
>>>>>>>> >>>>>>>>>>>>>>> (GCC)
>>>>>>>> >>>>>>>>>>>>>>> """
>>>>>>>> >>>>>>>>>>>>>>> I
>>>>>>>> tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189]
>>>>>>>> >>>>>>>>>>>>>>> kernel reported version is: 346.47.0
>>>>>>>> >>>>>>>>>>>>>>> I
>>>>>>>> tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU
>>>>>>>> >>>>>>>>>>>>>>> devices available on machine.
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> Must there be nvidia driver installed inside the
>>>>>>>> container?
>>>>>>>> >>>>>>>>>>>>>>> Outside? The container shares the same kernel with
>>>>>>>> the host and nvidia
>>>>>>>> >>>>>>>>>>>>>>> kernel module needs to be loaded... How this is
>>>>>>>> handled? Any requirements on
>>>>>>>> >>>>>>>>>>>>>>> nvidia driver and cuda versions inside and outside
>>>>>>>> of the container?
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> Thank you,
>>>>>>>> >>>>>>>>>>>>>>> Igor
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>>
>>>>>>>> >>>>>>>>>>>>>>> --
>>>>>>>> >>>>>>>>>>>>>>> You received this message because you are
>>>>>>>> subscribed to the
>>>>>>>> >>>>>>>>>>>>>>> Google Groups "singularity" group.
>>>>>>>> >>>>>>>>>>>>>>> To unsubscribe from this group and stop receiving
>>>>>>>> emails from
>>>>>>>> >>>>>>>>>>>>>>> it, send an email to
>>>>>>>> singu...@lbl.gov.
>>>>>>>> >>>>>>>>>>>
>>>>>>>> >>>>>>>>>>> --
>>>>>>>> >>>>>>>>>>> You received this message because you are subscribed to
>>>>>>>> the
>>>>>>>> >>>>>>>>>>> Google Groups "singularity" group.
>>>>>>>> >>>>>>>>>>> To unsubscribe from this group and stop receiving
>>>>>>>> emails from it,
>>>>>>>> >>>>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>> >>>>>>>>>>
>>>>>>>> >>>>>>>>>>
>>>>>>>> >>>>>>>>>> --
>>>>>>>> >>>>>>>>>> You received this message because you are subscribed to
>>>>>>>> the Google
>>>>>>>> >>>>>>>>>> Groups "singularity" group.
>>>>>>>> >>>>>>>>>> To unsubscribe from this group and stop receiving emails
>>>>>>>> from it,
>>>>>>>> >>>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> --
>>>>>>>> >>>>>>>>> You received this message because you are subscribed to
>>>>>>>> the Google
>>>>>>>> >>>>>>>>> Groups "singularity" group.
>>>>>>>> >>>>>>>>> To unsubscribe from this group and stop receiving emails
>>>>>>>> from it,
>>>>>>>> >>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>> >>>>>>>>>
>>>>>>>> >>>>>>>>> --
>>>>>>>> >>>>>>>>> You received this message because you are subscribed to
>>>>>>>> the Google
>>>>>>>> >>>>>>>>> Groups "singularity" group.
>>>>>>>> >>>>>>>>> To unsubscribe from this group and stop receiving emails
>>>>>>>> from it,
>>>>>>>> >>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>> >>>>>>>>
>>>>>>>> >>>>>>>>
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> --
>>>>>>>> >>>>>>> You received this message because you are subscribed to the
>>>>>>>> Google
>>>>>>>> >>>>>>> Groups "singularity" group.
>>>>>>>> >>>>>>> To unsubscribe from this group and stop receiving emails
>>>>>>>> from it,
>>>>>>>> >>>>>>> send an email to singu...@lbl.gov.
>>>>>>>> >>>>>>>
>>>>>>>> >>>>>>> --
>>>>>>>> >>>>>>> You received this message because you are subscribed to the
>>>>>>>> Google
>>>>>>>> >>>>>>> Groups "singularity" group.
>>>>>>>> >>>>>>> To unsubscribe from this group and stop receiving emails
>>>>>>>> from it,
>>>>>>>> >>>>>>> send an email to singu...@lbl.gov.
>>>>>>>> >>>>>>
>>>>>>>> >>>>>>
>>>>>>>> >>>>>> --
>>>>>>>> >>>>>> You received this message because you are subscribed to the
>>>>>>>> Google
>>>>>>>> >>>>>> Groups "singularity" group.
>>>>>>>> >>>>>> To unsubscribe from this group and stop receiving emails
>>>>>>>> from it, send
>>>>>>>> >>>>>> an email to singu...@lbl.gov.
>>>>>>>> >>>>>>
>>>>>>>> >>>>>> --
>>>>>>>> >>>>>> You received this message because you are subscribed to the
>>>>>>>> Google
>>>>>>>> >>>>>> Groups "singularity" group.
>>>>>>>> >>>>>> To unsubscribe from this group and stop receiving emails
>>>>>>>> from it, send
>>>>>>>> >>>>>> an email to singu...@lbl.gov.
>>>>>>>> >>>>>
>>>>>>>> >>>>>
>>>>>>>> >>>>> --
>>>>>>>> >>>>> You received this message because you are subscribed to the
>>>>>>>> Google
>>>>>>>> >>>>> Groups "singularity" group.
>>>>>>>> >>>>> To unsubscribe from this group and stop receiving emails from
>>>>>>>> it, send
>>>>>>>> >>>>> an email to singu...@lbl.gov.
>>>>>>>> >>>>>
>>>>>>>> >>>>> --
>>>>>>>> >>>>> You received this message because you are subscribed to the
>>>>>>>> Google
>>>>>>>> >>>>> Groups "singularity" group.
>>>>>>>> >>>>> To unsubscribe from this group and stop receiving emails from
>>>>>>>> it, send
>>>>>>>> >>>>> an email to singu...@lbl.gov.
>>>>>>>> >>>>
>>>>>>>> >>>>
>>>>>>>> >>>> --
>>>>>>>> >>>> You received this message because you are subscribed to the
>>>>>>>> Google
>>>>>>>> >>>> Groups "singularity" group.
>>>>>>>> >>>> To unsubscribe from this group and stop receiving emails from
>>>>>>>> it, send
>>>>>>>> >>>> an email to singu...@lbl.gov.
>>>>>>>> >>>
>>>>>>>> >>>
>>>>>>>> >>> --
>>>>>>>> >>> You received this message because you are subscribed to the
>>>>>>>> Google Groups
>>>>>>>> >>> "singularity" group.
>>>>>>>> >>> To unsubscribe from this group and stop receiving emails from
>>>>>>>> it, send an
>>>>>>>> >>> email to singu...@lbl.gov.
>>>>>>>> >>
>>>>>>>> >> --
>>>>>>>> >> You received this message because you are subscribed to the
>>>>>>>> Google Groups
>>>>>>>> >> "singularity" group.
>>>>>>>> >> To unsubscribe from this group and stop receiving emails from
>>>>>>>> it, send an
>>>>>>>> >> email to singu...@lbl.gov.
>>>>>>>> >
>>>>>>>> > --
>>>>>>>> > You received this message because you are subscribed to the
>>>>>>>> Google Groups
>>>>>>>> > "singularity" group.
>>>>>>>> > To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an
>>>>>>>> > email to singu...@lbl.gov.
>>>>>>>>
>>>>>>>> --
>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>> Groups "singularity" group.
>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Gregory M. Kurtzer
>>>>>>> High Performance Computing Services (HPCS)
>>>>>>> University of California
>>>>>>> Lawrence Berkeley National Laboratory
>>>>>>> One Cyclotron Road, Berkeley, CA 94720
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>
>>>>>> --
>>>>>> You received this message because you are subscribed to the Google
>>>>>> Groups "singularity" group.
>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>> send an email to singu...@lbl.gov.
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>> --
>>>>> Gregory M. Kurtzer
>>>>> High Performance Computing Services (HPCS)
>>>>> University of California
>>>>> Lawrence Berkeley National Laboratory
>>>>> One Cyclotron Road, Berkeley, CA 94720
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>>
>>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>



-- 
Gregory M. Kurtzer
High Performance Computing Services (HPCS)
University of California
Lawrence Berkeley National Laboratory
One Cyclotron Road, Berkeley, CA 94720

--001a114114a09c98ee053918ec59
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><br><div class=3D"gmail_extra"><br><div class=3D"gmail_quo=
te">On Tue, Aug 2, 2016 at 8:52 AM, Nathan Lin <span dir=3D"ltr">&lt;<a hre=
f=3D"mailto:nathan...@gmail.com" target=3D"_blank">nathan...@gmail.com</a>&=
gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 =
0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Gre=
g,<div><br></div><div>Sorry for this email, just saw your recent reply. Can=
 you tell me a bit more about the /environment file? That seems like it wou=
ld definitely solve one of my major issues I&#39;ve been running into. Shou=
ld it be formatted similar to a standard bash profile file?</div></div></bl=
ockquote><div><br></div><div>Containers built/bootstrapped with Singularity=
 v2.1 (or newer) will have the file /environment which will get sourced aut=
omatically when invoking the container. You are correct, you can format it =
similar to your standard bash/shell profile script. In order to be portable=
, just make sure you follow Bourne semantics (not Bash) so don&#39;t do any=
thing fancy. lol</div><div><br></div><div>Hope that helps!</div><div><br></=
div><div>Greg</div><div><br></div><div>=C2=A0</div><blockquote class=3D"gma=
il_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-lef=
t:1ex"><div dir=3D"ltr"><div><br></div><div>Thanks!</div><span class=3D"HOE=
nZb"><font color=3D"#888888"><div>Nathan</div></font></span></div><div clas=
s=3D"HOEnZb"><div class=3D"h5"><div class=3D"gmail_extra"><br><div class=3D=
"gmail_quote">On Tue, Aug 2, 2016 at 11:50 AM, Nathan Lin <span dir=3D"ltr"=
>&lt;<a href=3D"mailto:nathan...@gmail.com" target=3D"_blank">nathan...@gma=
il.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"=
margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"=
ltr">Hi Greg,<div><br></div><div>I think that something along the line of w=
hat you brainstormed would work, but it would probably require that the ima=
ge and the host computer are using the same version of lib.c. At this point=
, I just can&#39;t seem to think about a different way to get around the in=
herent different in the dependencies of the two versions of the library. Bu=
t I&#39;m also not familiar with this kind of stuff (I&#39;ve really only b=
een working with Linux and containers this summer), so maybe there is a sol=
ution out there!</div><div><br></div><div>Best,</div><div>Nathan</div></div=
><div><div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Tue=
, Aug 2, 2016 at 11:46 AM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mail=
to:nathan...@gmail.com" target=3D"_blank">nathan...@gmail.com</a>&gt;</span=
> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;bo=
rder-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Igor,<div><b=
r></div><div>Sorry I was going to include this detail, but I was typing on =
my phone and got lazy. The setting of LD_LIBRARY_PATH is not really automat=
ic. On our clusters, we have modules and basically when we load the TensorF=
low module, it parses the /lib folder for the correct NVIDIA driver version=
 for the computer and stores it as a variable. Then, part of my runscript s=
ets LD_LIBRARY_PATH to include the path to the driver I installed on the im=
age. Not the most elegant solution, but it works. On our cluster, we are tr=
ying to have the image be as similar to a python interpreter as possible, s=
o using runscripts works well for us.</div><div><br></div><div>Best,</div><=
div>Nathan</div></div><div><div><div class=3D"gmail_extra"><br><div class=
=3D"gmail_quote">On Tue, Aug 2, 2016 at 11:39 AM, Igor Yakushin <span dir=
=3D"ltr">&lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">igor...=
@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=
=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=
=3D"ltr">Nathan,<div>Considering that singularity ignores $HOME/.bashrc and=
 in version 2.1 gives you sh, not bash, by default, how do you make singula=
rity set LD_LIBRARY_PATH automatically? Do you wrap bash or is there some o=
ther hooks? On my cluster different nodes have different versions of nvidia=
 driver and different tesla cards. So it would be useful for an image to be=
 able to automatically set LD_LIBRARY_PATH and PATH to point to the correct=
 version of the driver.</div><div>Thank you,</div><div>Igor</div></div><div=
><div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Tue, Aug=
 2, 2016 at 10:29 AM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mailto:na=
than...@gmail.com" target=3D"_blank">nathan...@gmail.com</a>&gt;</span> wro=
te:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-=
left:1px #ccc solid;padding-left:1ex"><div dir=3D"auto"><div></div><div>Hi,=
</div><div><br></div><div>From my experiences, attempting to use the NVIDIA=
 drivers on the host was not the most successful approach. Although first o=
f all, I think it is important to distinguish between the CUDA drivers and =
the NVIDIA drivers. This is made more confusing because the CUDA toolkit wa=
nts to install its own version of the NVIDIA drivers, but the point is the =
CUDA drivers are relatively portable while the NVIDIA drivers are not so mu=
ch.=C2=A0</div><div><br></div><div>The errors I ran into with the NVIDIA dr=
iver (specifically the library libcuda.so.352.63) was that there seemed to =
be a difference between the version of the library that was installed on th=
e cluster and the version of the library I got from extracting the library =
without installing the driver (using the --extract-only option). I think th=
is has to do with the fact that something is actually compiled when you ins=
tall the driver, but the point is that the two versions of the library have=
 different dependencies. And it seems that the version on the cluster depen=
ds on some libraries that are installed on the cluster. Although I did not =
mess with my singularity install (with bind path and such) there didn&#39;t=
 seem like a good resolution for this because the reason we are using singu=
larity is precisely because we want our image to have a newer version of li=
b.c. Thus, the ability for our image to get the libraries it needs from the=
 host computer is pretty much nonexistent. Instead, I&#39;ve set up my imag=
e to have multiple version numbers of the libcuda.so library, and depending=
 on the host machine, the image adds the appropriate driver to LD_LIBRARY_P=
ATH. This isn&#39;t the greatest solution, but it was the best I could thin=
k of.=C2=A0</div><div><br></div><div>I hope that was helpful, and good luck=
!</div><div><br></div><div>Best,</div><div>Nathan</div><div><div><div><br>O=
n Aug 2, 2016, at 11:05 AM, Gregory M. Kurtzer &lt;<a href=3D"mailto:gmku..=
.@lbl.gov" target=3D"_blank">gmku...@lbl.gov</a>&gt; wrote:<br><br></div><b=
lockquote type=3D"cite"><div><div dir=3D"ltr"><div><br></div><div class=3D"=
gmail_extra"><div class=3D"gmail_quote">On Tue, Aug 2, 2016 at 7:58 AM, Igo=
r Yakushin <span dir=3D"ltr">&lt;<a href=3D"mailto:igor...@gmail.com" targe=
t=3D"_blank">igor...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=
=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;bo=
rder-left-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex">=
<div dir=3D"ltr">Hi Greg,<div>I got an impression that Nathan was saying th=
at you cannot just copy host NVIDIA drivers. </div></div></blockquote><div>=
<br></div><div><div>I&#39;m not sure how &quot;copy-able&quot; the drivers =
are, but I have the impression they are compiled against an older version o=
f libC so they should be relatively portable... I think this is how Nvidia-=
docker works.</div></div><div>=C2=A0</div><blockquote class=3D"gmail_quote"=
 style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:=
solid;border-left-color:rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"=
><div>Did I misunderstand it? How do you use &quot;bind path&quot;? Is it a=
 feature of Singularity?</div></div></blockquote><div><br></div><div><div>&=
quot;bind path&quot; is in your configuration file (singularity.conf) and w=
ill bind files/directories outside the container to inside.</div></div><div=
><br></div><div>=C2=A0</div><blockquote class=3D"gmail_quote" style=3D"marg=
in:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-l=
eft-color:rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"><div>Also, wo=
uld this solution be portable? Do you mean that this &quot;bind path&quot; =
happens dynamically as long as the host has some NVIDIA driver and would wo=
rk with any version without having to rebuild the container?</div></div></b=
lockquote><div><br></div><div>That would be the idea yes. It should be as p=
ortable as Nvidia&#39;s solution (as I understand it) lol. Maybe someone el=
se has more information on this who can chime in.</div><div>=C2=A0</div><bl=
ockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;border-lef=
t-width:1px;border-left-style:solid;border-left-color:rgb(204,204,204);padd=
ing-left:1ex"><div dir=3D"ltr"><div>Thank you,</div></div></blockquote><div=
><br></div><div>My pleasure!</div><div>=C2=A0</div><blockquote class=3D"gma=
il_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-le=
ft-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex"><div di=
r=3D"ltr"><div>Igor</div></div><div><div><div class=3D"gmail_extra"><br><di=
v class=3D"gmail_quote">On Tue, Aug 2, 2016 at 9:35 AM, Gregory M. Kurtzer =
<span dir=3D"ltr">&lt;<a href=3D"mailto:gmku...@lbl.gov" target=3D"_blank">=
gmku...@lbl.gov</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" =
style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:s=
olid;border-left-color:rgb(204,204,204);padding-left:1ex">I think the best =
way of doing this is to have the host provide the CUDA drivers that properl=
y match the kernel drivers that it has installed on the host to a directory=
. Then use=C2=A0&quot;bind path&quot; to link in=C2=A0those drivers into th=
e container and set the LD_LIBRARY_PATH in /etc/singularity/init to match t=
hat directory.=C2=A0<div><br></div><div>This feature will be MUCH better wh=
en we will be able to link in arbitrary directories into the containers wit=
hout having to rely on the bind point existing.=C2=A0</div><div><br></div>G=
reg<div><div><div><br></div><div><span></span><br><div><br>On Monday, Augus=
t 1, 2016, Bernard Li &lt;<a href=3D"mailto:ber...@vanhpc.org" target=3D"_b=
lank">ber...@vanhpc.org</a>&gt; wrote:<br><blockquote class=3D"gmail_quote"=
 style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:=
solid;border-left-color:rgb(204,204,204);padding-left:1ex">Hi Igor:<br>
<br>
352.39 and Tesla K80.<br>
<br>
Thanks,<br>
<br>
Bernard<br>
<br>
On Mon, Aug 1, 2016 at 10:21 PM, Igor Yakushin &lt;<a>igor...@gmail.com</a>=
&gt; wrote:<br>
&gt; Hi Bernard,<br>
&gt; What nvidia driver version is on your host?=C2=A0 What card model?<br>
&gt; Thank you,<br>
&gt; Igor<br>
&gt;<br>
&gt;<br>
&gt; On Aug 1, 2016 11:55 PM, &quot;Bernard Li&quot; &lt;<a>ber...@vanhpc.o=
rg</a>&gt; wrote:<br>
&gt;&gt;<br>
&gt;&gt; Hey Igor:<br>
&gt;&gt;<br>
&gt;&gt; If you can make the tensorflow Singularity container available, I&=
#39;d like<br>
&gt;&gt; to try that out on our cluster.<br>
&gt;&gt;<br>
&gt;&gt; Thanks,<br>
&gt;&gt;<br>
&gt;&gt; Bernard<br>
&gt;&gt;<br>
&gt;&gt; On Monday, 1 August 2016, Igor Yakushin &lt;<a>igor...@gmail.com</=
a>&gt; wrote:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt; The main problem was that if you try to install cuda, it would=
 by default<br>
&gt;&gt;&gt; install driver as well that might be of different version than=
 the driver<br>
&gt;&gt;&gt; installed with NVIDIA*.run file. So when installing cuda, use =
an option not<br>
&gt;&gt;&gt; to install the driver. It is much easier to find NVIDIA*.run f=
ile of the<br>
&gt;&gt;&gt; version you need than cuda*.run with the right driver.=C2=A0 W=
hen downloading<br>
&gt;&gt;&gt; NVIDIA*.run, pay attention that you are asking for Tesla card =
(if that&#39;s<br>
&gt;&gt;&gt; what you have). Consumer cards have different driver (I do not=
 remember if<br>
&gt;&gt;&gt; it is reflected in the file name but I suspect not, because I =
made this<br>
&gt;&gt;&gt; mistake).<br>
&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; On Mon, Aug 1, 2016 at 8:56 AM, Nathan Lin &lt;<a>nathan...@gm=
ail.com</a>&gt;<br>
&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; That&#39;s great to hear Igor! What ended up being the pro=
blem?<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; On Mon, Aug 1, 2016 at 1:43 AM, Rick Wagner &lt;<a>richard=
...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; Igor,<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; If you had a chance to post your definition file or th=
e steps you took,<br>
&gt;&gt;&gt;&gt;&gt; I know several of us would appreciate it. Getting Tens=
orFlow running on<br>
&gt;&gt;&gt;&gt;&gt; CentOS was a huge effort for our support staff. And th=
at&#39;s just one of many<br>
&gt;&gt;&gt;&gt;&gt; GPU-enabled applications.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --Rick<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; On Jul 31, 2016, at 10:20 PM, Igor Yakushin &lt;<a>igo=
r...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; Thank you, Nathan. It finally works!<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin &lt;<a>nat=
han...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; Yes I do<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; On Jul 31, 2016, at 5:03 PM, Igor Yakushin &lt;<a>=
igor...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt; When you import tensorflow in python, does it tell=
 you what cuda<br>
&gt;&gt;&gt;&gt;&gt;&gt; libraries it is loading or not?<br>
&gt;&gt;&gt;&gt;&gt;&gt; Do you see these messages:<br>
&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; import tensorflow as tf<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcublas.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcudnn.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcufft.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcuda.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108] su=
ccessfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcurand.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin &lt;<a=
>nathan...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Igor,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; In regards to your first questions, the OS/dri=
vers of your building<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; computer should not matter. I built an Ubuntu =
14.04 image on my RHEL 7 box<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; for our RHEL 6 cluster. I&#39;m not sure that =
the toolkit is that version<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; specific, my image seems to work fine and it&#=
39;s running 353.63. There is one<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; thing that I do that may be helpful. I read it=
 somewhere online and am not<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; actually sure if it does anything, but I&#39;v=
e included it in my image<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; definitions just in case. Apparently there is =
something about initializing<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; the CUDA Toolkit. As part of my definition fil=
e I run &#39;make&#39; on the CUDA<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; sample &#39;deviceQuery&#39;. Maybe that will =
help?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Best,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Nathan<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Jul 31, 2016, at 1:51 PM, Igor Yakushin &lt=
;<a>igor...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I got a little bit further: nvidia-smi is work=
ing now but tensorflow<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; still complains:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/ubuntu_14.04.img&gt; nvidia-smi<br=
>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Sun Jul 31 17:33:44 2016<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +---------------------------------------------=
---------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | NVIDIA-SMI 352.55=C2=A0 =C2=A0 =C2=A0Driver =
Version: 352.55=C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |-------------------------------+-------------=
---------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | GPU=C2=A0 Name=C2=A0 =C2=A0 =C2=A0 =C2=A0 Pe=
rsistence-M| Bus-Id=C2=A0 =C2=A0 =C2=A0 =C2=A0 Disp.A | Volatile<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Uncorr. ECC |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | Fan=C2=A0 Temp=C2=A0 Perf=C2=A0 Pwr:Usage/Ca=
p|=C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0Memory-Usage | GPU-Util<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Compute M. |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=C2=A0 =C2=A00=C2=A0 Tesla K40m=C2=A0 =C2=A0 =
=C2=A0 =C2=A0 =C2=A0 Off=C2=A0 | 0000:20:00.0=C2=A0 =C2=A0 =C2=A0Off |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | N/A=C2=A0 =C2=A045C=C2=A0 =C2=A0 P0=C2=A0 =
=C2=A0 79W / 235W |=C2=A0 =C2=A0 158MiB / 11519MiB |=C2=A0 =C2=A0 =C2=A045%=
<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Default |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------------------------+-------------=
---------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=C2=A0 =C2=A01=C2=A0 Tesla K40m=C2=A0 =C2=A0 =
=C2=A0 =C2=A0 =C2=A0 Off=C2=A0 | 0000:8B:00.0=C2=A0 =C2=A0 =C2=A0Off |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | N/A=C2=A0 =C2=A023C=C2=A0 =C2=A0 P8=C2=A0 =
=C2=A0 18W / 235W |=C2=A0 =C2=A0 =C2=A061MiB / 11519MiB |=C2=A0 =C2=A0 =C2=
=A0 0%<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Default |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------------------------+-------------=
---------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +---------------------------------------------=
--------------------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; | Processes:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; GPU Memory |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=C2=A0 GPU=C2=A0 =C2=A0 =C2=A0 =C2=A0PID=C2=
=A0 Type=C2=A0 Process name<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Usage=C2=A0 =C2=A0 =C2=A0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; +---------------------------------------------=
--------------------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/ubuntu_14.04.img&gt; python<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Python 2.7.6 (default, Mar 22 2014, 22:59:56)<=
br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; [GCC 4.8.2] on linux2<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Type &quot;help&quot;, &quot;copyright&quot;, =
&quot;credits&quot; or &quot;license&quot; for more<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; information.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; import tensorflow<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcublas.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcudnn.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcufft.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcuda.so.1 locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loader.cc:108=
] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcurand.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; ss =3D tensorflow.Session()<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; E tensorflow/stream_executor/cuda/cuda_driver.=
cc:491] failed call to<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; cuInit: CUDA_ERROR_NO_DEVICE<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:153] retrieving<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA diagnostic information for host: midway-l=
34-02<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:160] hostname:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; midway-l34-02<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:185] libcuda<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; reported version is: 352.93.0<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:356] driver<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; version file contents: &quot;&quot;&quot;NVRM =
version: NVIDIA UNIX x86_64 Kernel Module<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; 352.55=C2=A0 Thu Oct=C2=A0 8 15:18:00 PDT 2015=
<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; GCC version:=C2=A0 gcc version 4.4.7 20120313 =
(Red Hat 4.4.7-16) (GCC)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; &quot;&quot;&quot;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:189] kernel<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; reported version is: 352.55.0<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; E tensorflow/stream_executor/cuda/cuda_diagnos=
tics.cc:296] kernel<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; version 352.55.0 does not match DSO version 35=
2.93.0 -- cannot find working<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; devices in this configuration<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/core/common_runtime/gpu/gpu_init.=
cc:81] No GPU devices<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; available on machine.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; As far as I understand the problem is that cud=
a-7.5 was built or<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; relies on nvidia 352.93 while I have NVIDIA dr=
iver 352.55 both on the host<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; and container. So far I could not find cuda-7.=
5 built with 352.55.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; cuda-7.5 has stabs directory in which there is=
 libcuda.so. The<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; problem is probably coming from there. However=
, I doubt I can just replace<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; libcuda.so in the stubs directory by a differe=
nt version or turn it into<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; symbolic link to a different version in the dr=
iver? Because its size is much<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; smaller than the size of the real libcuda.so i=
n the driver. So I suspect, it<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; is really only some kind of interface to the r=
eal library?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Sun, Jul 31, 2016 at 9:36 AM, Igor Yakushin=
 &lt;<a>igor...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; When installing cuda libraries and tensorf=
low into the singularity<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; image, is it important to be on the same h=
ost with the same version of<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA/OS on which you are going to run late=
r?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I do not have root on the machine I am goi=
ng to run later and<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; prepare the image on a different machine w=
ith a different version of nvidia<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver and a different flavor of Linux.<br=
>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Sun, Jul 31, 2016 at 8:39 AM, Nathan Li=
n<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;<a>nathan...@gmail.com</a>&gt; wrote:<=
br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Igor,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I don&#39;t necessarily have a great a=
nswer for you. If seems like you<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; are doing everything right, yet it is =
still not working. In my case, yes<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; nvidia-smi as well as TensorFlow both =
work correctly. I feel like your error<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; still has to do with the version of li=
bcuda.so you are using. Notice how<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Python seems to correctly load libcuda=
.so, yet there is later an error that<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; is unable to find libcuda.so. My first=
 suspicion is that there is still a<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; version mismatch between the drivers i=
nstalled on the image and on the host.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; If you are sure that is not true, it m=
ay be possible that the version of the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver that is installed on the machin=
e isn&#39;t new enough for the GPU. That<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; actually occurred on our cluster, and =
after a sysadmin updated the driver,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; it worked. Barring that I am not too s=
ure. Maybe if you provide me with the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; full details of your installation (the=
 versions of the packages that you<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; have installed, the OS of your image a=
nd host), I might be able to think<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; about something, but my suspicion is t=
hat the driver version on your host<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; machine may not be new enough.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Best,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Nathan<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Jul 31, 2016, at 12:17 AM, Igor Yak=
ushin &lt;<a>igor...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I have found exactly the same version =
of NVIDIA driver and<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; extracted from it the libraries and nv=
idia executables and copied them in<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; /usr/lib64/nvidia and /usr/bin and cre=
ated the corresponding symbolic links.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; However, I still cannot use GPU inside=
 singularity: nvidia-smi says &quot;GPU<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; access blocked by the operating system=
&quot; (does it work in your case?) and<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; when tensorflow session starts it also=
 complains that &quot;No GPU devices<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; available on machine&quot;. However, n=
otice that tensorflow seems to think that a<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; different version of NVIDIA driver is =
used. Not sure where it is coming<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; from. The machine on which the image w=
as built has version 361.42<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Python 2.7.12 (default, Jul=C2=A0 1 20=
16, 15:12:24)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; [GCC 5.4.0 20160609] on linux2<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Type &quot;help&quot;, &quot;copyright=
&quot;, &quot;credits&quot; or &quot;license&quot; for more<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; information.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; import tensorflow<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcublas.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcudnn.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcufft.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcuda.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/dso_loade=
r.cc:108] successfully opened<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; CUDA library libcurand.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; ss =3D tensorflow.Session=
()<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; E tensorflow/stream_executor/cuda/cuda=
_driver.cc:491] failed call<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; to cuInit: CUDA_ERROR_UNKNOWN<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:153]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; retrieving CUDA diagnostic information=
 for host: midway230<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:160]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; hostname: midway230<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:185] libcuda<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; reported version is: Not found: was un=
able to find libcuda.so DSO loaded<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; into this program<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:347] driver<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; version file contents: &quot;&quot;&qu=
ot;NVRM version: NVIDIA UNIX x86_64 Kernel Module<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 352.55=C2=A0 Thu Oct=C2=A0 8 15:18:00 =
PDT 2015<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GCC version:=C2=A0 gcc version 4.4.7 2=
0120313 (Red Hat 4.4.7-16) (GCC)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &quot;&quot;&quot;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/stream_executor/cuda/cuda=
_diagnostics.cc:189] kernel<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; reported version is: 352.55.0<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/core/common_runtime/gpu/g=
pu_init.cc:81] No GPU devices<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; available on machine.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/tensorflow_0.9.img&gt; nvi=
dia-smi<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Failed to initialize NVML: GPU access =
blocked by the operating<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; system<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thu, Jul 28, 2016 at 9:34 PM, Natha=
n Lin<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &lt;<a>nathan...@gmail.com</a>&gt; wro=
te:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I am not sure how to find the corr=
ect driver version, but from my<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; testing, the version must match ex=
actly. I will admit that I have had<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; problems finding specific versions=
 of the driver from NVIDIA&#39;s website. I<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; had to ask a sysadmin for the inst=
aller that they used. In order to extract<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; the files, you need to use the --e=
xtract-only option. For instance, you will<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; have to run something like &#39; s=
h /NVIDIA-Linux-x86_64-352.63.run<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --extract-only&#39;/ . You will th=
en be given a directory with all the libraries<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; that would have been installed. Yo=
u will need to copy the libcuda.so.###.##<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; library (and you can copy any NVID=
IA executables that you want such as<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; nvidia-smi). Good luck!<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thu, Jul 28, 2016 at 8:51 PM, I=
gor &lt;<a>igor...@gmail.com</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I mean I am using this file fr=
om NVIDIA website<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; cuda_7.5.18_linux.run to insta=
ll the driver, opengl, cuda. Driver<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; installation fails, cuda succe=
eds.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Also, when I run<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; sh cuda_7.5.18_linux.run<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I am offered to install the dr=
iver version 352.39 while on the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; host it is 346.47. I cannot up=
grade the host. Any idea where I can get<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 346.17?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tried using the same link ju=
st substitute 18 for something else<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; but have not found the files:<=
br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; wget<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; <a href=3D"http://developer.do=
wnload.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.=
run" target=3D"_blank">http://developer.download.nvidia.com/compute/cuda/7.=
5/Prod/local_installers/cuda_7.5.1X_linux.run</a><br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thursday, July 28, 2016 at =
7:34:55 PM UTC-5, Igor wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi Nathan,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; When I try to install the =
driver by running NVIDIA*.run script<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; inside the image, it fails=
, probably because it tries to modify kernel that<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; belongs to host?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; How do I extract just libc=
uda.so.345.67 without installing the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver (which is obviously=
 problematic) and why would copying the library<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; from the host would not wo=
rk?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thursday, July 28, 2016=
 at 7:18:26 PM UTC-5, Nathan Lin<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Also if you are using =
the binary installation of TensorFlow you<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; need CUDA toolkit 7.5 =
and cuDNN v4. These only need to be installed on our<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; image. As I mentioned =
earlier you will need the libcuda.so.###.## library on<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; your image. It is very=
 important that this is the same version of the NVIDIA<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver as you have on =
your nose (seemingly 346.67 for you). I should&#39;ve have<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; also mentioned that yo=
u want the libcuda.so.345.67 library that you get from<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; extracting the NVIDIA =
installer. It will not work if you try to copy the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; libcuda.so library tha=
t from you node.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Let me know if you hav=
e any more questions.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Best,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Nathan<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thursday, July 28, =
2016, Nathan Lin &lt;<a>nat...@gmail.com</a>&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hello,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Yes you are correc=
t. The NVIDIA driver must be installed on<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; your image as well=
. However, you honestly only need the libcuda.so.###.##<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; library and the ap=
propriate links for that library. Once you have those<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; installed in your =
image, it should work.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Best,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Nathan<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On Thursday, July =
28, 2016, Igor &lt;<a>igor...@gmail.com</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Hi All,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I am trying to=
 use GPU-enabled tensorflow and it cannot find<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GPU card from =
inside the container.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; On the host:<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; $ lspci | grep=
 -i nvidia<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 20:00.0 3D con=
troller: NVIDIA Corporation GK110BGL [Tesla<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; K40m] (rev a1)=
<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 8b:00.0 3D con=
troller: NVIDIA Corporation GK110BGL [Tesla<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; K40m] (rev a1)=
<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; $ nvidia-smi<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thu Jul 28 19:=
01:42 2016<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------=
-----------------------------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | NVIDIA-SMI 3=
46.47=C2=A0 =C2=A0 =C2=A0Driver Version: 346.47=C2=A0 =C2=A0 =C2=A0 =C2=A0 =
=C2=A0|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |-------------=
------------------+----------------------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | GPU=C2=A0 Na=
me=C2=A0 =C2=A0 =C2=A0 =C2=A0 Persistence-M| Bus-Id=C2=A0 =C2=A0 =C2=A0 =C2=
=A0 Disp.A |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Volatile Uncor=
r. ECC |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | Fan=C2=A0 Te=
mp=C2=A0 Perf=C2=A0 Pwr:Usage/Cap|=C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0Memory-=
Usage |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GPU-Util=C2=A0=
 Compute M. |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=C2=A0 =C2=A0=
0=C2=A0 Tesla K40m=C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0 Off=C2=A0 | 0000:20:00=
.0=C2=A0 =C2=A0 =C2=A0Off |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | N/A=C2=A0 =
=C2=A030C=C2=A0 =C2=A0 P8=C2=A0 =C2=A0 20W / 235W |=C2=A0 =C2=A0 =C2=A066Mi=
B / 11519MiB |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0%=C2=A0 =C2=
=A0 =C2=A0 Default |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------=
------------------+----------------------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=C2=A0 =C2=A0=
1=C2=A0 Tesla K40m=C2=A0 =C2=A0 =C2=A0 =C2=A0 =C2=A0 Off=C2=A0 | 0000:8B:00=
.0=C2=A0 =C2=A0 =C2=A0Off |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | N/A=C2=A0 =
=C2=A026C=C2=A0 =C2=A0 P8=C2=A0 =C2=A0 19W / 235W |=C2=A0 =C2=A0 =C2=A060Mi=
B / 11519MiB |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 0%=C2=A0 =C2=
=A0 =C2=A0 Default |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------=
------------------+----------------------+----------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; +-------------=
----------------------------------------------------------------+<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; | Processes:<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GPU Memory |<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=C2=A0 GPU=C2=
=A0 =C2=A0 =C2=A0 =C2=A0PID=C2=A0 Type=C2=A0 Process name<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Usage=C2=A0 =
=C2=A0 =C2=A0 |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D|<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=C2=A0 =C2=A0=
 0=C2=A0 =C2=A0 =C2=A011671=C2=A0 =C2=A0 G=C2=A0 =C2=A0/usr/bin/X<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 9MiB |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; |=C2=A0 =C2=A0=
 1=C2=A0 =C2=A0 =C2=A011671=C2=A0 =C2=A0 G=C2=A0 =C2=A0/usr/bin/X<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 3MiB |<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Inside singula=
rity:<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; $ singularity =
shell<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; /software/src/=
singularity_images/tensorflow_0.9.img<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/te=
nsorflow_0.9.img&gt; lspci | grep -i nvidia<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; bash: lspci: c=
ommand not found<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/te=
nsorflow_0.9.img&gt; nvidia-smi<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; bash: nvidia-s=
mi: command not found<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Singularity/te=
nsorflow_0.9.img&gt; python<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Python 2.7.12 =
(default, Jul=C2=A0 1 2016, 15:12:24)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; [GCC 5.4.0 201=
60609] on linux2<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Type &quot;hel=
p&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; =
for more<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; information.<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; i=
mport tensorflow as tf<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcublas.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcudnn.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcufft.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcuda.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/dso_loader.cc:108] successfully<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; opened CUDA li=
brary libcurand.so locally<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; s=
ess =3D tf.Session()<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; E tensorflow/s=
tream_executor/cuda/cuda_driver.cc:491] failed<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; call to cuInit=
: CUDA_ERROR_UNKNOWN<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:153]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; retrieving CUD=
A diagnostic information for host: midway-l34-01<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:160]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; hostname: midw=
ay-l34-01<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:185]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; libcuda report=
ed version is: Not found: was unable to find libcuda.so DSO<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; loaded into th=
is program<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:347]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; driver version=
 file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 Kernel<b=
r>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Module=C2=A0 3=
46.47=C2=A0 Thu Feb 19 18:56:03 PST 2015<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; GCC version:=
=C2=A0 gcc version 4.4.7 20120313 (Red Hat 4.4.7-11)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; (GCC)<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; &quot;&quot;&q=
uot;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:189]<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; kernel reporte=
d version is: 346.47.0<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; I tensorflow/c=
ore/common_runtime/gpu/gpu_init.cc:81] No GPU<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; devices availa=
ble on machine.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Must there be =
nvidia driver installed inside the container?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Outside? The c=
ontainer shares the same kernel with the host and nvidia<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; kernel module =
needs to be loaded... How this is handled? Any requirements on<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; nvidia driver =
and cuda versions inside and outside of the container?<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Thank you,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Igor<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received t=
his message because you are subscribed to the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Google Groups =
&quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe=
 from this group and stop receiving emails from<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; it, send an em=
ail to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message beca=
use you are subscribed to the<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Google Groups &quot;singularit=
y&quot; group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group=
 and stop receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@l=
bl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because =
you are subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; gro=
up.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and=
 stop receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.g=
ov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you =
are subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<=
br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and sto=
p receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.gov</=
a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you =
are subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<=
br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and sto=
p receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.gov</=
a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you are subs=
cribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiv=
ing emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you are subs=
cribed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiv=
ing emails from it,<br>
&gt;&gt;&gt;&gt;&gt;&gt;&gt; send an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you are subscrib=
ed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving =
emails from it, send<br>
&gt;&gt;&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt;&gt; You received this message because you are subscrib=
ed to the Google<br>
&gt;&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving =
emails from it, send<br>
&gt;&gt;&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; You received this message because you are subscribed t=
o the Google<br>
&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emai=
ls from it, send<br>
&gt;&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; You received this message because you are subscribed t=
o the Google<br>
&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emai=
ls from it, send<br>
&gt;&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt; You received this message because you are subscribed to th=
e Google<br>
&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emails f=
rom it, send<br>
&gt;&gt;&gt;&gt; an email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; --<br>
&gt;&gt;&gt; You received this message because you are subscribed to the Go=
ogle Groups<br>
&gt;&gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt;&gt; To unsubscribe from this group and stop receiving emails from =
it, send an<br>
&gt;&gt;&gt; email to <a>singu...@lbl.gov</a>.<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; You received this message because you are subscribed to the Google=
 Groups<br>
&gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt; To unsubscribe from this group and stop receiving emails from it, =
send an<br>
&gt;&gt; email to <a>singu...@lbl.gov</a>.<br>
&gt;<br>
&gt; --<br>
&gt; You received this message because you are subscribed to the Google Gro=
ups<br>
&gt; &quot;singularity&quot; group.<br>
&gt; To unsubscribe from this group and stop receiving emails from it, send=
 an<br>
&gt; email to <a>singu...@lbl.gov</a>.<br>
<br>
--<br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singu...@lbl.gov</a>.<br>
</blockquote></div></div><br><br></div></div><span>-- <br><div dir=3D"ltr">=
<div>Gregory M. Kurtzer<br>High Performance Computing Services (HPCS)<br>Un=
iversity of California<br>Lawrence Berkeley National Laboratory<br>One Cycl=
otron Road, Berkeley, CA 94720</div></div><br>

<p></p></span><div><div>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>High Performance Computing=
 Services (HPCS)<br>University of California<br>Lawrence Berkeley National =
Laboratory<br>One Cyclotron Road, Berkeley, CA 94720</div></div></div>
</div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div class=3D"gmail_signature" data-smartmail=3D"gmail_signature"><div dir=
=3D"ltr"><div>Gregory M. Kurtzer<br>High Performance Computing Services (HP=
CS)<br>University of California<br>Lawrence Berkeley National Laboratory<br=
>One Cyclotron Road, Berkeley, CA 94720</div></div></div>
</div></div>

--001a114114a09c98ee053918ec59--

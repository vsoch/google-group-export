X-Received: by 10.98.16.131 with SMTP id 3mr873766pfq.40.1508470065009;
        Thu, 19 Oct 2017 20:27:45 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.98.13.143 with SMTP id 15ls2261885pfn.14.gmail; Thu, 19 Oct
 2017 20:27:44 -0700 (PDT)
X-Received: by 10.99.45.198 with SMTP id t189mr3178089pgt.286.1508470064110;
        Thu, 19 Oct 2017 20:27:44 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1508470064; cv=none;
        d=google.com; s=arc-20160816;
        b=PGWanXLKFmvxiRABrpsdEpUy5nlPLUkkh0atXJHJQpN27zt4KLtrYTmvFs5PyzCZJf
         LW6Q7txILcYvDvRuWVYLXhtrDcDKS9B3Lhcb9AkUHOVEi16HkbzxGc30mnHVotmjfl+E
         TvJ3A/Wms0m1TPHzQI81/xkuG8izTSpu12knVW6UnfNu28CRkMgbn6YWrQSkd2xhSPef
         ImLP0Zb9MySp1B9M/b5BlogGUa6NpCZFOSp8EdWiBpuxM0DNdNlIKsSPCXR4qihFUGsQ
         jcebd29f4dHrvfJrb8qfJFaB6gy2+8ocKBtUXgVoS2Ia+e9I2nMJVFxHwSaABLQEV0qS
         czvg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:references:in-reply-to:mime-version
         :dkim-signature:arc-authentication-results;
        bh=sKCGf3Taj34840om0KH7Ethbjo6dAXnCzah/UbCEFGg=;
        b=XX9ALg9NZ8Ul9Spm5czdOxcEBM+peGptpeGN55AoSYMKUFuvovLLB+NTwgAoXh+pJE
         cIeWkYwKSeYhss2U972BCd2aGfOrSyRdtgslhyqRwu0n1eJpU86jZFxrAexfjWKUHZ9d
         3ktLMAQOjioB5Mr9vl1wBVJpTmzlWqhjq/UKZ0y+qXrELyo1H7TMW+B82uKHJB1ODTGT
         ZM8BiiqllpS0AMi/y1dsCGsBLQxhCz80U0ebVCB3YZlAzteHt1xIzW6JsqRk54x2VZrt
         K20oMAKfAlfHq/cAsMFpZIC2CQ5GqncSh28naEoDLecOAw8K94ah3Q7qMxlqdcp2VEzI
         vzcQ==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=Kbgf15n6;
       spf=pass (google.com: domain of davidg...@gmail.com designates 209.85.218.49 as permitted sender) smtp.mailfrom=davidg...@gmail.com
Return-Path: <davidg...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id w28si28169pgm.49.2017.10.19.20.27.43
        for <singu...@lbl.gov>;
        Thu, 19 Oct 2017 20:27:44 -0700 (PDT)
Received-SPF: pass (google.com: domain of davidg...@gmail.com designates 209.85.218.49 as permitted sender) client-ip=209.85.218.49;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=Kbgf15n6;
       spf=pass (google.com: domain of davidg...@gmail.com designates 209.85.218.49 as permitted sender) smtp.mailfrom=davidg...@gmail.com
X-Ironport-SBRS: 2.7
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2EQAQALbOlZfzHaVdFcHgYMGQYMgkRCA?=
 =?us-ascii?q?oEQbicHg2sIgTaYJ4F6kHSFT4ElAwIXGygiAQ6ERU8ChQQHQhUBAQEBAQEBAQE?=
 =?us-ascii?q?BAQIQAQEJCwsIJjGCOAUCAwIeBARGJwIvAQEBAQEBAQEBAQEBAQEBAQEBAQEBA?=
 =?us-ascii?q?QEBAQEBAQEBAQEJAgwBHj8BAQEBAgEjHQENDh4DAQsGAwILDSoCAiEBAQ4DAQU?=
 =?us-ascii?q?BCxEOBwQBHASILoE4AQMNCAULjRKRG0CMDIIFBQEcgwkFg2MKGScNWIMBAQEBA?=
 =?us-ascii?q?QYBAQEBAQEBGQIBBRKDHYIHgVGFGIJegXQBEgFMgmeCYQWKGX+VfzyHYYgVhHm?=
 =?us-ascii?q?TGYxOOIhaGR+BFTVyNFg0ISVeNYIvCYIaKoIuJDYBB4gcSIFtAQEB?=
X-IronPort-AV: E=Sophos;i="5.43,405,1503385200"; 
   d="scan'208,217";a="93492533"
Received: from mail-oi0-f49.google.com ([209.85.218.49])
  by fe3.lbl.gov with ESMTP; 19 Oct 2017 20:27:42 -0700
Received: by mail-oi0-f49.google.com with SMTP id n82so18183821oig.3
        for <singu...@lbl.gov>; Thu, 19 Oct 2017 20:27:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=sKCGf3Taj34840om0KH7Ethbjo6dAXnCzah/UbCEFGg=;
        b=Kbgf15n6hWh63fWafR1Sgherx5wR2KnvFDAONC7W1e8eBv/7FHl3Xj2QPumNQ/F0b6
         XGk2Z9xRGh9lm0DxKlO7Vo1YBlyu036XkUfCmE0pGaanVx+ewuj+F4kPQfjZ1toouEiu
         1HEJ79fJqNlMLCzLit4zE1clHvRCxlFTkg+FNOvnDVHoDJJ92bVVSPHqtmzak/Ocb9ni
         e4g4JuYdQzujLERUwBKXzCflKDxrqLU9TaBezFkWTXvM7hjlGo6ggNZqLlufvNEUyx+y
         UbzxKIBbfk30bXlSWfuBOw4kxfut5jnwgapV46LpXQfAi1WZx9CiliZ4kHLUDZAObpXV
         88kA==
X-Gm-Message-State: AMCzsaUqXtnCo3vnlI0ocsxlPMYSdylt+/QIXVyPkMZC7MbtdTViOSzI
	QLbChDAfDG04iquPBq8Ma+ySF/oUmgO0I5zDwlk=
X-Received: by 10.157.19.28 with SMTP id f28mr2166200ote.333.1508470061454;
 Thu, 19 Oct 2017 20:27:41 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.157.35.197 with HTTP; Thu, 19 Oct 2017 20:27:01 -0700 (PDT)
In-Reply-To: <f3a7007b-dc0a-4e76-acf2-68515fcef0f9@lbl.gov>
References: <43e70f0f-e4c3-4876-aff5-ed8255ebbae4@lbl.gov> <CAHGBjRwXGr50wCTgknTD6TAhxoFc-hOvLr07qPw7YHeW3eqwdA@mail.gmail.com>
 <942d5c3f-57a6-4d81-a4d9-5755b03fdc60@lbl.gov> <CAHGBjRxZ+D=Cbfr2OeaM3VFkDAUjKVY7xt4rw=bwZ-nBfUx1eg@mail.gmail.com>
 <CAN9aCeeTjvu+gns3yNR05L4i7zWffUtUw9HzY+JDtdppymL2uQ@mail.gmail.com>
 <CAPqNE2VsR2YahtA=V42WXk+8ERTTUVuU=BiTiNWasNFAMtnTYQ@mail.gmail.com>
 <b088840b-feaf-46ba-8c23-50265967356b@lbl.gov> <f3a7007b-dc0a-4e76-acf2-68515fcef0f9@lbl.gov>
From: David Godlove <davidg...@gmail.com>
Date: Thu, 19 Oct 2017 23:27:01 -0400
Message-ID: <CAN9aCefg8ukYp=Y8Dj3hd0Cy-ipd0mhnfEi_8LGsNoiE5QgjLA@mail.gmail.com>
Subject: Re: [Singularity] Beginner Singularity question (StarCCM++)
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="001a113d00042ad9ed055bf20e46"

--001a113d00042ad9ed055bf20e46
Content-Type: text/plain; charset="UTF-8"

Awesome!  And thanks for posting this on GitHub.  No doubt it will be
useful to many users in the future.

On Thu, Oct 19, 2017 at 1:42 PM, Matt Kijowski <matthew...@gmail.com>
wrote:

> Well, I think I have it working.  I created a simple/crappy wrapper script
> for SSH and put it on github.
>
> https://github.com/mkijowski/ssh-wrapper
>
> This should be somewhat easy to modify for other programs that have built
> in MPI and have the ability to specify an alternative remote shell wrapper.
>
> Matt
>
>
> On Friday, October 13, 2017 at 12:51:17 PM UTC-4, Michael Galloway wrote:
>>
>> I too would be interested in seeing if this workflow is successful. We as
>> well have struggled a bit with STARCCM+'s peculiarities.
>>
>> --- michael
>>
>> On Friday, October 13, 2017 at 1:19:16 AM UTC-4, John Hearns wrote:
>>>
>>> Matt, I would be interested in the answer to this one also.
>>> For anyone not familiar with Star-CCM it is wrapped up in a very long
>>> and tortuous launcher script. I have had cause to look at this very closely
>>> in the past.  You can choose different MPIs though, as I recall Platform
>>> and OpenMPI at least. I don't think though you can specify anything of your
>>> own making...  As an aside the wrapper also makes the GUI difficult to
>>> launch under vglrun.
>>>
>>> On 12 October 2017 at 23:47, David Godlove <dav...@gmail.com> wrote:
>>>
>>>> You may also want to have a look at this thread:
>>>>
>>>>  https://groups.google.com/a/lbl.gov/forum/#!searchin/singul
>>>> arity/kombrink/singularity/3fvDLR07Ll8/s6pjgfg0CgAJ
>>>>
>>>> And in particular this script which is supposed to replace ssh in your
>>>> mpi container:
>>>>
>>>> https://pastebin.com/vqXXRzb5
>>>>
>>>> On Thu, Oct 12, 2017 at 3:31 PM, Andrew Rokitka <ar...@gmail.com>
>>>> wrote:
>>>>
>>>>> I've done something similar.  Take advantage of the 'singularity run'
>>>>> functionality to do this.  Executing *./starccm.img* is the same as
>>>>> running "*singularity run starccm.img*".   If you *ln -s starccm.img
>>>>> mpirun* and then execute ./mpirun, it too is the same as running "*singularity
>>>>> run starccm.img*".   In your run script, you can write a case
>>>>> statement that handles all of the commands you expect to consume and then
>>>>> execute them within the container accordingly.  Then you softlink those
>>>>> command names to starccm.img. For example (and this isn't meant to
>>>>> necessarily work in your environment):
>>>>>
>>>>> My image is: /misc/shared/images/analysis.img
>>>>>
>>>>> In /misc/shared/bin, i have softlinks to /misc/shared/images/analysis.img
>>>>> for all of my commands, including all of the mpich commands
>>>>>
>>>>> I have my $PATH set with /misc/shared/bin first so that mpirun is
>>>>> /misc/shared/bin/mpirun and not /usr/bin/mpirun
>>>>>
>>>>> I have a runscript (I hope this formats correctly!) that allows you to
>>>>> run the softlinked commands and any options within the container itself:
>>>>>
>>>>> -------------------------------------------------------------
>>>>>   EXEC_NAME=`basename $SINGULARITY_NAME || echo ""`
>>>>>
>>>>>   case $EXEC_NAME in
>>>>>     R)
>>>>>       CMD="/usr/bin/${EXEC_NAME}"
>>>>>       ;;
>>>>>     starccm)
>>>>>       CMD="/misc/analysisprogram/${EXEC_NAME}"
>>>>>       ;;
>>>>>     bt2line|check_callstack|clog2_join|clog2_print|clog2_repair|
>>>>> mpiexec.hydra|parkill|rlog_check_timeorder|rlog_print)
>>>>>       CMD="/usr/bin/${EXEC_NAME}"
>>>>>       ;;
>>>>>     clog2print|clog2TOslog2|clogprint|clogTOslog2|hydra_nameserv
>>>>> er|hydra_persist|hydra_pmi_proxy|jumpshot|logconvertor|
>>>>> mpic++|mpicc|mpich2version|mpicxx|mpiexec|mpif77|mpif90|mpirun)
>>>>>       CMD="/usr/lib64/mpi-mpich2/bin/${EXEC_NAME}"
>>>>>       ;;
>>>>>     *)
>>>>>       CMD="Command not found"
>>>>>       exit 1
>>>>>   esac
>>>>>
>>>>>   cd $PWD
>>>>>   $CMD $@
>>>>>
>>>>> -------------------------------------------------------------
>>>>>
>>>>> So what happens is if I run *R CMD INSTALL /tmp/boguspackage.tgz*,
>>>>> it's actually running R within the container.  I suspect you could fairly
>>>>> easily do something similar with starccm++.
>>>>>
>>>>>
>>>>>
>>>>> On Thu, Oct 12, 2017 at 2:53 PM, Matt Kijowski <mat...@gmail.com>
>>>>> wrote:
>>>>>
>>>>>> yes (ish).  I dont really care whether mpi runs inside the container
>>>>>> or outside.  But given that starccm+ seems to only work with its own built
>>>>>> in mpi I think I need it running within the container itself.
>>>>>>
>>>>>>
>>>>>> On Thursday, October 12, 2017 at 2:48:04 PM UTC-4, Andrew Rokitka
>>>>>> wrote:
>>>>>>>
>>>>>>> Just to clarify - you want mpi to run within the container itself?
>>>>>>>
>>>>>>> On Thu, Oct 12, 2017 at 2:41 PM, Matt Kijowski <mat...@gmail.com
>>>>>>> > wrote:
>>>>>>>
>>>>>>>> Hello all, we're just starting to use Singularity on our HPC system
>>>>>>>> in conjunction with Slurm and I am having some difficulties understanding
>>>>>>>> how to set up one of our containers (but I might be setting things up
>>>>>>>> wrong).
>>>>>>>>
>>>>>>>> So I understand why we would use mpirun outside of a container, but
>>>>>>>> what is a good configuration for a program (StarCCM++) that wraps its own
>>>>>>>> MPI and remote commands into its execution?
>>>>>>>>
>>>>>>>> Example.  I have a 64 node cluster and starccm++ installed into a
>>>>>>>> container.  If I want to run my job inside the container I execute:
>>>>>>>> *srun singularity exec starccm.img starccm+ options simfile*where
>>>>>>>> srun requests a compute node from slurm and executes the rest of the
>>>>>>>> command on that compute node.  The problem I have is with parallel jobs.
>>>>>>>> starccm+ wants to start its processes on the compute nodes itself (I can
>>>>>>>> specify what sort of remote shell to use and which compute nodes I have
>>>>>>>> requested via a machine list file in the options) but starccm+ is not aware
>>>>>>>> that it needs to launch a singularity container on the compute nodes first.
>>>>>>>>
>>>>>>>> My first thought is I need to launch the containers on the compute
>>>>>>>> nodes before executing the starccm++ parallel job so that when it uses SSH
>>>>>>>> to log in to the compute nodes the container is already running but I'm not
>>>>>>>> sure on how to accomplish this.  Any thoughts?
>>>>>>>>
>>>>>>>> --
>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>> Groups "singularity" group.
>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>> You received this message because you are subscribed to the Google
>>>>>> Groups "singularity" group.
>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>> send an email to singu...@lbl.gov.
>>>>>>
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a113d00042ad9ed055bf20e46
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Awesome!=C2=A0 And thanks for posting this on GitHub.=C2=
=A0 No doubt it will be useful to many users in the future.=C2=A0</div><div=
 class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Oct 19, 2017 =
at 1:42 PM, Matt Kijowski <span dir=3D"ltr">&lt;<a href=3D"mailto:matthew..=
.@gmail.com" target=3D"_blank">matthew...@gmail.com</a>&gt;</span> wrote:<b=
r><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:=
1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Well, I think I have it w=
orking.=C2=A0 I created a simple/crappy wrapper script for SSH and put it o=
n github.<br><br><a href=3D"https://github.com/mkijowski/ssh-wrapper" targe=
t=3D"_blank">https://github.com/mkijowski/<wbr>ssh-wrapper</a><br><br>This =
should be somewhat easy to modify for other programs that have built in MPI=
 and have the ability to specify an alternative remote shell wrapper.<span =
class=3D"HOEnZb"><font color=3D"#888888"><br><br>Matt</font></span><div><di=
v class=3D"h5"><br><br>On Friday, October 13, 2017 at 12:51:17 PM UTC-4, Mi=
chael Galloway wrote:<blockquote class=3D"gmail_quote" style=3D"margin:0;ma=
rgin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"lt=
r">I too would be interested in seeing if this workflow is successful. We a=
s well have struggled a bit with STARCCM+&#39;s peculiarities.<div><br></di=
v><div>--- michael<br><br>On Friday, October 13, 2017 at 1:19:16 AM UTC-4, =
John Hearns wrote:<blockquote class=3D"gmail_quote" style=3D"margin:0;margi=
n-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">=
<div>Matt, I would be interested in the answer to this one also.</div><div>=
For anyone not familiar with Star-CCM it is wrapped up in a very long and t=
ortuous launcher script. I have had cause to look at this very closely in t=
he past.=C2=A0 You can choose different MPIs though, as I recall Platform a=
nd OpenMPI at least. I don&#39;t think though you can specify anything of y=
our own making...=C2=A0 As an aside the wrapper also makes the GUI difficul=
t to launch under vglrun.</div></div><div><br><div class=3D"gmail_quote">On=
 12 October 2017 at 23:47, David Godlove <span dir=3D"ltr">&lt;<a rel=3D"no=
follow">dav...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmai=
l_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left=
:1ex"><div dir=3D"ltr">You may also want to have a look at this thread:<div=
><br></div><div>=C2=A0<a href=3D"https://groups.google.com/a/lbl.gov/forum/=
#!searchin/singularity/kombrink/singularity/3fvDLR07Ll8/s6pjgfg0CgAJ" rel=
=3D"nofollow" target=3D"_blank">https://groups.google.com/a/l<wbr>bl.gov/fo=
rum/#!searchin/singul<wbr>arity/kombrink/singularity/<wbr>3fvDLR07Ll8/s6pjg=
fg0CgAJ</a></div><div><br></div><div>And in particular this script which is=
 supposed to replace ssh in your mpi container:</div><div><br></div><div><a=
 style=3D"margin:0px;padding:0px;border:0px;color:rgb(102,17,204);font-fami=
ly:Arial,Helvetica,sans-serif;font-size:13px" href=3D"https://pastebin.com/=
vqXXRzb5" rel=3D"nofollow" target=3D"_blank">https://pastebin.com/vqXXRzb5<=
/a><br></div></div><div><div><div><br><div class=3D"gmail_quote">On Thu, Oc=
t 12, 2017 at 3:31 PM, Andrew Rokitka <span dir=3D"ltr">&lt;<a rel=3D"nofol=
low">ar...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_qu=
ote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex=
"><div dir=3D"ltr">I&#39;ve done something similar.=C2=A0 Take advantage of=
 the &#39;singularity run&#39; functionality to do this.=C2=A0 Executing <i=
>./starccm.img</i> is the same as running &quot;<i>singularity run starccm.=
img</i>&quot;. =C2=A0 If you <i>ln -s starccm.img mpirun</i>=C2=A0and then =
execute ./mpirun, it too is the same as running &quot;<i>singularity run st=
arccm.img</i>&quot;. =C2=A0 In your run script, you can write a case statem=
ent that handles all of the commands you expect to consume and then execute=
 them within the container accordingly.=C2=A0 Then you softlink those comma=
nd names to starccm.img. For example (and this isn&#39;t meant to necessari=
ly work in your environment):<div><br></div><div>My image is: /misc/shared/=
images/analysis.i<wbr>mg=C2=A0<br></div><div><br></div><div>In /misc/shared=
/bin, i have softlinks to /misc/shared/images/analysis.i<wbr>mg for all of =
my commands, including all of the mpich commands</div><div><br></div><div>I=
 have my $PATH set with /misc/shared/bin first so that mpirun is /misc/shar=
ed/bin/mpirun and not /usr/bin/mpirun</div><div><br></div><div>I have a run=
script (I hope this formats correctly!) that allows you to run the softlink=
ed commands and any options within the container itself:</div><div><font fa=
ce=3D"monospace, monospace"><br></font></div><div><font face=3D"monospace, =
monospace">------------------------------<wbr>-----------------------------=
-<wbr>-</font></div><div><span style=3D"font-family:monospace,monospace">=
=C2=A0 EXEC_NAME=3D`basename $SINGULARITY_NAME || echo &quot;&quot;`</span>=
<br></div><div><span style=3D"font-family:monospace,monospace"><br></span><=
/div><div><div><font face=3D"monospace, monospace">=C2=A0 case $EXEC_NAME i=
n</font></div><div><font face=3D"monospace, monospace">=C2=A0 =C2=A0 R)</fo=
nt></div><div><font face=3D"monospace, monospace">=C2=A0 =C2=A0 =C2=A0 CMD=
=3D&quot;/usr/bin/${EXEC_NAME}&quot;</font></div><div><span style=3D"font-f=
amily:monospace,monospace">=C2=A0 =C2=A0 =C2=A0</span><span style=3D"font-f=
amily:monospace,monospace">=C2=A0</span><font face=3D"monospace, monospace"=
>;;</font></div><div><font face=3D"monospace, monospace">=C2=A0 =C2=A0 star=
ccm)</font></div><div><span style=3D"font-family:monospace,monospace">=C2=
=A0 =C2=A0 =C2=A0</span><span style=3D"font-family:monospace,monospace">=C2=
=A0</span><font face=3D"monospace, monospace">CMD=3D&quot;/misc/analysispro=
gram/$<wbr>{EXEC_NAME}&quot;</font></div><div><span style=3D"font-family:mo=
nospace,monospace">=C2=A0 =C2=A0 =C2=A0</span><span style=3D"font-family:mo=
nospace,monospace">=C2=A0</span><font face=3D"monospace, monospace">;;</fon=
t></div><div><font face=3D"monospace, monospace">=C2=A0 =C2=A0 bt2line|chec=
k_callstack|clog2_<wbr>join|clog2_print|clog2_repair|<wbr>mpiexec.hydra|par=
kill|rlog_che<wbr>ck_timeorder|rlog_print)</font></div><div><span style=3D"=
font-family:monospace,monospace">=C2=A0 =C2=A0 =C2=A0</span><span style=3D"=
font-family:monospace,monospace">=C2=A0</span><font face=3D"monospace, mono=
space">CMD=3D&quot;/usr/bin/${EXEC_NAME}&quot;</font></div><div><span style=
=3D"font-family:monospace,monospace">=C2=A0 =C2=A0 =C2=A0</span><span style=
=3D"font-family:monospace,monospace">=C2=A0</span><font face=3D"monospace, =
monospace">;;</font></div><div><span style=3D"font-family:monospace,monospa=
ce">=C2=A0 =C2=A0 clog2print|clog2TOslog2|clogpr<wbr>int|clogTOslog2|hydra_=
nameserv<wbr>er|hydra_persist|hydra_pmi_<wbr>proxy|jumpshot|logconvertor|<w=
br>mpic++|mpicc|mpich2version|<wbr>mpicxx|mpiexec|mpif77|mpif90|<wbr>mpirun=
)</span></div><div><span style=3D"font-family:monospace,monospace">=C2=A0 =
=C2=A0 =C2=A0</span><span style=3D"font-family:monospace,monospace">=C2=A0<=
/span><font face=3D"monospace, monospace">CMD=3D&quot;/usr/lib64/mpi-mpich2=
/b<wbr>in/${EXEC_NAME}&quot;</font></div><div><span style=3D"font-family:mo=
nospace,monospace">=C2=A0 =C2=A0 =C2=A0</span><span style=3D"font-family:mo=
nospace,monospace">=C2=A0</span><font face=3D"monospace, monospace">;;</fon=
t></div><div><font face=3D"monospace, monospace">=C2=A0 =C2=A0 *)</font></d=
iv><div><span style=3D"font-family:monospace,monospace">=C2=A0 =C2=A0 =C2=
=A0</span><span style=3D"font-family:monospace,monospace">=C2=A0</span><fon=
t face=3D"monospace, monospace">CMD=3D&quot;Command not found&quot;</font><=
/div><div><span style=3D"font-family:monospace,monospace">=C2=A0 =C2=A0 =C2=
=A0</span><span style=3D"font-family:monospace,monospace">=C2=A0</span><fon=
t face=3D"monospace, monospace">exit 1</font></div><div><span style=3D"font=
-family:monospace,monospace">=C2=A0 esac</span><br></div><div><span style=
=3D"font-family:monospace,monospace"><br></span></div><div><font face=3D"mo=
nospace, monospace">=C2=A0 cd $PWD</font></div><div><font face=3D"monospace=
, monospace">=C2=A0 $CMD $@</font></div><div><font face=3D"monospace, monos=
pace"><br></font></div><div><font face=3D"monospace, monospace">-----------=
-------------------<wbr>------------------------------<wbr>-</font><br><div=
><div><br></div><div>So what happens is if I run <i>R CMD INSTALL /tmp/bogu=
spackage.tgz</i>, it&#39;s actually running R within the container.=C2=A0 I=
 suspect you could fairly easily do something similar with starccm++.</div>=
<div><br><div><br></div></div></div></div></div></div><div><div><div><br><d=
iv class=3D"gmail_quote">On Thu, Oct 12, 2017 at 2:53 PM, Matt Kijowski <sp=
an dir=3D"ltr">&lt;<a rel=3D"nofollow">mat...@gmail.com</a>&gt;</span> wrot=
e:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-l=
eft:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">yes (ish).=C2=A0 I do=
nt really care whether mpi runs inside the container or outside.=C2=A0 But =
given that starccm+ seems to only work with its own built in mpi I think I =
need it running within the container itself.<span><br><br><br>On Thursday, =
October 12, 2017 at 2:48:04 PM UTC-4, Andrew Rokitka wrote:</span><blockquo=
te class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1p=
x #ccc solid;padding-left:1ex"><span><div dir=3D"ltr">Just to clarify - you=
 want mpi to run within the container itself?</div></span><div><br><div cla=
ss=3D"gmail_quote"><span>On Thu, Oct 12, 2017 at 2:41 PM, Matt Kijowski <sp=
an dir=3D"ltr">&lt;<a rel=3D"nofollow">mat...@gmail.com</a>&gt;</span> wrot=
e:<br></span><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;b=
order-left:1px #ccc solid;padding-left:1ex"><span><div dir=3D"ltr">Hello al=
l, we&#39;re just starting to use Singularity on our HPC system in conjunct=
ion with Slurm and I am having some difficulties understanding how to set u=
p one of our containers (but I might be setting things up wrong).<br><br>So=
 I understand why we would use mpirun outside of a container, but what is a=
 good configuration for a program (StarCCM++) that wraps its own MPI and re=
mote commands into its execution?<br><br>Example.=C2=A0 I have a 64 node cl=
uster and starccm++ installed into a container.=C2=A0 If I want to run my j=
ob inside the container I execute: <i>srun singularity exec starccm.img sta=
rccm+ options simfile<br></i>where srun requests a compute node from slurm =
and executes the rest of the command on that compute node.=C2=A0 The proble=
m I have is with parallel jobs.=C2=A0 starccm+ wants to start its processes=
 on the compute nodes itself (I can specify what sort of remote shell to us=
e and which compute nodes I have requested via a machine list file in the o=
ptions) but starccm+ is not aware that it needs to launch a singularity con=
tainer on the compute nodes first.<br><br>My first thought is I need to lau=
nch the containers on the compute nodes before executing the starccm++ para=
llel job so that when it uses SSH to log in to the compute nodes the contai=
ner is already running but I&#39;m not sure on how to accomplish this.=C2=
=A0 Any thoughts?<span><font color=3D"#888888"><br><i></i></font></span></d=
iv></span><span><font color=3D"#888888"><span>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br></span>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</font></span></blockquote></div><br></div>
</blockquote></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br></div>
</blockquote></div></div></blockquote></div></div></div><div class=3D"HOEnZ=
b"><div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

--001a113d00042ad9ed055bf20e46--

Date: Wed, 10 May 2017 06:40:02 -0700 (PDT)
From: John Galt <spe...@gmail.com>
To: singularity <singu...@lbl.gov>
Cc: arangog...@gmail.com
Message-Id: <df6cbaf6-fc7b-45fc-ba69-b809260b732f@lbl.gov>
In-Reply-To: <f833171b-698a-43c2-b0bd-c80d4dba783d@lbl.gov>
References: <3aac77f3-071c-45db-846e-9b92c2807dbb@lbl.gov>
 <f833171b-698a-43c2-b0bd-c80d4dba783d@lbl.gov>
Subject: Re: Singularity with MPI
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_2520_1778920852.1494423602971"

------=_Part_2520_1778920852.1494423602971
Content-Type: multipart/alternative; 
	boundary="----=_Part_2521_1600048935.1494423602971"

------=_Part_2521_1600048935.1494423602971
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hi,

thanks for your comment. Indeed, it appeared that I did not had the same 
versions of OpenMPI running on the host and the image (it was 2.1 on the 
host and the dev/master on the image).

After installing the development version on the host, everything went fine.


On Tuesday, May 9, 2017 at 5:22:24 PM UTC-5, Carlos Eduardo Arango 
Gutierrez wrote:
>
> Hi
> Just have a doubt when you say "If open a shell withing the container both 
> commands can be executed successfully."
>
> Do you have the same MPI version installed on your host?
>
> Could you try to run the ring example on the host?
>
> On Tuesday, 9 May 2017 17:13:41 UTC-5, John Galt wrote:
>>
>> Hello,
>>
>> I am trying to run Singularity with MPI and am facing some issues. For 
>> now I am trying that locally on a Linux Mint 18.1 and reproduce the MPI 
>> ring test shown on the website. 
>>
>> For now I am encountering the following error:
>>
>> *> mpirun --hostfile hostfile -np 1 singularity exec centos_MPI.img 
>> /usr/bin/ring*
>> **** An error occurred in MPI_Init*
>> **** on a NULL communicator*
>> **** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,*
>> ****    and potentially your MPI job)*
>> *[milton:7631] Local abort before MPI_INIT completed completed 
>> successfully, but am not able to aggregate error messages, and not able to 
>> guarantee that all other processes were killed!*
>> *-------------------------------------------------------*
>> *Primary job  terminated normally, but 1 process returned*
>> *a non-zero exit code.. Per user-direction, the job has been aborted.*
>> *-------------------------------------------------------*
>>
>> *--------------------------------------------------------------------------*
>> *mpirun detected that one or more processes exited with non-zero status, 
>> thus causing*
>> *the job to be terminated. The first process to do so was:*
>>
>> *  Process name: [[5261,1],0]*
>> *  Exit code:    1*
>>
>> *--------------------------------------------------------------------------*
>>
>>  
>> I have attached the Singularity file that is used to bootstrap the image 
>> as well as a shell script with the commands that are used for boostraping. 
>> Hostfile is the hostfile that I use to run the test. Both the *ring* and 
>> *hello* OpenMPI examples have been tested but with no success. If open a 
>> shell withing the container both commands can be executed successfully.
>>
>> Any clue of what I missed ?
>>
>> Thanks in advance for your help.
>>
>> Regards,
>>
>>
>> John
>>
>
------=_Part_2521_1600048935.1494423602971
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi,<div><br></div><div>thanks for your comment. Indeed, it=
 appeared that I did not had the same versions of OpenMPI running on the ho=
st and the image (it was 2.1 on the host and the dev/master on the image).<=
/div><div><br></div><div>After installing the development version on the ho=
st, everything went fine.</div><div><br></div><div><br>On Tuesday, May 9, 2=
017 at 5:22:24 PM UTC-5, Carlos Eduardo Arango Gutierrez wrote:<blockquote =
class=3D"gmail_quote" style=3D"margin: 0;margin-left: 0.8ex;border-left: 1p=
x #ccc solid;padding-left: 1ex;"><div dir=3D"ltr">Hi<div>Just have a doubt =
when you say &quot;If open a shell withing the container both commands can =
be executed successfully.&quot;</div><div><br></div><div>Do you have the sa=
me MPI version installed on your host?</div><div><br></div><div>Could you t=
ry to run the ring example on the host?<br><br>On Tuesday, 9 May 2017 17:13=
:41 UTC-5, John Galt  wrote:<blockquote class=3D"gmail_quote" style=3D"marg=
in:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex"><div di=
r=3D"ltr">Hello,<div><br></div><div>I am trying to run Singularity with MPI=
 and am facing some issues. For now I am trying that locally on a Linux Min=
t 18.1 and reproduce the MPI ring test shown on the website.=C2=A0</div><di=
v><br></div><div>For now I am encountering the following error:</div><div><=
i><font face=3D"courier new, monospace"><br></font></i></div><div><div><i><=
font face=3D"courier new, monospace">&gt; mpirun --hostfile hostfile -np 1 =
singularity exec centos_MPI.img /usr/bin/ring</font></i></div><div><i><font=
 face=3D"courier new, monospace">*** An error occurred in MPI_Init</font></=
i></div><div><i><font face=3D"courier new, monospace">*** on a NULL communi=
cator</font></i></div><div><i><font face=3D"courier new, monospace">*** MPI=
_ERRORS_ARE_FATAL (processes in this communicator will now abort,</font></i=
></div><div><i><font face=3D"courier new, monospace">*** =C2=A0 =C2=A0and p=
otentially your MPI job)</font></i></div><div><i><font face=3D"courier new,=
 monospace">[milton:7631] Local abort before MPI_INIT completed completed s=
uccessfully, but am not able to aggregate error messages, and not able to g=
uarantee that all other processes were killed!</font></i></div><div><i><fon=
t face=3D"courier new, monospace">------------------------------<wbr>------=
-------------------</font></i></div><div><i><font face=3D"courier new, mono=
space">Primary job =C2=A0terminated normally, but 1 process returned</font>=
</i></div><div><i><font face=3D"courier new, monospace">a non-zero exit cod=
e.. Per user-direction, the job has been aborted.</font></i></div><div><i><=
font face=3D"courier new, monospace">------------------------------<wbr>---=
----------------------</font></i></div><div><i><font face=3D"courier new, m=
onospace">------------------------------<wbr>------------------------------=
<wbr>--------------</font></i></div><div><i><font face=3D"courier new, mono=
space">mpirun detected that one or more processes exited with non-zero stat=
us, thus causing</font></i></div><div><i><font face=3D"courier new, monospa=
ce">the job to be terminated. The first process to do so was:</font></i></d=
iv><div><i><font face=3D"courier new, monospace"><br></font></i></div><div>=
<i><font face=3D"courier new, monospace">=C2=A0 Process name: [[5261,1],0]<=
/font></i></div><div><i><font face=3D"courier new, monospace">=C2=A0 Exit c=
ode: =C2=A0 =C2=A01</font></i></div><div><i><font face=3D"courier new, mono=
space">------------------------------<wbr>------------------------------<wb=
r>--------------</font></i></div></div><div><br></div><div>=C2=A0</div><div=
>I have attached the Singularity file that is used to bootstrap the image a=
s well as a shell script with the commands that are used for boostraping. H=
ostfile is the hostfile that I use to run the test. Both the <b>ring</b>=C2=
=A0and <b>hello</b>=C2=A0OpenMPI examples have been tested but with no succ=
ess. If open a shell withing the container both commands can be executed su=
ccessfully.</div><div><br></div><div>Any clue of what I missed ?</div><div>=
<br></div><div>Thanks in advance for your help.</div><div><br></div><div>Re=
gards,</div><div><br></div><div><br></div><div>John</div></div></blockquote=
></div></div></blockquote></div></div>
------=_Part_2521_1600048935.1494423602971--

------=_Part_2520_1778920852.1494423602971--

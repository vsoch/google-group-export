X-Received: by 10.36.23.150 with SMTP id 144mr2630940ith.6.1463159446020;
        Fri, 13 May 2016 10:10:46 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.50.3 with SMTP id y3ls965782ioy.16.gmail; Fri, 13 May 2016
 10:10:45 -0700 (PDT)
X-Received: by 10.98.36.12 with SMTP id r12mr24902882pfj.86.1463159445416;
        Fri, 13 May 2016 10:10:45 -0700 (PDT)
Return-Path: <rhc.o...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTPS id p64si13259564pfb.235.2016.05.13.10.10.45
        for <singu...@lbl.gov>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Fri, 13 May 2016 10:10:45 -0700 (PDT)
Received-SPF: pass (google.com: domain of rhc.o...@gmail.com designates 209.85.220.66 as permitted sender) client-ip=209.85.220.66;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of rhc.o...@gmail.com designates 209.85.220.66 as permitted sender) smtp.mailfrom=rhc.o...@gmail.com
X-Ironport-SBRS: 1.1
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2GrAQA9CjZXb0LcVdFehQqDOoEMoGgBAQEBBog5hm6EdwENgg0Bhyc4FAEBAQEBAQEDDwEKCxQfMYI3ORBVAitAAQEBAwESER0BDSwDAQsBBQUYJwMCAiEQAwEFAQsRDgcEARwEAYdzAw8IBaMqgTE+MYs7hEIFh3AnDYQvHQIGEIVNBgWCM4JXgkOBThEBgxwrgi4FjlOJIzGMJYsqDoVah1yGJzCBDh4BAXeBURuBa04Hhx6BNQEBAQ
X-IronPort-AV: E=Sophos;i="5.24,614,1455004800"; 
   d="scan'208,217";a="23297007"
Received: from mail-pa0-f66.google.com ([209.85.220.66])
  by fe4.lbl.gov with ESMTP; 13 May 2016 10:10:31 -0700
Received: by mail-pa0-f66.google.com with SMTP id zy2so10518505pac.2
        for <singu...@lbl.gov>; Fri, 13 May 2016 10:10:31 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=sender:from:message-id:mime-version:subject:date:references:to
         :in-reply-to;
        bh=t9i3cFbqtxK6zQRbTHvONyjiwNyBJgfrfM/LoQeh0Us=;
        b=J/ws5SFcsN7idGD/mVsz5r30B0v3mWhnKj/i/zGmxQkxsrifVXqxLF5WlvmhyxuWw2
         KM06+N1Zmc8I795Yq4SJGlxVDzMlxjUCckQouesnVH+R+thMVVHep9i6TEr5vVHgJ8li
         xQjbhVfHD6ELn0r9qE3FbMg6SoUu0RaNzHdkBd8x9TJ1veN/lbtilx3qHZI+jfWTOYeY
         EZvd2AZCktjvDkbJ5hG5uTy+yLnwhD2WlRUx0y/rvw1VxGmnshngQ/jU/i5ZXgnzTVV+
         JyhbW4RwCLWX0EMx78uulh630qDlnwX4bJl4BnHlr0cRXO70pOhm8q6aD6EocY6ie6JZ
         /rVg==
X-Gm-Message-State: AOPr4FW+Ja5hIpFdIijUcaMS4D1u8wIdWr/vlTFpM1mK/q/67iM4TdNc7kv5gzjTae1laA==
X-Received: by 10.66.119.177 with SMTP id kv17mr24859887pab.57.1463159430868;
        Fri, 13 May 2016 10:10:30 -0700 (PDT)
Return-Path: <rhc.o...@gmail.com>
Received: from [192.168.0.8] ([208.100.172.177])
        by smtp.gmail.com with ESMTPSA id d78sm28721946pfb.59.2016.05.13.10.10.28
        for <singu...@lbl.gov>
        (version=TLSv1/SSLv3 cipher=OTHER);
        Fri, 13 May 2016 10:10:29 -0700 (PDT)
Sender: Ralph Castain <rhc.o...@gmail.com>
From: Ralph Castain <r...@open-mpi.org>
Content-Type: multipart/alternative; boundary="Apple-Mail=_A25B47F5-B6B1-4F11-AC61-207F46462BB1"
Message-Id: <414C0039-42A3-4C2E-89F6-3D97D082C742@open-mpi.org>
Mime-Version: 1.0 (Mac OS X Mail 9.3 \(3124\))
Subject: Re: [Singularity] SIngularity and MPI implementations
Date: Fri, 13 May 2016 10:10:28 -0700
References: <a5f7347e-4bf8-486c-b06f-f00e2e762747@lbl.gov> <CAN7etTwFQcnyMjry5ZvRKVqrWo2FqpAPAwQ1ZfpzJdOk3kRp_A@mail.gmail.com> <CAAS-_CBb3sy393W1Bga5Wnr9-EvSHC6NPNaOx58Mpdw-LiFq8g@mail.gmail.com>
To: singularity@lbl.gov
In-Reply-To: <CAAS-_CBb3sy393W1Bga5Wnr9-EvSHC6NPNaOx58Mpdw-LiFq8g@mail.gmail.com>
X-Mailer: Apple Mail (2.3124)

--Apple-Mail=_A25B47F5-B6B1-4F11-AC61-207F46462BB1
Content-Transfer-Encoding: quoted-printable
Content-Type: text/plain;
	charset=utf-8


> On May 13, 2016, at 9:52 AM, Taras Shapovalov <shapov...@gmail.com> wrote=
:
>=20
> Hi Ralph and Gregory,
>=20
> Thank you the both for the so detailed answers! I see your replies comple=
ment each other. Although I am a bit confused now with the whole picture, s=
o could you confirm that I get the ideas correctly:
>=20
> 1. All implementations of MPI by default should work with Singularity con=
tainers (maybe not as optimal as could be, but should start and finish corr=
ectly always). Actually I've tested recently MPICH+Singularity with several=
 workload managers, worked fine (did not benchmark it comparing with Open M=
PI). I did not manage to make Singularity+MPI work in LSF, but this is a di=
fferent story that deserves a separate thread.

Correct - the LSF issue is likely a problem of getting the required setup i=
nfo passed by LSF

>=20
> 2. MPI process calls dl_open, thus the more MPI processes starts on a nod=
e, the more times dl_open will be called. Open MPI 2.0.1 somehow solves thi=
s magically (I don't get how) and dl_open is called only once per node. Oth=
er implementations of MPI and older Open MPI are not Singularity aware, thu=
s they still will call dl_open each time when MPI process spawns.=20

Not exactly. Singularity will solve the dl_open problem by itself. What the=
 container does is wrap all the dl_open libraries into the container, and s=
o all dl_open calls by the app are locally resolved. Thus, you automaticall=
y resolve the IO node bottleneck scaling issue.

What OMPI adds is that it pulls the container only once/node. Other mpiexec=
 implementations will pull the container again for every local process. So =
if you have 100 procs/node, OMPI will result in 100x fewer =E2=80=9Cpulls=
=E2=80=9D thru that IO node.

>=20
> 3. dl_open issue affects only process start time and does not effect the =
process execution, so on small scale with long running processes there is n=
o difference between Open MPI 2.0.1 and older Open MPI versions (as well as=
 other MPI implementations).

Correct

>=20
> 4. When sapp is built then Singularity detects Open MPI (even older then =
2.0.1, right?) and resolves all dependencies automatically adding all files=
 to the sapp. But with, say, MVAPICH2 the dependencies are not resolved aut=
omatically, so user should add some stuff manually.

Correct

>=20
> 5. Apart of solving dl_open issue Open MPI 2.0.1 does some splitting betw=
een the host and the container, which allows user/admin to not optimize Ope=
n MPI for a target platform. I really don't get how Singularity does this, =
but I get the problem. Could you explain what Singularity or Open MPI 2.0.1=
 does for that specificaly?

When running under mpiexec with Singularity, OMPI=E2=80=99s local daemon on=
 each node actually runs outside of the containers. We then fork/exec the c=
ontainer itself, and the container is defined so it auto-executes the appli=
cation process. This allows us to minimize the services overhead, keeping a=
ll services outside of your container (and thus shared across all container=
s.

Other approaches have the daemon -inside- the container, and you get one da=
emon for each container - and thus, one daemon for each local application. =
So you get a higher overhead and therefore lower performance.

HTH
Ralph


>=20
> Best regards,
>=20
> Taras
>=20
>=20
> --=20
> You received this message because you are subscribed to the Google Groups=
 "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an=
 email to singu...@lbl.gov <mailto:singu...@lbl.gov>.


--Apple-Mail=_A25B47F5-B6B1-4F11-AC61-207F46462BB1
Content-Transfer-Encoding: quoted-printable
Content-Type: text/html;
	charset=utf-8

<html><head><meta http-equiv=3D"Content-Type" content=3D"text/html charset=
=3Dutf-8"></head><body style=3D"word-wrap: break-word; -webkit-nbsp-mode: s=
pace; -webkit-line-break: after-white-space;" class=3D""><br class=3D""><di=
v><blockquote type=3D"cite" class=3D""><div class=3D"">On May 13, 2016, at =
9:52 AM, Taras Shapovalov &lt;<a href=3D"mailto:shapov...@gmail.com" class=
=3D"">shapov...@gmail.com</a>&gt; wrote:</div><br class=3D"Apple-interchang=
e-newline"><div class=3D""><div dir=3D"ltr" class=3D""><div class=3D""><div=
 class=3D""><div class=3D""><div class=3D""><div class=3D""><div class=3D""=
>Hi Ralph and Gregory,<br class=3D""><br class=3D""></div>Thank you the bot=
h for the so detailed answers! I see your replies complement each other. Al=
though I am a bit confused now with the whole picture, so could you confirm=
 that I get the ideas correctly:<br class=3D""><br class=3D""></div>1. All =
implementations of MPI by default should work with Singularity containers (=
maybe not as optimal as could be, but should start and finish correctly alw=
ays). Actually I've tested recently MPICH+Singularity with several workload=
 managers, worked fine (did not benchmark it comparing with Open MPI). I di=
d not manage to make Singularity+MPI work in LSF, but this is a different s=
tory that deserves a separate thread.<br class=3D""></div></div></div></div=
></div></div></blockquote><div><br class=3D""></div>Correct - the LSF issue=
 is likely a problem of getting the required setup info passed by LSF</div>=
<div><br class=3D""><blockquote type=3D"cite" class=3D""><div class=3D""><d=
iv dir=3D"ltr" class=3D""><div class=3D""><div class=3D""><div class=3D""><=
div class=3D""><br class=3D""></div>2. MPI process calls dl_open, thus the =
more MPI processes starts on a node, the more times dl_open will be called.=
 Open MPI 2.0.1 somehow solves this magically (I don't get how) and dl_open=
 is called only once per node. Other implementations of MPI and older Open =
MPI are not Singularity aware, thus they still will call dl_open each time =
when MPI process spawns. <br class=3D""></div></div></div></div></div></blo=
ckquote><div><br class=3D""></div>Not exactly. Singularity will solve the d=
l_open problem by itself. What the container does is wrap all the dl_open l=
ibraries into the container, and so all dl_open calls by the app are locall=
y resolved. Thus, you automatically resolve the IO node bottleneck scaling =
issue.</div><div><br class=3D""></div><div>What OMPI adds is that it pulls =
the container only once/node. Other mpiexec implementations will pull the c=
ontainer again for every local process. So if you have 100 procs/node, OMPI=
 will result in 100x fewer =E2=80=9Cpulls=E2=80=9D thru that IO node.</div>=
<div><br class=3D""><blockquote type=3D"cite" class=3D""><div class=3D""><d=
iv dir=3D"ltr" class=3D""><div class=3D""><div class=3D""><div class=3D""><=
br class=3D"">3. dl_open issue affects only process start time and does not=
 effect the process execution, so on small scale with long running processe=
s there is no difference between Open MPI 2.0.1 and older Open MPI versions=
 (as well as other MPI implementations).<br class=3D""></div></div></div></=
div></div></blockquote><div><br class=3D""></div>Correct</div><div><br clas=
s=3D""><blockquote type=3D"cite" class=3D""><div class=3D""><div dir=3D"ltr=
" class=3D""><div class=3D""><div class=3D""><div class=3D""><br class=3D""=
></div><div class=3D"">4. When sapp is built then Singularity detects Open =
MPI (even older then 2.0.1, right?) and resolves all dependencies automatic=
ally adding all files to the sapp. But with, say, MVAPICH2 the dependencies=
 are not resolved automatically, so user should add some stuff manually.<br=
 class=3D""></div></div></div></div></div></blockquote><div><br class=3D"">=
</div>Correct</div><div><br class=3D""><blockquote type=3D"cite" class=3D""=
><div class=3D""><div dir=3D"ltr" class=3D""><div class=3D""><div class=3D"=
"><div class=3D""><br class=3D""></div>5. Apart of solving dl_open issue Op=
en MPI 2.0.1 does some splitting between the host and the container, which =
allows user/admin to not optimize Open MPI for a target platform. I really =
don't get how Singularity does this, but I get the problem. Could you expla=
in what Singularity or Open MPI 2.0.1 does for that specificaly?<br class=
=3D""></div></div></div></div></blockquote><div><br class=3D""></div><div>W=
hen running under mpiexec with Singularity, OMPI=E2=80=99s local daemon on =
each node actually runs outside of the containers. We then fork/exec the co=
ntainer itself, and the container is defined so it auto-executes the applic=
ation process. This allows us to minimize the services overhead, keeping al=
l services outside of your container (and thus shared across all containers=
.</div><div><br class=3D""></div><div>Other approaches have the daemon -ins=
ide- the container, and you get one daemon for each container - and thus, o=
ne daemon for each local application. So you get a higher overhead and ther=
efore lower performance.</div><div><br class=3D""></div><div>HTH</div><div>=
Ralph</div><div><br class=3D""></div><br class=3D""><blockquote type=3D"cit=
e" class=3D""><div class=3D""><div dir=3D"ltr" class=3D""><div class=3D""><=
div class=3D""><br class=3D""></div>Best regards,<br class=3D""><br class=
=3D""></div>Taras<br class=3D""><br class=3D""></div><div class=3D""><br cl=
ass=3D"webkit-block-placeholder"></div>

-- <br class=3D"">
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br class=3D"">
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" class=3D"">singu...@lbl.gov</a>=
.<br class=3D"">
</div></blockquote></div><br class=3D""></body></html>
--Apple-Mail=_A25B47F5-B6B1-4F11-AC61-207F46462BB1--

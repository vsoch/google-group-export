Date: Sat, 24 Feb 2018 16:28:23 -0800 (PST)
From: Valentin Kozlov <valenti...@gmail.com>
To: singularity <singu...@lbl.gov>
Message-Id: <74cbc46b-1eb9-4f43-a764-9de792ea86a6@lbl.gov>
Subject: singularity install on RHEL7 + GPU
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_10812_287206189.1519518503512"

------=_Part_10812_287206189.1519518503512
Content-Type: multipart/alternative; 
	boundary="----=_Part_10813_603971902.1519518503512"

------=_Part_10813_603971902.1519518503512
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hi all,

I am a bit experimenting with singularity and trying to install it on AWS, 
RHEL7 AMI (ami-c90195b0). 
I first install Nvidia stuff by downloading rpm from nvidia, 
cuda-repo-rhel7-9-1-local-9.1.85-1.x86_64. I clone singularity from git, 
compile it and install it (though no mksquashfs was installed).  nvidia-smi 
outputs 387.26

However, when I run under unprivileged user: singularity shell --nv 
docker://tensorflow/tensorflow:latest-gpu

I get following error messages:
~~~~~~~~~~
failed call to cuInit: CUDA_ERROR_UNKNOWN
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA 
diagnostic information for host: ip-172-31-20-167.eu-west-1.compute.internal
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: 
ip-172-31-20-167.eu-west-1.compute.internal
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported 
version is: Invalid argument: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form 
for driver version; got "1"
~~~~~~~~~~
I can still run nvidia-smi inside container and it produces right output.

'Funny' enough, if I install docker-ce and nvidia-docker, I can run same 
container in nvidia-docker, BUT I then can also run my command above, i.e. 
no error message. It seems to be related to the fact, that nvidia-docker 
puts additional kernel drivers in memory.

Any idea how to avoid the error without installing nvidia-docker?

Best,
Valentin

------=_Part_10813_603971902.1519518503512
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi all,<div><br></div><div>I am a bit experimenting with s=
ingularity and trying to install it on AWS, RHEL7 AMI (ami-c90195b0).=C2=A0=
</div><div>I first install Nvidia stuff by downloading rpm from nvidia, cud=
a-repo-rhel7-9-1-local-9.1.85-1.x86_64. I clone singularity from git, compi=
le it and install it (though no mksquashfs was installed).=C2=A0 nvidia-smi=
 outputs 387.26</div><div><br></div><div>However, when I run under unprivil=
eged user:=C2=A0singularity shell --nv docker://tensorflow/tensorflow:lates=
t-gpu</div><div><br></div><div>I get following error messages:</div><div><d=
iv>~~~~~~~~~~</div><div>failed call to cuInit: CUDA_ERROR_UNKNOWN</div><div=
>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA=
 diagnostic information for host: ip-172-31-20-167.eu-west-1.compute.intern=
al</div><div>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hos=
tname: ip-172-31-20-167.eu-west-1.compute.internal</div><div>I tensorflow/s=
tream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: I=
nvalid argument: expected %d.%d, %d.%d.%d, or %d.%d.%d.%d form for driver v=
ersion; got &quot;1&quot;</div></div><div>~~~~~~~~~~</div><div>I can still =
run nvidia-smi inside container and it produces right output.</div><div><br=
></div><div>&#39;Funny&#39; enough, if I install docker-ce and nvidia-docke=
r, I can run same container in nvidia-docker, BUT I then can also run my co=
mmand above, i.e. no error message. It seems to be related to the fact, tha=
t nvidia-docker puts additional kernel drivers in memory.</div><div><br></d=
iv><div>Any idea how to avoid the error without installing nvidia-docker?</=
div><div><br></div><div>Best,</div><div>Valentin</div></div>
------=_Part_10813_603971902.1519518503512--

------=_Part_10812_287206189.1519518503512--

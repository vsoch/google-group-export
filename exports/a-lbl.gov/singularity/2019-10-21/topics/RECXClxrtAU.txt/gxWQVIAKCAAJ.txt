Date: Wed, 27 Jun 2018 05:50:29 -0700 (PDT)
From: Dominique Hansen <dominiqu...@gmail.com>
To: singularity <singu...@lbl.gov>
Message-Id: <4d550130-4d54-4d4f-bf9f-a46f34132e96@lbl.gov>
Subject: Research data and containers
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_10129_71862277.1530103829692"

------=_Part_10129_71862277.1530103829692
Content-Type: multipart/alternative; 
	boundary="----=_Part_10130_1500724247.1530103829693"

------=_Part_10130_1500724247.1530103829693
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hello everyone,

I am seeking for tips and experience on how to handle research data, 
especially bigger sets of data (inside the GB range), in combination with 
containers.

I am a student assistant working in the IT department of a research 
institute. And I am involved in building the infrastructure for singularity 
containerization and introducing researchers to the technology. We have 
already build a few base images containing frequently used tools. Recently 
a research group approached us, wishing to integrate data, they created for 
one tool, into a container with the tool. The data takes up several GB of 
disk space and we are unsure how to handle this and similar future use 
cases.

Does anyone have a set of best practices or is there an intended way to use 
singularity with big research data?

The options we considered are:

   - Moving the data into the container at build time.
      - Pro:
      - Keeps the whole thing mobile
         - Keeps work away from the researchers
         - Can be referenced as a single entity in a publication.
      - Con:
      - Where would you store such big containers, especially several of 
         them?
         - What would happen, if separate versions of the tool are needed? 
         Keep the old and accumulate redundant data? Delete the old and risk 
         reproducibility problems? (Maybe container Apps can be used to minimize 
         this.)
         - Let the researchers mount the data into the container at startup.
      - Pro:
      - Keeps the containers slimmer, the tools more modular.
      - Con:
      - Adds to the workload and the things the researchers have to keep 
         track of.
         - Spreads the parts needed for reproduction over at least two 
         points.
         - Hampers mobility.
      - Mounting during early phases and publish with a container, 
   containing the data.
      - Pro:
         - Reduces amount of containers with redundant and deprecated  data.
         - Makes reproduction of results easier after publication.
      - Con:
         - Ads to the workload.
         - When is the point when its time to "freeze" the data inside the 
         container?
         - Storage of the container is still problematic.
         - Might introduce reproducibility problems, since you change the 
         original container to put the data into it.
      
Are there any recommendations from experience?

Thank you and best regards,
Dominique

------=_Part_10130_1500724247.1530103829693
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hello everyone,<br><br>I am seeking for tips and experienc=
e on how to handle research data, especially bigger sets of data (inside th=
e GB range), in combination with containers.<br><br>I am a student assistan=
t working in the IT department of a research institute. And I am involved i=
n building the infrastructure for singularity containerization and introduc=
ing researchers to the technology. We have already build a few base images =
containing frequently used tools. Recently a research group approached us, =
wishing to integrate data, they created for one tool, into a container with=
 the tool. The data takes up several GB of disk space and we are unsure how=
 to handle this and similar future use cases.<br><br>Does anyone have a set=
 of best practices or is there an intended way to use singularity with big =
research data?<br><br>The options we considered are:<br><ul><li>Moving the =
data into the container at build time.</li><ul><li>Pro:<br></li><ul><li>Kee=
ps the whole thing mobile</li><li>Keeps work away from the researchers</li>=
<li>Can be referenced as a single entity in a publication.</li></ul><li>Con=
:<br></li><ul><li>Where would you store such big containers, especially sev=
eral of them?<br></li><li>What would happen, if separate versions of the to=
ol are needed? Keep the old and accumulate redundant data? Delete the old a=
nd risk reproducibility problems? (Maybe container Apps can be used to mini=
mize this.)<br></li></ul></ul><li>Let the researchers mount the data into t=
he container at startup.</li><ul><li>Pro:<br></li><ul><li>Keeps the contain=
ers slimmer, the tools more modular.</li></ul><li>Con:<br></li><ul><li>Adds=
 to the workload and the things the researchers have to keep track of.</li>=
<li>Spreads the parts needed for reproduction over at least two points.</li=
><li>Hampers mobility.</li></ul></ul><li>Mounting during early phases and p=
ublish with a container, containing the data.</li><ul><li>Pro:</li><ul><li>=
Reduces amount of containers with redundant and deprecated=C2=A0 data.</li>=
<li>Makes reproduction of results easier after publication.</li></ul><li>Co=
n:</li><ul><li>Ads to the workload.</li><li>When is the point when its time=
 to &quot;freeze&quot; the data inside the container?</li><li>Storage of th=
e container is still problematic.<br></li><li>Might introduce reproducibili=
ty problems, since you change the original container to put the data into i=
t.</li></ul></ul></ul><div>Are there any recommendations from experience?</=
div><div><br></div><div>Thank you and best regards,</div><div>Dominique<br>=
</div></div>
------=_Part_10130_1500724247.1530103829693--

------=_Part_10129_71862277.1530103829692--

Date: Thu, 28 Jul 2016 17:51:53 -0700 (PDT)
From: Igor <igor...@gmail.com>
To: singularity <singu...@lbl.gov>
Message-Id: <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
In-Reply-To: <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov>
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
 <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov>
Subject: Re: [Singularity] How to use GPU in singularity?
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_2_2068057723.1469753513403"

------=_Part_2_2068057723.1469753513403
Content-Type: multipart/alternative; 
	boundary="----=_Part_3_1533699825.1469753513404"

------=_Part_3_1533699825.1469753513404
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

I mean I am using this file from NVIDIA website cuda_7.5.18_linux.run to 
install the driver, opengl, cuda. Driver installation fails, cuda succeeds. 
Also, when I run 
sh cuda_7.5.18_linux.run
I am offered to install the driver version 352.39 while on the host it is 346.47. 
I cannot upgrade the host. Any idea where I can get 346.17?
I tried using the same link just substitute 18 for something else but have 
not found the files:
wget 
http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run



On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:
>
> Hi Nathan,
> When I try to install the driver by running NVIDIA*.run script inside the 
> image, it fails, probably because it tries to modify kernel that belongs to 
> host?
> How do I extract just libcuda.so.345.67 without installing the driver 
> (which is obviously problematic) and why would copying the library from the 
> host would not work?
> Thank you,
> Igor
>
> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:
>>
>> Also if you are using the binary installation of TensorFlow you need CUDA 
>> toolkit 7.5 and cuDNN v4. These only need to be installed on our image. As 
>> I mentioned earlier you will need the libcuda.so.###.## library on your 
>> image. It is very important that this is the same version of the NVIDIA 
>> driver as you have on your nose (seemingly 346.67 for you). I should've 
>> have also mentioned that you want the libcuda.so.345.67 library that you 
>> get from extracting the NVIDIA installer. It will not work if you try to 
>> copy the libcuda.so library that from you node. 
>>
>> Let me know if you have any more questions. 
>>
>> Best,
>> Nathan
>>
>> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com> wrote:
>>
>>> Hello,
>>>
>>> Yes you are correct. The NVIDIA driver must be installed on your image 
>>> as well. However, you honestly only need the libcuda.so.###.## library and 
>>> the appropriate links for that library. Once you have those installed in 
>>> your image, it should work. 
>>>
>>> Best,
>>> Nathan 
>>>
>>> On Thursday, July 28, 2016, Igor <igor...@gmail.com> wrote:
>>>
>>>> Hi All,
>>>>
>>>> I am trying to use GPU-enabled tensorflow and it cannot find GPU card 
>>>> from inside the container.
>>>>
>>>> On the host:
>>>> $ lspci | grep -i nvidia 
>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev 
>>>> a1) 
>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1)
>>>>
>>>> $ nvidia-smi 
>>>> Thu Jul 28 19:01:42 2016        
>>>> +------------------------------------------------------+ 
>>>>                        
>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47         | 
>>>>                        
>>>> |-------------------------------+----------------------+----------------------+ 
>>>>
>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile 
>>>> Uncorr. ECC | 
>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util 
>>>>  Compute M. | 
>>>> |===============================+======================+======================| 
>>>>
>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off | 
>>>>                    0 | 
>>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB |      0% 
>>>>      Default | 
>>>> +-------------------------------+----------------------+----------------------+ 
>>>>
>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off | 
>>>>                    0 | 
>>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB |      0% 
>>>>      Default | 
>>>> +-------------------------------+----------------------+----------------------+ 
>>>>
>>>>
>>>>                                                                                
>>>> +-----------------------------------------------------------------------------+ 
>>>>
>>>> | Processes:                                                       GPU 
>>>> Memory | 
>>>> |  GPU       PID  Type  Process name 
>>>>                               Usage      | 
>>>> |=============================================================================| 
>>>>
>>>> |    0     11671    G   /usr/bin/X 
>>>>                                       9MiB | 
>>>> |    1     11671    G   /usr/bin/X 
>>>>                                       3MiB |
>>>>
>>>>
>>>> Inside singularity:
>>>> $ singularity shell /software/src/singularity_images/tensorflow_0.9.img
>>>>
>>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia 
>>>> bash: lspci: command not found 
>>>> Singularity/tensorflow_0.9.img> nvidia-smi 
>>>> bash: nvidia-smi: command not found 
>>>> Singularity/tensorflow_0.9.img> python 
>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)  
>>>> [GCC 5.4.0 20160609] on linux2 
>>>> Type "help", "copyright", "credits" or "license" for more information. 
>>>> >>> import tensorflow as tf 
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened 
>>>> CUDA library libcublas.so locally 
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened 
>>>> CUDA library libcudnn.so locally 
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened 
>>>> CUDA library libcufft.so locally 
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened 
>>>> CUDA library libcuda.so locally 
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened 
>>>> CUDA library libcurand.so locally 
>>>> >>> sess = tf.Session() 
>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to 
>>>> cuInit: CUDA_ERROR_UNKNOWN 
>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving 
>>>> CUDA diagnostic information for host: midway-l34-01 
>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: 
>>>> midway-l34-01 
>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda 
>>>> reported version is: Not found: was unable to find libcuda.so DSO loaded 
>>>> into this program 
>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver 
>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module 
>>>>  346.47  Thu Feb 19 18:56:03 PST 2015 
>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC)  
>>>> """ 
>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel 
>>>> reported version is: 346.47.0 
>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices 
>>>> available on machine.
>>>>
>>>> Must there be nvidia driver installed inside the container? Outside? 
>>>> The container shares the same kernel with the host and nvidia kernel module 
>>>> needs to be loaded... How this is handled? Any requirements on nvidia 
>>>> driver and cuda versions inside and outside of the container?
>>>>
>>>> Thank you,
>>>> Igor
>>>>
>>>>
>>>> -- 
>>>> You received this message because you are subscribed to the Google 
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send 
>>>> an email to singu...@lbl.gov.
>>>>
>>>
------=_Part_3_1533699825.1469753513404
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><span style=3D"font-family:monospace"><span style=3D"color=
: rgb(0, 0, 0);">I mean I am using this file from NVIDIA website cuda_7.5.1=
8_linux.run to install the driver, opengl, cuda. Driver installation fails,=
 cuda succeeds.=C2=A0</span></span><div><span style=3D"font-family:monospac=
e"><font color=3D"#000000">Also, when I run=C2=A0</font></span></div><div><=
span style=3D"font-family:monospace"><font color=3D"#000000">sh=C2=A0</font=
></span><font color=3D"#000000" face=3D"monospace">cuda_7.5.18_linux.run</f=
ont></div><div><span style=3D"font-family:monospace"><font color=3D"#000000=
">I am offered to install the driver version=C2=A0</font></span><span style=
=3D"font-family:monospace"><span style=3D"color: rgb(0, 0, 0);">352.39 whil=
e on the host it is=C2=A0</span></span><span style=3D"font-family:monospace=
"><span style=3D"color: rgb(0, 0, 0);">346.47. I cannot upgrade the host. A=
ny idea where I can get 346.17?</span></span></div><div><span style=3D"font=
-family:monospace"><font color=3D"#000000">I tried using the same link just=
 substitute 18 for something else but have not found the files:</font></spa=
n></div><div><span style=3D"font-family:monospace"><span style=3D"color: rg=
b(0, 0, 0);">wget http://developer.download.nvidia.com/compute/cuda/7.5/Pro=
d/local_installers/cuda_7.5.1X_linux.run</span><br></span><br></div><div><b=
r></div><div><br></div><div>On Thursday, July 28, 2016 at 7:34:55 PM UTC-5,=
 Igor wrote:<blockquote class=3D"gmail_quote" style=3D"margin: 0;margin-lef=
t: 0.8ex;border-left: 1px #ccc solid;padding-left: 1ex;"><div dir=3D"ltr">H=
i Nathan,<div>When I try to install the driver by running NVIDIA*.run scrip=
t inside the image, it fails, probably because it tries to modify kernel th=
at belongs to host?</div><div>How do I extract just libcuda.so.345.67 witho=
ut installing the driver (which is obviously problematic) and why would cop=
ying the library from the host would not work?</div><div>Thank you,</div><d=
iv>Igor<br><br>On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin w=
rote:<blockquote class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;=
border-left:1px #ccc solid;padding-left:1ex">Also if you are using the bina=
ry installation of TensorFlow you need CUDA toolkit 7.5 and cuDNN v4. These=
 only need to be installed on our image. As I mentioned earlier you will ne=
ed the libcuda.so.###.## library on your image. It is very important that t=
his is the same version of the NVIDIA driver as you have on your nose (seem=
ingly 346.67 for you). I should&#39;ve have also mentioned that you want th=
e libcuda.so.345.67 library that you get from extracting the NVIDIA install=
er. It will not work if you try to copy=C2=A0the libcuda.so library that fr=
om you node.=C2=A0<div><br></div><div>Let me know if you have any more ques=
tions.=C2=A0</div><div><br></div><div>Best,</div><div>Nathan<span></span><b=
r><br>On Thursday, July 28, 2016, Nathan Lin &lt;<a rel=3D"nofollow">nat...=
@gmail.com</a>&gt; wrote:<br><blockquote class=3D"gmail_quote" style=3D"mar=
gin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Hello,<div><br>=
</div><div>Yes you are correct. The NVIDIA driver must be installed on your=
 image as well. However, you honestly only need the libcuda.so.###.## libra=
ry and the appropriate links for that library. Once you have those installe=
d in your image, it should work.=C2=A0</div><div><br></div><div>Best,</div>=
<div>Nathan=C2=A0<span></span><br><br>On Thursday, July 28, 2016, Igor &lt;=
<a>igor...@gmail.com</a>&gt; wrote:<br><blockquote class=3D"gmail_quote" st=
yle=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div =
dir=3D"ltr">Hi All,<div><br><div>I am trying to use GPU-enabled tensorflow =
and it cannot find GPU card from inside the container.</div><div><br></div>=
<div>On the host:</div><div><span style=3D"font-family:monospace"><span sty=
le=3D"color:rgb(0,0,0)">$ lspci | grep -i nvidia
</span><br>20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] =
(rev a1)
<br>8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1=
)<br>
<br></span></div><div><span style=3D"font-family:monospace"><span style=3D"=
color:rgb(0,0,0)">$ nvidia-smi
</span><br>Thu Jul 28 19:01:42 2016 =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0<br>+-----------------------------<wbr>-------------------------+ =C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>| NVIDIA-SMI 3=
46.47 =C2=A0=C2=A0=C2=A0=C2=A0Driver Version: 346.47 =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0| =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0<br>|-----------------------------<wbr>--+---------------=
-------+----<wbr>------------------+
<br>| GPU =C2=A0Name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Persistence-=
M| Bus-Id =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan =C2=A0Temp =C2=A0Perf =C2=A0Pwr:Usage/Cap| =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0Memory-Usage | GPU-Util =C2=A0Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A00 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:20:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A030C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A020W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A066MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br>| =C2=A0=C2=A01 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:8B:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A026C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A019W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A060MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br> =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wb=
r>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>+----------------------------=
-<wbr>------------------------------<wbr>------------------+
<br>| Processes: =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0GPU Memory |
<br>| =C2=A0GPU =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0PID =C2=A0Type =C2=A0Pr=
ocess name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>Usage =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A0=C2=A00 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A09MiB |
<br>| =C2=A0=C2=A0=C2=A01 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A03MiB |<br>
<br></span></div></div><div><font face=3D"monospace"><br></font></div><div>=
<font face=3D"monospace">Inside singularity:</font></div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ singularity s=
hell /software/src/singularity_<wbr>images/tensorflow_0.9.img</span><br></s=
pan></div><div><span style=3D"font-family:monospace"><span style=3D"color:r=
gb(0,0,0)"><br></span></span></div><div><span style=3D"font-family:monospac=
e"><span style=3D"color:rgb(0,0,0)">Singularity/tensorflow_0.9.<wbr>img&gt;=
 lspci | grep -i nvidia
</span><br>bash: lspci: command not found
<br>Singularity/tensorflow_0.9.<wbr>img&gt; nvidia-smi
<br>bash: nvidia-smi: command not found
<br>Singularity/tensorflow_0.9.<wbr>img&gt; python
<br>Python 2.7.12 (default, Jul =C2=A01 2016, 15:12:24) =C2=A0<br>[GCC 5.4.=
0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow as tf
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcuda.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally
<br>&gt;&gt;&gt; sess =3D tf.Session()
<br>E tensorflow/stream_executor/<wbr>cuda/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway-l34-01
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:160] hostnam=
e: midway-l34-01
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:185] libcuda=
 reported version is: Not found: was unable to find libcuda.so DSO loaded i=
nto this program
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:347] driver =
version file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 K=
ernel Module =C2=A0346.47 =C2=A0Thu Feb 19 18:56:03 PST 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:189] kernel =
reported version is: 346.47.0
<br>I tensorflow/core/common_<wbr>runtime/gpu/gpu_init.cc:81] No GPU device=
s available on machine.<br>
<br></span></div><div><span style=3D"font-family:monospace">Must there be n=
vidia driver installed inside the container? Outside? The container shares =
the same kernel with the host and nvidia kernel module needs to be loaded..=
. How this is handled? Any requirements on nvidia driver and cuda versions =
inside and outside of the container?</span></div><div><span style=3D"font-f=
amily:monospace"><br></span></div><div><span style=3D"font-family:monospace=
">Thank you,</span></div><div><span style=3D"font-family:monospace">Igor</s=
pan></div><div><span style=3D"font-family:monospace"><br></span></div><div>=
<font face=3D"monospace"><br></font></div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</blockquote></div>
</blockquote></div>
</blockquote></div></div></blockquote></div></div>
------=_Part_3_1533699825.1469753513404--

------=_Part_2_2068057723.1469753513403--

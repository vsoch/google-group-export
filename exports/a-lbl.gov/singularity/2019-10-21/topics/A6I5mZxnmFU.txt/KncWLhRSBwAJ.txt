X-Received: by 2002:a17:902:5a4:: with SMTP id f33-v6mr3787096plf.12.1526664611730;
        Fri, 18 May 2018 10:30:11 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 2002:a63:2a0e:: with SMTP id q14-v6ls1885670pgq.30.gmail; Fri, 18
 May 2018 10:30:10 -0700 (PDT)
X-Received: by 2002:a62:fc8:: with SMTP id 69-v6mr10323456pfp.14.1526664610401;
        Fri, 18 May 2018 10:30:10 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1526664610; cv=none;
        d=google.com; s=arc-20160816;
        b=WM/0nvKrw1vSevIwatiqM8hlr1RnGAamnOvkwtZMlm9QTs+hoJdu9vdOwxx1vxYKUn
         L9Irblpr9Dg7WZi1HuVuzMhMi0jwlPM2FOfASAM24F2K4yXWEU4VTMRWwE4jccQXSXEL
         +0+nZl6lxJe6K6U0B/O2JYd6EWw+0Yn5utprgivMVW9zmjFrsCMwZtzEBGrU4y6t3BI6
         zNRk0RMCCHmh0gvwzMQIujjNrHbwq4MMNSFUzGAhr4RNeagJndn71dHbYGM7tfaRwple
         9GbK8cdd3LfWbfqbA1ER000gvIKaoNSISDgYOwOOBdRQf35jko7663L1qF8Z3x3X/DYA
         oZlw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=mime-version:content-language:accept-language:in-reply-to
         :references:message-id:date:thread-index:thread-topic:subject:to
         :from:arc-authentication-results;
        bh=WfCV7EEzJthMm/aEKVW92plsqTgp9dIFJELm1e1LZ4Y=;
        b=EYrHRPb3Ds0Mj4BL2dzSTXwNTPXczc8uLG8GadXE4txkvNVqunJYdEYfm7YMGiuOjd
         RgfjVZSy91Z6XUMgys7sorTY/QodPaVhcHw5XsGHan4YVX0mjFiiPuriCujl/XreFqCk
         ji/rK6z9aeVXvsliVjxOZusDauuV84f0IL7N0xJbT4Z0Z126Qna0cWXYyG9cY846JYFA
         E34GOxiBzZwAF7QZP5o/m+IiPmIgK/KYL0te4nzVt1kN3SMJx7C01d4lMyn1l5rANyhV
         Xwl+xYOpkcrdzn6RfRmkFv5UUHBwezmx39SO6xVQviXvYxh517BymwvS/2RS7PhXpt0V
         uYDg==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: domain of mka...@sdsc.edu designates 132.239.0.119 as permitted sender) smtp.mailfrom=mka...@sdsc.edu
Return-Path: <mka...@sdsc.edu>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id j131-v6si264512pgc.606.2018.05.18.10.30.10
        for <singu...@lbl.gov>;
        Fri, 18 May 2018 10:30:10 -0700 (PDT)
Received-SPF: pass (google.com: domain of mka...@sdsc.edu designates 132.239.0.119 as permitted sender) client-ip=132.239.0.119;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of mka...@sdsc.edu designates 132.239.0.119 as permitted sender) smtp.mailfrom=mka...@sdsc.edu
X-Ironport-SBRS: 2.3
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0F6BABQDP9ae3cA74RcHAEBAQQBAQoBA?=
 =?us-ascii?q?YJNASEpggkoCoNkiGmMG4F5gQ+HA4wzFIFWDgEKGAETgUuCdQKCEiE2FgECAQE?=
 =?us-ascii?q?BAQEBAgEBAhABAQkNCgcoJAuCNQUCAxoGgksBAQEBA047AgEIEQMBAQELHQchE?=
 =?us-ascii?q?AEUCQgCBAgHBAEHFQSDLHNMAxUBBKpHhw0NQgEHYYIniDWBVT6BD4JeLoJPgWk?=
 =?us-ascii?q?IARIBIR4WgnqCJAKHYIR2hD6GdRcsAwYCi1aPfIophk6BJSMDYi5xchM7gkOQT?=
 =?us-ascii?q?m8QgQWMNEdYAYEXAQE?=
X-IPAS-Result: =?us-ascii?q?A0F6BABQDP9ae3cA74RcHAEBAQQBAQoBAYJNASEpggkoCoN?=
 =?us-ascii?q?kiGmMG4F5gQ+HA4wzFIFWDgEKGAETgUuCdQKCEiE2FgECAQEBAQEBAgEBAhABA?=
 =?us-ascii?q?QkNCgcoJAuCNQUCAxoGgksBAQEBA047AgEIEQMBAQELHQchEAEUCQgCBAgHBAE?=
 =?us-ascii?q?HFQSDLHNMAxUBBKpHhw0NQgEHYYIniDWBVT6BD4JeLoJPgWkIARIBIR4WgnqCJ?=
 =?us-ascii?q?AKHYIR2hD6GdRcsAwYCi1aPfIophk6BJSMDYi5xchM7gkOQTm8QgQWMNEdYAYE?=
 =?us-ascii?q?XAQE?=
X-IronPort-AV: E=Sophos;i="5.49,415,1520924400"; 
   d="scan'208,217";a="116095863"
Received: from iport-bcv1-out.ucsd.edu ([132.239.0.119])
  by fe3.lbl.gov with ESMTP; 18 May 2018 10:30:08 -0700
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2HbAwBQDP9a/8wA74RcHAEBAQQBAQoBA?=
 =?us-ascii?q?YJNASEpggkoCoNkiGmOFIEPhwOMMxSBVg4BChgBE4FLgnUCgjM2FgECAQEBAQE?=
 =?us-ascii?q?BAgEBAmgdC4I1BQIDGgaCSwEBAQEDTjsCAQgRAwEBAQsdByEQARQJCAIECAcEA?=
 =?us-ascii?q?QcVBIMsc0wDFQGqS4cNDUIBB2GCJ4oKPoEPgl4ugk+BaQgBEgEhHhaCeoIkAod?=
 =?us-ascii?q?ghHaEPoZ1FywDBgKLVo98iimGToElIwMvMy5xchM7gkOQTm8QgQWMNEdYAYEXA?=
 =?us-ascii?q?QE?=
X-IPAS-Result: =?us-ascii?q?A2HbAwBQDP9a/8wA74RcHAEBAQQBAQoBAYJNASEpggkoCoN?=
 =?us-ascii?q?kiGmOFIEPhwOMMxSBVg4BChgBE4FLgnUCgjM2FgECAQEBAQEBAgEBAmgdC4I1B?=
 =?us-ascii?q?QIDGgaCSwEBAQEDTjsCAQgRAwEBAQsdByEQARQJCAIECAcEAQcVBIMsc0wDFQG?=
 =?us-ascii?q?qS4cNDUIBB2GCJ4oKPoEPgl4ugk+BaQgBEgEhHhaCeoIkAodghHaEPoZ1FywDB?=
 =?us-ascii?q?gKLVo98iimGToElIwMvMy5xchM7gkOQTm8QgQWMNEdYAYEXAQE?=
X-IronPort-AV: E=Sophos;i="5.49,415,1520924400"; 
   d="scan'208,217";a="720221519"
X-Spam-Status: No
X-Spam-Level: 
Received: from xcore-tpcs2.ucsd.edu (HELO XCORE-TPCS2.AD.UCSD.EDU) ([132.239.0.204])
  by iport-bcv1-out.ucsd.edu with ESMTP/TLS/AES256-GCM-SHA384; 18 May 2018 10:30:07 -0700
Received: from XMAIL-MBX-BT1.AD.UCSD.EDU ([fe80::b066:a961:2460:32af]) by
 XCORE-TPCS2.AD.UCSD.EDU ([fe80::95f8:1460:c137:278c%11]) with mapi id
 14.03.0319.002; Fri, 18 May 2018 10:29:36 -0700
From: "Kandes, Martin" <mka...@sdsc.edu>
To: "singu...@lbl.gov" <singu...@lbl.gov>
Subject: RE: [Singularity] Running an mpi program with mvapitch
Thread-Topic: [Singularity] Running an mpi program with mvapitch
Thread-Index: AQHT7q7jujwxgXJTekOIvhhQnqJ/1KQ1ueiW
Date: Fri, 18 May 2018 17:29:36 +0000
Message-ID: <B58197C146EC324AA00A2A07DC082602C2CBA0C3@XMAIL-MBX-BT1.AD.UCSD.EDU>
References: <167671ff-657d-4560-a35f-87091223fe29@lbl.gov>
In-Reply-To: <167671ff-657d-4560-a35f-87091223fe29@lbl.gov>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [169.228.91.19]
Content-Type: multipart/alternative;
	boundary="_000_B58197C146EC324AA00A2A07DC082602C2CBA0C3XMAILMBXBT1ADUC_"
MIME-Version: 1.0

--_000_B58197C146EC324AA00A2A07DC082602C2CBA0C3XMAILMBXBT1ADUC_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Hi George,

I run with different gcc compiler versions inside and outside my MPI contai=
ners. So I would be surprised if that is the issue here. I'm not sure I hav=
e a good recommendation of where to start debugging your problem. But I mig=
ht start by double checking the MPI versions match inside and outside the c=
ontainer. e.g. see [1].

Marty

[1]

[mkandes@comet-ln3 ~]$ srun --partition=3Ddebug --pty --nodes=3D1 --ntasks-=
per-node=3D24 -t 00:30:00 --wait=3D0 --export=3DALL /bin/bash
srun: job 16364303 queued and waiting for resources
srun: job 16364303 has been allocated resources
[mkandes@comet-14-06 ~]$ cd /scratch/mkandes/16364303/
[mkandes@comet-14-06 16364303]$ cp /oasis/scratch/comet/mkandes/temp_projec=
t/singularity/images/ubuntu-mvapich2.img ./
[mkandes@comet-14-06 16364303]$ module purge
[mkandes@comet-14-06 16364303]$ module load gnu
[mkandes@comet-14-06 16364303]$ module load mvapich2_ib
[mkandes@comet-14-06 16364303]$ module list
Currently Loaded Modulefiles:
  1) gnu/4.9.2         2) mvapich2_ib/2.1
[mkandes@comet-14-06 16364303]$ module load singularity
[mkandes@comet-14-06 16364303]$ gcc --version
gcc (GCC) 4.9.2
Copyright (C) 2014 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[mkandes@comet-14-06 16364303]$ mpirun --version
HYDRA build details:
    Version:                                 3.1.4
    Release Date:                            Thu Apr  2 17:15:15 EDT 2015
    CC:                              gcc  -fPIC -O3
    CXX:                             g++  -fPIC -O3
    F77:                             gfortran -fPIC -O3
    F90:                             gfortran -fPIC -O3
    Configure options:                       '--disable-option-checking' '-=
-prefix=3D/opt/mvapich2/gnu/ib' '--enable-shared' '--enable-sharedlibs=3Dgc=
c' '--with-hwloc' '--enable-f77' '--enable-fc' '--enable-hybrid' '--with-ib=
-include=3D/usr/include/infiniband' '--with-ib-libpath=3D/usr/lib64' '--ena=
ble-fast=3DO3' '--with-limic2=3D/state/partition1/git/mpi-roll/BUILD/sdsc-m=
vapich2_gnu_ib-2.1/../..//cache/build-limic' '--with-slurm=3D/usr/lib64/slu=
rm' '--with-file-system=3Dlustre' 'CC=3Dgcc' 'CFLAGS=3D-fPIC -O3 -O3' 'CXX=
=3Dg++' 'CXXFLAGS=3D-fPIC -O3 -O3' 'FC=3Dgfortran' 'FCFLAGS=3D-fPIC -O3 -O3=
' 'F77=3Dgfortran' 'FFLAGS=3D-L/usr/lib64 -L/lib -L/lib -fPIC -O3 -O3' '--c=
ache-file=3D/dev/null' '--srcdir=3D.' 'LDFLAGS=3D-L/usr/lib64 -L/lib -L/lib=
 -L/lib -Wl,-rpath,/lib -L/lib -Wl,-rpath,/lib -L/usr/lib64 -L/state/partit=
ion1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/../..//cache/build-limic/l=
ib -L/lib -L/lib' 'LIBS=3D-libmad -lrdmacm -libumad -libverbs -ldl -lrt -ll=
imic2 -lm -lpthread ' 'CPPFLAGS=3D-I/usr/include/infiniband -I/state/partit=
ion1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/mpl/inclu=
de -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2=
-2.1/src/mpl/include -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_g=
nu_ib-2.1/mvapich2-2.1/src/openpa/src -I/state/partition1/git/mpi-roll/BUIL=
D/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/openpa/src -D_REENTRANT -I/stat=
e/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/m=
pi/romio/include -I/include -I/include -I/usr/include/infiniband -I/state/p=
artition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/../..//cache/build-li=
mic/include -I/include -I/include'
    Process Manager:                         pmi
    Launchers available:                     ssh rsh fork slurm ll lsf sge =
manual persist
    Topology libraries available:            hwloc
    Resource management kernels available:   user slurm ll lsf sge pbs coba=
lt
    Checkpointing libraries available:
    Demux engines available:                 poll select
[mkandes@comet-14-06 16364303]$ singularity shell ubuntu-mvapich2.img
Singularity: Invoking an interactive shell within container...

Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303> gcc --version
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303> mpirun --version
HYDRA build details:
    Version:                                 3.1.4
    Release Date:                            Thu Apr  2 17:15:15 EDT 2015
    CC:                              gcc
    CXX:                             g++
    F77:                             gfortran
    F90:                             gfortran
    Configure options:                       '--disable-option-checking' '-=
-prefix=3D/opt/mvapich2' '--cache-file=3D/dev/null' '--srcdir=3D.' 'CC=3Dgc=
c' 'CFLAGS=3D -DNDEBUG -DNVALGRIND -O2' 'LDFLAGS=3D-L/lib -L/lib -L/lib -Wl=
,-rpath,/lib -L/lib -Wl,-rpath,/lib -L/lib -L/lib' 'LIBS=3D-libmad -lrdmacm=
 -libumad -libverbs -ldl -lrt -lm -lpthread ' 'CPPFLAGS=3D -I/tmp/mvapich2-=
2.1/src/mpl/include -I/tmp/mvapich2-2.1/src/mpl/include -I/tmp/mvapich2-2.1=
/src/openpa/src -I/tmp/mvapich2-2.1/src/openpa/src -D_REENTRANT -I/tmp/mvap=
ich2-2.1/src/mpi/romio/include -I/include -I/include -I/include -I/include'
    Process Manager:                         pmi
    Launchers available:                     ssh rsh fork slurm ll lsf sge =
manual persist
    Topology libraries available:            hwloc
    Resource management kernels available:   user slurm ll lsf sge pbs coba=
lt
    Checkpointing libraries available:
    Demux engines available:                 poll select
Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303>


________________________________
From: George Zaki [georg...@gmail.com]
Sent: Friday, May 18, 2018 6:48 AM
To: singularity
Subject: [Singularity] Running an mpi program with mvapitch

Hi singularity team,

I would like to run an MPI program in a singularity container. The program =
is compiled using mvapicth2.2 using a gcc version 5.4.

I can see that my cluster has a compiled version of mvapitch2.2 with gcc 5.=
3

When I run:

mpiexe -n 1 singularity exec /path/to/sing/image ./mpi-pi.o

the call does not return.

Does the gcc version has to be exactly the same? I tried the switch the com=
piler in this image:


BootStrap: docker
From: nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04

However when gcc 5.3 is used the mvapitch does not build correctly.

If that's the problem, Is there a preferred method of switching gcc version=
 in this container singularity container?

Thanks,
George

--
You received this message because you are subscribed to the Google Groups "=
singularity" group.
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to singu...@lbl.gov<mailto:singu...@lbl.gov>.

--_000_B58197C146EC324AA00A2A07DC082602C2CBA0C3XMAILMBXBT1ADUC_
Content-Type: text/html; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

<html dir=3D"ltr">
<head>
<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3Diso-8859-=
1">
<style type=3D"text/css" id=3D"owaParaStyle">P {margin-top:0;margin-bottom:=
0;}</style>
</head>
<body fpstyle=3D"1" ocsi=3D"0">
<div style=3D"direction: ltr;font-family: Tahoma;color: #000000;font-size: =
10pt;">
<div>Hi George,</div>
<div><br>
</div>
<div>I run with different gcc compiler versions inside and outside my MPI c=
ontainers. So I would be surprised if that is the issue here. I'm not sure =
I have a good recommendation of where to start debugging your problem. But =
I might start by double checking
 the MPI versions match inside and outside the container. e.g. see [1].</di=
v>
<div><br>
</div>
<div>Marty</div>
<div><br>
</div>
<div>[1]</div>
<div><br>
</div>
<div>[mkandes@comet-ln3 ~]$ srun --partition=3Ddebug --pty --nodes=3D1 --nt=
asks-per-node=3D24 -t 00:30:00 --wait=3D0 --export=3DALL /bin/bash<br>
srun: job 16364303 queued and waiting for resources<br>
srun: job 16364303 has been allocated resources<br>
[mkandes@comet-14-06 ~]$ cd /scratch/mkandes/16364303/<br>
[mkandes@comet-14-06 16364303]$ cp /oasis/scratch/comet/mkandes/temp_projec=
t/singularity/images/ubuntu-mvapich2.img ./<br>
[mkandes@comet-14-06 16364303]$ module purge<br>
[mkandes@comet-14-06 16364303]$ module load gnu<br>
[mkandes@comet-14-06 16364303]$ module load mvapich2_ib<br>
[mkandes@comet-14-06 16364303]$ module list<br>
Currently Loaded Modulefiles:<br>
&nbsp; 1) gnu/4.9.2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2) mvap=
ich2_ib/2.1<br>
[mkandes@comet-14-06 16364303]$ module load singularity<br>
[mkandes@comet-14-06 16364303]$ gcc --version<br>
gcc (GCC) 4.9.2<br>
Copyright (C) 2014 Free Software Foundation, Inc.<br>
This is free software; see the source for copying conditions.&nbsp; There i=
s NO<br>
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.=
<br>
<br>
[mkandes@comet-14-06 16364303]$ mpirun --version<br>
HYDRA build details:<br>
&nbsp;&nbsp;&nbsp; Version:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.1.4=
<br>
&nbsp;&nbsp;&nbsp; Release Date:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Thu Apr&nbsp; 2 17:15:15 EDT 2=
015<br>
&nbsp;&nbsp;&nbsp; CC:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; gcc&nbsp; -fPIC -O3&nbsp; <b=
r>
&nbsp;&nbsp;&nbsp; CXX:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; g&#43;&#43;&nbsp; -fPIC -O3&nbsp;=
 <br>
&nbsp;&nbsp;&nbsp; F77:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; gfortran -fPIC -O3&nbsp; <br>
&nbsp;&nbsp;&nbsp; F90:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; gfortran -fPIC -O3&nbsp; <br>
&nbsp;&nbsp;&nbsp; Configure options:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp; '--disable-option-checking' '--prefix=3D/opt/mvapich2/g=
nu/ib' '--enable-shared' '--enable-sharedlibs=3Dgcc' '--with-hwloc' '--enab=
le-f77' '--enable-fc' '--enable-hybrid' '--with-ib-include=3D/usr/include/i=
nfiniband' '--with-ib-libpath=3D/usr/lib64'
 '--enable-fast=3DO3' '--with-limic2=3D/state/partition1/git/mpi-roll/BUILD=
/sdsc-mvapich2_gnu_ib-2.1/../..//cache/build-limic' '--with-slurm=3D/usr/li=
b64/slurm' '--with-file-system=3Dlustre' 'CC=3Dgcc' 'CFLAGS=3D-fPIC -O3 -O3=
' 'CXX=3Dg&#43;&#43;' 'CXXFLAGS=3D-fPIC -O3 -O3' 'FC=3Dgfortran'
 'FCFLAGS=3D-fPIC -O3 -O3' 'F77=3Dgfortran' 'FFLAGS=3D-L/usr/lib64 -L/lib -=
L/lib -fPIC -O3 -O3' '--cache-file=3D/dev/null' '--srcdir=3D.' 'LDFLAGS=3D-=
L/usr/lib64 -L/lib -L/lib -L/lib -Wl,-rpath,/lib -L/lib -Wl,-rpath,/lib -L/=
usr/lib64 -L/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/.=
./..//cache/build-limic/lib
 -L/lib -L/lib' 'LIBS=3D-libmad -lrdmacm -libumad -libverbs -ldl -lrt -llim=
ic2 -lm -lpthread ' 'CPPFLAGS=3D-I/usr/include/infiniband -I/state/partitio=
n1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/mpl/include=
 -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2=
.1/src/mpl/include
 -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2=
.1/src/openpa/src -I/state/partition1/git/mpi-roll/BUILD/sdsc-mvapich2_gnu_=
ib-2.1/mvapich2-2.1/src/openpa/src -D_REENTRANT -I/state/partition1/git/mpi=
-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/mvapich2-2.1/src/mpi/romio/include
 -I/include -I/include -I/usr/include/infiniband -I/state/partition1/git/mp=
i-roll/BUILD/sdsc-mvapich2_gnu_ib-2.1/../..//cache/build-limic/include -I/i=
nclude -I/include'<br>
&nbsp;&nbsp;&nbsp; Process Manager:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pmi<br>
&nbsp;&nbsp;&nbsp; Launchers available:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp; ssh rsh fork slurm ll lsf sge manual persist<br>
&nbsp;&nbsp;&nbsp; Topology libraries available:&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; hwloc<br>
&nbsp;&nbsp;&nbsp; Resource management kernels available:&nbsp;&nbsp; user =
slurm ll lsf sge pbs cobalt<br>
&nbsp;&nbsp;&nbsp; Checkpointing libraries available:&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp; <br>
&nbsp;&nbsp;&nbsp; Demux engines available:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; poll selec=
t<br>
[mkandes@comet-14-06 16364303]$ singularity shell ubuntu-mvapich2.img <br>
Singularity: Invoking an interactive shell within container...<br>
<br>
Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303&gt; gcc --version=
<br>
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609<br>
Copyright (C) 2015 Free Software Foundation, Inc.<br>
This is free software; see the source for copying conditions.&nbsp; There i=
s NO<br>
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.=
<br>
<br>
Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303&gt; mpirun --vers=
ion<br>
HYDRA build details:<br>
&nbsp;&nbsp;&nbsp; Version:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.1.4=
<br>
&nbsp;&nbsp;&nbsp; Release Date:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Thu Apr&nbsp; 2 17:15:15 EDT 2=
015<br>
&nbsp;&nbsp;&nbsp; CC:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; gcc&nbsp;&nbsp;&nbsp; <br>
&nbsp;&nbsp;&nbsp; CXX:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; g&#43;&#43;&nbsp;&nbsp;&nbsp; <br=
>
&nbsp;&nbsp;&nbsp; F77:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; gfortran&nbsp;&nbsp; <br>
&nbsp;&nbsp;&nbsp; F90:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; gfortran&nbsp;&nbsp; <br>
&nbsp;&nbsp;&nbsp; Configure options:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp; '--disable-option-checking' '--prefix=3D/opt/mvapich2' =
'--cache-file=3D/dev/null' '--srcdir=3D.' 'CC=3Dgcc' 'CFLAGS=3D -DNDEBUG -D=
NVALGRIND -O2' 'LDFLAGS=3D-L/lib -L/lib -L/lib -Wl,-rpath,/lib -L/lib -Wl,-=
rpath,/lib -L/lib -L/lib'
 'LIBS=3D-libmad -lrdmacm -libumad -libverbs -ldl -lrt -lm -lpthread ' 'CPP=
FLAGS=3D -I/tmp/mvapich2-2.1/src/mpl/include -I/tmp/mvapich2-2.1/src/mpl/in=
clude -I/tmp/mvapich2-2.1/src/openpa/src -I/tmp/mvapich2-2.1/src/openpa/src=
 -D_REENTRANT -I/tmp/mvapich2-2.1/src/mpi/romio/include
 -I/include -I/include -I/include -I/include'<br>
&nbsp;&nbsp;&nbsp; Process Manager:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pmi<br>
&nbsp;&nbsp;&nbsp; Launchers available:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp; ssh rsh fork slurm ll lsf sge manual persist<br>
&nbsp;&nbsp;&nbsp; Topology libraries available:&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; hwloc<br>
&nbsp;&nbsp;&nbsp; Resource management kernels available:&nbsp;&nbsp; user =
slurm ll lsf sge pbs cobalt<br>
&nbsp;&nbsp;&nbsp; Checkpointing libraries available:&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp; <br>
&nbsp;&nbsp;&nbsp; Demux engines available:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; poll selec=
t<br>
Singularity ubuntu-mvapich2.img:/scratch/mkandes/16364303&gt;<br>
</div>
<div><br>
</div>
<div><br>
</div>
<div style=3D"font-family: Times New Roman; color: #000000; font-size: 16px=
">
<hr tabindex=3D"-1">
<div id=3D"divRpF902262" style=3D"direction: ltr;"><font size=3D"2" face=3D=
"Tahoma" color=3D"#000000"><b>From:</b> George Zaki [georg...@gmail.com]<br=
>
<b>Sent:</b> Friday, May 18, 2018 6:48 AM<br>
<b>To:</b> singularity<br>
<b>Subject:</b> [Singularity] Running an mpi program with mvapitch<br>
</font><br>
</div>
<div></div>
<div>
<div dir=3D"ltr">
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font style=3D"" size=3D"=
4" face=3D"arial, sans-serif">Hi singularity team,</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif"><br>
</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif">I would like to run an MPI program in a singularity cont=
ainer. The program is compiled using mvapicth2.2 using a gcc version 5.4.</=
font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif"><br>
</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif">I can see that my cluster has a compiled version of mvap=
itch2.2 with gcc 5.3</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif"><br>
</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif">When I run:</font></p>
<div style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"arial, sans-serif"=
><br>
</font></div>
<div style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"arial, sans-serif"=
>mpiexe -n 1 singularity exec /path/to/sing/image ./mpi-pi.o</font></div>
<div><font size=3D"4" face=3D"arial, sans-serif"><br>
</font></div>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif">the call does not return.</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif">&nbsp;<br>
</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif">Does the gcc version has to be exactly the same? I tried=
 the switch the compiler in this image:</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif"><br>
</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"></p>
<p style=3D"color:rgb(0,0,0); font-style:normal; font-weight:normal; letter=
-spacing:normal; text-align:start; text-indent:0px; text-transform:none; wh=
ite-space:normal; word-spacing:0px">
</p>
<p></p>
<div style=3D"color:rgb(0,0,0); font-style:normal; font-weight:normal; lett=
er-spacing:normal; text-align:start; text-indent:0px; text-transform:none; =
white-space:normal; word-spacing:0px">
<font size=3D"4" face=3D"arial, sans-serif">BootStrap: docker<br>
</font></div>
<div style=3D"color:rgb(0,0,0); font-style:normal; font-weight:normal; lett=
er-spacing:normal; text-align:start; text-indent:0px; text-transform:none; =
white-space:normal; word-spacing:0px">
<font size=3D"4" face=3D"arial, sans-serif">From: nvidia/cuda:8.0-cudnn6-de=
vel-ubuntu16.04<br>
</font></div>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif"><br>
</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif">However when gcc 5.3 is used the mvapitch does not build=
 correctly.</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif"><br>
</font></p>
<p class=3D"MsoNormal" style=3D"color:rgb(0,0,0)"><font size=3D"4" face=3D"=
arial, sans-serif">If that's the problem, Is there a preferred method of sw=
itching gcc version in this container singularity container?</font></p>
<div><font size=3D"4" face=3D"arial, sans-serif"><br>
</font></div>
<div><font size=3D"4" face=3D"arial, sans-serif">Thanks,</font></div>
<div><font style=3D"" size=3D"4" face=3D"arial, sans-serif">George</font></=
div>
</div>
<p></p>
-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to
<a href=3D"mailto:singularity&#43;unsu...@lbl.gov" target=3D"_blank">singul=
arity&#43;unsu...@lbl.gov</a>.<br>
</div>
</div>
</div>
</body>
</html>

--_000_B58197C146EC324AA00A2A07DC082602C2CBA0C3XMAILMBXBT1ADUC_--

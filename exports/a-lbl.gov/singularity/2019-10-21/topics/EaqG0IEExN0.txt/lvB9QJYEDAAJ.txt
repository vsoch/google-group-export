X-Received: by 10.36.85.196 with SMTP id e187mr2091410itb.2.1465430201888;
        Wed, 08 Jun 2016 16:56:41 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.30.201 with SMTP id e192ls226154ioe.87.gmail; Wed, 08 Jun
 2016 16:56:41 -0700 (PDT)
X-Received: by 10.66.222.202 with SMTP id qo10mr8370820pac.141.1465430201383;
        Wed, 08 Jun 2016 16:56:41 -0700 (PDT)
Return-Path: <goh...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTPS id o85si4002530pfi.171.2016.06.08.16.56.41
        for <singu...@lbl.gov>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Wed, 08 Jun 2016 16:56:41 -0700 (PDT)
Received-SPF: pass (google.com: domain of goh...@gmail.com designates 209.85.223.173 as permitted sender) client-ip=209.85.223.173;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of goh...@gmail.com designates 209.85.223.173 as permitted sender) smtp.mailfrom=goh...@gmail.com
X-Ironport-SBRS: 2.0
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2EtAwA+r1hXeK3fVdFehBR9BoM2owUGAQEBAQaBD0+BfZIhPgQXAQaFdQKBOgc7EQEBAQEBAQEDDwEKDQkJHzGCOjkKBiwBAQEBAQEBAQEBAQEBAQEaAisTEgIZAQEBAwESCAkdAQ0OHgMMBgMCCw0gCgICIQEBDgMBBQEcDgcEARoCBAGHcgEDDwgFj12PQoExPjGLO4FqglgFiAEKGScNUoMtAQEIAQEBAQEaAgYQhU+EEoEDgkOBTxEBgx2CWQWHfAEHhxeEIIRgNIYDhimBeoI3jGiHdoYtEh6BDw8lghoNHIFNOjIHiD0ECxeBHgEBAQ
X-IronPort-AV: E=Sophos;i="5.26,441,1459839600"; 
   d="scan'208,217";a="26523077"
Received: from mail-io0-f173.google.com ([209.85.223.173])
  by fe3.lbl.gov with ESMTP; 08 Jun 2016 16:56:39 -0700
Received: by mail-io0-f173.google.com with SMTP id o189so23964481ioe.2
        for <singu...@lbl.gov>; Wed, 08 Jun 2016 16:56:39 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=mIe7Xjj/raE9yOFRZ+z12kyPSUkIt5mR9djEkSfXCAA=;
        b=f9t5swKPytNUubboTJNgIinbkWMc3+dQsKBWrYQ/Gm4KY5BOcvd2WG8LZJAf8yJCrv
         ZhPwEuxwKNT8PGPt9C7oSEhnazTolCk7qzwCj7c2WEvo/z9zGbiL9DfDSWryUXYnjot1
         wymZbSsOa7ufgBV6dxpMjqY098SYQwXiB9X5Vs2vURTloDtwE9eCXGIhZSsNyLuvI6Ss
         DLfLPnWT5CThdqhqGJevWrSVthmopoNDIGAKxCLGzQuclT851VIgtFxAxDtMcyAkFGLB
         dJZsw5B4fJTnLhRO5CnvRTDNbsO09dAozSjk5JbsnmoJz1WUBZ6zfaO0ZOpT0l/bTLLd
         5OSg==
X-Gm-Message-State: ALyK8tLqvTohwmYZn6Pf4F38/8mUz49h9SgKO7Tf4ZfS9N4wGpunUZdI6e999YBnStjt5K57VSB4eDTWHIsTgQ==
X-Received: by 10.107.37.19 with SMTP id l19mr12504947iol.75.1465430199320;
 Wed, 08 Jun 2016 16:56:39 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.50.227.142 with HTTP; Wed, 8 Jun 2016 16:56:38 -0700 (PDT)
In-Reply-To: <CAN7etTykdT1UXi42d3+E=OKaDKpXapb5CFcyMfrRic0xXf6RWA@mail.gmail.com>
References: <CA+zw9q3gSaqZgo3tzOXyn5kwfeUS-LdCuyTnmWyPgfVjmxGBqA@mail.gmail.com>
 <CAN7etTz3V1eSH2r7Yd9y0MFFt24H2vuAB9FcViKbDAsdxtt9Pg@mail.gmail.com>
 <CA+zw9q0zaF0ajbLuPeT0H-Ag5t-ZfV9ux94hm+9m6XQ_JEQ7LA@mail.gmail.com> <CAN7etTykdT1UXi42d3+E=OKaDKpXapb5CFcyMfrRic0xXf6RWA@mail.gmail.com>
From: yiannis georgiou <goh...@gmail.com>
Date: Thu, 9 Jun 2016 01:56:38 +0200
Message-ID: <CA+zw9q2ftBoz3UJgOmU6qsDyESh8kShr3YfX1jtbF4+4WcwcbQ@mail.gmail.com>
Subject: Re: [Singularity] Singularity with Slurm and PMIx
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=001a11409d8e7946df0534cd0e7c

--001a11409d8e7946df0534cd0e7c
Content-Type: text/plain; charset=UTF-8

On Wed, Jun 8, 2016 at 10:57 PM, Gregory M. Kurtzer <gmku...@lbl.gov>
wrote:

>
> On Wed, Jun 8, 2016 at 1:48 PM, yiannis georgiou <goh...@gmail.com>
> wrote:
>
>> Hi Greg,
>>
>> bullseye!!! it worked for me like this:
>>
>
> Excellent!!
>
>
>>
>> [georgioy@rio11 ~]$ salloc -n4 -N2
>> [georgioy@rio11 ~]$ export SINGULARITY_NO_NAMESPACE_PID=1
>> [georgioy@rio11 ~]$ srun --mpi=pmix -n 4 -N2
>> /usr/local/singularity_v2/bin/singularity exec /tmp/ubuntu_v4.img
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>> Hello world from processor rio13, rank 2 out of 4 processors
>> Hello world from processor rio13, rank 3 out of 4 processors
>> Hello world from processor rio12, rank 0 out of 4 processors
>> Hello world from processor rio12, rank 1 out of 4 processors
>> ERROR: Could not clear loop device
>>
>> Any idea how I can correct the "ERROR: Could not clear loop device"
>> appearing at the end of the execution?
>>
>
> Hrmm.. Interesting, I wonder on which system it got that error. Is it
> possible to try and replicate the error on a single new (e.g. -N1)? The
> other thing to try is to run losetup (-a) on both rio12 and rio13 and see
> if /dev/loop0 is still bound somewhere.
>
It was related with a previously failed srun I think. When I did a new
clean salloc with different srun all worked without problem.

>
>
>> And when you have a moment could you explain me how this magic
>> environment variable make it work! I'm not sure I got it.
>>
>
> While most container systems are built around the idea of complete
> isolation, Singularity is focused on application portability so you can
> disable some of the namespaces as needed (with the PID namespace being the
> culprit here for OpenMPI's shared memory model).
>
Ok I see.

>
>
>>
>> One more question, I've noticed that there have been some changes in the
>> latest OpenMPI to improve performance when using singularity. Are they done
>> for PMIx or for all PMI versions?
>>
>
> Indeed. I'm hoping Ralph will chime in when he has a moment and can
> address this and possibly a better long term fix (and if it can't be done
> via the MPI side, I can do it on the Singularity side).
>
Ok

Thanks for your answers and the fast solution!

Yiannis

>
>
>>
>> Thanks a lot!
>>
>
> My pleasure!
>
> Greg
>
>
>
>
>>
>> Yiannis
>>
>>
>> On Wed, Jun 8, 2016 at 9:16 PM, Gregory M. Kurtzer <gmku...@lbl.gov>
>> wrote:
>>
>>> Hi Yiannis,
>>>
>>> I have a quick thing to test... The address not mapped error seems
>>> consistent with something else that I've seen when testing OpenMPI with
>>> shared memory and the NEWPID namespace. Try to disable the NEWPID namespace
>>> by exporting this environment variable:
>>>
>>> SINGULARITY_NO_NAMESPACE_PID=1
>>>
>>> Now you will need to export it in a place where all Singularity contexts
>>> will see it, maybe something like this:
>>>
>>> $ srun --mpi=pmix -n 4 -N 2 SINGULARITY_NO_NAMESPACE_PID=1 singularity
>>> exec /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>>>
>>> There is an OpenMPI plugin which sets this automatically in the current
>>> codebase, but I'm not sure how it will come into play in this usage
>>> scenario.
>>>
>>> Let me know how that works for ya!
>>>
>>> Thanks,
>>>
>>> Greg
>>>
>>> On Wed, Jun 8, 2016 at 12:09 PM, yiannis georgiou <goh...@gmail.com>
>>> wrote:
>>>
>>>> Hello,
>>>>
>>>> I'm trying to execute an MPI application from within a singularity
>>>> image through Slurm and pmix using the following command
>>>>
>>>> srun --mpi=pmix -n 4 -N 2 singularity exec /tmp/ubuntu_v4.img
>>>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>>>>
>>>> The slurmstepd process is spawned on the compute node and it seems to
>>>> have launched correctly the application from what we see on one of the
>>>> compute nodes:
>>>>
>>>> ========================================
>>>> [root@rio12 ~]# ps -aux
>>>> root     35147  0.1  0.0 562284  4016 ?        Sl   20:06   0:00
>>>> slurmstepd: [83.0]
>>>> georgioy 35158  0.2  0.0  10428   896 ?        S    20:06   0:00
>>>> Singularity: namespace
>>>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>>>> root     35162  0.0  0.0      0     0 ?        S<   20:06   0:00 [loop0]
>>>> georgioy 35163  0.0  0.0  10428   400 ?        S    20:06   0:00
>>>> Singularity: exec
>>>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>>>> root     35164  0.0  0.0      0     0 ?        S    20:06   0:00
>>>> [jbd2/loop0-8]
>>>> root     35165  0.0  0.0      0     0 ?        S    20:06   0:00
>>>> [ext4-dio-unwrit]
>>>> georgioy 35166  102  0.0 285476 14828 ?        RLl  20:06   0:12
>>>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>>>> ==========================================
>>>>
>>>> and I see the pmix related functions starting correctly in the slurmd
>>>> log files :
>>>>
>>>> ========================================
>>>>
>>>> [2016-06-08T20:12:08.004] [86.0] debug:  (null) [0] mpi_pmix.c:90
>>>> [p_mpi_hook_slurmstepd_prefork] mpi/pmix: start
>>>> [2016-06-08T20:12:08.004] [86.0] debug:  mpi/pmix: setup sockets
>>>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_client.c:78
>>>> [errhandler_reg_callbk] mpi/pmix: Error handler registration callback is
>>>> called with status=0, ref=0
>>>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_client.c:581
>>>> [pmixp_libpmix_job_set] mpi/pmix: task initialization
>>>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:220
>>>> [_agent_thread] mpi/pmix: Start agent thread
>>>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:313
>>>> [pmixp_agent_start] mpi/pmix: agent thread started: tid = 139672278615808
>>>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:84
>>>> [_conn_readable] mpi/pmix: fd = 9
>>>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:84
>>>> [_conn_readable] mpi/pmix: fd = 19
>>>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:256
>>>> [_pmix_timer_thread] mpi/pmix: Start timer thread
>>>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:335
>>>> [pmixp_agent_start] mpi/pmix: timer thread started: tid = 139672277563136
>>>>
>>>> =======================================
>>>>
>>>> However the application is never actually started and the srun fails
>>>> completely with the following output:
>>>>
>>>> =========================================
>>>> [georgioy@rio11 ~]$ srun --mpi=pmix -n 4 -N 2 singularity exec
>>>> /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>>>> [rio12:00001] *** Process received signal ***
>>>> [rio12:00001] Signal: Segmentation fault (11)
>>>> [rio12:00001] Signal code: Address not mapped (1)
>>>> [rio12:00001] Failing at address: 0x7fbd937e6010
>>>> [rio12:00001] [ 0] [rio12:00001] *** Process received signal ***
>>>> /lib/x86_64-linux-gnu/libpthread.so.0(+0x113d0)[0x7f26aeb233d0]
>>>> [rio12:00001] [ 1]
>>>> /usr/local/lib/libmca_common_sm.so.0(+0x1035)[0x7f269f964035]
>>>> [rio12:00001] [ 2]
>>>> /usr/local/lib/libmca_common_sm.so.0(common_sm_mpool_create+0xa3)[0x7f269f964583]
>>>> [rio12:00001] [ 3]
>>>> /usr/local/lib/openmpi/mca_btl_sm.so(mca_btl_sm_add_procs+0x5f1)[0x7f269fb68771]
>>>> [rio12:00001] [ 4]
>>>> /usr/local/lib/openmpi/mca_bml_r2.so(+0x2be7)[0x7f26a451fbe7]
>>>> [rio12:00001] [ 5]
>>>> /usr/local/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_add_procs+0xd2)[0x7f269ef35662]
>>>> [rio12:00001] [ 6]
>>>> /usr/local/lib/libmpi.so.0(ompi_mpi_init+0xa51)[0x7f26aed75d31]
>>>> [rio12:00001] [ 7]
>>>> /usr/local/lib/libmpi.so.0(MPI_Init+0xb9)[0x7f26aed9bdb9]
>>>> [rio12:00001] [ 8]
>>>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x4007ec]
>>>> [rio12:00001] [ 9]
>>>> /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f26ae769830]
>>>> [rio12:00001] Signal: Segmentation fault (11)
>>>> [rio12:00001] Signal code: Address not mapped (1)
>>>> [rio12:00001] Failing at address: 0x7fbd937e6010
>>>> [rio12:00001] [10]
>>>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x400709]
>>>> [rio12:00001] *** End of error message ***
>>>> [rio12:00001] [ 0]
>>>> /lib/x86_64-linux-gnu/libpthread.so.0(+0x113d0)[0x7f3f89c063d0]
>>>> [rio12:00001] [ 1]
>>>> /usr/local/lib/libmca_common_sm.so.0(+0x1035)[0x7f3f7eb1d035]
>>>> [rio12:00001] [ 2]
>>>> /usr/local/lib/libmca_common_sm.so.0(common_sm_mpool_create+0xa3)[0x7f3f7eb1d583]
>>>> [rio12:00001] [ 3]
>>>> /usr/local/lib/openmpi/mca_btl_sm.so(mca_btl_sm_add_procs+0x5f1)[0x7f3f7ed21771]
>>>> [rio12:00001] [ 4]
>>>> /usr/local/lib/openmpi/mca_bml_r2.so(+0x2be7)[0x7f3f7f5f3be7]
>>>> [rio12:00001] [ 5]
>>>> /usr/local/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_add_procs+0xd2)[0x7f3f7e0ee662]
>>>> [rio12:00001] [ 6]
>>>> /usr/local/lib/libmpi.so.0(ompi_mpi_init+0xa51)[0x7f3f89e58d31]
>>>> [rio12:00001] [ 7]
>>>> /usr/local/lib/libmpi.so.0(MPI_Init+0xb9)[0x7f3f89e7edb9]
>>>> [rio12:00001] [ 8]
>>>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x4007ec]
>>>> [rio12:00001] [ 9]
>>>> /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f3f8984c830]
>>>> [rio12:00001] [10]
>>>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x400709]
>>>> [rio12:00001] *** End of error message ***
>>>> slurmstepd: error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix:
>>>> ERROR: Error handler invoked: status = -25, nranges = 0: Success (0)
>>>> srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
>>>> slurmstepd: error: *** STEP 86.0 ON rio12 CANCELLED AT
>>>> 2016-06-08T20:12:08 ***
>>>> slurmstepd: error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix:
>>>> ERROR: Error handler invoked: status = -25, nranges = 0: Success (0)
>>>> slurmstepd: error: rio13 [1] pmixp_client.c:241 [errhandler] mpi/pmix:
>>>> ERROR: Error handler invoked: status = -25, nranges = 0: Success (0)
>>>> slurmstepd: error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix:
>>>> ERROR: Error handler invoked: status = -25, nranges = 0: Success (0)
>>>> srun: error: rio12: tasks 0-2: Killed
>>>> srun: error: rio13: task 3: Killed
>>>>
>>>> ============================================
>>>>
>>>> the results I get when launching with mpirun instead of srun are more
>>>> or less the same.
>>>>
>>>> From my understanding, the orted process, or in my case slurmstepd
>>>> process that launches the singularity container
>>>> and the MPI application, enables the communication of MPI libraries and
>>>> orted (or slurmstepd) through PMI (in my case here PMIx).
>>>> So I suppose the problem I see should be related with the mapping of
>>>> PMI from the container towards the orted or slurmstepd.
>>>>
>>>> What do you think?
>>>>
>>>> To give some more details, my singularity container has OpenMPI and
>>>> PMIx installed but not Slurm. I don't think that Slurm needs to reside
>>>> within the container in that context.
>>>> But I wasn't sure if OpenMPI and PMIx are needed both inside and
>>>> outside of the container.
>>>> So, I've tried using the exact same version of PMIx and OpenMPI in and
>>>> out of the container and the problem still persists.
>>>> The experiments have been done using RedHat hosts with CentOS or Ubuntu
>>>> singularity containers and the latest github versions of slurm, OpenMPI,
>>>> PMIx and singularity.
>>>>
>>>> By the way, do you have any MPI example for singularity v2?
>>>> Because the MPI example that you show here :
>>>> http://singularity.lbl.gov/#hpc
>>>>
>>>> is actually done using singularity v1, no?
>>>> In my understanding with singularity v2 we actually build a complete
>>>> image with OS not just the application with its libraries. Is this correct?
>>>>
>>>> Sorry for the long email and
>>>> thanks a lot for any extra info you can provide regarding singularity
>>>> v2 and MPI.
>>>>
>>>> Best Regards,
>>>> Yiannis
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>>
>>>
>>> --
>>> Gregory M. Kurtzer
>>> High Performance Computing Services (HPCS)
>>> University of California
>>> Lawrence Berkeley National Laboratory
>>> One Cyclotron Road, Berkeley, CA 94720
>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>> --
>> You received this message because you are subscribed to the Google Groups
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to singu...@lbl.gov.
>>
>
>
>
> --
> Gregory M. Kurtzer
> High Performance Computing Services (HPCS)
> University of California
> Lawrence Berkeley National Laboratory
> One Cyclotron Road, Berkeley, CA 94720
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a11409d8e7946df0534cd0e7c
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div class=3D"gmail_extra"><div class=3D"gmail_quote">On W=
ed, Jun 8, 2016 at 10:57 PM, Gregory M. Kurtzer <span dir=3D"ltr">&lt;<a hr=
ef=3D"mailto:gmku...@lbl.gov" target=3D"_blank">gmku...@lbl.gov</a>&gt;</sp=
an> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;=
border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr"><div class=3D=
"gmail_extra"><br><div class=3D"gmail_quote"><span class=3D"">On Wed, Jun 8=
, 2016 at 1:48 PM, yiannis georgiou <span dir=3D"ltr">&lt;<a href=3D"mailto=
:goh...@gmail.com" target=3D"_blank">goh...@gmail.com</a>&gt;</span> wrote:=
<br><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;bor=
der-left-width:1px;border-left-style:solid;border-left-color:rgb(204,204,20=
4);padding-left:1ex"><div dir=3D"ltr"><div><div><div><div><div><div>Hi Greg=
,<br><br></div>bullseye!!! it worked for me like this:<br></div></div></div=
></div></div></div></blockquote><div><br></div></span><div>Excellent!!</div=
><span class=3D""><div>=C2=A0</div><blockquote class=3D"gmail_quote" style=
=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;=
border-left-color:rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"><div>=
<div><div><div><div><br>[georgioy@rio11 ~]$ salloc -n4 -N2<br>[georgioy@rio=
11 ~]$ export SINGULARITY_NO_NAMESPACE_PID=3D1<br>[georgioy@rio11 ~]$ srun =
--mpi=3Dpmix -n 4 -N2 /usr/local/singularity_v2/bin/singularity exec /tmp/u=
buntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br>Hello world =
from processor rio13, rank 2 out of 4 processors<br>Hello world from proces=
sor rio13, rank 3 out of 4 processors<br>Hello world from processor rio12, =
rank 0 out of 4 processors<br>Hello world from processor rio12, rank 1 out =
of 4 processors<br>ERROR: Could not clear loop device<br><br></div>Any idea=
 how I can correct the &quot;ERROR: Could not clear loop device&quot; appea=
ring at the end of the execution?<br></div></div></div></div></div></blockq=
uote><div><br></div></span><div>Hrmm.. Interesting, I wonder on which syste=
m it got that error. Is it possible to try and replicate the error on a sin=
gle new (e.g. -N1)? The other thing to try is to run losetup (-a) on both r=
io12 and rio13 and see if /dev/loop0 is still bound somewhere.</div></div><=
/div></div></blockquote><div>It was related with a previously failed srun I=
 think. When I did a new clean salloc with different srun all worked withou=
t problem. <br></div><blockquote class=3D"gmail_quote" style=3D"margin:0 0 =
0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr"><div c=
lass=3D"gmail_extra"><div class=3D"gmail_quote"><span class=3D""><div>=C2=
=A0</div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8e=
x;border-left-width:1px;border-left-style:solid;border-left-color:rgb(204,2=
04,204);padding-left:1ex"><div dir=3D"ltr"><div><div><div><div></div>And wh=
en you have a moment could you explain me how this magic environment variab=
le make it work! I&#39;m not sure I got it.<br></div></div></div></div></bl=
ockquote><div><br></div></span><div>While most container systems are built =
around the idea of complete isolation, Singularity is focused on applicatio=
n portability so you can disable some of the namespaces as needed (with the=
 PID namespace being the culprit here for OpenMPI&#39;s shared memory model=
).</div></div></div></div></blockquote><div>Ok I see. <br></div><blockquote=
 class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc soli=
d;padding-left:1ex"><div dir=3D"ltr"><div class=3D"gmail_extra"><div class=
=3D"gmail_quote"><span class=3D""><div>=C2=A0</div><blockquote class=3D"gma=
il_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-le=
ft-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex"><div di=
r=3D"ltr"><div><div><div><br></div>One more question, I&#39;ve noticed that=
 there have been some changes in the latest OpenMPI to improve performance =
when using singularity. Are they done for PMIx or for all PMI versions?<br>=
</div></div></div></blockquote><div><br></div></span><div>Indeed. I&#39;m h=
oping Ralph will chime in when he has a moment and can address this and pos=
sibly a better long term fix (and if it can&#39;t be done via the MPI side,=
 I can do it on the Singularity side).</div></div></div></div></blockquote>=
<div>Ok<br><br></div><div>Thanks for your answers and the fast solution!<br=
></div><div><br></div><div>Yiannis <br></div><blockquote class=3D"gmail_quo=
te" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"=
><div dir=3D"ltr"><div class=3D"gmail_extra"><div class=3D"gmail_quote"><di=
v>=C2=A0</div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px=
 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color:rgb(=
204,204,204);padding-left:1ex"><div dir=3D"ltr"><div><div><br></div>Thanks =
a lot!</div></div></blockquote><div><br></div><div>My pleasure!</div><div><=
br></div><div>Greg</div><div><div class=3D"h5"><div><br></div><div><br></di=
v><div>=C2=A0</div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0p=
x 0px 0.8ex;border-left-width:1px;border-left-style:solid;border-left-color=
:rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr"><div><span><font color=
=3D"#888888"><br></font></span></div><span><font color=3D"#888888">Yiannis<=
br><div><div><div><div><div><div><div><div><br></div></div></div></div></di=
v></div></div></div></font></span></div><div><div><div class=3D"gmail_extra=
"><br><div class=3D"gmail_quote">On Wed, Jun 8, 2016 at 9:16 PM, Gregory M.=
 Kurtzer <span dir=3D"ltr">&lt;<a href=3D"mailto:gmku...@lbl.gov" target=3D=
"_blank">gmku...@lbl.gov</a>&gt;</span> wrote:<br><blockquote class=3D"gmai=
l_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left-width:1px;border-lef=
t-style:solid;border-left-color:rgb(204,204,204);padding-left:1ex"><div dir=
=3D"ltr">Hi Yiannis,<div><br></div><div>I have a quick thing to test... The=
 address not mapped error seems consistent with something else that I&#39;v=
e seen when testing OpenMPI with shared memory and the NEWPID namespace. Tr=
y to disable the NEWPID namespace by exporting this environment variable:</=
div><div><br></div><div>SINGULARITY_NO_NAMESPACE_PID=3D1<br></div><div><br>=
</div><div>Now you will need to export it in a place where all Singularity =
contexts will see it, maybe something like this:</div><div><br></div><div>$=
 srun --mpi=3Dpmix -n 4 -N 2 SINGULARITY_NO_NAMESPACE_PID=3D1 singularity e=
xec /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello</div>=
<div><br></div><div>There is an OpenMPI plugin which sets this automaticall=
y in the current codebase, but I&#39;m not sure how it will come into play =
in this usage scenario.</div><div><br></div><div>Let me know how that works=
 for ya!</div><div><br></div><div>Thanks,</div><div><br></div><div>Greg</di=
v></div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote"><div><div=
>On Wed, Jun 8, 2016 at 12:09 PM, yiannis georgiou <span dir=3D"ltr">&lt;<a=
 href=3D"mailto:goh...@gmail.com" target=3D"_blank">goh...@gmail.com</a>&gt=
;</span> wrote:<br></div></div><blockquote class=3D"gmail_quote" style=3D"m=
argin:0px 0px 0px 0.8ex;border-left-width:1px;border-left-style:solid;borde=
r-left-color:rgb(204,204,204);padding-left:1ex"><div><div><div dir=3D"ltr">=
<div><div><div>Hello,<br><br></div>I&#39;m trying to execute an MPI applica=
tion from within a singularity image through Slurm and pmix using the follo=
wing command <br><br></div>srun --mpi=3Dpmix -n 4 -N 2 singularity exec
 /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br><br><=
/div>The
 slurmstepd process is spawned on the compute node and it seems to have=20
launched correctly the application from what we see on one of the=20
compute nodes:<br><div><br>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br=
>[root@rio12 ~]# ps -aux<br>root=C2=A0=C2=A0=C2=A0=C2=A0 35147=C2=A0 0.1=C2=
=A0 0.0 562284=C2=A0 4016 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 Sl=C2=
=A0=C2=A0 20:06=C2=A0=C2=A0 0:00 slurmstepd: [83.0]=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0 <br>georgioy
 35158=C2=A0 0.2=C2=A0 0.0=C2=A0 10428=C2=A0=C2=A0 896 ?=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0 S=C2=A0=C2=A0=C2=A0 20:06=C2=A0=C2=A0 0:00 Singula=
rity:=20
namespace=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=20
/home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br>root=C2=A0=C2=A0=C2=A0=C2=
=A0 35162=C2=A0 0.0=C2=A0 0.0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 0=C2=A0=C2=A0=
=C2=A0=C2=A0 0 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 S&lt;=C2=A0=C2=
=A0 20:06=C2=A0=C2=A0 0:00 [loop0]<br>georgioy
 35163=C2=A0 0.0=C2=A0 0.0=C2=A0 10428=C2=A0=C2=A0 400 ?=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0 S=C2=A0=C2=A0=C2=A0 20:06=C2=A0=C2=A0 0:00 Singula=
rity:=20
exec=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=20
/home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br>root=C2=A0=C2=A0=C2=A0=C2=
=A0 35164=C2=A0 0.0=C2=A0 0.0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 0=C2=A0=C2=A0=
=C2=A0=C2=A0 0 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 S=C2=A0=C2=A0=C2=
=A0 20:06=C2=A0=C2=A0 0:00 [jbd2/loop0-8]<br>root=C2=A0=C2=A0=C2=A0=C2=A0 3=
5165=C2=A0 0.0=C2=A0 0.0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 0=C2=A0=C2=A0=C2=A0=
=C2=A0 0 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 S=C2=A0=C2=A0=C2=A0 20=
:06=C2=A0=C2=A0 0:00 [ext4-dio-unwrit]<br>georgioy 35166=C2=A0 102=C2=A0 0.=
0 285476 14828 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 RLl=C2=A0 20:06=
=C2=A0=C2=A0 0:12 /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br>=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br><br></div><div>and I see t=
he pmix related functions starting correctly in the slurmd log files :<br><=
br>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br><br>[2016-06-08T20:12:0=
8.004] [86.0] debug:=C2=A0 (null) [0] mpi_pmix.c:90 [p_mpi_hook_slurmstepd_=
prefork] mpi/pmix: start<br>[2016-06-08T20:12:08.004] [86.0] debug:=C2=A0 m=
pi/pmix: setup sockets<br>[2016-06-08T20:12:08.005]
 [86.0] debug:=C2=A0 rio12 [0] pmixp_client.c:78 [errhandler_reg_callbk]=20
mpi/pmix: Error handler registration callback is called with status=3D0,=20
ref=3D0<br>[2016-06-08T20:12:08.005] [86.0] debug:=C2=A0 rio12 [0] pmixp_cl=
ient.c:581 [pmixp_libpmix_job_set] mpi/pmix: task initialization<br>[2016-0=
6-08T20:12:08.005] [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:220 [_agent_=
thread] mpi/pmix: Start agent thread<br>[2016-06-08T20:12:08.005]
 [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:313 [pmixp_agent_start]=20
mpi/pmix: agent thread started: tid =3D 139672278615808<br>[2016-06-08T20:1=
2:08.005] [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:84 [_conn_readable] m=
pi/pmix: fd =3D 9<br>[2016-06-08T20:12:08.005] [86.0] debug:=C2=A0 rio12 [0=
] pmixp_agent.c:84 [_conn_readable] mpi/pmix: fd =3D 19<br>[2016-06-08T20:1=
2:08.005] [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:256 [_pmix_timer_thre=
ad] mpi/pmix: Start timer thread<br>[2016-06-08T20:12:08.005]
 [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:335 [pmixp_agent_start]=20
mpi/pmix: timer thread started: tid =3D 139672277563136<br><br>=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br></div><div><div><br></div><div>However th=
e application is never actually started and the srun fails completely with =
the following output:<br></div><div><br>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D<br>[georgioy@rio11 ~]$ srun --mpi=3Dpmix -n 4 -N 2 singular=
ity exec /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<=
br>[rio12:00001] *** Process received signal ***<br>[rio12:00001] Signal: S=
egmentation fault (11)<br>[rio12:00001] Signal code: Address not mapped (1)=
<br>[rio12:00001] Failing at address: 0x7fbd937e6010<br>[rio12:00001] [ 0] =
[rio12:00001] *** Process received signal ***<br>/lib/x86_64-linux-gnu/libp=
thread.so.0(+0x113d0)[0x7f26aeb233d0]<br>[rio12:00001] [ 1] /usr/local/lib/=
libmca_common_sm.so.0(+0x1035)[0x7f269f964035]<br>[rio12:00001] [ 2] /usr/l=
ocal/lib/libmca_common_sm.so.0(common_sm_mpool_create+0xa3)[0x7f269f964583]=
<br>[rio12:00001] [ 3] /usr/local/lib/openmpi/mca_btl_sm.so(mca_btl_sm_add_=
procs+0x5f1)[0x7f269fb68771]<br>[rio12:00001] [ 4] /usr/local/lib/openmpi/m=
ca_bml_r2.so(+0x2be7)[0x7f26a451fbe7]<br>[rio12:00001] [ 5] /usr/local/lib/=
openmpi/mca_pml_ob1.so(mca_pml_ob1_add_procs+0xd2)[0x7f269ef35662]<br>[rio1=
2:00001] [ 6] /usr/local/lib/libmpi.so.0(ompi_mpi_init+0xa51)[0x7f26aed75d3=
1]<br>[rio12:00001] [ 7] /usr/local/lib/libmpi.so.0(MPI_Init+0xb9)[0x7f26ae=
d9bdb9]<br>[rio12:00001] [ 8] /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hell=
o[0x4007ec]<br>[rio12:00001] [ 9] /lib/x86_64-linux-gnu/libc.so.6(__libc_st=
art_main+0xf0)[0x7f26ae769830]<br>[rio12:00001] Signal: Segmentation fault =
(11)<br>[rio12:00001] Signal code: Address not mapped (1)<br>[rio12:00001] =
Failing at address: 0x7fbd937e6010<br>[rio12:00001] [10] /home_nfs/georgioy=
/BENCHS/mpi-openmp/mpi_hello[0x400709]<br>[rio12:00001] *** End of error me=
ssage ***<br>[rio12:00001] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11=
3d0)[0x7f3f89c063d0]<br>[rio12:00001] [ 1] /usr/local/lib/libmca_common_sm.=
so.0(+0x1035)[0x7f3f7eb1d035]<br>[rio12:00001] [ 2] /usr/local/lib/libmca_c=
ommon_sm.so.0(common_sm_mpool_create+0xa3)[0x7f3f7eb1d583]<br>[rio12:00001]=
 [ 3] /usr/local/lib/openmpi/mca_btl_sm.so(mca_btl_sm_add_procs+0x5f1)[0x7f=
3f7ed21771]<br>[rio12:00001] [ 4] /usr/local/lib/openmpi/mca_bml_r2.so(+0x2=
be7)[0x7f3f7f5f3be7]<br>[rio12:00001] [ 5] /usr/local/lib/openmpi/mca_pml_o=
b1.so(mca_pml_ob1_add_procs+0xd2)[0x7f3f7e0ee662]<br>[rio12:00001] [ 6] /us=
r/local/lib/libmpi.so.0(ompi_mpi_init+0xa51)[0x7f3f89e58d31]<br>[rio12:0000=
1] [ 7] /usr/local/lib/libmpi.so.0(MPI_Init+0xb9)[0x7f3f89e7edb9]<br>[rio12=
:00001] [ 8] /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x4007ec]<br>[r=
io12:00001] [ 9] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x=
7f3f8984c830]<br>[rio12:00001] [10] /home_nfs/georgioy/BENCHS/mpi-openmp/mp=
i_hello[0x400709]<br>[rio12:00001] *** End of error message ***<br>slurmste=
pd:
 error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix: ERROR: Error
 handler invoked: status =3D -25, nranges =3D 0: Success (0)<br>srun: Job s=
tep aborted: Waiting up to 32 seconds for job step to finish.<br>slurmstepd=
: error: *** STEP 86.0 ON rio12 CANCELLED AT 2016-06-08T20:12:08 ***<br>slu=
rmstepd:
 error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix: ERROR: Error
 handler invoked: status =3D -25, nranges =3D 0: Success (0)<br>slurmstepd:=
=20
error: rio13 [1] pmixp_client.c:241 [errhandler] mpi/pmix: ERROR: Error=20
handler invoked: status =3D -25, nranges =3D 0: Success (0)<br>slurmstepd:=
=20
error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix: ERROR: Error=20
handler invoked: status =3D -25, nranges =3D 0: Success (0)<br>srun: error:=
 rio12: tasks 0-2: Killed<br>srun: error: rio13: task 3: Killed<br><br>=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br><br></div><div>th=
e results I get when launching with mpirun instead of srun are more or less=
 the same. <br><br></div><div>From my understanding, the orted process, or =
in my case slurmstepd process that launches the singularity container <br><=
/div><div>and
 the MPI application, enables the communication of MPI libraries and=20
orted (or slurmstepd) through PMI (in my case here PMIx).<br></div><div>So =
I suppose the problem I see should be related with the mapping of PMI from =
the container towards the orted or slurmstepd.<br><br></div><div>What do yo=
u think?<br></div><div><br></div><div>To
 give some more details, my singularity container has OpenMPI and PMIx=20
installed but not Slurm. I don&#39;t think that Slurm needs to reside withi=
n
 the container in that context.<br></div><div>But I wasn&#39;t sure if Open=
MPI and PMIx are needed both inside and outside of the container.<br></div>=
<div>So, I&#39;ve tried using the exact same version of PMIx and OpenMPI in=
 and out of the container and the problem still persists. <br></div><div>Th=
e
 experiments have been done using RedHat hosts with CentOS or Ubuntu=20
singularity containers and the latest github versions of slurm, OpenMPI,
 PMIx and singularity.<br></div><div><br></div><div>By the way, do you have=
 any MPI example for singularity v2? <br></div><div>Because the MPI example=
 that you show here : <a href=3D"http://singularity.lbl.gov/#hpc" target=3D=
"_blank">http://singularity.lbl.gov/#hpc</a><br><br></div><div>is actually =
done using singularity v1, no? <br>In
 my understanding with singularity v2 we actually build a complete image
 with OS not just the application with its libraries. Is this correct?<br><=
/div><div><br></div><div>Sorry for the long email and<br>thanks a lot for a=
ny extra info you can provide regarding singularity v2 and MPI.<br><br></di=
v><div>Best Regards,<br></div><div>Yiannis</div></div></div></div></div><sp=
an><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<span><font color=3D"#888888"><br>
</font></span></font></span></blockquote></div><span><font color=3D"#888888=
"><br><br clear=3D"all"><div><br></div>-- <br><div data-smartmail=3D"gmail_=
signature"><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>High Performance Com=
puting Services (HPCS)<br>University of California<br>Lawrence Berkeley Nat=
ional Laboratory<br>One Cyclotron Road, Berkeley, CA 94720</div></div></div=
>
</font></span></div><span><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</font></span></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div></div></div><div><div class=3D"h5"><br><br c=
lear=3D"all"><div><br></div>-- <br><div data-smartmail=3D"gmail_signature">=
<div dir=3D"ltr"><div>Gregory M. Kurtzer<br>High Performance Computing Serv=
ices (HPCS)<br>University of California<br>Lawrence Berkeley National Labor=
atory<br>One Cyclotron Road, Berkeley, CA 94720</div></div></div>
</div></div></div></div><div class=3D"HOEnZb"><div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div></div>

--001a11409d8e7946df0534cd0e7c--

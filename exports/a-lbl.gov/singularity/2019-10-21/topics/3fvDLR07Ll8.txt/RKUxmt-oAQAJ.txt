X-Received: by 10.129.156.142 with SMTP id t136mr5320677ywg.92.1497086224944;
        Sat, 10 Jun 2017 02:17:04 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.36.101.212 with SMTP id u203ls887587itb.5.canary-gmail; Sat,
 10 Jun 2017 02:17:04 -0700 (PDT)
X-Received: by 10.84.236.15 with SMTP id q15mr44787201plk.163.1497086224064;
        Sat, 10 Jun 2017 02:17:04 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1497086224; cv=none;
        d=google.com; s=arc-20160816;
        b=wLhjthw5M9OkGp12zOtC/Zlnz/IP3RGD4DfrsfGHPMbcPtcHPtDAW29+TYDEwIjWIV
         Ke8AHmyJOYunKXlbLxuXQs0dKFGmPeEXJWb5drC+EC5yBAe1Io8ukN8yMxEyjzTs0thu
         8G2bEGfM4Qx4/z+N1BWF/l8B2oGD+JuDMTeVe1DBk/HYinA7BKW0hyRNmDLulxAl8Pvi
         x6d2wXD+H6CW6KyOKdVraSiGJq6YrT0UuIOwZrn8GUD054LYkzDvVYDwfozkJnZZUn5Q
         o+jxd7vvqHc6kMSHCnkMSy+nhmw9AVt9nAQlfMDjBKl3dolNkQ5khm0jO9bTUgikdsc1
         jpuA==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:references:in-reply-to:mime-version
         :dkim-signature:arc-authentication-results;
        bh=N4K0K7zaHBs2lIHibNzLxeNb+caKGLJXJ7P/HSrxGsA=;
        b=MrURVvr370pYnGNPlQKDjfXdZSD5H6chb9CYl7o5wS2GBxTvpxhd/a0dxlpYPA1aue
         imRN8Z3To54d+0RyyF1jJIiKThADUZs7f0WIYpduW9BeL/GFG/GLMU4DXbNDSuPQJHd4
         849IVlZtw96vhDgdPpTllE50DRUikIYNdLozU/tcmgwz54ONO2f6sdGuvon/RZUlcLsA
         Pq2i0CZSbDXKq5+0qvcatnFdc6YWLxzgwjfU150LXg2pe7KLBm1tUorrD9LpVuX5DprL
         9cfLM/Ujp+KGPecAfov6SMgsAMFDZLyjGzdGRBSCI3xtKQsK7484a3xM8HfqZWwOAYJ+
         qWtA==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of heave...@gmail.com designates 209.85.214.47 as permitted sender) smtp.mailfrom=heave...@gmail.com
Return-Path: <heave...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id g6si2777010plk.491.2017.06.10.02.17.03
        for <singu...@lbl.gov>;
        Sat, 10 Jun 2017 02:17:04 -0700 (PDT)
Received-SPF: pass (google.com: domain of heave...@gmail.com designates 209.85.214.47 as permitted sender) client-ip=209.85.214.47;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of heave...@gmail.com designates 209.85.214.47 as permitted sender) smtp.mailfrom=heave...@gmail.com
X-Ironport-SBRS: 2.7
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2GVAgCpuDtZfy/WVdFcHgYMGQYMgkQ+T?=
 =?us-ascii?q?gGBSweDZQiBNpkaBgEBAQaBIwSQSoU5gU5DIQGCTIImgQcJAoJ6Bz8YAQEBAQE?=
 =?us-ascii?q?BAQEBAQECEAEBCQsLCCYxgjMFAgMaBghGKS8BAQEBAQEBAQEBHwIrJQEaAQICA?=
 =?us-ascii?q?SMdAQ0OHgMBCQIGAwILMAcCAhsGAQEOAwEFARwOBwQBGgIEiDmBOQEDCAUIBZN?=
 =?us-ascii?q?pkRo/jAiCBAUBHIMKBYNpChknDVaDPwEBAQEGAQEBAQEbAgYFDYYJhUaCWIFjE?=
 =?us-ascii?q?gGDLoJhAQSRPYN5gVQUhmY7imKEA4RkggaFQ4o9i0aHXhQfgRUfgQUzC3R2hGR?=
 =?us-ascii?q?EgVwxNgiHO0eBaQEBAQ?=
X-IronPort-AV: E=Sophos;i="5.39,322,1493708400"; 
   d="scan'208,217";a="78234537"
Received: from mail-it0-f47.google.com ([209.85.214.47])
  by fe3.lbl.gov with ESMTP; 10 Jun 2017 02:16:59 -0700
Received: by mail-it0-f47.google.com with SMTP id m62so7810761itc.0
        for <singu...@lbl.gov>; Sat, 10 Jun 2017 02:16:59 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=N4K0K7zaHBs2lIHibNzLxeNb+caKGLJXJ7P/HSrxGsA=;
        b=FH9c6pG/mhNVZBQc+ye3N9uevIp2wclBvl8pUW1c+ypok87Vk8c8LvU3GoUZg7Awi0
         CY/acaYvIeSfBIt3dWXlC4ALtau4jroa1H0pl35xa/gvjquTEXNz9MO2zV/HVmjvz5DR
         p2w163mqjr0bqKrnGQ+za3Htp48Ul5T9UNxPB6TLHHLa0ngq4WRPLOrvMxx2245wCyKv
         J2wDmhXZ7mfInGPrHlVMHMZSw4SKJmYxQC60nvNudxvH2oloYedGjLOdEQh9Ad/A539L
         aOn/wsl7SH9CIk4L9TKYMyGZ83JrS1heOa5HgKg1xbtWXtumQaedSt57xIN8hK0exGQp
         tkrA==
X-Gm-Message-State: AODbwcC3OudKiM1yCqeX8Lw+7qDOv4fBLF8hh9E+R07TZvuibrHjNOHk
	6l7mECyv7fDl+LGw+hL6vSQ1/qGvkQ==
X-Received: by 10.36.99.67 with SMTP id j64mr3638209itc.5.1497086219022; Sat,
 10 Jun 2017 02:16:59 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.165.133 with HTTP; Sat, 10 Jun 2017 02:16:38 -0700 (PDT)
In-Reply-To: <6117a8ba-063e-4799-aeb3-38a2558a0458@lbl.gov>
References: <cc84e6d1-49ad-416d-8480-78863790f5fd@lbl.gov> <6117a8ba-063e-4799-aeb3-38a2558a0458@lbl.gov>
From: Guohua Li <heave...@gmail.com>
Date: Sat, 10 Jun 2017 18:16:38 +0900
Message-ID: <CAKjpbPgtBHN7iNK9tzABD=A-1K8qKPmzHBsBpeSWRiGyFvKdVQ@mail.gmail.com>
Subject: Re: [Singularity] Re: Is there any way to run mpirun command inside
 container for multi-host system?
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="001a113ac2ac487aff0551978c78"

--001a113ac2ac487aff0551978c78
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

Really thanks for your reply!

Please post the script when you find it.

Now I'm testing every MPI version which host installed MPI version can
support much MPI versions inside the container!

Hope your script can solve our problem!


=EC=98=81=EC=9B=90=ED=9E=88 =EC=82=B4 =EA=B2=83 =EC=B2=98=EB=9F=BC =EA=BF=
=88=EA=BE=B8=EA=B3=A0 =EB=82=B4=EC=9D=BC =EC=A3=BD=EC=9D=84 =EA=B2=83 =EC=
=B2=98=EB=9F=BC =EC=82=B4=EC=9E=90!
This too shall pass away!

=E2=80=BB =EC=9D=B4=EA=B5=AD=ED=99=94 LI GUOHUA
=E2=80=BB =EA=B1=B4=EA=B5=AD=EB=8C=80=ED=95=99=EA=B5=90 =EB=8C=80=ED=95=99=
=EC=9B=90 =EC=8B=A0=EA=B8=B0=EC=88=A0=EC=9C=B5=ED=95=A9=ED=95=99=EA=B3=BC =
=EB=B0=95=EC=82=AC=EA=B3=BC=EC=A0=95
=E2=80=BB =EC=9C=B5=ED=95=A9 =EC=BB=B4=ED=93=A8=ED=8C=85 =EC=97=B0=EA=B5=AC=
=EC=8B=A4 (IC Lab)
=E2=80=BB iIT, Department of Advanced Technology Fusion, Konkuk University
=E2=80=BB Industry-University Cooperation Bldg. 805
=E2=80=BB KonKuk University, Hwayang-dong, Gwangjin-Gu, Seoul 143-701 South=
 Korea
=E2=80=BB Cell Phone: +82) 10-3666-8263
=E2=80=BB E-mail: heave...@gmail.com <heave...@gmail.com>

2017-06-10 18:07 GMT+09:00 'Stefan Kombrink' via singularity <
singu...@lbl.gov>:

> I've got some experience on running multi node jobs with mpirun inside th=
e
> containers.
> Greg is right that it will be difficult to find an general purpose
> solution for arbitary HPC systems and software.
> I made it work for two heavily used applications on our cluster one of
> which used IntelMPI and the other OpenMPI 1.6
> The main thing was to replace /bin/ssh in order to tweak mpirun to wrap
> "ssh hostname cmd" to "ssh 'singularity ContainerName exec cmd'
> I had to apply some more workarounds to make IB work properly (mainly
> envvars to configure MPI properly) but essentially the efford was
> justifiable.
>
> Sorry cant find the link to the ssh wrapper script right now but I can
> post it later when you are interested in it. It is really just a few line=
s
> of bash code.
>
> Stefan
>
>
> Am Donnerstag, 8. Juni 2017 15:17:30 UTC+2 schrieb Guohua Li:
>>
>>
>> For our HPC system, really need run mpirun command inside the container
>> on multi-host.
>>
>> How can we fix the issues?
>>
>> In my experience, when I build mpi job on multihost, everytime I change
>> the version of MPI inside the container, I have to change the version of
>> MPI on the host.
>>
>> Is there any solution for run mpi command inside the container on
>> multi-host system?
>>
>>
>>
>>
>> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a113ac2ac487aff0551978c78
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Really thanks for your reply!=C2=A0<div><br></div><div>Ple=
ase post the script when you find it.=C2=A0<div><br></div><div>Now I&#39;m =
testing every MPI version which host installed MPI version can support much=
 MPI versions inside the container!=C2=A0</div></div><div><br></div><div>Ho=
pe your script can solve our problem!</div><div><br></div></div><div class=
=3D"gmail_extra"><br clear=3D"all"><div><div class=3D"gmail_signature" data=
-smartmail=3D"gmail_signature"><div dir=3D"ltr"><div><div dir=3D"ltr"><div>=
<div dir=3D"ltr"><div><span style=3D"color:rgb(182,182,182);font-family:&#3=
9;Microsoft Yahei&#39;,Arial;text-align:center">=EC=98=81=EC=9B=90=ED=9E=88=
=C2=A0=EC=82=B4=C2=A0=EA=B2=83=C2=A0=EC=B2=98=EB=9F=BC=C2=A0=EA=BF=88=EA=BE=
=B8=EA=B3=A0=C2=A0=EB=82=B4=EC=9D=BC=C2=A0=EC=A3=BD=EC=9D=84=C2=A0=EA=B2=83=
=C2=A0=EC=B2=98=EB=9F=BC=C2=A0=EC=82=B4=EC=9E=90!</span><span style=3D"colo=
r:rgb(182,182,182);font-family:&#39;Microsoft Yahei&#39;,Arial;text-align:c=
enter">=C2=A0</span>=C2=A0</div><div><font color=3D"#999999">This too shall=
 pass away!<br></font><br><font color=3D"#6666cc" face=3D"&#39;comic sans m=
s&#39;, sans-serif" style=3D"background-color:rgb(255,255,255)">=E2=80=BB =
=EC=9D=B4=EA=B5=AD=ED=99=94 LI GUOHUA<br>=E2=80=BB =EA=B1=B4=EA=B5=AD=EB=8C=
=80=ED=95=99=EA=B5=90 =EB=8C=80=ED=95=99=EC=9B=90 =EC=8B=A0=EA=B8=B0=EC=88=
=A0=EC=9C=B5=ED=95=A9=ED=95=99=EA=B3=BC =EB=B0=95=EC=82=AC=EA=B3=BC=EC=A0=
=95</font></div><div><span style=3D"color:rgb(102,102,204);font-family:&#39=
;comic sans ms&#39;,sans-serif;background-color:rgb(255,255,255)">=E2=80=BB=
</span><font color=3D"#3366ff">=C2=A0</font><font color=3D"#6666cc">=EC=9C=
=B5=ED=95=A9 =EC=BB=B4=ED=93=A8=ED=8C=85 =EC=97=B0=EA=B5=AC=EC=8B=A4 (IC La=
b)</font><font color=3D"#6666cc" face=3D"&#39;comic sans ms&#39;, sans-seri=
f" style=3D"background-color:rgb(255,255,255)"><br>=E2=80=BB iIT, Departmen=
t of Advanced Technology Fusion, Konkuk University<br>=E2=80=BB Industry-Un=
iversity Cooperation Bldg. 805</font></div>
<div><font face=3D"&#39;comic sans ms&#39;, sans-serif" style=3D"background=
-color:rgb(255,255,255)"><font color=3D"#6666cc">=E2=80=BB KonKuk Universit=
y, Hwayang-dong, Gwangjin-Gu, Seoul 143-701 South Korea<br>=E2=80=BB Cell P=
hone: +82) 10-3666-8263</font><br><font color=3D"#9999ff">=E2=80=BB E-mail:=
 heavenkong</font><a style=3D"color:rgb(153,153,255)" href=3D"mailto:heave.=
..@gmail.com" target=3D"_blank">@gmail.com</a></font></div></div></div></di=
v></div></div></div></div>
<br><div class=3D"gmail_quote">2017-06-10 18:07 GMT+09:00 &#39;Stefan Kombr=
ink&#39; via singularity <span dir=3D"ltr">&lt;<a href=3D"mailto:singu...@l=
bl.gov" target=3D"_blank">singu...@lbl.gov</a>&gt;</span>:<br><blockquote c=
lass=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;=
padding-left:1ex"><div dir=3D"ltr">I&#39;ve got some experience on running =
multi node jobs with mpirun inside the containers.<br>Greg is right that it=
 will be difficult to find an general purpose solution for arbitary HPC sys=
tems and software.<br>I made it work for two heavily used applications on o=
ur cluster one of which used IntelMPI and the other OpenMPI 1.6<br>The main=
 thing was to replace /bin/ssh in order to tweak mpirun to wrap &quot;ssh h=
ostname cmd&quot; to &quot;ssh &#39;singularity ContainerName exec cmd&#39;=
<br>I had to apply some more workarounds to make IB work properly (mainly e=
nvvars to configure MPI properly) but essentially the efford was justifiabl=
e.<br><br>Sorry cant find the link to the ssh wrapper script right now but =
I can post it later when you are interested in it. It is really just a few =
lines of bash code.<span class=3D"HOEnZb"><font color=3D"#888888"><br><br>S=
tefan</font></span><div><div class=3D"h5"><br><br>Am Donnerstag, 8. Juni 20=
17 15:17:30 UTC+2 schrieb Guohua Li:<blockquote class=3D"gmail_quote" style=
=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex"=
><div dir=3D"ltr"><br><div><font size=3D"4">For our HPC system, really need=
 run mpirun command inside the container on multi-host.=C2=A0</font></div><=
div><font size=3D"4"><br></font></div><div><font size=3D"4">How can we fix =
the issues?=C2=A0</font></div><div><font size=3D"4"><br></font></div><div><=
font size=3D"4">In my experience, when I build mpi job on multihost, everyt=
ime I change the version of MPI inside the container, I have to change the =
version of MPI on the host.=C2=A0</font></div><div><font size=3D"4"><br></f=
ont></div><div><font size=3D"4">Is there any solution for run mpi=C2=A0comm=
and inside the container on multi-host system?=C2=A0</font></div><div><font=
 size=3D"4"><br></font></div><div><font size=3D"4"><br></font></div><div><f=
ont size=3D"4"><br></font></div><div><font size=3D"4"><br></font></div></di=
v></blockquote></div></div></div><div class=3D"HOEnZb"><div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

--001a113ac2ac487aff0551978c78--

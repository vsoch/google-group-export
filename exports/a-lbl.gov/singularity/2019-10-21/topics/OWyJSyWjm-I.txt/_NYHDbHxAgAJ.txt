X-Received: by 10.98.163.2 with SMTP id s2mr1751861pfe.1.1511717165665;
        Sun, 26 Nov 2017 09:26:05 -0800 (PST)
X-BeenThere: singularity@lbl.gov
Received: by 10.159.204.146 with SMTP id t18ls3154267plo.15.gmail; Sun, 26 Nov
 2017 09:26:04 -0800 (PST)
X-Received: by 10.84.235.140 with SMTP id p12mr32517931plk.153.1511717164628;
        Sun, 26 Nov 2017 09:26:04 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1511717164; cv=none;
        d=google.com; s=arc-20160816;
        b=DwR0eTHKUBrUWxJjbycC6OrbK9Yptuy5AzpvybXRsLZ2cczMH/KZ6STznD+EKPZvm7
         C0zzONCKxjWgpQTQ4o57Sp79zSBnfSWWsDcJYTYOQmy7LznUQAb55Vm3KFpj8uoQX7C3
         jEI/f/Hl5wTEJLaP/l3BdQ+/P8mAfmybE7swN3az/PL+sDOtGT9XMRXCn6UWxZsoJscI
         C8gBpdsd1LBDRBliaVs472bz41NpxclGWk3adHTesQ74SADmuBIc3k9q4n8XfdZoVHeS
         Td4sKOrBSpuOWWWN1qPn8vQ6SDKwEhd2YVf4eVHngv4glbbVGnDLeQgDTHiGbqpmh0NE
         ASRw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:references:in-reply-to:mime-version
         :dkim-signature:arc-authentication-results;
        bh=4eV5CbMzdIOimq1h40g0biwqHZyvBTOq1xztAZe7bFA=;
        b=sFzKjuAiP9oMHfR/BwQYOxdoIEq4/K5y8OEYO8owZTUroQ7R+R5AuxOSmAbV6+1ec0
         4IV3VFymk2EJn/TDCqpsT3Iq+ytwt4S9lxee6Z/TrMz8XrJ3uBH8AOP153nOG3gz/Ciq
         EIDbBO6fLjzLzuD6NT9mefH8Xf4u0TGxZ2K/dz/j2DiVIAoYWNuJXvYa/oi6qcT/M3Xx
         r+AIEZK4Lc4ryPPJyww3J8DyQ7pqytmlxbMVrNjv1S+Y1XdMw758aSbnL0+lNNzAigLP
         WJ6VQXh4v9tpZY9F+hnWMxlvdvONt9d5PU8hXciPAcmsZZbhnonpBX+lTzGxEqGSCkGZ
         oqWQ==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=W8An03uT;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.218.45 as permitted sender) smtp.mailfrom=vso...@gmail.com
Return-Path: <vso...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id k3si21763485pld.688.2017.11.26.09.26.04
        for <singu...@lbl.gov>;
        Sun, 26 Nov 2017 09:26:04 -0800 (PST)
Received-SPF: pass (google.com: domain of vso...@gmail.com designates 209.85.218.45 as permitted sender) client-ip=209.85.218.45;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=W8An03uT;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.218.45 as permitted sender) smtp.mailfrom=vso...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2GKAACW+Bpahi3aVdFXAx0BAQUBCwGDD?=
 =?us-ascii?q?gKBEm4nB4NwCIE2l3+BfZZ9gT5AAyIBDIRHTwKEVwdDFAEBAQEBAQEBAQECEAE?=
 =?us-ascii?q?BAQgLCwgoL4I4BQIDGgYFBEgmAwMBAQEBAQEBAQEjAQEBAQEBAQEBAQEBAQEBA?=
 =?us-ascii?q?QEYAg0eJQEBGAEBAQECARoJBBkBDQ4eAwELBgULDSAKAgIhAQEOAwEFARwOBwQ?=
 =?us-ascii?q?BBwESAgSIMYE3AQMNCAULmV1AjBCBbRgFARyDCgWDVwoZJw1YgmcBAQEBBgEBA?=
 =?us-ascii?q?QEBAQEBGAIGEoMoggeFWxh2gmuBdQkBEgEJNwwagk6CYwWTCoYciGM9h3KDaoQ?=
 =?us-ascii?q?3hHmCFpE4ijeCPzuIdRkfgRY2Vi5vbxVrgWcBDwmCECofghQgNgEBAQEEh39Ig?=
 =?us-ascii?q?XABAQE?=
X-IronPort-AV: E=Sophos;i="5.44,459,1505804400"; 
   d="scan'208,217";a="97709146"
Received: from mail-oi0-f45.google.com ([209.85.218.45])
  by fe3.lbl.gov with ESMTP; 26 Nov 2017 09:26:02 -0800
Received: by mail-oi0-f45.google.com with SMTP id g139so7962077oic.5
        for <singu...@lbl.gov>; Sun, 26 Nov 2017 09:26:02 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=4eV5CbMzdIOimq1h40g0biwqHZyvBTOq1xztAZe7bFA=;
        b=W8An03uTfO7FfSQ+RziQE5SGzXM6YpRkcDwYnbWmi/XFetjHJl6E7wyE5fqjoB/zrE
         VUwKe9IzMK8LNOvSw+GzteySTg1bW+r1iTjGeYultqWP3mJuS0KncuTr6PjdXUa0ySTT
         AuMzt3Un6ytkknFem8P4Mtz+XVtCQrZG/WZZUm4RgyKRcZxFwDwaSNPWSwdN5mgZswhM
         C18alpnlM9HMs//3dsdb1GIYq8URW4dJO6vwWURPES8nQMugZaWHDKyKFP40E1S6DNvJ
         dUShvZLUitnxBnehLW8N0xjMecJacLiUbLG2iBsYCyCsWvj2x4fJFhCGQh3tRHz53k4B
         vsXg==
X-Gm-Message-State: AJaThX51XC9WLz/G02hkonopr1ax3TbS7N9SobednZFk7nGnGM+VJwQb
	m5QwgF3cmMAWO/9qN2dZS5gAvX5iejLOr1vZeHZnEbwg
X-Received: by 10.202.75.81 with SMTP id y78mr22932996oia.107.1511717161243;
 Sun, 26 Nov 2017 09:26:01 -0800 (PST)
MIME-Version: 1.0
Received: by 10.74.165.72 with HTTP; Sun, 26 Nov 2017 09:25:40 -0800 (PST)
In-Reply-To: <CAMG2UCAD1M4PiAef2tmvt2YzG7_8LTih=RFQ5waRjU36oaKRJQ@mail.gmail.com>
References: <cecdf0cf-7c70-4ff6-bb41-d5523587a550@lbl.gov> <CAM=pu+J9otnhcnP3knQ4L22nfLvCGkU6pLZejFhZE2fTi_QhDw@mail.gmail.com>
 <CAMG2UCB4f4=gG0D6rESr67dDhZaDquEeR718=2JPck+eTOR8qw@mail.gmail.com>
 <CAM=pu+KWN3F0DydrYY1h1+vmS67afT9Y3TLeWyDUwRFfWJbpww@mail.gmail.com>
 <CAMG2UCCYWB+kzBjr7O6A1Bjm8jawyjGFmWWr3QRVT=qUs2YX5w@mail.gmail.com>
 <CAM=pu++FqTxTMJ4EmN7m4S3=3+eyVVmrV0r3dQVxEEZTAPNLGg@mail.gmail.com> <CAMG2UCAD1M4PiAef2tmvt2YzG7_8LTih=RFQ5waRjU36oaKRJQ@mail.gmail.com>
From: v <vso...@gmail.com>
Date: Sun, 26 Nov 2017 09:25:40 -0800
Message-ID: <CAM=pu+J6SXK31HqK9gr7A_Np2U5JZgv86Orr87H6g01tUmKBCg@mail.gmail.com>
Subject: Re: [Singularity] Celery RabbitMQ worker packaged in a Singularity container
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="001a113529a26599e6055ee61493"

--001a113529a26599e6055ee61493
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

As far as I know not yet, it would need to be possible to define networking
between containers like Docker does -->
https://docs.docker.com/engine/userguide/networking/ and then have an
orchestrator to map between host and other containers. What you could try
is starting container instances that use a (shared) network (localhost) and
maybe have them operate at different ports?

Just curious - what is your strategy for the layer between the web
application and the GPU servers? These kind of connections (to a shared
resource with sensitive data and what not) historically can make some
nervous :P

I think what you are saying is:

 1. user requests task on front end
 2. front end handles authentication and authorization
 3. front end submits job to celery
 4. celery task is a Singularity container running on GPU, and since worker
=3D=3D container, it requires networking

and what I'm suggesting is to separate the front / back servers a bit more:

 1. user requests task on front end
 2. front end handles authentication and authorization
 3. front end submits job to celery (still frontend)
 4. celery worker(still frontend) is a process that finishes configuration
of job (memory? time? cluster? queue type?) and sends job to a back end
queue (slurm, sge)
 5. the slurm/sge queues are optimized for this sort of thing, so you just
load the singularity module, run the job, and send a signal back to the
front end queue.

So a few notes on the above:
 - there is flexibility (step 4) to have different kinds of queues in
different locations. The front end worker is the manager of where things go=
.
 - the singularity container is not required to have a network, or be
constantly running.
 - the main server (the same celery workers) also need a means to receive
messages of something finishing to update the server, this could be a POST
or similar.
 - ideally you could manage slurm or sge with an API.

I think there are two general recipes you can follow here. If you go the
"old school HPC route" then you would do something like the above. You
don't have a container cluster, you have standard job managers and tools
that communicate to them.  If you go the "container cluster" route then
what would be needed is to have orchestration defined for Singularity, and
even better integration with Kubernetes. Several have talked about this but
I don't see any code yet :) It's a bit of a catch 22, because you could
just use Docker for the second, but wait you can't because Docker + HPC =3D
death. You could just use HPC technology for the first but wait you can't,
because that's not going to plug in easily in environments outside of HPC.
So your choices are to help make Singularity more enterprise/cloudy to
integrate into container clusters, or to imagine if a more HPC-centric
method could be adopted in different environments. I think generally
connecting protected clusters to the outside world is a hard problem, take
a look at Agave --> https://github.com/agaveapi for inspiration.

Best,

Vanessa




On Sun, Nov 26, 2017 at 8:48 AM, Dejan =C5=A0tepec <stepec...@gmail.com>
wrote:

> Frontend server probably using Flask yes will authenticate the user using
> calls to existing backend so this part is taken care of. After sucessfull
> authentication I would like to send task to the task queue (celery) and o=
ne
> of the predefinied and started gpu workers that would run on separate nod=
es
> using Singularity would take the job, execute it and send the results bac=
k
> to the frontend server which would deliver result back to the backend. So
> my only concern was if networking in Singularity supports this kind of id=
ea
> ( running container as a Celery worker - tcp connection to some remote
> queue, that maybe will also run as a Singularity container). Basically is
> this possible?
>
> 26. nov. 2017 4:32 pop. je oseba "v" <vso...@gmail.com> napisala:
>
> oh that is super cool! If the celery workers are part of the web service,
>> this is a reasonable approach I think. I would use a standard (front
>> server) set up with some application (e.g., django or flask driven if yo=
u
>> are using Python) controlling / set up with a queue, and instead of havi=
ng
>> the job queue living with the frontend server part, I would have one asy=
nc
>> task that has the job to assess metadata (eg, is this a user of cluster =
X?
>> how much memory and time does it need?) to send it to your infrastructur=
e
>> queue (a different queue!) to first pass through authentication,
>> authorization, etc. Actually, you could probably also do this with an
>> internal API. I've never tried, but it seems like it would be challengin=
g
>> to require the celery connected to the web application to actually contr=
ol
>> the nodes. If you get in some situation of wanting to add another set of
>> (kind of different or external nodes) it would be hard to do. If each is
>> sort of modular (meaning the celery workers have an authenticated genera=
l
>> message they can send anywhere, to multiple kinds of nodes) that seems l=
ike
>> a good approach.
>>
>> On Sun, Nov 26, 2017 at 7:26 AM, Dejan =C5=A0tepec <stepec...@gmail.com>
>> wrote:
>>
>>> The whole thing will be part of a bigger web service so this additional
>>> image processing service will get requests from some backend infrastruc=
ture
>>> and this service besides compute nodes will consist also from a server
>>> (master) that will accept remote requests (e.g. web sockets) and will b=
e
>>> pushing work to a queue to Celery workers. Probably Celery is not
>>> absolutely needed but we want the service to be portable not used only =
on
>>> HPCs but some other cluster using e.g. Kubernetes and Docker etc.
>>>
>>> 26. nov. 2017 4:17 pop. je oseba "v" <vso...@gmail.com> napisala:
>>>
>>> If management of resources (nodes) is in order, I think a proper job
>>>> manager might be better fit for this job. Celery (from how I've used i=
t) is
>>>> more appropriate for a situation like a web application where you want=
 the
>>>> server to have a job queue, and put tasks in it to run when there is f=
ree
>>>> compute time (and to run async). They are similar because a "master" n=
ode
>>>> maps to the broker, and the "slaves" map to the workers. Also in my
>>>> experience the workers are on and ready, which would translate to havi=
ng
>>>> multiple container instances running and listening for tasks. Is there=
 a
>>>> reason you have preference for celery instead of traditional SLURM / S=
GE /
>>>> other? I think if you really wanted to do this fully it would be most
>>>> logical to add an actual supporting plugin for singularity workers to
>>>> rabbitmq:
>>>>
>>>> https://pubs.vmware.com/vfabric5/index.jsp#com.vmware.vfabri
>>>> c.rabbitmq.2.4/plugin-development.html
>>>>
>>>> Or something similar with celery. Keep us in the loop!
>>>>
>>>> On Sun, Nov 26, 2017 at 12:50 AM, Dejan =C5=A0tepec <
>>>> stepec...@gmail.com> wrote:
>>>>
>>>>> I intented to use multiple instances of separete nodes because of
>>>>> heavy use of GPUs. I guess that for such usage there would be better =
to
>>>>> make workers completely independent as separate instances of containe=
rs.
>>>>> The only thing that I wasn't sure of is the networking part in Singul=
arity,
>>>>> meaning if we can connect to a remote queue to get a job.
>>>>>
>>>>> 26. nov. 2017 3:07 dop. je oseba "v" <vso...@gmail.com> napisala:
>>>>>
>>>>> This is a cool use case!
>>>>>>
>>>>>> So I'm guessing the image processing app is probably in python? And
>>>>>> you have python tasks defined for it? The broker is a remote queue
>>>>>> (RabbitMQ) that would utilize the workers.
>>>>>>
>>>>>> Is there a reason to have multiple instances for many workers? I've
>>>>>> tried both, and usually the solution I prefer is to start a single
>>>>>> container with concurrency (meaning multiple workers). By default th=
e call
>>>>>> to start the worker with celery will do the number of cores availabl=
e, but
>>>>>> you can also set it to be something different (eg celery -A myprojec=
t
>>>>>> worker --concurrency=3D10...). For Singularity you would want to hav=
e your
>>>>>> image, and then have a startscript for it, and have the startscript =
be this
>>>>>> celery command to start up the (concurrent) workers.
>>>>>>
>>>>>> I would start out doing the following:
>>>>>>
>>>>>>  - create a singularity image that has a startscript with your
>>>>>> command to start the workers
>>>>>>  - start an instance
>>>>>>  - set up your RabbitMQ and test sending jobs to it.
>>>>>>  - report back!
>>>>>>
>>>>>> Best,
>>>>>>
>>>>>> Vanessa
>>>>>>
>>>>>> On Sat, Nov 25, 2017 at 5:10 PM, Dejan =C5=A0tepec <
>>>>>> stepec...@gmail.com> wrote:
>>>>>>
>>>>>>> Hi all!
>>>>>>>
>>>>>>> As a new user of a Singularity I have a question about a use case. =
I
>>>>>>> intend to package an image processing app in a Singularity containe=
r but
>>>>>>> have a question about communication between separate nodes for exam=
ple
>>>>>>> using RabitMQ or to access to some remote queue. I intend to packag=
e these
>>>>>>> worker nodes as a Celery <http://www.celeryproject.org/> workers so
>>>>>>> I need to know if we can connect to a remote RabbitMQ queue from th=
e
>>>>>>> Singularity container to get a new batch of data to be processed fr=
om a
>>>>>>> remote queue. I intend to use Singularity as this nodes are computa=
tionally
>>>>>>> intensive and will be placed at some HPC with SLURM workload manage=
r
>>>>>>> installed of course having no sudo access.
>>>>>>>
>>>>>>> Best regards,
>>>>>>>
>>>>>>> Dejan
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Vanessa Villamia Sochat
>>>>>> Stanford University '16
>>>>>> (603) 321-0676
>>>>>>
>>>>>> --
>>>>>> You received this message because you are subscribed to the Google
>>>>>> Groups "singularity" group.
>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>> send an email to singu...@lbl.gov.
>>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, sen=
d
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Vanessa Villamia Sochat
>>>> Stanford University '16
>>>> (603) 321-0676
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>>
>>
>> --
>> Vanessa Villamia Sochat
>> Stanford University '16
>> (603) 321-0676
>>
>> --
>> You received this message because you are subscribed to the Google Group=
s
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n
>> email to singu...@lbl.gov.
>>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>



--=20
Vanessa Villamia Sochat
Stanford University '16
(603) 321-0676

--001a113529a26599e6055ee61493
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">As far as I know not yet, it would need to be possible to =
define networking between containers like Docker does --&gt;=C2=A0<a href=
=3D"https://docs.docker.com/engine/userguide/networking/">https://docs.dock=
er.com/engine/userguide/networking/</a> and then have an orchestrator to ma=
p between host and other containers. What you could try is starting contain=
er instances that use a (shared) network (localhost) and maybe have them op=
erate at different ports?<div><br></div><div>Just curious - what is your st=
rategy for the layer between the web application and the GPU servers? These=
 kind of connections (to a shared resource with sensitive data and what not=
) historically can make some nervous :P</div><div><br></div><div>I think wh=
at you are saying is:</div><div><br></div><div>=C2=A01. user requests task =
on front end</div><div>=C2=A02. front end handles authentication and author=
ization</div><div>=C2=A03. front end submits job to celery</div><div>=C2=A0=
4. celery task is a Singularity container running on GPU, and since worker =
=3D=3D container, it requires networking</div><div><br></div><div>and what =
I&#39;m suggesting is to separate the front / back servers a bit more:</div=
><div><br></div><div><div>=C2=A01. user requests task on front end</div><di=
v>=C2=A02. front end handles authentication and authorization</div><div>=C2=
=A03. front end submits job to celery (still frontend)</div><div>=C2=A04. c=
elery worker(still frontend) is a process that finishes configuration of jo=
b (memory? time? cluster? queue type?) and sends job to a back end queue (s=
lurm, sge)</div><div>=C2=A05. the slurm/sge queues are optimized for this s=
ort of thing, so you just load the singularity module, run the job, and sen=
d a signal back to the front end queue.</div></div><div><br></div><div>So a=
 few notes on the above:</div><div>=C2=A0- there is flexibility (step 4) to=
 have different kinds of queues in different locations. The front end worke=
r is the manager of where things go.</div><div>=C2=A0- the singularity cont=
ainer is not required to have a network, or be constantly running.</div><di=
v>=C2=A0- the main server (the same celery workers) also need a means to re=
ceive messages of something finishing to update the server, this could be a=
 POST or similar.</div><div>=C2=A0- ideally you could manage slurm or sge w=
ith an API.</div><div><br></div><div>I think there are two general recipes =
you can follow here. If you go the &quot;old school HPC route&quot; then yo=
u would do something like the above. You don&#39;t have a container cluster=
, you have standard job managers and tools that communicate to them.=C2=A0 =
If you go the &quot;container cluster&quot; route then what would be needed=
 is to have orchestration defined for Singularity, and even better integrat=
ion with Kubernetes. Several have talked about this but I don&#39;t see any=
 code yet :) It&#39;s a bit of a catch 22, because you could just use Docke=
r for the second, but wait you can&#39;t because Docker + HPC =3D death. Yo=
u could just use HPC technology for the first but wait you can&#39;t, becau=
se that&#39;s not going to plug in easily in environments outside of HPC. S=
o your choices are to help make Singularity more enterprise/cloudy to integ=
rate into container clusters, or to imagine if a more HPC-centric method co=
uld be adopted in different environments. I think generally connecting prot=
ected clusters to the outside world is a hard problem, take a look at Agave=
 --&gt;=C2=A0<a href=3D"https://github.com/agaveapi">https://github.com/aga=
veapi</a> for inspiration.</div><div><br></div><div>Best,</div><div><br></d=
iv><div>Vanessa</div><div><br></div><div><br></div><div><br></div></div><di=
v class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, Nov 26, 2017=
 at 8:48 AM, Dejan =C5=A0tepec <span dir=3D"ltr">&lt;<a href=3D"mailto:step=
ec...@gmail.com" target=3D"_blank">stepec...@gmail.com</a>&gt;</span> wrote=
:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-le=
ft:1px #ccc solid;padding-left:1ex"><div dir=3D"auto">Frontend server proba=
bly using Flask yes will authenticate the user using calls to existing back=
end so this part is taken care of. After sucessfull authentication I would =
like to send task to the task queue (celery) and one of the predefinied and=
 started gpu workers that would run on separate nodes using Singularity wou=
ld take the job, execute it and send the results back to the frontend serve=
r which would deliver result back to the backend. So my only concern was if=
 networking in Singularity supports this kind of idea ( running container a=
s a Celery worker - tcp connection to some remote queue, that maybe will al=
so run as a Singularity container). Basically is this possible?</div><div c=
lass=3D"gmail_extra"><br><div class=3D"gmail_quote">26. nov. 2017 4:32 pop.=
 je oseba &quot;v&quot; &lt;<a href=3D"mailto:vso...@gmail.com" target=3D"_=
blank">vso...@gmail.com</a>&gt; napisala:<div><div class=3D"h5"><br type=3D=
"attribution"><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;=
border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">oh that is su=
per cool! If the celery workers are part of the web service, this is a reas=
onable approach I think. I would use a standard (front server) set up with =
some application (e.g., django or flask driven if you are using Python) con=
trolling / set up with a queue, and instead of having the job queue living =
with the frontend server part, I would have one async task that has the job=
 to assess metadata (eg, is this a user of cluster X? how much memory and t=
ime does it need?) to send it to your infrastructure queue (a different que=
ue!) to first pass through authentication, authorization, etc. Actually, yo=
u could probably also do this with an internal API. I&#39;ve never tried, b=
ut it seems like it would be challenging to require the celery connected to=
 the web application to actually control the nodes. If you get in some situ=
ation of wanting to add another set of (kind of different or external nodes=
) it would be hard to do. If each is sort of modular (meaning the celery wo=
rkers have an authenticated general message they can send anywhere, to mult=
iple kinds of nodes) that seems like a good approach.</div><div class=3D"gm=
ail_extra"><br><div class=3D"gmail_quote">On Sun, Nov 26, 2017 at 7:26 AM, =
Dejan =C5=A0tepec <span dir=3D"ltr">&lt;<a href=3D"mailto:stepec...@gmail.c=
om" target=3D"_blank">stepec...@gmail.com</a>&gt;</span> wrote:<br><blockqu=
ote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc s=
olid;padding-left:1ex"><div dir=3D"auto">The whole thing will be part of a =
bigger web service so this additional image processing service will get req=
uests from some backend infrastructure and this service besides compute nod=
es will consist also from a server (master) that will accept remote request=
s (e.g. web sockets) and will be pushing work to a queue to Celery workers.=
 Probably Celery is not absolutely needed but we want the service to be por=
table not used only on HPCs but some other cluster using e.g. Kubernetes an=
d Docker etc.</div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote=
">26. nov. 2017 4:17 pop. je oseba &quot;v&quot; &lt;<a href=3D"mailto:vso.=
..@gmail.com" target=3D"_blank">vso...@gmail.com</a>&gt; napisala:<div><div=
 class=3D"m_-8300768368191560607m_1897365208364906938h5"><br type=3D"attrib=
ution"><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-=
left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">If management of res=
ources (nodes) is in order, I think a proper job manager might be better fi=
t for this job. Celery (from how I&#39;ve used it) is more appropriate for =
a situation like a web application where you want the server to have a job =
queue, and put tasks in it to run when there is free compute time (and to r=
un async). They are similar because a &quot;master&quot; node maps to the b=
roker, and the &quot;slaves&quot; map to the workers. Also in my experience=
 the workers are on and ready, which would translate to having multiple con=
tainer instances running and listening for tasks. Is there a reason you hav=
e preference for celery instead of traditional SLURM / SGE / other? I think=
 if you really wanted to do this fully it would be most logical to add an a=
ctual supporting plugin for singularity workers to rabbitmq:<div><br></div>=
<div><a href=3D"https://pubs.vmware.com/vfabric5/index.jsp#com.vmware.vfabr=
ic.rabbitmq.2.4/plugin-development.html" target=3D"_blank">https://pubs.vmw=
are.com/vfabri<wbr>c5/index.jsp#com.vmware.vfabri<wbr>c.rabbitmq.2.4/plugin=
-developm<wbr>ent.html</a><br></div><div><br></div><div>Or something simila=
r with celery. Keep us in the loop!</div></div><div class=3D"gmail_extra"><=
br><div class=3D"gmail_quote">On Sun, Nov 26, 2017 at 12:50 AM, Dejan =C5=
=A0tepec <span dir=3D"ltr">&lt;<a href=3D"mailto:stepec...@gmail.com" targe=
t=3D"_blank">stepec...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=
=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padd=
ing-left:1ex"><div dir=3D"auto">I intented to use multiple instances of sep=
arete nodes because of heavy use of GPUs. I guess that for such usage there=
 would be better to make workers completely independent as separate instanc=
es of containers. The only thing that I wasn&#39;t sure of is the networkin=
g part in Singularity, meaning if we can connect to a remote queue to get a=
 job.</div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">26. no=
v. 2017 3:07 dop. je oseba &quot;v&quot; &lt;<a href=3D"mailto:vso...@gmail=
.com" target=3D"_blank">vso...@gmail.com</a>&gt; napisala:<div><div class=
=3D"m_-8300768368191560607m_1897365208364906938m_3679851968510581478m_50937=
44772853157683h5"><br type=3D"attribution"><blockquote class=3D"gmail_quote=
" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><=
div dir=3D"ltr">This is a cool use case!<div><br></div><div>So I&#39;m gues=
sing the image processing app is probably in python? And you have python ta=
sks defined for it? The broker is a remote queue (RabbitMQ) that would util=
ize the workers.</div><div><br></div><div>Is there a reason to have multipl=
e instances for many workers? I&#39;ve tried both, and usually the solution=
 I prefer is to start a single container with concurrency (meaning multiple=
 workers). By default the call to start the worker with celery will do the =
number of cores available, but you can also set it to be something differen=
t (eg celery -A myproject worker --concurrency=3D10...). For Singularity yo=
u would want to have your image, and then have a startscript for it, and ha=
ve the startscript be this celery command to start up the (concurrent) work=
ers.</div><div><br></div><div>I would start out doing the following:</div><=
div><br></div><div>=C2=A0- create a singularity image that has a startscrip=
t with your command to start the workers</div><div>=C2=A0- start an instanc=
e</div><div>=C2=A0- set up your RabbitMQ and test sending jobs to it.</div>=
<div>=C2=A0- report back!</div><div><br></div><div>Best,</div><div><br></di=
v><div>Vanessa</div></div><div class=3D"gmail_extra"><br><div class=3D"gmai=
l_quote">On Sat, Nov 25, 2017 at 5:10 PM, Dejan =C5=A0tepec <span dir=3D"lt=
r">&lt;<a href=3D"mailto:stepec...@gmail.com" target=3D"_blank">stepec...@g=
mail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=
=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=
=3D"ltr">Hi all!<div><br></div><div>As a new user of a Singularity I have a=
 question about a use case. I intend to package an image processing app in =
a Singularity container but have a question about communication between sep=
arate nodes for example using RabitMQ or to access to some remote queue. I =
intend to package these worker nodes as a <a href=3D"http://www.celeryproje=
ct.org/" target=3D"_blank">Celery</a> workers so I need to know if we can c=
onnect to a remote RabbitMQ queue from the Singularity container to get a n=
ew batch of data to be processed from a remote queue. I intend to use Singu=
larity as this nodes are computationally intensive and will be placed at so=
me HPC with SLURM workload manager installed of course having no sudo acces=
s.</div><div><br></div><div>Best regards,</div><div><br></div><div>Dejan</d=
iv></div><span class=3D"m_-8300768368191560607m_1897365208364906938m_367985=
1968510581478m_5093744772853157683m_4020543116012023696m_378002040465260588=
6HOEnZb"><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</font></span></blockquote></div><br><br clear=3D"all"><div><br></div>-- <b=
r><div class=3D"m_-8300768368191560607m_1897365208364906938m_36798519685105=
81478m_5093744772853157683m_4020543116012023696m_3780020404652605886gmail_s=
ignature" data-smartmail=3D"gmail_signature">Vanessa Villamia Sochat<br>Sta=
nford University &#39;16<br><div><div><div><a href=3D"tel:(603)%20321-0676"=
 value=3D"+16033210676" target=3D"_blank">(603) 321-0676</a></div></div></d=
iv></div>
</div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div></div></div></div><div class=3D"m_-8300768368191560607m_=
1897365208364906938m_3679851968510581478m_5093744772853157683HOEnZb"><div c=
lass=3D"m_-8300768368191560607m_1897365208364906938m_3679851968510581478m_5=
093744772853157683h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div class=3D"m_-8300768368191560607m_1897365208364906938m_3679851968510581=
478m_5093744772853157683gmail_signature" data-smartmail=3D"gmail_signature"=
>Vanessa Villamia Sochat<br>Stanford University &#39;16<br><div><div><div><=
a href=3D"tel:(603)%20321-0676" value=3D"+16033210676" target=3D"_blank">(6=
03) 321-0676</a></div></div></div></div>
</div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div></div></div></div><div class=3D"m_-8300768368191560607m_=
1897365208364906938HOEnZb"><div class=3D"m_-8300768368191560607m_1897365208=
364906938h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div class=3D"m_-8300768368191560607m_1897365208364906938gmail_signature" d=
ata-smartmail=3D"gmail_signature">Vanessa Villamia Sochat<br>Stanford Unive=
rsity &#39;16<br><div><div><div><a href=3D"tel:(603)%20321-0676" value=3D"+=
16033210676" target=3D"_blank">(603) 321-0676</a></div></div></div></div>
</div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div></div></div></div><div class=3D"HOEnZb"><div class=3D"h5=
">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div class=3D"gmail_signature" data-smartmail=3D"gmail_signature">Vanessa V=
illamia Sochat<br>Stanford University &#39;16<br><div><div><div>(603) 321-0=
676</div></div></div></div>
</div>

--001a113529a26599e6055ee61493--

X-Received: by 10.66.236.99 with SMTP id ut3mr22297198pac.36.1465418938999;
        Wed, 08 Jun 2016 13:48:58 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.36.60.150 with SMTP id m144ls245342ita.20.gmail; Wed, 08 Jun
 2016 13:48:58 -0700 (PDT)
X-Received: by 10.66.183.168 with SMTP id en8mr7739276pac.64.1465418938392;
        Wed, 08 Jun 2016 13:48:58 -0700 (PDT)
Return-Path: <goh...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTPS id rz5si3157895pab.104.2016.06.08.13.48.58
        for <singu...@lbl.gov>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Wed, 08 Jun 2016 13:48:58 -0700 (PDT)
Received-SPF: pass (google.com: domain of goh...@gmail.com designates 209.85.223.173 as permitted sender) client-ip=209.85.223.173;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of goh...@gmail.com designates 209.85.223.173 as permitted sender) smtp.mailfrom=goh...@gmail.com
X-Ironport-SBRS: 2.6
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2FeAgAahFhXfq3fVdFehBR9BoM2on4HAQEBBoEPT4F9kiE+BBcBBoV1AoE+BzsRAQEBAQEBAQMPAQEJDQkJIS+COjkKBiwBAQEBAQEBAQEBAQEBAQEaAisTEgIZAQEBAwESCAkdAQ0OHgMBCwYDAgsNKgICIQEBDgMBBQEcDgcEARwEAYdyAQMPCAWPUI9CgTE+MYs7gWqCWAWHdAoZJw1Sgy0BCgEBAQEaAgYQhU+FFYJDgU8RAYMdglkFh3wBhx6EIIRgNIYDhimBeoI3jGiHdYYtEh6BDw8lghoNHIFNOjIHiEQECxeBHgEBAQ
X-IronPort-AV: E=Sophos;i="5.26,441,1459839600"; 
   d="scan'208,217";a="26499360"
Received: from mail-io0-f173.google.com ([209.85.223.173])
  by fe3.lbl.gov with ESMTP; 08 Jun 2016 13:48:54 -0700
Received: by mail-io0-f173.google.com with SMTP id m62so20592311iof.0
        for <singu...@lbl.gov>; Wed, 08 Jun 2016 13:48:54 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=rZtx6EJtLIy5LmFZhZ1R/FKqXNaWCkgCPuDeO6puq/s=;
        b=lVoWta+ecaW1aUzxp0cdJmnR85+mHGGWUhiPS3VJ50Z6p7hfDqhJckZAb73I1W3CTD
         MCedDVKHUC2yTBlVFn/yeUPWz0yqyMj38pJnk0fu4WEhkuKYIEIAyfGoK9tYu1duTHuN
         17EVMeG5sVSPZtp1HKmA5LqAXVMuwbwo76kSH7WVKwGji8PgGVTcKPlXYLq1jRaqRSML
         5fpoz+3PneMSDKZ3xlIl/O/dKzco3X0jyow7K6jqOwEasfMDdkQPmW5+jKSEg6ZHFJXS
         CFEnmJsLLs8aVCWRYc8E4N3gt/pEV8AHtF3H27MPkIvcbAc7HJrE7c3uR+P3MKerwak/
         0I0A==
X-Gm-Message-State: ALyK8tJsxu3Ifi6Mo9aEHkYqYo3NLhhiY4wLtE74n4hkFdbaJWRGiNX3w5w+T2E2KiqG8SXFjq070ZDKbLjhyw==
X-Received: by 10.107.169.67 with SMTP id s64mr11282198ioe.19.1465418934060;
 Wed, 08 Jun 2016 13:48:54 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.50.227.142 with HTTP; Wed, 8 Jun 2016 13:48:53 -0700 (PDT)
In-Reply-To: <CAN7etTz3V1eSH2r7Yd9y0MFFt24H2vuAB9FcViKbDAsdxtt9Pg@mail.gmail.com>
References: <CA+zw9q3gSaqZgo3tzOXyn5kwfeUS-LdCuyTnmWyPgfVjmxGBqA@mail.gmail.com>
 <CAN7etTz3V1eSH2r7Yd9y0MFFt24H2vuAB9FcViKbDAsdxtt9Pg@mail.gmail.com>
From: yiannis georgiou <goh...@gmail.com>
Date: Wed, 8 Jun 2016 22:48:53 +0200
Message-ID: <CA+zw9q0zaF0ajbLuPeT0H-Ag5t-ZfV9ux94hm+9m6XQ_JEQ7LA@mail.gmail.com>
Subject: Re: [Singularity] Singularity with Slurm and PMIx
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=001a11421a440343c60534ca6f29

--001a11421a440343c60534ca6f29
Content-Type: text/plain; charset=UTF-8

Hi Greg,

bullseye!!! it worked for me like this:

[georgioy@rio11 ~]$ salloc -n4 -N2
[georgioy@rio11 ~]$ export SINGULARITY_NO_NAMESPACE_PID=1
[georgioy@rio11 ~]$ srun --mpi=pmix -n 4 -N2
/usr/local/singularity_v2/bin/singularity exec /tmp/ubuntu_v4.img
/home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
Hello world from processor rio13, rank 2 out of 4 processors
Hello world from processor rio13, rank 3 out of 4 processors
Hello world from processor rio12, rank 0 out of 4 processors
Hello world from processor rio12, rank 1 out of 4 processors
ERROR: Could not clear loop device

Any idea how I can correct the "ERROR: Could not clear loop device"
appearing at the end of the execution?
And when you have a moment could you explain me how this magic environment
variable make it work! I'm not sure I got it.

One more question, I've noticed that there have been some changes in the
latest OpenMPI to improve performance when using singularity. Are they done
for PMIx or for all PMI versions?

Thanks a lot!
Yiannis


On Wed, Jun 8, 2016 at 9:16 PM, Gregory M. Kurtzer <gmku...@lbl.gov>
wrote:

> Hi Yiannis,
>
> I have a quick thing to test... The address not mapped error seems
> consistent with something else that I've seen when testing OpenMPI with
> shared memory and the NEWPID namespace. Try to disable the NEWPID namespace
> by exporting this environment variable:
>
> SINGULARITY_NO_NAMESPACE_PID=1
>
> Now you will need to export it in a place where all Singularity contexts
> will see it, maybe something like this:
>
> $ srun --mpi=pmix -n 4 -N 2 SINGULARITY_NO_NAMESPACE_PID=1 singularity
> exec /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>
> There is an OpenMPI plugin which sets this automatically in the current
> codebase, but I'm not sure how it will come into play in this usage
> scenario.
>
> Let me know how that works for ya!
>
> Thanks,
>
> Greg
>
> On Wed, Jun 8, 2016 at 12:09 PM, yiannis georgiou <goh...@gmail.com>
> wrote:
>
>> Hello,
>>
>> I'm trying to execute an MPI application from within a singularity image
>> through Slurm and pmix using the following command
>>
>> srun --mpi=pmix -n 4 -N 2 singularity exec /tmp/ubuntu_v4.img
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>>
>> The slurmstepd process is spawned on the compute node and it seems to
>> have launched correctly the application from what we see on one of the
>> compute nodes:
>>
>> ========================================
>> [root@rio12 ~]# ps -aux
>> root     35147  0.1  0.0 562284  4016 ?        Sl   20:06   0:00
>> slurmstepd: [83.0]
>> georgioy 35158  0.2  0.0  10428   896 ?        S    20:06   0:00
>> Singularity: namespace
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>> root     35162  0.0  0.0      0     0 ?        S<   20:06   0:00 [loop0]
>> georgioy 35163  0.0  0.0  10428   400 ?        S    20:06   0:00
>> Singularity: exec
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>> root     35164  0.0  0.0      0     0 ?        S    20:06   0:00
>> [jbd2/loop0-8]
>> root     35165  0.0  0.0      0     0 ?        S    20:06   0:00
>> [ext4-dio-unwrit]
>> georgioy 35166  102  0.0 285476 14828 ?        RLl  20:06   0:12
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>> ==========================================
>>
>> and I see the pmix related functions starting correctly in the slurmd log
>> files :
>>
>> ========================================
>>
>> [2016-06-08T20:12:08.004] [86.0] debug:  (null) [0] mpi_pmix.c:90
>> [p_mpi_hook_slurmstepd_prefork] mpi/pmix: start
>> [2016-06-08T20:12:08.004] [86.0] debug:  mpi/pmix: setup sockets
>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_client.c:78
>> [errhandler_reg_callbk] mpi/pmix: Error handler registration callback is
>> called with status=0, ref=0
>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_client.c:581
>> [pmixp_libpmix_job_set] mpi/pmix: task initialization
>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:220
>> [_agent_thread] mpi/pmix: Start agent thread
>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:313
>> [pmixp_agent_start] mpi/pmix: agent thread started: tid = 139672278615808
>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:84
>> [_conn_readable] mpi/pmix: fd = 9
>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:84
>> [_conn_readable] mpi/pmix: fd = 19
>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:256
>> [_pmix_timer_thread] mpi/pmix: Start timer thread
>> [2016-06-08T20:12:08.005] [86.0] debug:  rio12 [0] pmixp_agent.c:335
>> [pmixp_agent_start] mpi/pmix: timer thread started: tid = 139672277563136
>>
>> =======================================
>>
>> However the application is never actually started and the srun fails
>> completely with the following output:
>>
>> =========================================
>> [georgioy@rio11 ~]$ srun --mpi=pmix -n 4 -N 2 singularity exec
>> /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello
>> [rio12:00001] *** Process received signal ***
>> [rio12:00001] Signal: Segmentation fault (11)
>> [rio12:00001] Signal code: Address not mapped (1)
>> [rio12:00001] Failing at address: 0x7fbd937e6010
>> [rio12:00001] [ 0] [rio12:00001] *** Process received signal ***
>> /lib/x86_64-linux-gnu/libpthread.so.0(+0x113d0)[0x7f26aeb233d0]
>> [rio12:00001] [ 1]
>> /usr/local/lib/libmca_common_sm.so.0(+0x1035)[0x7f269f964035]
>> [rio12:00001] [ 2]
>> /usr/local/lib/libmca_common_sm.so.0(common_sm_mpool_create+0xa3)[0x7f269f964583]
>> [rio12:00001] [ 3]
>> /usr/local/lib/openmpi/mca_btl_sm.so(mca_btl_sm_add_procs+0x5f1)[0x7f269fb68771]
>> [rio12:00001] [ 4]
>> /usr/local/lib/openmpi/mca_bml_r2.so(+0x2be7)[0x7f26a451fbe7]
>> [rio12:00001] [ 5]
>> /usr/local/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_add_procs+0xd2)[0x7f269ef35662]
>> [rio12:00001] [ 6]
>> /usr/local/lib/libmpi.so.0(ompi_mpi_init+0xa51)[0x7f26aed75d31]
>> [rio12:00001] [ 7]
>> /usr/local/lib/libmpi.so.0(MPI_Init+0xb9)[0x7f26aed9bdb9]
>> [rio12:00001] [ 8]
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x4007ec]
>> [rio12:00001] [ 9]
>> /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f26ae769830]
>> [rio12:00001] Signal: Segmentation fault (11)
>> [rio12:00001] Signal code: Address not mapped (1)
>> [rio12:00001] Failing at address: 0x7fbd937e6010
>> [rio12:00001] [10]
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x400709]
>> [rio12:00001] *** End of error message ***
>> [rio12:00001] [ 0]
>> /lib/x86_64-linux-gnu/libpthread.so.0(+0x113d0)[0x7f3f89c063d0]
>> [rio12:00001] [ 1]
>> /usr/local/lib/libmca_common_sm.so.0(+0x1035)[0x7f3f7eb1d035]
>> [rio12:00001] [ 2]
>> /usr/local/lib/libmca_common_sm.so.0(common_sm_mpool_create+0xa3)[0x7f3f7eb1d583]
>> [rio12:00001] [ 3]
>> /usr/local/lib/openmpi/mca_btl_sm.so(mca_btl_sm_add_procs+0x5f1)[0x7f3f7ed21771]
>> [rio12:00001] [ 4]
>> /usr/local/lib/openmpi/mca_bml_r2.so(+0x2be7)[0x7f3f7f5f3be7]
>> [rio12:00001] [ 5]
>> /usr/local/lib/openmpi/mca_pml_ob1.so(mca_pml_ob1_add_procs+0xd2)[0x7f3f7e0ee662]
>> [rio12:00001] [ 6]
>> /usr/local/lib/libmpi.so.0(ompi_mpi_init+0xa51)[0x7f3f89e58d31]
>> [rio12:00001] [ 7]
>> /usr/local/lib/libmpi.so.0(MPI_Init+0xb9)[0x7f3f89e7edb9]
>> [rio12:00001] [ 8]
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x4007ec]
>> [rio12:00001] [ 9]
>> /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x7f3f8984c830]
>> [rio12:00001] [10]
>> /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x400709]
>> [rio12:00001] *** End of error message ***
>> slurmstepd: error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix:
>> ERROR: Error handler invoked: status = -25, nranges = 0: Success (0)
>> srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
>> slurmstepd: error: *** STEP 86.0 ON rio12 CANCELLED AT
>> 2016-06-08T20:12:08 ***
>> slurmstepd: error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix:
>> ERROR: Error handler invoked: status = -25, nranges = 0: Success (0)
>> slurmstepd: error: rio13 [1] pmixp_client.c:241 [errhandler] mpi/pmix:
>> ERROR: Error handler invoked: status = -25, nranges = 0: Success (0)
>> slurmstepd: error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix:
>> ERROR: Error handler invoked: status = -25, nranges = 0: Success (0)
>> srun: error: rio12: tasks 0-2: Killed
>> srun: error: rio13: task 3: Killed
>>
>> ============================================
>>
>> the results I get when launching with mpirun instead of srun are more or
>> less the same.
>>
>> From my understanding, the orted process, or in my case slurmstepd
>> process that launches the singularity container
>> and the MPI application, enables the communication of MPI libraries and
>> orted (or slurmstepd) through PMI (in my case here PMIx).
>> So I suppose the problem I see should be related with the mapping of PMI
>> from the container towards the orted or slurmstepd.
>>
>> What do you think?
>>
>> To give some more details, my singularity container has OpenMPI and PMIx
>> installed but not Slurm. I don't think that Slurm needs to reside within
>> the container in that context.
>> But I wasn't sure if OpenMPI and PMIx are needed both inside and outside
>> of the container.
>> So, I've tried using the exact same version of PMIx and OpenMPI in and
>> out of the container and the problem still persists.
>> The experiments have been done using RedHat hosts with CentOS or Ubuntu
>> singularity containers and the latest github versions of slurm, OpenMPI,
>> PMIx and singularity.
>>
>> By the way, do you have any MPI example for singularity v2?
>> Because the MPI example that you show here :
>> http://singularity.lbl.gov/#hpc
>>
>> is actually done using singularity v1, no?
>> In my understanding with singularity v2 we actually build a complete
>> image with OS not just the application with its libraries. Is this correct?
>>
>> Sorry for the long email and
>> thanks a lot for any extra info you can provide regarding singularity v2
>> and MPI.
>>
>> Best Regards,
>> Yiannis
>>
>> --
>> You received this message because you are subscribed to the Google Groups
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to singu...@lbl.gov.
>>
>
>
>
> --
> Gregory M. Kurtzer
> High Performance Computing Services (HPCS)
> University of California
> Lawrence Berkeley National Laboratory
> One Cyclotron Road, Berkeley, CA 94720
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a11421a440343c60534ca6f29
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div><div><div><div><div><div>Hi Greg,<br><br></div>bullse=
ye!!! it worked for me like this:<br><br>[georgioy@rio11 ~]$ salloc -n4 -N2=
<br>[georgioy@rio11 ~]$ export SINGULARITY_NO_NAMESPACE_PID=3D1<br>[georgio=
y@rio11 ~]$ srun --mpi=3Dpmix -n 4 -N2 /usr/local/singularity_v2/bin/singul=
arity exec /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hell=
o<br>Hello world from processor rio13, rank 2 out of 4 processors<br>Hello =
world from processor rio13, rank 3 out of 4 processors<br>Hello world from =
processor rio12, rank 0 out of 4 processors<br>Hello world from processor r=
io12, rank 1 out of 4 processors<br>ERROR: Could not clear loop device<br><=
br></div>Any idea how I can correct the &quot;ERROR: Could not clear loop d=
evice&quot; appearing at the end of the execution?<br></div>And when you ha=
ve a moment could you explain me how this magic environment variable make i=
t work! I&#39;m not sure I got it.<br><br></div>One more question, I&#39;ve=
 noticed that there have been some changes in the latest OpenMPI to improve=
 performance when using singularity. Are they done for PMIx or for all PMI =
versions?<br><br></div>Thanks a lot!<br></div>Yiannis<br><div><div><div><di=
v><div><div><div><div><br></div></div></div></div></div></div></div></div><=
/div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Wed, Jun =
8, 2016 at 9:16 PM, Gregory M. Kurtzer <span dir=3D"ltr">&lt;<a href=3D"mai=
lto:gmku...@lbl.gov" target=3D"_blank">gmku...@lbl.gov</a>&gt;</span> wrote=
:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-le=
ft:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Yiannis,<div><br></=
div><div>I have a quick thing to test... The address not mapped error seems=
 consistent with something else that I&#39;ve seen when testing OpenMPI wit=
h shared memory and the NEWPID namespace. Try to disable the NEWPID namespa=
ce by exporting this environment variable:</div><div><br></div><div>SINGULA=
RITY_NO_NAMESPACE_PID=3D1<br></div><div><br></div><div>Now you will need to=
 export it in a place where all Singularity contexts will see it, maybe som=
ething like this:</div><div><br></div><div>$ srun --mpi=3Dpmix -n 4 -N 2 SI=
NGULARITY_NO_NAMESPACE_PID=3D1 singularity exec /tmp/ubuntu_v4.img /home_nf=
s/georgioy/BENCHS/mpi-openmp/mpi_hello</div><div><br></div><div>There is an=
 OpenMPI plugin which sets this automatically in the current codebase, but =
I&#39;m not sure how it will come into play in this usage scenario.</div><d=
iv><br></div><div>Let me know how that works for ya!</div><div><br></div><d=
iv>Thanks,</div><div><br></div><div>Greg</div></div><div class=3D"gmail_ext=
ra"><br><div class=3D"gmail_quote"><div><div class=3D"h5">On Wed, Jun 8, 20=
16 at 12:09 PM, yiannis georgiou <span dir=3D"ltr">&lt;<a href=3D"mailto:go=
h...@gmail.com" target=3D"_blank">goh...@gmail.com</a>&gt;</span> wrote:<br=
></div></div><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;b=
order-left:1px #ccc solid;padding-left:1ex"><div><div class=3D"h5"><div dir=
=3D"ltr"><div><div><div>Hello,<br><br></div>I&#39;m trying to execute an MP=
I application from within a singularity image through Slurm and pmix using =
the following command <br><br></div>srun --mpi=3Dpmix -n 4 -N 2 singularity=
 exec
 /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br><br><=
/div>The
 slurmstepd process is spawned on the compute node and it seems to have=20
launched correctly the application from what we see on one of the=20
compute nodes:<br><div><br>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br=
>[root@rio12 ~]# ps -aux<br>root=C2=A0=C2=A0=C2=A0=C2=A0 35147=C2=A0 0.1=C2=
=A0 0.0 562284=C2=A0 4016 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 Sl=C2=
=A0=C2=A0 20:06=C2=A0=C2=A0 0:00 slurmstepd: [83.0]=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0 <br>georgioy
 35158=C2=A0 0.2=C2=A0 0.0=C2=A0 10428=C2=A0=C2=A0 896 ?=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0 S=C2=A0=C2=A0=C2=A0 20:06=C2=A0=C2=A0 0:00 Singula=
rity:=20
namespace=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=20
/home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br>root=C2=A0=C2=A0=C2=A0=C2=
=A0 35162=C2=A0 0.0=C2=A0 0.0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 0=C2=A0=C2=A0=
=C2=A0=C2=A0 0 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 S&lt;=C2=A0=C2=
=A0 20:06=C2=A0=C2=A0 0:00 [loop0]<br>georgioy
 35163=C2=A0 0.0=C2=A0 0.0=C2=A0 10428=C2=A0=C2=A0 400 ?=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0 S=C2=A0=C2=A0=C2=A0 20:06=C2=A0=C2=A0 0:00 Singula=
rity:=20
exec=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=20
/home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br>root=C2=A0=C2=A0=C2=A0=C2=
=A0 35164=C2=A0 0.0=C2=A0 0.0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 0=C2=A0=C2=A0=
=C2=A0=C2=A0 0 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 S=C2=A0=C2=A0=C2=
=A0 20:06=C2=A0=C2=A0 0:00 [jbd2/loop0-8]<br>root=C2=A0=C2=A0=C2=A0=C2=A0 3=
5165=C2=A0 0.0=C2=A0 0.0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 0=C2=A0=C2=A0=C2=A0=
=C2=A0 0 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 S=C2=A0=C2=A0=C2=A0 20=
:06=C2=A0=C2=A0 0:00 [ext4-dio-unwrit]<br>georgioy 35166=C2=A0 102=C2=A0 0.=
0 285476 14828 ?=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 RLl=C2=A0 20:06=
=C2=A0=C2=A0 0:12 /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<br>=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br><br></div><div>and I see t=
he pmix related functions starting correctly in the slurmd log files :<br><=
br>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br><br>[2016-06-08T20:12:0=
8.004] [86.0] debug:=C2=A0 (null) [0] mpi_pmix.c:90 [p_mpi_hook_slurmstepd_=
prefork] mpi/pmix: start<br>[2016-06-08T20:12:08.004] [86.0] debug:=C2=A0 m=
pi/pmix: setup sockets<br>[2016-06-08T20:12:08.005]
 [86.0] debug:=C2=A0 rio12 [0] pmixp_client.c:78 [errhandler_reg_callbk]=20
mpi/pmix: Error handler registration callback is called with status=3D0,=20
ref=3D0<br>[2016-06-08T20:12:08.005] [86.0] debug:=C2=A0 rio12 [0] pmixp_cl=
ient.c:581 [pmixp_libpmix_job_set] mpi/pmix: task initialization<br>[2016-0=
6-08T20:12:08.005] [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:220 [_agent_=
thread] mpi/pmix: Start agent thread<br>[2016-06-08T20:12:08.005]
 [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:313 [pmixp_agent_start]=20
mpi/pmix: agent thread started: tid =3D 139672278615808<br>[2016-06-08T20:1=
2:08.005] [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:84 [_conn_readable] m=
pi/pmix: fd =3D 9<br>[2016-06-08T20:12:08.005] [86.0] debug:=C2=A0 rio12 [0=
] pmixp_agent.c:84 [_conn_readable] mpi/pmix: fd =3D 19<br>[2016-06-08T20:1=
2:08.005] [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:256 [_pmix_timer_thre=
ad] mpi/pmix: Start timer thread<br>[2016-06-08T20:12:08.005]
 [86.0] debug:=C2=A0 rio12 [0] pmixp_agent.c:335 [pmixp_agent_start]=20
mpi/pmix: timer thread started: tid =3D 139672277563136<br><br>=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br></div><div><div><br></div><div>However th=
e application is never actually started and the srun fails completely with =
the following output:<br></div><div><br>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D<br>[georgioy@rio11 ~]$ srun --mpi=3Dpmix -n 4 -N 2 singular=
ity exec /tmp/ubuntu_v4.img /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello<=
br>[rio12:00001] *** Process received signal ***<br>[rio12:00001] Signal: S=
egmentation fault (11)<br>[rio12:00001] Signal code: Address not mapped (1)=
<br>[rio12:00001] Failing at address: 0x7fbd937e6010<br>[rio12:00001] [ 0] =
[rio12:00001] *** Process received signal ***<br>/lib/x86_64-linux-gnu/libp=
thread.so.0(+0x113d0)[0x7f26aeb233d0]<br>[rio12:00001] [ 1] /usr/local/lib/=
libmca_common_sm.so.0(+0x1035)[0x7f269f964035]<br>[rio12:00001] [ 2] /usr/l=
ocal/lib/libmca_common_sm.so.0(common_sm_mpool_create+0xa3)[0x7f269f964583]=
<br>[rio12:00001] [ 3] /usr/local/lib/openmpi/mca_btl_sm.so(mca_btl_sm_add_=
procs+0x5f1)[0x7f269fb68771]<br>[rio12:00001] [ 4] /usr/local/lib/openmpi/m=
ca_bml_r2.so(+0x2be7)[0x7f26a451fbe7]<br>[rio12:00001] [ 5] /usr/local/lib/=
openmpi/mca_pml_ob1.so(mca_pml_ob1_add_procs+0xd2)[0x7f269ef35662]<br>[rio1=
2:00001] [ 6] /usr/local/lib/libmpi.so.0(ompi_mpi_init+0xa51)[0x7f26aed75d3=
1]<br>[rio12:00001] [ 7] /usr/local/lib/libmpi.so.0(MPI_Init+0xb9)[0x7f26ae=
d9bdb9]<br>[rio12:00001] [ 8] /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hell=
o[0x4007ec]<br>[rio12:00001] [ 9] /lib/x86_64-linux-gnu/libc.so.6(__libc_st=
art_main+0xf0)[0x7f26ae769830]<br>[rio12:00001] Signal: Segmentation fault =
(11)<br>[rio12:00001] Signal code: Address not mapped (1)<br>[rio12:00001] =
Failing at address: 0x7fbd937e6010<br>[rio12:00001] [10] /home_nfs/georgioy=
/BENCHS/mpi-openmp/mpi_hello[0x400709]<br>[rio12:00001] *** End of error me=
ssage ***<br>[rio12:00001] [ 0] /lib/x86_64-linux-gnu/libpthread.so.0(+0x11=
3d0)[0x7f3f89c063d0]<br>[rio12:00001] [ 1] /usr/local/lib/libmca_common_sm.=
so.0(+0x1035)[0x7f3f7eb1d035]<br>[rio12:00001] [ 2] /usr/local/lib/libmca_c=
ommon_sm.so.0(common_sm_mpool_create+0xa3)[0x7f3f7eb1d583]<br>[rio12:00001]=
 [ 3] /usr/local/lib/openmpi/mca_btl_sm.so(mca_btl_sm_add_procs+0x5f1)[0x7f=
3f7ed21771]<br>[rio12:00001] [ 4] /usr/local/lib/openmpi/mca_bml_r2.so(+0x2=
be7)[0x7f3f7f5f3be7]<br>[rio12:00001] [ 5] /usr/local/lib/openmpi/mca_pml_o=
b1.so(mca_pml_ob1_add_procs+0xd2)[0x7f3f7e0ee662]<br>[rio12:00001] [ 6] /us=
r/local/lib/libmpi.so.0(ompi_mpi_init+0xa51)[0x7f3f89e58d31]<br>[rio12:0000=
1] [ 7] /usr/local/lib/libmpi.so.0(MPI_Init+0xb9)[0x7f3f89e7edb9]<br>[rio12=
:00001] [ 8] /home_nfs/georgioy/BENCHS/mpi-openmp/mpi_hello[0x4007ec]<br>[r=
io12:00001] [ 9] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0)[0x=
7f3f8984c830]<br>[rio12:00001] [10] /home_nfs/georgioy/BENCHS/mpi-openmp/mp=
i_hello[0x400709]<br>[rio12:00001] *** End of error message ***<br>slurmste=
pd:
 error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix: ERROR: Error
 handler invoked: status =3D -25, nranges =3D 0: Success (0)<br>srun: Job s=
tep aborted: Waiting up to 32 seconds for job step to finish.<br>slurmstepd=
: error: *** STEP 86.0 ON rio12 CANCELLED AT 2016-06-08T20:12:08 ***<br>slu=
rmstepd:
 error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix: ERROR: Error
 handler invoked: status =3D -25, nranges =3D 0: Success (0)<br>slurmstepd:=
=20
error: rio13 [1] pmixp_client.c:241 [errhandler] mpi/pmix: ERROR: Error=20
handler invoked: status =3D -25, nranges =3D 0: Success (0)<br>slurmstepd:=
=20
error: rio12 [0] pmixp_client.c:241 [errhandler] mpi/pmix: ERROR: Error=20
handler invoked: status =3D -25, nranges =3D 0: Success (0)<br>srun: error:=
 rio12: tasks 0-2: Killed<br>srun: error: rio13: task 3: Killed<br><br>=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<br><br></div><div>th=
e results I get when launching with mpirun instead of srun are more or less=
 the same. <br><br></div><div>From my understanding, the orted process, or =
in my case slurmstepd process that launches the singularity container <br><=
/div><div>and
 the MPI application, enables the communication of MPI libraries and=20
orted (or slurmstepd) through PMI (in my case here PMIx).<br></div><div>So =
I suppose the problem I see should be related with the mapping of PMI from =
the container towards the orted or slurmstepd.<br><br></div><div>What do yo=
u think?<br></div><div><br></div><div>To
 give some more details, my singularity container has OpenMPI and PMIx=20
installed but not Slurm. I don&#39;t think that Slurm needs to reside withi=
n
 the container in that context.<br></div><div>But I wasn&#39;t sure if Open=
MPI and PMIx are needed both inside and outside of the container.<br></div>=
<div>So, I&#39;ve tried using the exact same version of PMIx and OpenMPI in=
 and out of the container and the problem still persists. <br></div><div>Th=
e
 experiments have been done using RedHat hosts with CentOS or Ubuntu=20
singularity containers and the latest github versions of slurm, OpenMPI,
 PMIx and singularity.<br></div><div><br></div><div>By the way, do you have=
 any MPI example for singularity v2? <br></div><div>Because the MPI example=
 that you show here : <a href=3D"http://singularity.lbl.gov/#hpc" target=3D=
"_blank">http://singularity.lbl.gov/#hpc</a><br><br></div><div>is actually =
done using singularity v1, no? <br>In
 my understanding with singularity v2 we actually build a complete image
 with OS not just the application with its libraries. Is this correct?<br><=
/div><div><br></div><div>Sorry for the long email and<br>thanks a lot for a=
ny extra info you can provide regarding singularity v2 and MPI.<br><br></di=
v><div>Best Regards,<br></div><div>Yiannis</div></div></div></div></div><sp=
an><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<span class=3D"HOEnZb"><font color=3D"#888888"><br>
</font></span></font></span></blockquote></div><span class=3D"HOEnZb"><font=
 color=3D"#888888"><br><br clear=3D"all"><div><br></div>-- <br><div data-sm=
artmail=3D"gmail_signature"><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>Hig=
h Performance Computing Services (HPCS)<br>University of California<br>Lawr=
ence Berkeley National Laboratory<br>One Cyclotron Road, Berkeley, CA 94720=
</div></div></div>
</font></span></div><span class=3D"HOEnZb"><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</font></span></blockquote></div><br></div>

--001a11421a440343c60534ca6f29--

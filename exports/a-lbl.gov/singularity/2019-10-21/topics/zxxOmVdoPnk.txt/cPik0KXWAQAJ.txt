Date: Tue, 24 Apr 2018 06:44:37 -0700 (PDT)
From: Randy Ellison <Randy....@framatome.com>
To: singularity <singu...@lbl.gov>
Message-Id: <a79e4f12-3726-4fce-be8d-6d0696b5c844@lbl.gov>
In-Reply-To: <CAHqiYpcmRgVPQ_5ZspNOz_BsLT=yfW5MgGJHLE-MYWizbzMU-Q@mail.gmail.com>
References: <CAHqiYpcmRgVPQ_5ZspNOz_BsLT=yfW5MgGJHLE-MYWizbzMU-Q@mail.gmail.com>
Subject: Re: qsub within a conatainer
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_22877_515477049.1524577477355"

------=_Part_22877_515477049.1524577477355
Content-Type: multipart/alternative; 
	boundary="----=_Part_22878_2071141894.1524577477355"

------=_Part_22878_2071141894.1524577477355
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

I have found that ssh to the external host just for the qsub allows the 
elevated privilege to occur, but does not impact the engineering 
calculations, only the scheduling of them.

My python scripts perform a "ssh <hostname> qsub -q <my_queue> 
<script_to_run>"

Note that the <script_to_run> is on a mounted file systems that can be seen 
internal and external to the container.

All the good engineering stuff occurs in the <script_to_run> that will 
actually be in its own container.

The script_to_run will typically be a simple wrapper around the singularity 
exec call, like: "sungularity exec mycontainer.simg runprogram.sh"
Or, the full command line can be put into then singularity call.

On Tuesday, April 24, 2018 at 8:12:17 AM UTC-4, airzinger wrote:

> Hello,
>
> I am building a singularity image containing a pipeline scripts  that  
> have multiple qsub commands (mostly job arrays).Any suggestions on how I  
> can build this image in a way that when I run my container from my HPC ,  
> the qsub commands within my pipeline scripts inside container get executed 
> and jobs can run on my compute nodes?  Will I need to do a a bind mount of 
> some sort?
>
> Regards,
>
> Haseeb Mahmud 
>

------=_Part_22878_2071141894.1524577477355
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div>I have found that ssh to the external host just for t=
he qsub allows the elevated privilege to occur, but does not impact the eng=
ineering calculations, only the scheduling of them.</div><div><br></div><di=
v>My python scripts perform a &quot;ssh &lt;hostname&gt; qsub -q &lt;my_que=
ue&gt; &lt;script_to_run&gt;&quot;</div><div><br></div><div>Note that the &=
lt;script_to_run&gt; is on a mounted file systems that can be seen internal=
 and external to the container.</div><div><br></div><div>All the good engin=
eering stuff occurs in the &lt;script_to_run&gt; that will actually be in i=
ts own container.</div><div><br></div><div>The script_to_run will typically=
 be a=C2=A0simple=C2=A0wrapper around the singularity exec call, like:=C2=
=A0&quot;sungularity exec mycontainer.simg runprogram.sh&quot;</div><div>Or=
, the full command line can be put into then singularity call.</div><div><b=
r>On Tuesday, April 24, 2018 at 8:12:17 AM UTC-4, airzinger wrote:</div><bl=
ockquote class=3D"gmail_quote" style=3D"margin: 0px 0px 0px 0.8ex; padding-=
left: 1ex; border-left-color: rgb(204, 204, 204); border-left-width: 1px; b=
order-left-style: solid;"><div dir=3D"ltr">Hello,<div><br></div><div>I am b=
uilding a singularity image containing a pipeline scripts=C2=A0 that=C2=A0 =
have multiple qsub commands (mostly job arrays).Any suggestions on how I=C2=
=A0 can build this image in a way that when I run my container from my HPC =
,=C2=A0 the qsub commands within my pipeline scripts inside container get e=
xecuted and jobs can run on my compute nodes?=C2=A0 Will I need to do a a b=
ind mount of some sort?</div><div><br></div><div>Regards,</div><div><br></d=
iv><div>Haseeb Mahmud=C2=A0</div></div>
</blockquote></div>
------=_Part_22878_2071141894.1524577477355--

------=_Part_22877_515477049.1524577477355--

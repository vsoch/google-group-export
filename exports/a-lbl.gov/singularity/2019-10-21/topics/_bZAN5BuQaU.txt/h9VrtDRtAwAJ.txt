X-Received: by 10.99.116.23 with SMTP id p23mr5630543pgc.136.1524620897247;
        Tue, 24 Apr 2018 18:48:17 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.101.78.4 with SMTP id r4ls4416083pgt.20.gmail; Tue, 24 Apr
 2018 18:48:16 -0700 (PDT)
X-Received: by 10.101.87.201 with SMTP id q9mr22586277pgr.215.1524620895792;
        Tue, 24 Apr 2018 18:48:15 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1524620895; cv=none;
        d=google.com; s=arc-20160816;
        b=x941QudV0191Uimxmqezo1MAbKqZoUocuTWDrK8CxaB4RWVl7NSuW/IFiWvPJMXVAw
         bDBWgL3nNmabxYoDFj9XS2OoWagA2BwP7fdlJowkEwA2djSKIjWyA7K5jQj/FDAZJeAh
         CQi1YbhJLK5tSDuhqhAKk71RE2eyWvDlGES2vZeMTSbKXE4bLWX5AayZXFwePa4d3qrl
         WqPn5E1ucJ0AfwKyaXoIPrhoZf9Ndgvx1jl99wA2ncnee4XBGngubLjA3IRgyldmKA96
         xtf+IKb0qJAqWwtBjyJVXKEEpArwJ1Gk5z4t0GeL3AqzIi0XAMy46Z9MqaluiikDo8rc
         5T2A==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=mime-version:content-language:accept-language:in-reply-to
         :references:message-id:date:thread-index:thread-topic:subject:to
         :from:arc-authentication-results;
        bh=2PFG5rgVV4E6MYHkK2FPghFmmIeSOyHx1qY5GDF3+5k=;
        b=MYLCN+0513qKcAM/qF7PyfpNGof5aJOD080/e3Q822dtB2Mv9E3TSRbrf5BLLD7GwG
         e2iBK+7MKqXljeG0kqQLOeBwahmHPy3ItOrpVVAs/YeZhaa51CNOSYqfztCAhrw7ZEcA
         Mrgkx/y0L769xbEeDmsfzqiEpJT0xcCzzpsrqJy5JoI57jyvciH9w8knsXZ8Ve+lNsws
         lK3wlJpO5Ej8PBjkbTu7DjYqLfA45mvGMFTpmUzXFggHdQkjBreUy4EdmX/weRlfoafD
         3d/knEmzBmET+U4b6cT4LLGKTw8Jf4sZPUHulLrbrb8gkJlqsEf8juBbmov8wHjWL1wu
         FYiw==
ARC-Authentication-Results: i=1; mx.google.com;
       spf=pass (google.com: domain of mka...@sdsc.edu designates 132.239.0.167 as permitted sender) smtp.mailfrom=mka...@sdsc.edu
Return-Path: <mka...@sdsc.edu>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id c41-v6si14091195plj.503.2018.04.24.18.48.15
        for <singu...@lbl.gov>;
        Tue, 24 Apr 2018 18:48:15 -0700 (PDT)
Received-SPF: pass (google.com: domain of mka...@sdsc.edu designates 132.239.0.167 as permitted sender) client-ip=132.239.0.167;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of mka...@sdsc.edu designates 132.239.0.167 as permitted sender) smtp.mailfrom=mka...@sdsc.edu
X-Ironport-SBRS: 2.3
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A0E6AQDE3N9ae6cA74RbHAEBAQQBAQoBA?=
 =?us-ascii?q?YJNIimBDBdjKAqDWohmjB+BdIEPgWeFBowqgSkwCAMBChgBCgkCgSgBIIJ1AoJ?=
 =?us-ascii?q?5ITcVAQIBAQEBAQECAQECEAEBCwsKBygjAQuCNQUCAxoGBQRLKQMDAQEBAQEBA?=
 =?us-ascii?q?QEBJAEBAQEBAQEBAQEBAQEBARoCDTESAQEYAQEBAQMaDSc7AgEIEQEDAQELCwE?=
 =?us-ascii?q?BCQcHIRABFAMGCAIECAIFBAEHEwIEgxdzTAMVAQQKpTARgwkzhw0NQgEHYYI/i?=
 =?us-ascii?q?AyBVT6BD4JdLoJPPAYCgRsSARIBDxIdEgUJCQGCZ4IEIAKMCzWLESwDBQKFXIU?=
 =?us-ascii?q?nQIRtimCJNgJChjiBJQwmVg0hcXITgn4JghcXg0WBf4MVhT5vAQ+BBYx2DRcwW?=
 =?us-ascii?q?AGBFwEB?=
X-IPAS-Result: =?us-ascii?q?A0E6AQDE3N9ae6cA74RbHAEBAQQBAQoBAYJNIimBDBdjKAq?=
 =?us-ascii?q?DWohmjB+BdIEPgWeFBowqgSkwCAMBChgBCgkCgSgBIIJ1AoJ5ITcVAQIBAQEBA?=
 =?us-ascii?q?QECAQECEAEBCwsKBygjAQuCNQUCAxoGBQRLKQMDAQEBAQEBAQEBJAEBAQEBAQE?=
 =?us-ascii?q?BAQEBAQEBARoCDTESAQEYAQEBAQMaDSc7AgEIEQEDAQELCwEBCQcHIRABFAMGC?=
 =?us-ascii?q?AIECAIFBAEHEwIEgxdzTAMVAQQKpTARgwkzhw0NQgEHYYI/iAyBVT6BD4JdLoJ?=
 =?us-ascii?q?PPAYCgRsSARIBDxIdEgUJCQGCZ4IEIAKMCzWLESwDBQKFXIUnQIRtimCJNgJCh?=
 =?us-ascii?q?jiBJQwmVg0hcXITgn4JghcXg0WBf4MVhT5vAQ+BBYx2DRcwWAGBFwEB?=
X-IronPort-AV: E=Sophos;i="5.49,325,1520924400"; 
   d="scan'208,217";a="113409399"
Received: from iport-acv9-out.ucsd.edu ([132.239.0.167])
  by fe3.lbl.gov with ESMTP; 24 Apr 2018 18:48:13 -0700
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2GGAgDU3d9a/3UA74RbHAEBAQQBAQoBA?=
 =?us-ascii?q?YJNIimBDBdjKAqDWohmjhOBD4FnhQaMKoEpMAgDAQoYAQoJAoEoASCCdQKDGjc?=
 =?us-ascii?q?VAQIBAQEBAQECAQECaBwBC4I1BQIDGgYFBEspAwMBAQEBAQEBAQEkAQEBAQEBA?=
 =?us-ascii?q?QEBAQEBAQEBGgINMRIBARgBAQEBAxoNJzsCAQgRAQMBAQsLAQEJBwchEAEUAwY?=
 =?us-ascii?q?IAgQIAgUEAQcTAgSDF3NMAxUBDqU0EYMJM4cNDUIBB2GCP4lhPoEPgl0ugk88B?=
 =?us-ascii?q?gKBGxIBEgEPEh0SBQkJAYJnggQgAowLNYsRLAMFAoVchSdAhG2KYIk2AkKGOIE?=
 =?us-ascii?q?lDCYjMw0hcXITgn4JghcXg0WBf4MVhT5vAQ+BBYx2DRcwWAGBFwEB?=
X-IPAS-Result: =?us-ascii?q?A2GGAgDU3d9a/3UA74RbHAEBAQQBAQoBAYJNIimBDBdjKAq?=
 =?us-ascii?q?DWohmjhOBD4FnhQaMKoEpMAgDAQoYAQoJAoEoASCCdQKDGjcVAQIBAQEBAQECA?=
 =?us-ascii?q?QECaBwBC4I1BQIDGgYFBEspAwMBAQEBAQEBAQEkAQEBAQEBAQEBAQEBAQEBGgI?=
 =?us-ascii?q?NMRIBARgBAQEBAxoNJzsCAQgRAQMBAQsLAQEJBwchEAEUAwYIAgQIAgUEAQcTA?=
 =?us-ascii?q?gSDF3NMAxUBDqU0EYMJM4cNDUIBB2GCP4lhPoEPgl0ugk88BgKBGxIBEgEPEh0?=
 =?us-ascii?q?SBQkJAYJnggQgAowLNYsRLAMFAoVchSdAhG2KYIk2AkKGOIElDCYjMw0hcXITg?=
 =?us-ascii?q?n4JghcXg0WBf4MVhT5vAQ+BBYx2DRcwWAGBFwEB?=
X-IronPort-AV: E=Sophos;i="5.49,325,1520924400"; 
   d="scan'208,217";a="34858046"
X-Spam-Status: No
X-Spam-Level: 
Received: from xcore-cub1.ucsd.edu (HELO XCORE-CUB1.AD.UCSD.EDU) ([132.239.0.117])
  by iport-acv9-out.ucsd.edu with ESMTP/TLS/AES256-GCM-SHA384; 24 Apr 2018 18:48:12 -0700
Received: from XMAIL-MBX-BT1.AD.UCSD.EDU ([fe80::b066:a961:2460:32af]) by
 XCORE-CUB1.AD.UCSD.EDU ([fe80::982e:2e45:1345:fcd1%11]) with mapi id
 14.03.0319.002; Tue, 24 Apr 2018 18:48:12 -0700
From: "Kandes, Martin" <mka...@sdsc.edu>
To: "singu...@lbl.gov" <singu...@lbl.gov>
Subject: RE: [Singularity] Can I use a writeable image on a non-root system?
Thread-Topic: [Singularity] Can I use a writeable image on a non-root system?
Thread-Index: AQHT3CIzK+99tohTJEq8/5smI5+VL6QQrjk1gAAGu8Q=
Date: Wed, 25 Apr 2018 01:48:11 +0000
Message-ID: <B58197C146EC324AA00A2A07DC082602C2CAA5B6@XMAIL-MBX-BT1.AD.UCSD.EDU>
References: <5e42e0a7-2077-4f26-98a9-addf92e118bc@lbl.gov>,<B58197C146EC324AA00A2A07DC082602C2CAA59A@XMAIL-MBX-BT1.AD.UCSD.EDU>
In-Reply-To: <B58197C146EC324AA00A2A07DC082602C2CAA59A@XMAIL-MBX-BT1.AD.UCSD.EDU>
Accept-Language: en-US
Content-Language: en-US
X-MS-Has-Attach:
X-MS-TNEF-Correlator:
x-originating-ip: [137.110.35.197]
Content-Type: multipart/alternative;
	boundary="_000_B58197C146EC324AA00A2A07DC082602C2CAA5B6XMAILMBXBT1ADUC_"
MIME-Version: 1.0

--_000_B58197C146EC324AA00A2A07DC082602C2CAA5B6XMAILMBXBT1ADUC_
Content-Type: text/plain; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

Jonathan,

I was able to find a ticket where I helped a user do this recently [0]. I f=
orget off the top of my head why the JuliaGPU packages were having trouble =
being installed natively on the system (maybe the cuDNN requirement?), but =
this is a case where I setup one of these 'hybrid' Singularity solutions. I=
t's not the way I like to do it, but it's workable if it's the best you can=
 do.

Marty

[0]

Hi Bruno,

I was able to pull together a potential solution here today. It's hybrid so=
lution using Singularity [1]. While it's not as convenient as I would have =
liked, so far it looks like it may work for you.

The Julia installation requires using this Singularity container [2]. As it=
s name indicates, this image holds all of the dependencies required to comp=
ile Julia from source. It also includes CUDA 8.0 and cuDNN as you requested=
.

While all of the required dependencies for Julia are installed in [2], you =
must actually compile and install Julia itself outside the container in you=
r $HOME directory on Comet. The key, however, is you will perform the compi=
lation and installation process in your $HOME directory while working from =
a shell session within the container. Once you get to the part when you beg=
in installing the CUDA support Julia, it will tests if there is an actual p=
hysical GPU available on the system. Therefore, this compilation and instal=
lation process also needs to be performed on one of the GPU nodes. I would =
recommend using a P100 node. Julia's automated checks of the physical GPU h=
ardware probably set the GPU architecture setting used to compile the packa=
ges providing CUDA support [3]. If they set this up properly, compiling on =
a P100 should then allow the install to be backwards compatible running on =
the K80 GPU nodes as well. However, this is something you will want to test=
, that is, if you plan to run on both types of GPUs.

I know this probably sounds overly complicated, and it is somewhat, but the=
re really aren't too many steps. Let me walk you through them ...

To request a P100 GPU on a node, run this command [4]. Once a GPU has been =
allocated to you on one of the nodes [5], you should be able to ssh directl=
y to the node [6].

After logging into the node, load the Singularity module and then create an=
 interactive shell within the container [7]. From here, download, build and=
 install Julia from its github repo [8]. The build will take some time (~2 =
hours maybe).

Finally, once the standard Julia build was completed. Run Julia and Pkg.add=
 the CUDA-enabled libraries as needed [9]. If all goes well, you should now=
 have a working Julia build with CUDA support. Note, however, while Julia i=
s now installed in your $HOME directory, you will still have to run all of =
your jobs from within the Singularity container since it holds many of the =
dependencies needed to run Julia. We can assist you with constructing job b=
atch scripts when the time comes, if necessary.

Anyhow, give the build a try and let me know if you have any questions.

Marty Kandes
SDSC User Services Group

P.S. If the process above is too much work, you might also try creating a S=
ingularity container from their Docker image [10]. Singularity is suppose t=
o have decent support for importing Docker-based containers [11]. However, =
it may be a gamble on what version of CUDA and cuDNN is installed.

[1]

singularity.lbl.gov

[2]

/oasis/scratch/comet/mkandes/temp_project/singularity/images/julia-dep-only=
.img

[3]

https://github.com/JuliaGPU/

[4]

[mkandes@comet-ln3 ~]$ salloc --account=3Duse300 --partition=3Dgpu-shared -=
-nodes=3D1 --ntasks-per-node=3D7 --gres=3Dgpu:p100:1 --time=3D04:00:00

[5]

[mkandes@comet-ln3 ~]$ salloc --account=3Duse300 --partition=3Dgpu-shared -=
-nodes=3D1 --ntasks-per-node=3D7 --gres=3Dgpu:p100:1 --time=3D04:00:00
salloc: Pending job allocation 13258864
salloc: job 13258864 queued and waiting for resources
salloc: job 13258864 has been allocated resources
salloc: Granted job allocation 13258864
salloc: Waiting for resource configuration
salloc: Nodes comet-33-01 are ready for job

[6]

[mkandes@comet-ln3 ~]$ ssh comet-33-01
Last login: Sun Nov 12 21:48:46 2017 from comet-ln2.local
Rocks Compute Node
Rocks 6.2 (SideWinder)
Profile built 15:43 22-Jun-2017

Kickstarted 16:18 22-Jun-2017

                      WELCOME TO
      __________________  __  _______________
        -----/ ____/ __ \/  |/  / ____/_  __/
          --/ /   / / / / /|_/ / __/   / /
           / /___/ /_/ / /  / / /___  / /
           \____/\____/_/  /_/_____/ /_/

[mkandes@comet-33-01 ~]$

[7]

[mkandes@comet-ln3 ~]$ ssh comet-33-01
Last login: Sun Nov 12 21:48:46 2017 from comet-ln2.local
Rocks Compute Node
Rocks 6.2 (SideWinder)
Profile built 15:43 22-Jun-2017

Kickstarted 16:18 22-Jun-2017

                      WELCOME TO
      __________________  __  _______________
        -----/ ____/ __ \/  |/  / ____/_  __/
          --/ /   / / / / /|_/ / __/   / /
           / /___/ /_/ / /  / / /___  / /
           \____/\____/_/  /_/_____/ /_/

[mkandes@comet-33-01 ~]$ pwd
/home/mkandes
[mkandes@comet-33-01 ~]$ module purge
[mkandes@comet-33-01 ~]$ module load singularity
[mkandes@comet-33-01 ~]$ singularity shell /oasis/scratch/comet/mkandes/tem=
p_project/singularity/images/julia-dep-only.img
Singularity: Invoking an interactive shell within container...

Singularity julia-dep-only.img:~> pwd
/home/mkandes
Singularity julia-dep-only.img:~>

[8]

git clone https://github.com/JuliaLang/julia.git
cd julia
git checkout v0.6.0
make
./julia

[9]

Singularity julia-dep-only.img:~/Software/julia/julia> ./julia
               _
   _       _ _(_)_     |  A fresh approach to technical computing
  (_)     | (_) (_)    |  Documentation: https://docs.julialang.org
   _ _   _| |_  __ _   |  Type "?help" for help.
  | | | | | | |/ _` |  |
  | | |_| | | | (_| |  |  Version 0.6.0 (2017-06-19 13:05 UTC)
 _/ |\__'_|_|_|\__'_|  |
|__/                   |  x86_64-linux-gnu

julia> Pkg.add("CUDAnative")
INFO: Initializing package repository /home/mkandes/.julia/v0.6
INFO: Cloning METADATA from https://github.com/JuliaLang/METADATA.jl
INFO: Cloning cache of CUDAapi from https://github.com/JuliaGPU/CUDAapi.jl.=
git
INFO: Cloning cache of CUDAdrv from https://github.com/JuliaGPU/CUDAdrv.jl.=
git
INFO: Cloning cache of CUDAnative from https://github.com/JuliaGPU/CUDAnati=
ve.jl.git
INFO: Cloning cache of Compat from https://github.com/JuliaLang/Compat.jl.g=
it
INFO: Cloning cache of LLVM from https://github.com/maleadt/LLVM.jl.git
INFO: Installing CUDAapi v0.2.1
INFO: Installing CUDAdrv v0.6.1
INFO: Installing CUDAnative v0.5.3
INFO: Installing Compat v0.39.0
INFO: Installing LLVM v0.5.1
INFO: Building CUDAdrv
WARNING: Found multiple CUDA driver installations: /usr/lib/x86_64-linux-gn=
u and /usr
INFO: Building LLVM
INFO: Building CUDAnative
WARNING: Found multiple CUDA toolkit installations: /usr/local/cuda and /us=
r/local/cuda-8.0/targets/x86_64-linux
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.
INFO: Package database updated

julia> Pkg.test("CUDAnative")
INFO: Testing CUDAnative
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.
WARNING: Encountered incompatible LLVM IR for codegen_ref_nonexisting() at =
capability 6.0.0: CUDAnative.InvalidIRError("calls the Julia runtime", ("jl=
_get_binding_or_error",   %2 =3D tail call i8** @jl_get_binding_or_error(i8=
** inttoptr (i64 47201155301392 to i8**), i8** inttoptr (i64 47201225307528=
 to i8**)), !dbg !13))
WARNING: Encountered incompatible LLVM IR for codegen_ref_nonexisting() at =
capability 6.0.0: CUDAnative.InvalidIRError("calls the Julia runtime", ("jl=
_undefined_var_error",   tail call void @jl_undefined_var_error(i8** inttop=
tr (i64 47201225307528 to i8**)), !dbg !13))
WARNING: Encountered incompatible LLVM IR for codegen_call_nonexisting() at=
 capability 6.0.0: CUDAnative.InvalidIRError("calls the Julia runtime", ("j=
l_get_binding_or_error",   %11 =3D call i8** @jl_get_binding_or_error(i8** =
inttoptr (i64 47201155301392 to i8**), i8** inttoptr (i64 47201225307528 to=
 i8**)), !dbg !16))
WARNING: Encountered incompatible LLVM IR for codegen_call_nonexisting() at=
 capability 6.0.0: CUDAnative.InvalidIRError("calls the Julia runtime", ("j=
l_undefined_var_error",   call void @jl_undefined_var_error(i8** inttoptr (=
i64 47201225307528 to i8**)), !dbg !16))
WARNING: Encountered incompatible LLVM IR for codegen_call_nonexisting() at=
 capability 6.0.0: CUDAnative.InvalidIRError("calls the Julia runtime", ("j=
l_apply_generic",   %17 =3D call i8** @jl_apply_generic(i8*** %1, i32 1), !=
dbg !16))
INFO: Testing using device Tesla P100-PCIE-16GB
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.
WARNING: Documenter.jl not installed, skipping CUDAnative documentation tes=
ts.
Test Summary: | Pass  Total
CUDAnative    |  127    127
INFO: CUDAnative tests passed

julia> exit()
Singularity julia-dep-only.img:~/Software/julia/julia> exit
exit
[mkandes@comet-34-10 julia]$ exit
logout

Connection to comet-34-10 closed.

[10]

https://github.com/JuliaGPU/docker

[11]

http://singularity.lbl.gov/docs-docker

________________________________
From: Kandes, Martin [mka...@sdsc.edu]
Sent: Tuesday, April 24, 2018 6:37 PM
To: singu...@lbl.gov
Subject: RE: [Singularity] Can I use a writeable image on a non-root system=
?

Hi Jonathan,

I don't believe so. Generally, you have to build your Singularity images on=
 a system you have sudo/root access to and then transfer it to the HPC wher=
e you want to run it, where as you said you don't have sudo/root access.

However, one work-around here might be to build a basic container on the sy=
stem you have sudo/root access to, transfer this base image over to the HPC=
 system, then install additional packages in your $HOME directory while ins=
ide the container to pickup some of the dependencies you already installed =
within the image itself. We sometimes have to install additional packages f=
or users in this 'hybrid' Singularity configuration, where only the depende=
ncies are inside the container and the remaining software is installed with=
in the users $HOME directory. Hopefully that makes sense.

Marty

________________________________
From: Jonathan Greenberg [jgr...@gmail.com]
Sent: Tuesday, April 24, 2018 4:15 PM
To: singularity
Subject: [Singularity] Can I use a writeable image on a non-root system?

We're having challenges with the development phase of singularity, where we=
 really need to develop our image co-located with our data/hardware, but it=
 is on an HPC where we don't have root access.  If we build a REALLY simple=
 image on a root'ed system via --writeable or sandbox or something, can we =
move it to the HPC (non-root) system and the shell -> apt-get install etc. =
stuff on the image?  Or does the use of non-root singularity runtime system=
s mean we can't modify the image on those systems?

--j

--
You received this message because you are subscribed to the Google Groups "=
singularity" group.
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to singu...@lbl.gov<mailto:singu...@lbl.gov>.

--
You received this message because you are subscribed to the Google Groups "=
singularity" group.
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to singu...@lbl.gov<mailto:singu...@lbl.gov>.

--_000_B58197C146EC324AA00A2A07DC082602C2CAA5B6XMAILMBXBT1ADUC_
Content-Type: text/html; charset="iso-8859-1"
Content-Transfer-Encoding: quoted-printable

<html dir=3D"ltr">
<head>
<meta http-equiv=3D"Content-Type" content=3D"text/html; charset=3Diso-8859-=
1">
<style type=3D"text/css" id=3D"owaParaStyle">
<!--
p
=09{margin-top:0;
=09margin-bottom:0}
-->
P {margin-top:0;margin-bottom:0;}</style>
</head>
<body fpstyle=3D"1" ocsi=3D"0">
<div style=3D"direction: ltr;font-family: Tahoma;color: #000000;font-size: =
10pt;">Jonathan,<br>
<br>
I was able to find a ticket where I helped a user do this recently [0]. I f=
orget off the top of my head why the JuliaGPU packages were having trouble =
being installed natively on the system (maybe the cuDNN requirement?), but =
this is a case where I setup one
 of these 'hybrid' Singularity solutions. It's not the way I like to do it,=
 but it's workable if it's the best you can do.
<br>
<br>
Marty<br>
<br>
[0]<br>
<br>
<font size=3D"2"><span style=3D"font-size:10pt;">Hi Bruno,<br>
<br>
I was able to pull together a potential solution here today. It's hybrid so=
lution using Singularity [1]. While it's not as convenient as I would have =
liked, so far it looks like it may work for you.<br>
<br>
The Julia installation requires using this Singularity container [2]. As it=
s name indicates, this image holds all of the dependencies required to comp=
ile Julia from source. It also includes CUDA 8.0 and cuDNN as you requested=
.<br>
<br>
While all of the required dependencies for Julia are installed in [2], you =
must actually compile and install Julia itself outside the container in you=
r $HOME directory on Comet. The key, however, is you will perform the compi=
lation and installation process
 in your $HOME directory while working from a shell session within the cont=
ainer. Once you get to the part when you begin installing the CUDA support =
Julia, it will tests if there is an actual physical GPU available on the sy=
stem. Therefore, this compilation
 and installation process also needs to be performed on one of the GPU node=
s. I would recommend using a P100 node. Julia's automated checks of the phy=
sical GPU hardware probably set the GPU architecture setting used to compil=
e the packages providing CUDA support
 [3]. If they set this up properly, compiling on a P100 should then allow t=
he install to be backwards compatible running on the K80 GPU nodes as well.=
 However, this is something you will want to test, that is, if you plan to =
run on both types of GPUs.<br>
<br>
I know this probably sounds overly complicated, and it is somewhat, but the=
re really aren't too many steps. Let me walk you through them ...<br>
<br>
To request a P100 GPU on a node, run this command [4]. Once a GPU has been =
allocated to you on one of the nodes [5], you should be able to ssh directl=
y to the node [6].
<br>
<br>
After logging into the node, load the Singularity module and then create an=
 interactive shell within the container [7]. From here, download, build and=
 install Julia from its github repo [8]. The build will take some time (~2 =
hours maybe).
<br>
<br>
Finally, once the standard Julia build was completed. Run Julia and Pkg.add=
 the CUDA-enabled libraries as needed [9]. If all goes well, you should now=
 have a working Julia build with CUDA support. Note, however, while Julia i=
s now installed in your $HOME directory,
 you will still have to run all of your jobs from within the Singularity co=
ntainer since it holds many of the dependencies needed to run Julia. We can=
 assist you with constructing job batch scripts when the time comes, if nec=
essary.<br>
<br>
Anyhow, give the build a try and let me know if you have any questions. <br=
>
<br>
Marty Kandes<br>
SDSC User Services Group<br>
<br>
P.S. If the process above is too much work, you might also try creating a S=
ingularity container from their Docker image [10]. Singularity is suppose t=
o have decent support for importing Docker-based containers [11]. However, =
it may be a gamble on what version
 of CUDA and cuDNN is installed. <br>
<br>
[1]<br>
<br>
singularity.lbl.gov<br>
<br>
[2]<br>
<br>
/oasis/scratch/comet/mkandes/temp_project/singularity/images/julia-dep-only=
.img<br>
<br>
[3]<br>
<br>
<a href=3D"https://github.com/JuliaGPU/" target=3D"_blank">https://github.c=
om/JuliaGPU/</a><br>
<br>
[4]<br>
<br>
[mkandes@comet-ln3 ~]$ salloc --account=3Duse300 --partition=3Dgpu-shared -=
-nodes=3D1 --ntasks-per-node=3D7 --gres=3Dgpu:p100:1 --time=3D04:00:00<br>
<br>
[5]<br>
<br>
[mkandes@comet-ln3 ~]$ salloc --account=3Duse300 --partition=3Dgpu-shared -=
-nodes=3D1 --ntasks-per-node=3D7 --gres=3Dgpu:p100:1 --time=3D04:00:00<br>
salloc: Pending job allocation 13258864<br>
salloc: job 13258864 queued and waiting for resources<br>
salloc: job 13258864 has been allocated resources<br>
salloc: Granted job allocation 13258864<br>
salloc: Waiting for resource configuration<br>
salloc: Nodes comet-33-01 are ready for job<br>
<br>
[6]<br>
<br>
[mkandes@comet-ln3 ~]$ ssh comet-33-01<br>
Last login: Sun Nov 12 21:48:46 2017 from comet-ln2.local<br>
Rocks Compute Node<br>
Rocks 6.2 (SideWinder)<br>
Profile built 15:43 22-Jun-2017<br>
<br>
Kickstarted 16:18 22-Jun-2017<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; WELCOME TO <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; __________________&nbsp; __&nbsp; __________=
_____<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----/ ____/ __ \/&nbsp; |/&nbsp=
; / ____/_&nbsp; __/<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --/ /&nbsp;&nbsp; / =
/ / / /|_/ / __/&nbsp;&nbsp; / /<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; / /___/ /_/ / =
/&nbsp; / / /___&nbsp; / /<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \____/\____/_/=
&nbsp; /_/_____/ /_/<br>
<br>
[mkandes@comet-33-01 ~]$ <br>
<br>
[7]<br>
<br>
[mkandes@comet-ln3 ~]$ ssh comet-33-01<br>
Last login: Sun Nov 12 21:48:46 2017 from comet-ln2.local<br>
Rocks Compute Node<br>
Rocks 6.2 (SideWinder)<br>
Profile built 15:43 22-Jun-2017<br>
<br>
Kickstarted 16:18 22-Jun-2017<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; WELCOME TO <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; __________________&nbsp; __&nbsp; __________=
_____<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -----/ ____/ __ \/&nbsp; |/&nbsp=
; / ____/_&nbsp; __/<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --/ /&nbsp;&nbsp; / =
/ / / /|_/ / __/&nbsp;&nbsp; / /<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; / /___/ /_/ / =
/&nbsp; / / /___&nbsp; / /<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \____/\____/_/=
&nbsp; /_/_____/ /_/<br>
<br>
[mkandes@comet-33-01 ~]$ pwd<br>
/home/mkandes<br>
[mkandes@comet-33-01 ~]$ module purge <br>
[mkandes@comet-33-01 ~]$ module load singularity<br>
[mkandes@comet-33-01 ~]$ singularity shell /oasis/scratch/comet/mkandes/tem=
p_project/singularity/images/julia-dep-only.img<br>
Singularity: Invoking an interactive shell within container...<br>
<br>
Singularity julia-dep-only.img:~&gt; pwd<br>
/home/mkandes<br>
Singularity julia-dep-only.img:~&gt; <br>
<br>
[8]<br>
<br>
git clone <a href=3D"https://github.com/JuliaLang/julia.git" target=3D"_bla=
nk">https://github.com/JuliaLang/julia.git</a><br>
cd julia<br>
git checkout v0.6.0<br>
make&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <=
br>
./julia<br>
<br>
[9]<br>
<br>
Singularity julia-dep-only.img:~/Software/julia/julia&gt; ./julia<br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp; _<br>
&nbsp;&nbsp; _&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; _ _(_)_&nbsp;&nbsp;&nbsp=
;&nbsp; |&nbsp; A fresh approach to technical computing<br>
&nbsp; (_)&nbsp;&nbsp;&nbsp;&nbsp; | (_) (_)&nbsp;&nbsp;&nbsp; |&nbsp; Docu=
mentation: <a href=3D"https://docs.julialang.org" target=3D"_blank">
https://docs.julialang.org</a><br>
&nbsp;&nbsp; _ _&nbsp;&nbsp; _| |_&nbsp; __ _&nbsp;&nbsp; |&nbsp; Type &quo=
t;?help&quot; for help.<br>
&nbsp; | | | | | | |/ _` |&nbsp; |<br>
&nbsp; | | |_| | | | (_| |&nbsp; |&nbsp; Version 0.6.0 (2017-06-19 13:05 UT=
C)<br>
&nbsp;_/ |\__'_|_|_|\__'_|&nbsp; |<br>
|__/&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |&nbsp; x86_64-linux-gnu<br>
<br>
julia&gt; Pkg.add(&quot;CUDAnative&quot;)<br>
INFO: Initializing package repository /home/mkandes/.julia/v0.6<br>
INFO: Cloning METADATA from <a href=3D"https://github.com/JuliaLang/METADAT=
A.jl" target=3D"_blank">
https://github.com/JuliaLang/METADATA.jl</a><br>
INFO: Cloning cache of CUDAapi from <a href=3D"https://github.com/JuliaGPU/=
CUDAapi.jl.git" target=3D"_blank">
https://github.com/JuliaGPU/CUDAapi.jl.git</a><br>
INFO: Cloning cache of CUDAdrv from <a href=3D"https://github.com/JuliaGPU/=
CUDAdrv.jl.git" target=3D"_blank">
https://github.com/JuliaGPU/CUDAdrv.jl.git</a><br>
INFO: Cloning cache of CUDAnative from <a href=3D"https://github.com/JuliaG=
PU/CUDAnative.jl.git" target=3D"_blank">
https://github.com/JuliaGPU/CUDAnative.jl.git</a><br>
INFO: Cloning cache of Compat from <a href=3D"https://github.com/JuliaLang/=
Compat.jl.git" target=3D"_blank">
https://github.com/JuliaLang/Compat.jl.git</a><br>
INFO: Cloning cache of LLVM from <a href=3D"https://github.com/maleadt/LLVM=
.jl.git" target=3D"_blank">
https://github.com/maleadt/LLVM.jl.git</a><br>
INFO: Installing CUDAapi v0.2.1<br>
INFO: Installing CUDAdrv v0.6.1<br>
INFO: Installing CUDAnative v0.5.3<br>
INFO: Installing Compat v0.39.0<br>
INFO: Installing LLVM v0.5.1<br>
INFO: Building CUDAdrv<br>
WARNING: Found multiple CUDA driver installations: /usr/lib/x86_64-linux-gn=
u and /usr<br>
INFO: Building LLVM<br>
INFO: Building CUDAnative<br>
WARNING: Found multiple CUDA toolkit installations: /usr/local/cuda and /us=
r/local/cuda-8.0/targets/x86_64-linux<br>
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.<br>
INFO: Package database updated<br>
<br>
julia&gt; Pkg.test(&quot;CUDAnative&quot;)<br>
INFO: Testing CUDAnative<br>
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.<br>
WARNING: Encountered incompatible LLVM IR for codegen_ref_nonexisting() at =
capability 6.0.0: CUDAnative.InvalidIRError(&quot;calls the Julia runtime&q=
uot;, (&quot;jl_get_binding_or_error&quot;,&nbsp;&nbsp; %2 =3D tail call i8=
** @jl_get_binding_or_error(i8** inttoptr (i64 47201155301392 to
 i8**), i8** inttoptr (i64 47201225307528 to i8**)), !dbg !13))<br>
WARNING: Encountered incompatible LLVM IR for codegen_ref_nonexisting() at =
capability 6.0.0: CUDAnative.InvalidIRError(&quot;calls the Julia runtime&q=
uot;, (&quot;jl_undefined_var_error&quot;,&nbsp;&nbsp; tail call void @jl_u=
ndefined_var_error(i8** inttoptr (i64 47201225307528 to i8**)),
 !dbg !13))<br>
WARNING: Encountered incompatible LLVM IR for codegen_call_nonexisting() at=
 capability 6.0.0: CUDAnative.InvalidIRError(&quot;calls the Julia runtime&=
quot;, (&quot;jl_get_binding_or_error&quot;,&nbsp;&nbsp; %11 =3D call i8** =
@jl_get_binding_or_error(i8** inttoptr (i64 47201155301392 to i8**),
 i8** inttoptr (i64 47201225307528 to i8**)), !dbg !16))<br>
WARNING: Encountered incompatible LLVM IR for codegen_call_nonexisting() at=
 capability 6.0.0: CUDAnative.InvalidIRError(&quot;calls the Julia runtime&=
quot;, (&quot;jl_undefined_var_error&quot;,&nbsp;&nbsp; call void @jl_undef=
ined_var_error(i8** inttoptr (i64 47201225307528 to i8**)), !dbg
 !16))<br>
WARNING: Encountered incompatible LLVM IR for codegen_call_nonexisting() at=
 capability 6.0.0: CUDAnative.InvalidIRError(&quot;calls the Julia runtime&=
quot;, (&quot;jl_apply_generic&quot;,&nbsp;&nbsp; %17 =3D call i8** @jl_app=
ly_generic(i8*** %1, i32 1), !dbg !16))<br>
INFO: Testing using device Tesla P100-PCIE-16GB<br>
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.<br>
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.<br>
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.<br>
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.<br>
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.<br>
WARNING: Method definition convert(Type{LLVM.LLVMType}, Type{T} where T) in=
 module Interop at /home/mkandes/.julia/v0.6/LLVM/src/interop/base.jl:54 ov=
erwritten in module CUDAnative at /home/mkandes/.julia/v0.6/CUDAnative/src/=
cgutils.jl:159.<br>
WARNING: Documenter.jl not installed, skipping CUDAnative documentation tes=
ts.<br>
Test Summary: | Pass&nbsp; Total<br>
CUDAnative&nbsp;&nbsp;&nbsp; |&nbsp; 127&nbsp;&nbsp;&nbsp; 127<br>
INFO: CUDAnative tests passed<br>
<br>
julia&gt; exit()<br>
Singularity julia-dep-only.img:~/Software/julia/julia&gt; exit<br>
exit<br>
[mkandes@comet-34-10 julia]$ exit<br>
logout<br>
<br>
Connection to comet-34-10 closed.<br>
<br>
[10]<br>
<br>
<a href=3D"https://github.com/JuliaGPU/docker" target=3D"_blank">https://gi=
thub.com/JuliaGPU/docker</a><br>
<br>
[11]<br>
<br>
<a href=3D"http://singularity.lbl.gov/docs-docker" target=3D"_blank">http:/=
/singularity.lbl.gov/docs-docker</a><br>
<br>
</span></font>
<div style=3D"font-family: Times New Roman; color: #000000; font-size: 16px=
">
<hr tabindex=3D"-1">
<div id=3D"divRpF675897" style=3D"direction: ltr;"><font size=3D"2" face=3D=
"Tahoma" color=3D"#000000"><b>From:</b> Kandes, Martin [mka...@sdsc.edu]<br=
>
<b>Sent:</b> Tuesday, April 24, 2018 6:37 PM<br>
<b>To:</b> singu...@lbl.gov<br>
<b>Subject:</b> RE: [Singularity] Can I use a writeable image on a non-root=
 system?<br>
</font><br>
</div>
<div></div>
<div>
<div style=3D"direction:ltr; font-family:Tahoma; color:#000000; font-size:1=
0pt">Hi Jonathan,<br>
<br>
I don't believe so. Generally, you have to build your Singularity images on=
 a system you have sudo/root access to and then transfer it to the HPC wher=
e you want to run it, where as you said you don't have sudo/root access.
<br>
<br>
However, one work-around here might be to build a basic container on the sy=
stem you have sudo/root access to, transfer this base image over to the HPC=
 system, then install additional packages in your $HOME directory while ins=
ide the container to pickup some
 of the dependencies you already installed within the image itself. We some=
times have to install additional packages for users in this 'hybrid' Singul=
arity configuration, where only the dependencies are inside the container a=
nd the remaining software is installed
 within the users $HOME directory. Hopefully that makes sense.<br>
<br>
Marty<br>
<br>
<div style=3D"font-family:Times New Roman; color:#000000; font-size:16px">
<hr tabindex=3D"-1">
<div id=3D"divRpF255726" style=3D"direction:ltr"><font size=3D"2" face=3D"T=
ahoma" color=3D"#000000"><b>From:</b> Jonathan Greenberg [jgr...@gmail.com]=
<br>
<b>Sent:</b> Tuesday, April 24, 2018 4:15 PM<br>
<b>To:</b> singularity<br>
<b>Subject:</b> [Singularity] Can I use a writeable image on a non-root sys=
tem?<br>
</font><br>
</div>
<div></div>
<div>
<div dir=3D"ltr">We're having challenges with the development phase of sing=
ularity, where we really need to develop our image co-located with our data=
/hardware, but it is on an HPC where we don't have root access.&nbsp; If we=
 build a REALLY simple image on a root'ed
 system via --writeable or sandbox or something, can we move it to the HPC =
(non-root) system and the shell -&gt; apt-get install etc. stuff on the ima=
ge?&nbsp; Or does the use of non-root singularity runtime systems mean we c=
an't modify the image on those systems?
<div><br>
</div>
<div>--j</div>
</div>
<p></p>
-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to
<a href=3D"mailto:singularity&#43;unsu...@lbl.gov" target=3D"_blank">singul=
arity&#43;unsu...@lbl.gov</a>.<br>
</div>
</div>
</div>
<p></p>
-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to
<a href=3D"mailto:singularity&#43;unsu...@lbl.gov" target=3D"_blank">singul=
arity&#43;unsu...@lbl.gov</a>.<br>
</div>
</div>
</div>
</body>
</html>

--_000_B58197C146EC324AA00A2A07DC082602C2CAA5B6XMAILMBXBT1ADUC_--

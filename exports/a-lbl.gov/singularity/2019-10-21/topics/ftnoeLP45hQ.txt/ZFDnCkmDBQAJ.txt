Date: Wed, 12 Dec 2018 01:17:09 -0800 (PST)
From: =?UTF-8?Q?Tobias_K=C3=BChn?= <t.k...@gmx.de>
To: singularity <singu...@lbl.gov>
Cc: vol...@sf.mpg.de
Message-Id: <c9275075-bac6-4729-95d0-b9b150316159@lbl.gov>
In-Reply-To: <3C72B887-BED3-4FEB-AFC3-0600655FEA9E@sf.mpg.de>
References: <D6CEE1F3-2086-4270-A505-92C4A0991B3F@sf.mpg.de>
 <3C72B887-BED3-4FEB-AFC3-0600655FEA9E@sf.mpg.de>
Subject: Re: [Singularity] using BeeGFS parallel file system inside a
 singularity container
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_196_195719698.1544606229605"

------=_Part_196_195719698.1544606229605
Content-Type: multipart/alternative; 
	boundary="----=_Part_197_1406295601.1544606229605"

------=_Part_197_1406295601.1544606229605
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hello Stefan,

excuseme for hijacking this thread, but how do you manage to start beegfs=
=20
Client in a singularity container?

Greeting Tobi

Am Dienstag, 4. Oktober 2016 16:08:36 UTC+2 schrieb Dr . Stefan Vollmar:
>
> Sorry for the noise: I can now happily answer my own question - the way w=
e=20
> installed singularity 2.1.2 (without prefix) after building in=20
> /usr/local/src resulted in a file=20
> /usr/local/etc/singularity/singularity.conf which is apparently evaluated=
=20
> when /usr/local/bin/singularity is called.=20
>
> What we did:=20
> (1) created directory (mount point) /beegfs in the container=20
> (2) added line "bind path =3D /beegfs=E2=80=9D in singularity.conf (see a=
bove)=20
>
> A little benchmarking with iozone showed no discernible performance=20
> degration when running the benchmark from within the container - excellen=
t!=20
>
> Feature suggestion:=20
> This did not work at first for us (and hence the original posting) becaus=
e=20
> we did not know which singularity.conf was used (maybe the documentation=
=20
> could be a bit clearer about that - or singularity could have a commandli=
ne=20
> option for querying which config files are being used).=20
>
> Feature suggestion:=20
> It was also not clear to us whether we needed to provide infiniband or=20
> other packages/configurations normally required to mount our parallel fil=
e=20
> system inside the container. It turns out - and this is a killer feature =
of=20
> singularity - none of this hassle is needed inside the container (it is,=
=20
> obviously, required on the host). We could have deduced that from the=20
> documentation - but maybe this is something that could feature more=20
> prominently in the documentation (not least because it is such a convenie=
nt=20
> feature).=20
>
> Best,=20
>  Stefan=20
>
> > On 29 Sep 2016, at 20:16, Dr . Stefan Vollmar <v...@sf.mpg.de=20
> <javascript:>> wrote:=20
> >=20
> > We have just started to play with singularity and think about using it=
=20
> on our HPC systems - thanks for a great new tool!=20
> >=20
> > Our HPC clusters are connected via infiniband to a parallel file system=
=20
> (BeeGFS, formerly known as FhGFS) which we want to use inside a singulari=
ty=20
> container.=20
> >=20
> > On the host, this is mounted as /beegfs and I have provided the same=20
> mount point inside the container. Also the container has a=20
> /etc/singularity/singularity.conf file with a "bind path =3D /beegfs=E2=
=80=9D line=20
> (is that being used?) - anything else we need to do?=20
> >=20
> > Many thanks in advance!=20
> > Best,=20
> > Stefan=20
> > --=20
> > Dr. Stefan Vollmar=20
> > Max Planck Institute for Metabolism Research=20
>
>
------=_Part_197_1406295601.1544606229605
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div>Hello Stefan,</div><div><br></div><div>excuseme for h=
ijacking this thread, but how do you manage to start beegfs Client in a sin=
gularity container?</div><div><br></div><div>Greeting Tobi</div><br>Am Dien=
stag, 4. Oktober 2016 16:08:36 UTC+2 schrieb Dr . Stefan Vollmar:<blockquot=
e class=3D"gmail_quote" style=3D"margin: 0;margin-left: 0.8ex;border-left: =
1px #ccc solid;padding-left: 1ex;">Sorry for the noise: I can now happily a=
nswer my own question - the way we installed singularity 2.1.2 (without pre=
fix) after building in /usr/local/src resulted in a file /usr/local/etc/sin=
gularity/<wbr>singularity.conf which is apparently evaluated when /usr/loca=
l/bin/singularity is called.
<br>
<br>What we did:=20
<br>(1) created directory (mount point) /beegfs in the container
<br>(2) added line &quot;bind path =3D /beegfs=E2=80=9D in singularity.conf=
 (see above)
<br>
<br>A little benchmarking with iozone showed no discernible performance deg=
ration when running the benchmark from within the container - excellent!
<br>
<br>Feature suggestion:
<br>This did not work at first for us (and hence the original posting) beca=
use we did not know which singularity.conf was used (maybe the documentatio=
n could be a bit clearer about that - or singularity could have a commandli=
ne option for querying which config files are being used).=20
<br>
<br>Feature suggestion:
<br>It was also not clear to us whether we needed to provide infiniband or =
other packages/configurations normally required to mount our parallel file =
system inside the container. It turns out - and this is a killer feature of=
 singularity - none of this hassle is needed inside the container (it is, o=
bviously, required on the host). We could have deduced that from the docume=
ntation - but maybe this is something that could feature more prominently i=
n the documentation (not least because it is such a convenient feature).
<br>
<br>Best,
<br>=C2=A0Stefan
<br>
<br>&gt; On 29 Sep 2016, at 20:16, Dr . Stefan Vollmar &lt;<a onmousedown=
=3D"this.href=3D&#39;javascript:&#39;;return true;" onclick=3D"this.href=3D=
&#39;javascript:&#39;;return true;" href=3D"javascript:" target=3D"_blank" =
rel=3D"nofollow" gdf-obfuscated-mailto=3D"gQ9UfmV1AAAJ">v...@sf.mpg.de</a>&=
gt; wrote:
<br>&gt;=20
<br>&gt; We have just started to play with singularity and think about usin=
g it on our HPC systems - thanks for a great new tool!
<br>&gt;=20
<br>&gt; Our HPC clusters are connected via infiniband to a parallel file s=
ystem (BeeGFS, formerly known as FhGFS) which we want to use inside a singu=
larity container.
<br>&gt;=20
<br>&gt; On the host, this is mounted as /beegfs and I have provided the sa=
me mount point inside the container. Also the container has a /etc/singular=
ity/singularity.<wbr>conf file with a &quot;bind path =3D /beegfs=E2=80=9D =
line (is that being used?) - anything else we need to do?=20
<br>&gt;=20
<br>&gt; Many thanks in advance!
<br>&gt; Best,
<br>&gt; Stefan=20
<br>&gt; --=20
<br>&gt; Dr. Stefan Vollmar
<br>&gt; Max Planck Institute for Metabolism Research
<br>
<br></blockquote></div>
------=_Part_197_1406295601.1544606229605--

------=_Part_196_195719698.1544606229605--

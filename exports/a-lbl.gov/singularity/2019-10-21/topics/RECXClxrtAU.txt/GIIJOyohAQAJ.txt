X-Received: by 2002:a65:464f:: with SMTP id k15-v6mr1656578pgr.158.1530150288478;
        Wed, 27 Jun 2018 18:44:48 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 2002:a65:60ce:: with SMTP id r14-v6ls1456112pgv.10.gmail; Wed, 27
 Jun 2018 18:44:47 -0700 (PDT)
X-Received: by 2002:a65:44c3:: with SMTP id g3-v6mr7099706pgs.231.1530150287430;
        Wed, 27 Jun 2018 18:44:47 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1530150287; cv=none;
        d=google.com; s=arc-20160816;
        b=FBgE9j0gQ1Xe9rndgTR7y9M3NdlLyfU4SMJf8P08pBCz2yi+VWrLK2bHni47y3+oB1
         Xb39bv0WFZWBFGimJEfTVD3ki6gPnXgoR9QPhigDJt0mBtFOTYBySZO+WhurqSzpgyHK
         f5do2Go04CgO2rauuth73rVPTQD0OdVUiXRCfKwdMSSweksb5IHho76madM0BRkR1T2a
         cssA5D+e5h0bEdFt1iciRtZC1E88nGkQdL7HQkruaR5G+kOaOKNJPGdgbFmW9mjw66wu
         5wPZFs1ts1Oaq5v/zxvuz8M0HZw213V7x0X6dYhlHRSwcMlMxubcbqmbJlC6AiyJ4ATu
         3KfA==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:in-reply-to:references:mime-version
         :dkim-signature:arc-authentication-results;
        bh=Ituzj1aY7iLyLKn1ArQHsdIuzl7m2hte1AI2IzRfiyw=;
        b=Y4HDIC8+mS5jD8XVhcpTXMy2FRkYYL3Mhz4w0m+0ewDqqJNDOHhUQACaAW5icMvuQ9
         IbiTw+94NXTvAnE1YDtj1vGbyRghuLuIw0ro9n0ECPrk3opfPi58RSyj2XQ8ZksW378U
         fsC5FguwAC53UKbIGgNZ608E0BKiCY49Q1Sz4Z+oK8L9ZFg5Tu7fPwDWsYjEOY6FpYyL
         nTAAdv0rbLO0ny57yQX/stpsOnlUJ83auJrHSKb/lyXps/EHU09/pbtlZymBbzdWhy6T
         j7FLvD8VRghMy8H5VL6aYiMrXOggUR+yV60FLFPW+s8EvAxxbTXlHqjucI+wgB/WMGYJ
         euLA==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=O6tlxxce;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.214.44 as permitted sender) smtp.mailfrom=vso...@gmail.com
Return-Path: <vso...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id r16-v6si4610615pgv.282.2018.06.27.18.44.47
        for <singu...@lbl.gov>;
        Wed, 27 Jun 2018 18:44:47 -0700 (PDT)
Received-SPF: pass (google.com: domain of vso...@gmail.com designates 209.85.214.44 as permitted sender) client-ip=209.85.214.44;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=O6tlxxce;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.214.44 as permitted sender) smtp.mailfrom=vso...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2AQBACmPDRbhizWVdFRCQODUIEMfyiDc?=
 =?us-ascii?q?waBHYJQkFOCB5ARhQcUgWYjAQqBVIJ1AoMZITYWAQIBAQIBAQIBEwEBAQgLCwg?=
 =?us-ascii?q?pIwyCNQUCAwIeglcBAQEBAgEdBgQZAQ0OHgMBCwYFCw0qAgIhAQEOAwEFARwOB?=
 =?us-ascii?q?wQBGgIEgwQBKIE+AQMNCAUKoTI8iVcRgSCBaRYFAReCcgVqgmoKGSYNVleBFAI?=
 =?us-ascii?q?GEohbghWBD4MPglY3CwIBAYEfDAESAQkCNQwagjqCVQKHT4FfgxhqhCWHMCwJh?=
 =?us-ascii?q?gCGCoMJggKLSIonToZvMIEnDFgucXAVbII4CRaCBA4JegEOgjyCZIIwhV4fMAE?=
 =?us-ascii?q?PjXEOFzCBbQUBAQ?=
X-IronPort-AV: E=Sophos;i="5.51,281,1526367600"; 
   d="scan'208,217";a="27828702"
Received: from mail-it0-f44.google.com ([209.85.214.44])
  by fe4.lbl.gov with ESMTP; 27 Jun 2018 18:44:45 -0700
Received: by mail-it0-f44.google.com with SMTP id p17-v6so5246862itc.2
        for <singu...@lbl.gov>; Wed, 27 Jun 2018 18:44:45 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to;
        bh=Ituzj1aY7iLyLKn1ArQHsdIuzl7m2hte1AI2IzRfiyw=;
        b=O6tlxxcerR4IbxRU94BHAIORraUIwpXX4E5Jllmnb5r8ymNWvb4/QC1nYpCiUuunmd
         SkhnoZDTApDD4HPp8Mh+mlcANniliBPkNJSPnQrXinoi1buqSePT+6nZJAjkNH6ihHwM
         Ps7SWxuq/pkuUaE5/K129MNDOag0iNwyUmGwYcHWgeVbjRurhpYsjJDZ7vABtBBuugMH
         AhZlIt227Y/dqzVLWhOtGSLKGaE3kbMRQpfVwGDfXaqV/AvparkTOXqlegcw0Ma2Xma1
         iiULVa3+nLsa8EqHIda3aeXJAufuPOOAKEysE/8J9iZK36gJwTxFV8E5gDp6G3+JmaTu
         LFZQ==
X-Gm-Message-State: APt69E1cLZY0S0YUGCkAu3b4DedUr6f00mbbclefPlkstPgOzhuCZiaC
	0xx6bnltZgrmCvzeMrG56FIPqbrj5jZ8TyPZZ0n4wuxY
X-Received: by 2002:a02:9bc1:: with SMTP id f1-v6mr7176172jal.90.1530150284893;
 Wed, 27 Jun 2018 18:44:44 -0700 (PDT)
MIME-Version: 1.0
References: <4d550130-4d54-4d4f-bf9f-a46f34132e96@lbl.gov> <CAJZ53CkoPup6sXotzVLO_toCu2c+rwK-A6Y0+TU277Y9km8N9w@mail.gmail.com>
 <CAM=pu+Jq2HcgVEBoYJ-USVQomnT6=pmd_16UdEpz2nniPQewdw@mail.gmail.com>
 <CADf5cTEmD1BEEg=jQHf2rrK1h+cwPYYqSD3Tz0UKS-RpumNNRA@mail.gmail.com> <CAMsq4T1c4vA5Yv6_bWJhpNC=UCze1reP2yPQa2YUtutJRPzQbA@mail.gmail.com>
In-Reply-To: <CAMsq4T1c4vA5Yv6_bWJhpNC=UCze1reP2yPQa2YUtutJRPzQbA@mail.gmail.com>
From: v <vso...@gmail.com>
Date: Wed, 27 Jun 2018 18:44:33 -0700
Message-ID: <CAM=pu+L-DXgQJ4eSUqSEnriDX9U2+dwOU-e2P2gWFxW3jsPcWQ@mail.gmail.com>
Subject: Re: [Singularity] Research data and containers
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="0000000000002f222b056fa9e0ba"

--0000000000002f222b056fa9e0ba
Content-Type: text/plain; charset="UTF-8"

Your description of the different components is on point.

Finding hosting for large data is, and will continue to be, always one of
the biggest problems. It's expensive. Someone has to pay for it. Nobody
will do it for you for free. We are lucky to have things like Github repos,
Google Drive, Dropbox, that gives some (mediocre) access to small data. For
large data, everyone is pretty much on their own. Most academics have a
university that provides some sort of web space / library data archive, and
if you are publishing, some journals will support it too -->
https://www.nature.com/sdata/policies/repositories. I try to figure out
hacks to get everything hosted, for free, in version control, but that
breaks when anything gets large.

The entity that manages a data respository, if this is a thing, must have
incentive to do it. The datasets have to bring in money in some way, or
someone has to value it enough to pay for it. That's sort of what most
things come down to, unfortunately.


On Wed, Jun 27, 2018 at 6:38 PM Maxime Hebrard <maxime...@gmail.com>
wrote:

> I start to use singularity / containers and obviously I ran into the
> same question ...
>
> a half solution that I found by exploring existing solution (thanks to
> nf-core and SciLifeLab to share their workflow / containers) is ( as
> far I understand ):
>
> the container encapsulate only the sorftware.
> the data are store in external repositories.
>
> the user receive the container.
>
> case 1:
> the user download the data by himself and point his files to the container
> the container use local files as resources
> pros:
>  * the container is slim
>  * user can store the data on machine A (data server) and run the
> software on machine B (analyse server)
> cons:
> * user is involved in downloading the right data
>
> case 2:
> the user do not have the data
> the container download the data from the external repository
> the container use the data it just download
> pro:
> * the container manage everything
> cons:
> * the step of downloading the data require bandwith + disk space =
> time and resources
>
> a general worry for both scenarii is:
> who manage the data repository ? can we ensure the version of the data
> package will be maintain ?
>
> Waiting for your feedback ;)
> Maxime
>
> On Thu, Jun 28, 2018 at 8:15 AM, 'Chris Hines' via singularity
> <singu...@lbl.gov> wrote:
> > To quote 90's band "The Offspring" IMHO "You gotta keep 'em separated"
> >
> > Personally I think this is a larger question: How do we (as research
> > software engineers, or whatever you would like to call us today) catalog
> and
> > attach references (DOI's I guess) to larger data sets. Does it make
> sense to
> > mksquashfs or tar.bz2? What if they are already in a single hdf5 file?
> And
> > what about the output data set? we obviously want that to land outside
> the
> > computational container, but how should we package the output so it can
> be
> > referenced directly? How do we make that whole thing discoverable and
> > encourage researchers to attach sufficient metadata to make it
> searchable?
> >
> > I'm wondering if part of the solution is some sort of "meta container"
> that
> > downloads a set of versioned data with specific checksums, and a
> versioned
> > tool container with a specific checksum, and attaches them in a
> reproducible
> > way.
> >
> > To address Dominque's question directly: I'd keep the "semi-separated".
> > Whatever your researchers use for archiving/cataloging/managing their
> data
> > sets, keep that in place and add the singularity container to the data
> set
> > (rather than adding the data set to the singularity container).
> >
> > Regards,
> > --
> > Chris.
> > Monash eResearch Centre, Monash University, Australia
> >
> > On Thu, 28 Jun 2018 at 01:19, v <vso...@gmail.com> wrote:
> >>
> >> If you are making containers with singularity (and using Squashfs
> anyway)
> >> it wouldn't be so nutty to just compress with mksquashfs and then mount
> >> where needed - I did this with a huge dataset and it worked pretty
> nicely
> >> :_) It relies on FUSE then and all the issues around that, but it's an
> >> option!
> >>
> >> This is good showing of how use use mksquashfs (it's really
> >> simple,actually!) -->
> >> http://tldp.org/HOWTO/SquashFS-HOWTO/creatingandusing.html
> >> And then mount -->
> >> https://vsoch.github.io/datasets/2018/zenodo/#mount-with-sudo
> >>
> >> On Wed, Jun 27, 2018 at 8:14 AM Brandon Barker
> >> <brando...@cornell.edu> wrote:
> >>>
> >>> I seem to recall code ocean may have explored this idea. Sorry I can't
> >>> say more, at the moment.
> >>>
> >>> On Wed, Jun 27, 2018, 8:50 AM Dominique Hansen
> >>> <dominiqu...@gmail.com> wrote:
> >>>>
> >>>> Hello everyone,
> >>>>
> >>>> I am seeking for tips and experience on how to handle research data,
> >>>> especially bigger sets of data (inside the GB range), in combination
> with
> >>>> containers.
> >>>>
> >>>> I am a student assistant working in the IT department of a research
> >>>> institute. And I am involved in building the infrastructure for
> singularity
> >>>> containerization and introducing researchers to the technology. We
> have
> >>>> already build a few base images containing frequently used tools.
> Recently a
> >>>> research group approached us, wishing to integrate data, they created
> for
> >>>> one tool, into a container with the tool. The data takes up several
> GB of
> >>>> disk space and we are unsure how to handle this and similar future use
> >>>> cases.
> >>>>
> >>>> Does anyone have a set of best practices or is there an intended way
> to
> >>>> use singularity with big research data?
> >>>>
> >>>> The options we considered are:
> >>>>
> >>>> Moving the data into the container at build time.
> >>>>
> >>>> Pro:
> >>>>
> >>>> Keeps the whole thing mobile
> >>>> Keeps work away from the researchers
> >>>> Can be referenced as a single entity in a publication.
> >>>>
> >>>> Con:
> >>>>
> >>>> Where would you store such big containers, especially several of them?
> >>>> What would happen, if separate versions of the tool are needed? Keep
> the
> >>>> old and accumulate redundant data? Delete the old and risk
> reproducibility
> >>>> problems? (Maybe container Apps can be used to minimize this.)
> >>>>
> >>>> Let the researchers mount the data into the container at startup.
> >>>>
> >>>> Pro:
> >>>>
> >>>> Keeps the containers slimmer, the tools more modular.
> >>>>
> >>>> Con:
> >>>>
> >>>> Adds to the workload and the things the researchers have to keep track
> >>>> of.
> >>>> Spreads the parts needed for reproduction over at least two points.
> >>>> Hampers mobility.
> >>>>
> >>>> Mounting during early phases and publish with a container, containing
> >>>> the data.
> >>>>
> >>>> Pro:
> >>>>
> >>>> Reduces amount of containers with redundant and deprecated  data.
> >>>> Makes reproduction of results easier after publication.
> >>>>
> >>>> Con:
> >>>>
> >>>> Ads to the workload.
> >>>> When is the point when its time to "freeze" the data inside the
> >>>> container?
> >>>> Storage of the container is still problematic.
> >>>> Might introduce reproducibility problems, since you change the
> original
> >>>> container to put the data into it.
> >>>>
> >>>> Are there any recommendations from experience?
> >>>>
> >>>> Thank you and best regards,
> >>>> Dominique
> >>>>
> >>>> --
> >>>> You received this message because you are subscribed to the Google
> >>>> Groups "singularity" group.
> >>>> To unsubscribe from this group and stop receiving emails from it, send
> >>>> an email to singu...@lbl.gov.
> >>>
> >>> --
> >>> You received this message because you are subscribed to the Google
> Groups
> >>> "singularity" group.
> >>> To unsubscribe from this group and stop receiving emails from it, send
> an
> >>> email to singu...@lbl.gov.
> >>>
> >>> --
> >>> Vanessa Villamia Sochat
> >>> Stanford University '16
> >>> (603) 321-0676
> >>
> >> --
> >> You received this message because you are subscribed to the Google
> Groups
> >> "singularity" group.
> >> To unsubscribe from this group and stop receiving emails from it, send
> an
> >> email to singu...@lbl.gov.
> >
> > --
> > You received this message because you are subscribed to the Google Groups
> > "singularity" group.
> > To unsubscribe from this group and stop receiving emails from it, send an
> > email to singu...@lbl.gov.
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>


-- 
Vanessa Villamia Sochat
Stanford University '16
(603) 321-0676

--0000000000002f222b056fa9e0ba
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Your description of the different components is on point.=
=C2=A0<div><br></div><div>Finding hosting for large data is, and will conti=
nue to be, always one of the biggest problems. It&#39;s expensive. Someone =
has to pay for it. Nobody will do it for you for free. We are lucky to have=
 things like Github repos, Google Drive, Dropbox, that gives some (mediocre=
) access to small data. For large data, everyone is pretty much on their ow=
n. Most academics have a university that provides some sort of web space / =
library data archive, and if you are publishing, some journals will support=
 it too --&gt;=C2=A0<a href=3D"https://www.nature.com/sdata/policies/reposi=
tories">https://www.nature.com/sdata/policies/repositories</a>. I try to fi=
gure out hacks to get everything hosted, for free, in version control, but =
that breaks when anything gets large.</div><div><br></div><div>The entity t=
hat manages a data respository, if this is a thing, must have incentive to =
do it. The datasets have to bring in money in some way, or someone has to v=
alue it enough to pay for it. That&#39;s sort of what most things come down=
 to, unfortunately.</div><div><br></div></div><br><div class=3D"gmail_quote=
"><div dir=3D"ltr">On Wed, Jun 27, 2018 at 6:38 PM Maxime Hebrard &lt;<a hr=
ef=3D"mailto:maxime...@gmail.com">maxime...@gmail.com</a>&gt; wrote:<br></d=
iv><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex;bord=
er-left:1px solid rgb(204,204,204);padding-left:1ex">I start to use singula=
rity / containers and obviously I ran into the<br>
same question ...<br>
<br>
a half solution that I found by exploring existing solution (thanks to<br>
nf-core and SciLifeLab to share their workflow / containers) is ( as<br>
far I understand ):<br>
<br>
the container encapsulate only the sorftware.<br>
the data are store in external repositories.<br>
<br>
the user receive the container.<br>
<br>
case 1:<br>
the user download the data by himself and point his files to the container<=
br>
the container use local files as resources<br>
pros:<br>
=C2=A0* the container is slim<br>
=C2=A0* user can store the data on machine A (data server) and run the<br>
software on machine B (analyse server)<br>
cons:<br>
* user is involved in downloading the right data<br>
<br>
case 2:<br>
the user do not have the data<br>
the container download the data from the external repository<br>
the container use the data it just download<br>
pro:<br>
* the container manage everything<br>
cons:<br>
* the step of downloading the data require bandwith + disk space =3D<br>
time and resources<br>
<br>
a general worry for both scenarii is:<br>
who manage the data repository ? can we ensure the version of the data<br>
package will be maintain ?<br>
<br>
Waiting for your feedback ;)<br>
Maxime<br>
<br>
On Thu, Jun 28, 2018 at 8:15 AM, &#39;Chris Hines&#39; via singularity<br>
&lt;<a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.gov<=
/a>&gt; wrote:<br>
&gt; To quote 90&#39;s band &quot;The Offspring&quot; IMHO &quot;You gotta =
keep &#39;em separated&quot;<br>
&gt;<br>
&gt; Personally I think this is a larger question: How do we (as research<b=
r>
&gt; software engineers, or whatever you would like to call us today) catal=
og and<br>
&gt; attach references (DOI&#39;s I guess) to larger data sets. Does it mak=
e sense to<br>
&gt; mksquashfs or tar.bz2? What if they are already in a single hdf5 file?=
 And<br>
&gt; what about the output data set? we obviously want that to land outside=
 the<br>
&gt; computational container, but how should we package the output so it ca=
n be<br>
&gt; referenced directly? How do we make that whole thing discoverable and<=
br>
&gt; encourage researchers to attach sufficient metadata to make it searcha=
ble?<br>
&gt;<br>
&gt; I&#39;m wondering if part of the solution is some sort of &quot;meta c=
ontainer&quot; that<br>
&gt; downloads a set of versioned data with specific checksums, and a versi=
oned<br>
&gt; tool container with a specific checksum, and attaches them in a reprod=
ucible<br>
&gt; way.<br>
&gt;<br>
&gt; To address Dominque&#39;s question directly: I&#39;d keep the &quot;se=
mi-separated&quot;.<br>
&gt; Whatever your researchers use for archiving/cataloging/managing their =
data<br>
&gt; sets, keep that in place and add the singularity container to the data=
 set<br>
&gt; (rather than adding the data set to the singularity container).<br>
&gt;<br>
&gt; Regards,<br>
&gt; --<br>
&gt; Chris.<br>
&gt; Monash eResearch Centre, Monash University, Australia<br>
&gt;<br>
&gt; On Thu, 28 Jun 2018 at 01:19, v &lt;<a href=3D"mailto:vso...@gmail.com=
" target=3D"_blank">vso...@gmail.com</a>&gt; wrote:<br>
&gt;&gt;<br>
&gt;&gt; If you are making containers with singularity (and using Squashfs =
anyway)<br>
&gt;&gt; it wouldn&#39;t be so nutty to just compress with mksquashfs and t=
hen mount<br>
&gt;&gt; where needed - I did this with a huge dataset and it worked pretty=
 nicely<br>
&gt;&gt; :_) It relies on FUSE then and all the issues around that, but it&=
#39;s an<br>
&gt;&gt; option!<br>
&gt;&gt;<br>
&gt;&gt; This is good showing of how use use mksquashfs (it&#39;s really<br=
>
&gt;&gt; simple,actually!) --&gt;<br>
&gt;&gt; <a href=3D"http://tldp.org/HOWTO/SquashFS-HOWTO/creatingandusing.h=
tml" rel=3D"noreferrer" target=3D"_blank">http://tldp.org/HOWTO/SquashFS-HO=
WTO/creatingandusing.html</a><br>
&gt;&gt; And then mount --&gt;<br>
&gt;&gt; <a href=3D"https://vsoch.github.io/datasets/2018/zenodo/#mount-wit=
h-sudo" rel=3D"noreferrer" target=3D"_blank">https://vsoch.github.io/datase=
ts/2018/zenodo/#mount-with-sudo</a><br>
&gt;&gt;<br>
&gt;&gt; On Wed, Jun 27, 2018 at 8:14 AM Brandon Barker<br>
&gt;&gt; &lt;<a href=3D"mailto:brando...@cornell.edu" target=3D"_blank">bra=
ndo...@cornell.edu</a>&gt; wrote:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I seem to recall code ocean may have explored this idea. Sorry=
 I can&#39;t<br>
&gt;&gt;&gt; say more, at the moment.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; On Wed, Jun 27, 2018, 8:50 AM Dominique Hansen<br>
&gt;&gt;&gt; &lt;<a href=3D"mailto:dominiqu...@gmail.com" target=3D"_blank"=
>dominiqu...@gmail.com</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Hello everyone,<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; I am seeking for tips and experience on how to handle rese=
arch data,<br>
&gt;&gt;&gt;&gt; especially bigger sets of data (inside the GB range), in c=
ombination with<br>
&gt;&gt;&gt;&gt; containers.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; I am a student assistant working in the IT department of a=
 research<br>
&gt;&gt;&gt;&gt; institute. And I am involved in building the infrastructur=
e for singularity<br>
&gt;&gt;&gt;&gt; containerization and introducing researchers to the techno=
logy. We have<br>
&gt;&gt;&gt;&gt; already build a few base images containing frequently used=
 tools. Recently a<br>
&gt;&gt;&gt;&gt; research group approached us, wishing to integrate data, t=
hey created for<br>
&gt;&gt;&gt;&gt; one tool, into a container with the tool. The data takes u=
p several GB of<br>
&gt;&gt;&gt;&gt; disk space and we are unsure how to handle this and simila=
r future use<br>
&gt;&gt;&gt;&gt; cases.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Does anyone have a set of best practices or is there an in=
tended way to<br>
&gt;&gt;&gt;&gt; use singularity with big research data?<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; The options we considered are:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Moving the data into the container at build time.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Keeps the whole thing mobile<br>
&gt;&gt;&gt;&gt; Keeps work away from the researchers<br>
&gt;&gt;&gt;&gt; Can be referenced as a single entity in a publication.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Where would you store such big containers, especially seve=
ral of them?<br>
&gt;&gt;&gt;&gt; What would happen, if separate versions of the tool are ne=
eded? Keep the<br>
&gt;&gt;&gt;&gt; old and accumulate redundant data? Delete the old and risk=
 reproducibility<br>
&gt;&gt;&gt;&gt; problems? (Maybe container Apps can be used to minimize th=
is.)<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Let the researchers mount the data into the container at s=
tartup.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Keeps the containers slimmer, the tools more modular.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Adds to the workload and the things the researchers have t=
o keep track<br>
&gt;&gt;&gt;&gt; of.<br>
&gt;&gt;&gt;&gt; Spreads the parts needed for reproduction over at least tw=
o points.<br>
&gt;&gt;&gt;&gt; Hampers mobility.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Mounting during early phases and publish with a container,=
 containing<br>
&gt;&gt;&gt;&gt; the data.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Reduces amount of containers with redundant and deprecated=
=C2=A0 data.<br>
&gt;&gt;&gt;&gt; Makes reproduction of results easier after publication.<br=
>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Ads to the workload.<br>
&gt;&gt;&gt;&gt; When is the point when its time to &quot;freeze&quot; the =
data inside the<br>
&gt;&gt;&gt;&gt; container?<br>
&gt;&gt;&gt;&gt; Storage of the container is still problematic.<br>
&gt;&gt;&gt;&gt; Might introduce reproducibility problems, since you change=
 the original<br>
&gt;&gt;&gt;&gt; container to put the data into it.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Are there any recommendations from experience?<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Thank you and best regards,<br>
&gt;&gt;&gt;&gt; Dominique<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt; You received this message because you are subscribed to th=
e Google<br>
&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emails f=
rom it, send<br>
&gt;&gt;&gt;&gt; an email to <a href=3D"mailto:singularity%...@lbl.gov" tar=
get=3D"_blank">singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; --<br>
&gt;&gt;&gt; You received this message because you are subscribed to the Go=
ogle Groups<br>
&gt;&gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt;&gt; To unsubscribe from this group and stop receiving emails from =
it, send an<br>
&gt;&gt;&gt; email to <a href=3D"mailto:singularity%...@lbl.gov" target=3D"=
_blank">singu...@lbl.gov</a>.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; --<br>
&gt;&gt;&gt; Vanessa Villamia Sochat<br>
&gt;&gt;&gt; Stanford University &#39;16<br>
&gt;&gt;&gt; (603) 321-0676<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; You received this message because you are subscribed to the Google=
 Groups<br>
&gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt; To unsubscribe from this group and stop receiving emails from it, =
send an<br>
&gt;&gt; email to <a href=3D"mailto:singularity%...@lbl.gov" target=3D"_bla=
nk">singu...@lbl.gov</a>.<br>
&gt;<br>
&gt; --<br>
&gt; You received this message because you are subscribed to the Google Gro=
ups<br>
&gt; &quot;singularity&quot; group.<br>
&gt; To unsubscribe from this group and stop receiving emails from it, send=
 an<br>
&gt; email to <a href=3D"mailto:singularity%...@lbl.gov" target=3D"_blank">=
singu...@lbl.gov</a>.<br>
<br>
-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singularity%...@lbl.gov" target=3D"_blank">singu.=
..@lbl.gov</a>.<br>
</blockquote></div><br clear=3D"all"><div><br></div>-- <br><div dir=3D"ltr"=
 class=3D"gmail_signature"><div class=3D"gmail_signature">Vanessa Villamia =
Sochat<br>Stanford University &#39;16<br><div><div><div>(603) 321-0676</div=
></div></div></div></div>

--0000000000002f222b056fa9e0ba--

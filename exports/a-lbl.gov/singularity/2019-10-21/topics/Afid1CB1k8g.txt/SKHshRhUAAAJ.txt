X-Received: by 10.13.254.67 with SMTP id o64mr606522ywf.164.1494350577082;
        Tue, 09 May 2017 10:22:57 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.36.90.66 with SMTP id v63ls342661ita.0.gmail; Tue, 09 May 2017
 10:22:56 -0700 (PDT)
X-Received: by 10.98.65.216 with SMTP id g85mr1075317pfd.187.1494350575428;
        Tue, 09 May 2017 10:22:55 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1494350575; cv=none;
        d=google.com; s=arc-20160816;
        b=uPW3U+D9KGWxe8uMAUfvMtGbG4tOeFNbQ8M1VqtX8k2pDffPTOAP8b7fTAT6CGOR6b
         UTfzGEoDXR5HbjDAR9HvOfCDeM8h3HEZnXpDSE4kADZcbuHmJXGmBaIB9pfO1o0UUNlQ
         1rab3w4hwzucrcsHHlo3h6xUgHVUR4GEPC/K0sdaZl1E6Sv2F8Fo7vqlqp9/x9QnuLt7
         uNH4KguvP54rK97gxpsPs6OIDtOPQMMpGcon0BzqwkDdCtjVUXabpjEolrdMMcbBgeX9
         ZaiH4cT9Gb0FKP5s7hKfnF/UuLeH/XJgYHOdTK9QQW1xzyFML3Z2xoxy0JaIwqhmxrGu
         BINg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:references:in-reply-to:mime-version
         :dkim-signature:arc-authentication-results;
        bh=NDjGvD143CFNIfyXX2DuuT4dxQ9AYdqvPKe2PExUEfU=;
        b=bnliy2eJnMrWr7CCiuEhSEAAsYujBFRp744W/gx4F2L8nKe4v3EsRetdcb1oZUuqY4
         6NLBZibnec1YslOqngM5wpFW6+Ue1BM06jmb2ggJuJwSolOKtsWPkHtRuR2FDxBFJfiB
         ztE/WGs/tHwyrKUFQeN9bAK6rhwvTwxWYyHM/kpO0r/zxohL5pvcsFg51GKFpWfuyC7e
         3ObJtWBevx1sttPpJHXrwAq6UtOaF7bGxsqgpJH2IYEL+nnkcRBg0qgvcnwJYyeCb+tC
         PkEjXjXn4z5X9UL5ZTveI7p8wZZfjstoQzFP5+hxZcjLpdZLHW9kqdonESOAKn8/gUoI
         RkOg==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of gmku...@gmail.com designates 209.85.214.51 as permitted sender) smtp.mailfrom=gmku...@gmail.com
Return-Path: <gmku...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id z69si431999pgz.228.2017.05.09.10.22.55
        for <singu...@lbl.gov>;
        Tue, 09 May 2017 10:22:55 -0700 (PDT)
Received-SPF: pass (google.com: domain of gmku...@gmail.com designates 209.85.214.51 as permitted sender) client-ip=209.85.214.51;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of gmku...@gmail.com designates 209.85.214.51 as permitted sender) smtp.mailfrom=gmku...@gmail.com
X-Ironport-SBRS: 2.7
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2HvAADf+RFZfzPWVdFdHAEBBAEBCgEBF?=
 =?us-ascii?q?wEBBAEBCgEBgwGBC4EMB4NaCIoYkVaVcoFMQyEBCoV4AoRlBz8YAQEBAQEBAQE?=
 =?us-ascii?q?BAQECEAEBCQsLCCYxgjMEAgMZBQQERiEILwEBAQEBAQEBAQEBAQEBAQEZAisMG?=
 =?us-ascii?q?QEBGAEBAQECASMdAQgFDh4DAQsGBQsNIAoCAiEBAQ4DAQUBCxEOBwQBHASINIE?=
 =?us-ascii?q?zAQMNCAUJph0/jAiCBAUBHIMKBYNSChknDVaCYgEBCAEBAQEBARoCBhKFWoVsg?=
 =?us-ascii?q?kQQgWASAQaDIIJfBYoyhnWFRoZdOwGKToN3hFORa4sqJ4cnFB+BFR94DTMLcHS?=
 =?us-ascii?q?ETIIuIDYHhj9HgWcBAQE?=
X-IronPort-AV: E=Sophos;i="5.38,315,1491289200"; 
   d="scan'208,217";a="74176516"
Received: from mail-it0-f51.google.com ([209.85.214.51])
  by fe3.lbl.gov with ESMTP; 09 May 2017 10:22:48 -0700
Received: by mail-it0-f51.google.com with SMTP id o5so9893351ith.1
        for <singu...@lbl.gov>; Tue, 09 May 2017 10:22:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=NDjGvD143CFNIfyXX2DuuT4dxQ9AYdqvPKe2PExUEfU=;
        b=kWgjOoQ009qgeLLmB/zFwc6rf0oc5D1zdAnD5jtM6E1pM7aotJdnnc/rKDItTfNzYs
         dHOaqCQdDO2M4XtqM6aGB4WSCyr82hu/66G8COtFVpPGfeyVZTjXxxUdA0NQt0GugjLJ
         18dUPgOXNOkB0sxO7SrUev1BAS67JUTXsi2JeFoH3ChdNlAcQIXGLAfUfHLeKlkZ6AiQ
         /f311Ivjc9HcSOAqAqwNhqU5dLaEF+tjCnJNHvh4dRWUSy0vGfnsqxcqdYqwIUTZ8mPR
         /3dpWGodkX5TswSHGwrLOjxTB5qK/1OVQRvgFqBgn2otFuOeY6Um6PCji5T7p6hCdSY6
         Upxw==
X-Gm-Message-State: AODbwcB6g6g//5Dx3SFYY/hPQj9LxHQulfXkq/Oi2WjZ+33yeCPw+oag
	RvqqjJctOjVWVgPR5UOOkFPRSl0FxL9u
X-Received: by 10.36.162.72 with SMTP id o8mr1444286iti.42.1494350568087; Tue,
 09 May 2017 10:22:48 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.107.175.69 with HTTP; Tue, 9 May 2017 10:22:47 -0700 (PDT)
In-Reply-To: <CA+KhMPuEDbs3KhwsnWbcuXOa81fa9ycmRuXVt8iHchFsXULw8g@mail.gmail.com>
References: <a0e56124-ca94-41e3-b45e-95bb975f3a5b@lbl.gov> <CAApQTTivqe1aPi+WKiojxmU=9KzKRsWc_MHgnxB8_Ld8nkk+4Q@mail.gmail.com>
 <2584fc67-fbbd-444a-9a28-e95be7c10e32@lbl.gov> <CAApQTTj2E4ax8YwJHr78VtPi86Evo0d8T7L_6t2VBMfmN3eegw@mail.gmail.com>
 <3259b1a2-9dc7-4a02-8922-235390a3f907@lbl.gov> <CAApQTTjJfSQmZpJ=H=jNpKV-CJ9dVtuYCf-Pwc9vfcrg9md7CQ@mail.gmail.com>
 <CA+KhMPuEDbs3KhwsnWbcuXOa81fa9ycmRuXVt8iHchFsXULw8g@mail.gmail.com>
From: "Gregory M. Kurtzer" <gmku...@gmail.com>
Date: Tue, 9 May 2017 10:22:47 -0700
Message-ID: <CAApQTTiczBgFqvCQCiXbnJj6=N28A6EfujCc=G4HXBfFTf+f4A@mail.gmail.com>
Subject: Re: [Singularity] Issue with MPI and Singularity
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=f403045fc05cc7fb0d054f1a9a7a

--f403045fc05cc7fb0d054f1a9a7a
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi Jerrin,

How many processors/cores do you have per node? If it is less then 20 (as
you showed in your Singularity example), then it would still fit on a
single node.

Thanks!

On Tue, May 9, 2017 at 10:18 AM, Jerrin Suresh <jerrin...@gmail.com>
wrote:

> Oops, sorry about that. Nope, we just have the hostname of the compute
> nodes in the hosts file.
>
> ~~~~
> :~> cat hosts
> nid00900
> nid00901
> ~~~~
>
> In addition, the MPI setup in the server is working fine. However, it's
> when using singularity that we are facing the issue.
>
> ~~~~
> aprun1:~> ccmrun mpirun -np 20 --hostfile hosts singularity exec mpi.img
> /usr/bin/ring
> =E2=80=9Copenmpi=E2=80=9D version =E2=80=9C1.8.4=E2=80=9D loaded.
> Hello world!  I am process number: 8 on host nid00900
> Hello world!  I am process number: 9 on host nid00900
> Hello world!  I am process number: 10 on host nid00900
> Hello world!  I am process number: 11 on host nid00900
> Hello world!  I am process number: 12 on host nid00900
> Hello world!  I am process number: 13 on host nid00900
> Hello world!  I am process number: 14 on host nid00900
> Hello world!  I am process number: 15 on host nid00900
> Hello world!  I am process number: 16 on host nid00900
> Hello world!  I am process number: 17 on host nid00900
> Hello world!  I am process number: 18 on host nid00900
> Hello world!  I am process number: 19 on host nid00900
> Hello world!  I am process number: 0 on host nid00900
> Hello world!  I am process number: 1 on host nid00900
> Hello world!  I am process number: 2 on host nid00900
> Hello world!  I am process number: 3 on host nid00900
> Hello world!  I am process number: 4 on host nid00900
> Hello world!  I am process number: 6 on host nid00900
> Hello world!  I am process number: 7 on host nid00900
> Hello world!  I am process number: 5 on host nid00900
> Application 8102212 resources: utime ~2s, stime ~3s, Rss ~5672, inblocks
> ~62653, outblocks ~1812
> ~~~~
>
> Without singularity,
>
> ~~~~
>
> :~> ccmrun mpirun -n 64 --hostfile hosts ./a.out
>
> Hello world!  I am process number: 0 on host nid00922
> Hello world!  I am process number: 2 on host nid00922
> Hello world!  I am process number: 4 on host nid00922
> Hello world!  I am process number: 6 on host nid00922
> Hello world!  I am process number: 8 on host nid00922
> Hello world!  I am process number: 10 on host nid00922
> Hello world!  I am process number: 14 on host nid00922
> Hello world!  I am process number: 15 on host nid00922
> Hello world!  I am process number: 16 on host nid00922
> Hello world!  I am process number: 17 on host nid00922
> Hello world!  I am process number: 18 on host nid00922
> Hello world!  I am process number: 19 on host nid00922
> Hello world!  I am process number: 20 on host nid00922
> Hello world!  I am process number: 21 on host nid00922
> Hello world!  I am process number: 22 on host nid00922
> Hello world!  I am process number: 23 on host nid00922
> Hello world!  I am process number: 24 on host nid00922
> Hello world!  I am process number: 25 on host nid00922
> Hello world!  I am process number: 26 on host nid00922
> Hello world!  I am process number: 27 on host nid00922
> Hello world!  I am process number: 28 on host nid00922
> Hello world!  I am process number: 29 on host nid00922
> Hello world!  I am process number: 30 on host nid00922
> Hello world!  I am process number: 31 on host nid00922
> Hello world!  I am process number: 1 on host nid00922
> Hello world!  I am process number: 3 on host nid00922
> Hello world!  I am process number: 5 on host nid00922
> Hello world!  I am process number: 7 on host nid00922
> Hello world!  I am process number: 9 on host nid00922
> Hello world!  I am process number: 11 on host nid00922
> Hello world!  I am process number: 12 on host nid00922
> Hello world!  I am process number: 13 on host nid00922
> Hello world!  I am process number: 32 on host nid00923
> Hello world!  I am process number: 34 on host nid00923
> Hello world!  I am process number: 50 on host nid00923
> Hello world!  I am process number: 51 on host nid00923
> Hello world!  I am process number: 52 on host nid00923
> Hello world!  I am process number: 53 on host nid00923
> Hello world!  I am process number: 54 on host nid00923
> Hello world!  I am process number: 55 on host nid00923
> Hello world!  I am process number: 56 on host nid00923
> Hello world!  I am process number: 57 on host nid00923
> Hello world!  I am process number: 58 on host nid00923
> Hello world!  I am process number: 59 on host nid00923
> Hello world!  I am process number: 60 on host nid00923
> Hello world!  I am process number: 61 on host nid00923
> Hello world!  I am process number: 62 on host nid00923
> Hello world!  I am process number: 63 on host nid00923
> Hello world!  I am process number: 33 on host nid00923
> Hello world!  I am process number: 35 on host nid00923
> Hello world!  I am process number: 36 on host nid00923
> Hello world!  I am process number: 37 on host nid00923
> Hello world!  I am process number: 38 on host nid00923
> Hello world!  I am process number: 39 on host nid00923
> Hello world!  I am process number: 40 on host nid00923
> Hello world!  I am process number: 41 on host nid00923
> Hello world!  I am process number: 42 on host nid00923
> Hello world!  I am process number: 43 on host nid00923
> Hello world!  I am process number: 44 on host nid00923
> Hello world!  I am process number: 45 on host nid00923
> Hello world!  I am process number: 46 on host nid00923
> Hello world!  I am process number: 47 on host nid00923
> Hello world!  I am process number: 48 on host nid00923
> Hello world!  I am process number: 49 on host nid00923
>
> ~~~~
> ~jerrin
>
> On Tue, May 9, 2017 at 1:01 PM, Gregory M. Kurtzer <gmku...@gmail.com>
> wrote:
>
>> Oh, about the hosts file, I mean what is the order of the hosts, is the
>> local host also present, do you provide the default and max number of
>> slots, etc..
>>
>> Thanks!
>>
>> On Tue, May 9, 2017 at 9:56 AM, jerrin <jerrin...@gmail.com> wrote:
>>
>>> Okay, l can try with a higher version of OpenMPI on both the container
>>> as well as host.
>>>
>>> :~> file hosts
>>>
>>> hosts: ASCII text
>>>
>>> On Tuesday, May 9, 2017 at 12:36:49 PM UTC-4, Gregory Kurtzer wrote:
>>>>
>>>> Well, I've had issues running Open MPI < 2.x with Singularity (on both
>>>> host and container).
>>>>
>>>> BTW, I'm just curious, what is the format of the hosts file?
>>>>
>>>> On Tue, May 9, 2017 at 9:29 AM, jerrin <jer...@gmail.com> wrote:
>>>>
>>>>> I can try that on a different server. But the highest version of
>>>>> OpenMPI on the HPC system is 1.8.4. Is this something related to old
>>>>> version of openmpi?
>>>>>
>>>>> On Tuesday, May 9, 2017 at 11:27:41 AM UTC-4, Gregory Kurtzer wrote:
>>>>>>
>>>>>> Can you re-test with the Open MPI version inside and outside the
>>>>>> container being something greater then 2.x?
>>>>>>
>>>>>> Thanks!
>>>>>>
>>>>>> On Tue, May 9, 2017 at 8:14 AM, jerrin <jer...@gmail.com> wrote:
>>>>>>
>>>>>>> Hi,
>>>>>>>
>>>>>>> I am trying to set up MPI with Singularity. I had set up openmpi
>>>>>>> version 1.8.4 in the container as the host system has the same open=
mpi
>>>>>>> version. However, the container does not understand that there are =
2
>>>>>>> compute nodes even after specifying a hosts file. So each time I sp=
awn the
>>>>>>> MPI processes it just executes on a single node. The contents of th=
e hosts
>>>>>>> file is nid00900,nid00901.
>>>>>>>
>>>>>>> ~~~~~~
>>>>>>> aprun1:~> ccmrun mpirun -np 20 --hostfile hosts singularity exec
>>>>>>> mpi.img /usr/bin/ring
>>>>>>>
>>>>>>> =E2=80=9Copenmpi=E2=80=9D version =E2=80=9C1.8.4=E2=80=9D loaded.
>>>>>>> Hello world! I am process number: 8 on host nid00900
>>>>>>> Hello world! I am process number: 9 on host nid00900
>>>>>>> Hello world! I am process number: 10 on host nid00900
>>>>>>> Hello world! I am process number: 11 on host nid00900
>>>>>>> Hello world! I am process number: 12 on host nid00900
>>>>>>> Hello world! I am process number: 13 on host nid00900
>>>>>>> Hello world! I am process number: 14 on host nid00900
>>>>>>> Hello world! I am process number: 15 on host nid00900
>>>>>>> Hello world! I am process number: 16 on host nid00900
>>>>>>> Hello world! I am process number: 17 on host nid00900
>>>>>>> Hello world! I am process number: 18 on host nid00900
>>>>>>> Hello world! I am process number: 19 on host nid00900
>>>>>>> Hello world! I am process number: 0 on host nid00900
>>>>>>> Hello world! I am process number: 1 on host nid00900
>>>>>>> Hello world! I am process number: 2 on host nid00900
>>>>>>> Hello world! I am process number: 3 on host nid00900
>>>>>>> Hello world! I am process number: 4 on host nid00900
>>>>>>> Hello world! I am process number: 6 on host nid00900
>>>>>>> Hello world! I am process number: 7 on host nid00900
>>>>>>> Hello world! I am process number: 5 on host nid00900
>>>>>>>
>>>>>>> Application 8102212 resources: utime ~2s, stime ~3s, Rss ~5672,
>>>>>>> inblocks ~62653, outblocks ~1812
>>>>>>> ~~~~~~
>>>>>>>
>>>>>>> In addition, the singularity version in the host is 2.2.1
>>>>>>>
>>>>>>>
>>>>>>> Regards,
>>>>>>> Jerrin
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>
>>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, sen=
d
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>
>>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>> --
>> You received this message because you are subscribed to the Google Group=
s
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n
>> email to singu...@lbl.gov.
>>
>
>
>
> --
> MS CS Fall-16
> Indiana University
> www.linkedin.com/in/jerrinsuresh
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--f403045fc05cc7fb0d054f1a9a7a
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi Jerrin,<div><br></div><div>How many processors/cores do=
 you have per node? If it is less then 20 (as you showed in your Singularit=
y example), then it would still fit on a single node.</div><div><br></div><=
div>Thanks!</div></div><div class=3D"gmail_extra"><br><div class=3D"gmail_q=
uote">On Tue, May 9, 2017 at 10:18 AM, Jerrin Suresh <span dir=3D"ltr">&lt;=
<a href=3D"mailto:jerrin...@gmail.com" target=3D"_blank">jerrin...@gmail.co=
m</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margi=
n:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">=
Oops, sorry about that. Nope, we just have the hostname of the compute node=
s in the hosts file.<div><br></div><div>~~~~</div>:~&gt; cat hosts <br>nid0=
0900<br>nid00901<div>~~~~</div><div><br></div><div>In addition, the MPI set=
up in the server is working fine. However, it&#39;s when using singularity =
that we are facing the issue.=C2=A0</div><div><div class=3D"h5"><div><br></=
div><div>~~~~</div><div><div>a<font size=3D"1">prun1:~&gt; ccmrun mpirun -n=
p 20 --hostfile hosts singularity exec mpi.img /usr/bin/ring</font></div><d=
iv><font size=3D"1">=E2=80=9Copenmpi=E2=80=9D version =E2=80=9C1.8.4=E2=80=
=9D loaded.</font></div><div><font size=3D"1">Hello world!=C2=A0 I am proce=
ss number: 8 on host nid00900</font></div><div><font size=3D"1">Hello world=
!=C2=A0 I am process number: 9 on host nid00900</font></div><div><font size=
=3D"1">Hello world!=C2=A0 I am process number: 10 on host nid00900</font></=
div><div><font size=3D"1">Hello world!=C2=A0 I am process number: 11 on hos=
t nid00900</font></div><div><font size=3D"1">Hello world!=C2=A0 I am proces=
s number: 12 on host nid00900</font></div><div><font size=3D"1">Hello world=
!=C2=A0 I am process number: 13 on host nid00900</font></div><div><font siz=
e=3D"1">Hello world!=C2=A0 I am process number: 14 on host nid00900</font><=
/div><div><font size=3D"1">Hello world!=C2=A0 I am process number: 15 on ho=
st nid00900</font></div><div><font size=3D"1">Hello world!=C2=A0 I am proce=
ss number: 16 on host nid00900</font></div><div><font size=3D"1">Hello worl=
d!=C2=A0 I am process number: 17 on host nid00900</font></div><div><font si=
ze=3D"1">Hello world!=C2=A0 I am process number: 18 on host nid00900</font>=
</div><div><font size=3D"1">Hello world!=C2=A0 I am process number: 19 on h=
ost nid00900</font></div><div><font size=3D"1">Hello world!=C2=A0 I am proc=
ess number: 0 on host nid00900</font></div><div><font size=3D"1">Hello worl=
d!=C2=A0 I am process number: 1 on host nid00900</font></div><div><font siz=
e=3D"1">Hello world!=C2=A0 I am process number: 2 on host nid00900</font></=
div><div><font size=3D"1">Hello world!=C2=A0 I am process number: 3 on host=
 nid00900</font></div><div><font size=3D"1">Hello world!=C2=A0 I am process=
 number: 4 on host nid00900</font></div><div><font size=3D"1">Hello world!=
=C2=A0 I am process number: 6 on host nid00900</font></div><div><font size=
=3D"1">Hello world!=C2=A0 I am process number: 7 on host nid00900</font></d=
iv><div><font size=3D"1">Hello world!=C2=A0 I am process number: 5 on host =
nid00900</font></div><div><font size=3D"1">Application 8102212 resources: u=
time ~2s, stime ~3s, Rss ~5672, inblocks ~62653, outblocks ~1812</font></di=
v></div><div>~~~~</div><div><br></div></div></div><div>Without singularity,=
</div><div><br></div><div>~~~~</div><div>







<p class=3D"m_-4455386444432382273gmail-p1"><font size=3D"1"><span class=3D=
"m_-4455386444432382273gmail-s1">:~&gt; ccmrun mpirun </span><span class=3D=
"m_-4455386444432382273gmail-s2">-n</span><span class=3D"m_-445538644443238=
2273gmail-s1"> </span><span class=3D"m_-4455386444432382273gmail-s3">64</sp=
an><span class=3D"m_-4455386444432382273gmail-s1"> </span><span class=3D"m_=
-4455386444432382273gmail-s2">--hostfile</span><span class=3D"m_-4455386444=
432382273gmail-s1"> hosts ./a.out</span></font></p></div><div><p class=3D"m=
_-4455386444432382273gmail-p1"><font size=3D"1">Hello world!=C2=A0 I am pro=
cess number: 0 on host nid00922<br>Hello world!=C2=A0 I am process number: =
2 on host nid00922<br>Hello world!=C2=A0 I am process number: 4 on host nid=
00922<br>Hello world!=C2=A0 I am process number: 6 on host nid00922<br>Hell=
o world!=C2=A0 I am process number: 8 on host nid00922<br>Hello world!=C2=
=A0 I am process number: 10 on host nid00922<br>Hello world!=C2=A0 I am pro=
cess number: 14 on host nid00922<br>Hello world!=C2=A0 I am process number:=
 15 on host nid00922<br>Hello world!=C2=A0 I am process number: 16 on host =
nid00922<br>Hello world!=C2=A0 I am process number: 17 on host nid00922<br>=
Hello world!=C2=A0 I am process number: 18 on host nid00922<br>Hello world!=
=C2=A0 I am process number: 19 on host nid00922<br>Hello world!=C2=A0 I am =
process number: 20 on host nid00922<br>Hello world!=C2=A0 I am process numb=
er: 21 on host nid00922<br>Hello world!=C2=A0 I am process number: 22 on ho=
st nid00922<br>Hello world!=C2=A0 I am process number: 23 on host nid00922<=
br>Hello world!=C2=A0 I am process number: 24 on host nid00922<br>Hello wor=
ld!=C2=A0 I am process number: 25 on host nid00922<br>Hello world!=C2=A0 I =
am process number: 26 on host nid00922<br>Hello world!=C2=A0 I am process n=
umber: 27 on host nid00922<br>Hello world!=C2=A0 I am process number: 28 on=
 host nid00922<br>Hello world!=C2=A0 I am process number: 29 on host nid009=
22<br>Hello world!=C2=A0 I am process number: 30 on host nid00922<br>Hello =
world!=C2=A0 I am process number: 31 on host nid00922<br>Hello world!=C2=A0=
 I am process number: 1 on host nid00922<br>Hello world!=C2=A0 I am process=
 number: 3 on host nid00922<br>Hello world!=C2=A0 I am process number: 5 on=
 host nid00922<br>Hello world!=C2=A0 I am process number: 7 on host nid0092=
2<br>Hello world!=C2=A0 I am process number: 9 on host nid00922<br>Hello wo=
rld!=C2=A0 I am process number: 11 on host nid00922<br>Hello world!=C2=A0 I=
 am process number: 12 on host nid00922<br>Hello world!=C2=A0 I am process =
number: 13 on host nid00922<br>Hello world!=C2=A0 I am process number: 32 o=
n host nid00923<br>Hello world!=C2=A0 I am process number: 34 on host nid00=
923<br>Hello world!=C2=A0 I am process number: 50 on host nid00923<br>Hello=
 world!=C2=A0 I am process number: 51 on host nid00923<br>Hello world!=C2=
=A0 I am process number: 52 on host nid00923<br>Hello world!=C2=A0 I am pro=
cess number: 53 on host nid00923<br>Hello world!=C2=A0 I am process number:=
 54 on host nid00923<br>Hello world!=C2=A0 I am process number: 55 on host =
nid00923<br>Hello world!=C2=A0 I am process number: 56 on host nid00923<br>=
Hello world!=C2=A0 I am process number: 57 on host nid00923<br>Hello world!=
=C2=A0 I am process number: 58 on host nid00923<br>Hello world!=C2=A0 I am =
process number: 59 on host nid00923<br>Hello world!=C2=A0 I am process numb=
er: 60 on host nid00923<br>Hello world!=C2=A0 I am process number: 61 on ho=
st nid00923<br>Hello world!=C2=A0 I am process number: 62 on host nid00923<=
br>Hello world!=C2=A0 I am process number: 63 on host nid00923<br>Hello wor=
ld!=C2=A0 I am process number: 33 on host nid00923<br>Hello world!=C2=A0 I =
am process number: 35 on host nid00923<br>Hello world!=C2=A0 I am process n=
umber: 36 on host nid00923<br>Hello world!=C2=A0 I am process number: 37 on=
 host nid00923<br>Hello world!=C2=A0 I am process number: 38 on host nid009=
23<br>Hello world!=C2=A0 I am process number: 39 on host nid00923<br>Hello =
world!=C2=A0 I am process number: 40 on host nid00923<br>Hello world!=C2=A0=
 I am process number: 41 on host nid00923<br>Hello world!=C2=A0 I am proces=
s number: 42 on host nid00923<br>Hello world!=C2=A0 I am process number: 43=
 on host nid00923<br>Hello world!=C2=A0 I am process number: 44 on host nid=
00923<br>Hello world!=C2=A0 I am process number: 45 on host nid00923<br>Hel=
lo world!=C2=A0 I am process number: 46 on host nid00923<br>Hello world!=C2=
=A0 I am process number: 47 on host nid00923<br>Hello world!=C2=A0 I am pro=
cess number: 48 on host nid00923<br>Hello world!=C2=A0 I am process number:=
 49 on host nid00923</font></p><p class=3D"m_-4455386444432382273gmail-p1">=
~~~~</p></div><div>~jerrin</div></div><div class=3D"gmail_extra"><div><div =
class=3D"h5"><br><div class=3D"gmail_quote">On Tue, May 9, 2017 at 1:01 PM,=
 Gregory M. Kurtzer <span dir=3D"ltr">&lt;<a href=3D"mailto:gmku...@gmail.c=
om" target=3D"_blank">gmku...@gmail.com</a>&gt;</span> wrote:<br><blockquot=
e class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc sol=
id;padding-left:1ex"><div dir=3D"ltr">Oh, about the hosts file, I mean what=
 is the order of the hosts, is the local host also present, do you provide =
the default and max number of slots, etc..<div><br></div><div>Thanks!</div>=
</div><div class=3D"m_-4455386444432382273HOEnZb"><div class=3D"m_-44553864=
44432382273h5"><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On=
 Tue, May 9, 2017 at 9:56 AM, jerrin <span dir=3D"ltr">&lt;<a href=3D"mailt=
o:jerrin...@gmail.com" target=3D"_blank">jerrin...@gmail.com</a>&gt;</span>=
 wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;bor=
der-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Okay, l can try =
with a higher version of OpenMPI on both the container as well as host.=C2=
=A0<div><br></div><div>







<p class=3D"m_-4455386444432382273m_-226751292281952031m_889220570339195763=
1p1"><span class=3D"m_-4455386444432382273m_-226751292281952031m_8892205703=
391957631s1">:~&gt; file hosts=C2=A0</span></p>
<p class=3D"m_-4455386444432382273m_-226751292281952031m_889220570339195763=
1p1"><span class=3D"m_-4455386444432382273m_-226751292281952031m_8892205703=
391957631s1">hosts: ASCII text</span></p><div><span><br>On Tuesday, May 9, =
2017 at 12:36:49 PM UTC-4, Gregory Kurtzer wrote:</span><blockquote class=
=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc s=
olid;padding-left:1ex"><span><div dir=3D"ltr">Well, I&#39;ve had issues run=
ning Open MPI &lt; 2.x with Singularity (on both host and container).<div><=
br></div><div>BTW, I&#39;m just curious, what is the format of the hosts fi=
le?</div></div></span><div><div class=3D"m_-4455386444432382273m_-226751292=
281952031h5"><div><br><div class=3D"gmail_quote">On Tue, May 9, 2017 at 9:2=
9 AM, jerrin <span dir=3D"ltr">&lt;<a rel=3D"nofollow">jer...@gmail.com</a>=
&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0=
 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">I can=
 try that on a different server. But the highest version of OpenMPI on the =
HPC system is 1.8.4. Is this something related to old version of openmpi?<s=
pan><br><br>On Tuesday, May 9, 2017 at 11:27:41 AM UTC-4, Gregory Kurtzer w=
rote:</span><blockquote class=3D"gmail_quote" style=3D"margin:0;margin-left=
:0.8ex;border-left:1px #ccc solid;padding-left:1ex"><span><div dir=3D"ltr">=
Can you re-test with the Open MPI version inside and outside the container =
being something greater then 2.x?<div><br></div><div>Thanks!</div></div></s=
pan><div><br><div class=3D"gmail_quote"><div><div>On Tue, May 9, 2017 at 8:=
14 AM, jerrin <span dir=3D"ltr">&lt;<a rel=3D"nofollow">jer...@gmail.com</a=
>&gt;</span> wrote:<br></div></div><blockquote class=3D"gmail_quote" style=
=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div><di=
v><div dir=3D"ltr">Hi,<div><br></div><div>I am trying to set up MPI with Si=
ngularity. I had set up openmpi version 1.8.4 in the container as the host =
system has the same openmpi version. However, the container does not unders=
tand that there are 2 compute nodes even after specifying=C2=A0a hosts file=
. So each time I spawn the MPI processes it just executes on a single node.=
 The contents of the hosts file is=C2=A0nid00900,nid00901.</div>







<div><br></div><div>~~~~~~</div>aprun1:~&gt; ccmrun mpirun -np 20 --hostfil=
e hosts singularity exec mpi.img /usr/bin/ring <br><br>=E2=80=9Copenmpi=E2=
=80=9D version =E2=80=9C1.8.4=E2=80=9D loaded. <br>Hello world! I am proces=
s number: 8 on host nid00900 <br>Hello world! I am process number: 9 on hos=
t nid00900 <br>Hello world! I am process number: 10 on host nid00900 <br>He=
llo world! I am process number: 11 on host nid00900 <br>Hello world! I am p=
rocess number: 12 on host nid00900 <br>Hello world! I am process number: 13=
 on host nid00900 <br>Hello world! I am process number: 14 on host nid00900=
 <br>Hello world! I am process number: 15 on host nid00900 <br>Hello world!=
 I am process number: 16 on host nid00900 <br>Hello world! I am process num=
ber: 17 on host nid00900 <br>Hello world! I am process number: 18 on host n=
id00900 <br>Hello world! I am process number: 19 on host nid00900<br>Hello =
world! I am process number: 0 on host nid00900 <br>Hello world! I am proces=
s number: 1 on host nid00900 <br>Hello world! I am process number: 2 on hos=
t nid00900 <br>Hello world! I am process number: 3 on host nid00900 <br>Hel=
lo world! I am process number: 4 on host nid00900 <br>Hello world! I am pro=
cess number: 6 on host nid00900 <br>Hello world! I am process number: 7 on =
host nid00900 <br>Hello world! I am process number: 5 on host nid00900 <br>=
<br>Application 8102212 resources: utime ~2s, stime ~3s, Rss ~5672, inblock=
s ~62653, outblocks ~1812<div>~~~~~~</div><div><br></div><div>In addition, =
the singularity version in the host is 2.2.1</div><div><br></div><div><br><=
/div><div>Regards,</div><div>Jerrin=C2=A0</div></div></div></div><span><fon=
t color=3D"#888888"><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br></div></div>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</font></span></blockquote></div><br></div>
</blockquote></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div></div></div><div class=3D"m_-445538644443238=
2273m_-226751292281952031HOEnZb"><div class=3D"m_-4455386444432382273m_-226=
751292281952031h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div></div><=
/div><span class=3D"HOEnZb"><font color=3D"#888888">-- <br><div class=3D"m_=
-4455386444432382273gmail_signature" data-smartmail=3D"gmail_signature"><di=
v dir=3D"ltr"><div><div dir=3D"ltr"><div><div>MS CS Fall-16<br></div><div>I=
ndiana University<br><span><span><a href=3D"http://www.linkedin.com/in/" ta=
rget=3D"_blank">www.linkedin.com/in/</a></span><span>jerrinsure<wbr>sh</spa=
n></span><br></div><div dir=3D"ltr"><div><div><br></div></div></div></div><=
/div></div></div></div>
</font></span></div><div class=3D"HOEnZb"><div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

--f403045fc05cc7fb0d054f1a9a7a--

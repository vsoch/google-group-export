X-Received: by 10.107.46.135 with SMTP id u7mr4192535iou.14.1488444629355;
        Thu, 02 Mar 2017 00:50:29 -0800 (PST)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.16.98 with SMTP id y95ls362582ioi.8.gmail; Thu, 02 Mar
 2017 00:50:28 -0800 (PST)
X-Received: by 10.99.156.2 with SMTP id f2mr14307174pge.189.1488444628381;
        Thu, 02 Mar 2017 00:50:28 -0800 (PST)
Return-Path: <rem...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id o9si6848236pge.380.2017.03.02.00.50.28
        for <singu...@lbl.gov>;
        Thu, 02 Mar 2017 00:50:28 -0800 (PST)
Received-SPF: pass (google.com: domain of rem...@gmail.com designates 74.125.82.179 as permitted sender) client-ip=74.125.82.179;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of rem...@gmail.com designates 74.125.82.179 as permitted sender) smtp.mailfrom=rem...@gmail.com
X-Ironport-SBRS: 2.7
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2FVAABn27dYf7NSfUoaAz8BHAEBBAEBCgEBFgEBAQMBAQEJAQEBgkOBQ4EJB4NOCGOJJ5FngmSSUYFKGyUDHwEMgW1DEIFcgVoCgjcHPxgBAQEBAQEBAQEBAQIQAQEJCwsKGzGCMwQCAwEdBAQ9CgECLgEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBARICDAEeBA8DDwIYAQEBAwEaAQgdAQ0OHgMBCwYDAgsNGQIFAQkCAiEBAQ4DAQUBCxEOBwQBBwwHAgSId0kBAw0IBQmTElCRFj+MA4IEBQEcgwkFg2AKGScNVYJ9AQoBAQEBAQEBGAIGEodqgz+CUYFVEAIBSDABgiiCXwWBKwGHcmGFVoYehXs4AoE6hTt8hhiEKYF7U4EJg0WKAopOMYZwFB6BFQ8QdQ0wCDUfUxdOgzEqDAMdgWI/NQEGiBCBZwEBAQ
X-IronPort-AV: E=Sophos;i="5.35,230,1484035200"; 
   d="scan'208,217";a="65765623"
Received: from mail-ot0-f179.google.com ([74.125.82.179])
  by fe4.lbl.gov with ESMTP; 02 Mar 2017 00:50:22 -0800
Received: by mail-ot0-f179.google.com with SMTP id x10so47604258otb.1
        for <singu...@lbl.gov>; Thu, 02 Mar 2017 00:50:22 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=lZ4KLX094Ne7JbySRXncpevCsTMLU9ycJokYptsAw6A=;
        b=aTDoxGrMy7haNRag4cJhujIwB1XvT2Yr/z2a6P8ciFpT9NIzx6VAAhrJ0/JP2ipYf4
         CyY17pL4C3xVkEP/y5LA6Hu9nXBhmgrmX0sgnvX4PUyaVmJVUS1uin6bRrg8ipjV2ZE1
         xsbLjsTOWcLlzvoYWIhOHiw33/mA1kpwFvsZxyTAqg4OSwpcg+kChZbT/EeTqnZNBR2t
         JsLkwIzZxhE3wKSTuPYG8Z5J2HQXICByo8aMbELLT11ZtbenI72SAeI/8RO9yhFZFQHC
         9n11tpEwWFuOqIH8KhTw6ZPY/nRqKiLBGrWY9tMFPQvvVQSCNkZiAGZez67AeIB8TVkd
         NKVQ==
X-Gm-Message-State: AMke39m7ryDsDd3655Cg34/l/+XKaVRH0MlI7uV5n4BNGxRR42cfLtKACnjEsRr61GdcQrsAUj0a8bsr8IxN6A==
X-Received: by 10.157.43.98 with SMTP id f31mr3993165otd.260.1488444622058;
 Thu, 02 Mar 2017 00:50:22 -0800 (PST)
MIME-Version: 1.0
Received: by 10.183.1.3 with HTTP; Thu, 2 Mar 2017 00:50:21 -0800 (PST)
In-Reply-To: <CAN7etTwQYvZ2FdZx+NH9VRpD3daScBG+BKVPu0Tnijx9J3C9Kg@mail.gmail.com>
References: <d0a10fdc-f912-4e9c-8681-a54f5d53fd72@lbl.gov> <CAN7etTxxeYYxY7aB93H7E686y-8Qru-c_H3t1ANNQ_4oE1C-aA@mail.gmail.com>
 <887cfc8c-48ed-4720-8040-989e407f4203@lbl.gov> <CAN7etTwgGhbKjQw3EpWXMQN7jcQURt2tTHhWZn3FgZjij_=GDA@mail.gmail.com>
 <CABWwhHr9Z_h+nQM2SFq8Mhq=S1x+K9zCB74iPAn9tGdZKBUHNQ@mail.gmail.com>
 <CAA6Bz=fgxCcGtxQz7wVTTqgq_nyuLjNeuu2fOKMhJ3HTR6k5_g@mail.gmail.com>
 <edc73d0a-acb1-4cef-a23c-c4ab5f1b7289@lbl.gov> <a3f8cd92-cb6f-422a-8656-a127e48853f5@lbl.gov>
 <CAAfrVp0UHD+Adh40KeTSr6x1Evo7bKdtyqTN_ULdQSNwO+ATCg@mail.gmail.com>
 <CABWwhHrj6MKLWt8+4Pq9=Xti9cKtQjR53_aS0p-Ldhetx87S0w@mail.gmail.com> <CAN7etTwQYvZ2FdZx+NH9VRpD3daScBG+BKVPu0Tnijx9J3C9Kg@mail.gmail.com>
From: =?UTF-8?B?UsOpbXkgRGVybmF0?= <rem...@gmail.com>
Date: Thu, 2 Mar 2017 09:50:21 +0100
Message-ID: <CAA6Bz=e=SvCixnsvC21LAYYuPfYsxrqjDa8rBr8Uja3GKZWrXA@mail.gmail.com>
Subject: Re: [Singularity] Performance impact: My experience
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=001a113d69bcf73d3f0549bb847f

--001a113d69bcf73d3f0549bb847f
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hi Chih-Song,

I created a repository to share benchmarks on containers on GitHub :
https://github.com/remyd1/containers-benchs

Could you please add your results with all the details you gave in a
markdown file, and the scripts you used ?

Best regards,

Remy

2017-02-23 22:26 GMT+01:00 Gregory M. Kurtzer <gmku...@lbl.gov>:

> Hybrid mode being the MPI outside the container is different then the MPI
> inside the container.
>
> Tyler, you technically don't "have" to worry about it... unless, you want
> to use the IB (ducks and hides). Actually OFED is one of the major
> limitations of portability with containers. We've mostly solved the GPU
> issues, but not OFED.
>
> Greg
>
> On Thu, Feb 23, 2017 at 1:20 PM, Chihsong <chihs...@gmail.com> wrote:
>
>> What did you mean by hybrid mode? MPI + OpenMP or something else?
>>
>> Chih-Song
>>
>> On Thu, Feb 23, 2017 at 10:17 PM, Tyler Trafford <ttra...@gmail.com>
>> wrote:
>>
>>> I also thought that when running in hybrid mode we wouldn't have to
>>> worry about the interconnect inside the container....
>>>
>>> --
>>> Tyler Trafford
>>>
>>> On Thu, Feb 23, 2017 at 4:05 PM, Chih-Song Kuo <chihs...@gmail.com>
>>> wrote:
>>>
>>>> OK...Now after installing InfiniBand libraries things finally work
>>>> decently. From this lesson, I would suggest adding a remark about IB
>>>> support to http://singularity.lbl.gov/docs-hpc, because otherwise new
>>>> users can easily get confused about Singularity's support for InfiniBa=
nd.
>>>> And HPC is obviously defined by such high-speed interconnects (IB, OPA=
,
>>>> Cray, ...)
>>>>
>>>> To me, this does seem to be a serious issue which would potentially
>>>> decrease users' feeling about the portability of Singularity container=
s.
>>>> Think about a scientist developing codes on a workstation without
>>>> InfiniBand, and later making a test run on a small departmental cluste=
r
>>>> with InfiniBand, and eventually a production run on some white elephan=
t
>>>> with Intel Omni-Path. Just missing one interconnect library in the
>>>> container and not compiling the MPI against that library would immedia=
tely
>>>> break portability.
>>>>
>>>> Also I agree with the comment made in https://groups.google.com/a/lb
>>>> l.gov/forum/#!topic/singularity/fsCO1_StjjA that Singularity should
>>>> consider to include OFED drivers by default when creating a new contai=
ner.
>>>> Not sure if Greg you would change your mind here. The problem was real=
ly
>>>> not about orted. Yes, Open MPI worked without the OFED driver, but onl=
y on
>>>> Ethernet. Since Singularity is claimed to be the container for HPC,
>>>> including a well defined set of interconnect drivers and libraries tru=
ly
>>>> makes sense.
>>>>
>>>> For those who try to make your containers work with InfiniBand, I can
>>>> provide a few general hints. These were not rigorously tested though a=
nd I
>>>> doubt I have the time to do so.
>>>> 1. Issue ibv_devices in the container. You must be able able to see th=
e
>>>> name of your InfiniBand adpter. If not, then possibly some IB librarie=
s and
>>>> drivers are missing
>>>> 1.1. For Centos 7, the following rpm packages seem to be the minimum
>>>> requirement
>>>> libibverbs*
>>>> librdmacm*
>>>> 1.2. For Centos 6, the following rpm packages seem to be the minimum
>>>> requirement
>>>> libibverbs*
>>>> librdmacm*
>>>> libmlx*
>>>> 1.3. Nevertheless, in the end I installed more packages
>>>> yum -y install libmthca
>>>> yum -y install libibcm*
>>>> yum -y install libibmad*
>>>> yum -y install libibumad*
>>>> 1.4. Maybe the following will be useful, but I did not install them ye=
t
>>>> yum -y install dapl*
>>>> yum -y install ibacm*
>>>> yum -y install ibutils
>>>>
>>>> 2. After ./configure Open MPI, make sure you see the following.
>>>> OpenFabrics Verbs: yes
>>>> If you have OmniPath, then it should be
>>>> Intel Omnipath (PSM2): yes
>>>>
>>>> There are also other components like MXM  which can potentially be
>>>> "yes" if you installed Mellanox MXM.
>>>>
>>>> 3. When make Open MPI, use serial compilation, i.e. do not add the -j
>>>> flag. It sometimes causes explainable behaviors.
>>>>
>>>> 4. After make install Open MPI, make sure that the OpenIB component is
>>>> indeed installed.
>>>> ompi_info |grep openib
>>>> #Expect to see non-empty response
>>>>  MCA btl: openib (MCA v2.1.0, API v3.0.0, Component v3.0.0)
>>>>
>>>> 5. Make sure that the MPI version is the same on the host and in the
>>>> container
>>>>
>>>> My updated test result is provided below. If anybody would like to put
>>>> these figures into any other documents, please inform me.
>>>>
>>>> Host configuration:
>>>> 2x Intel E5-2680v2 (Ivybridge)
>>>> 64GB memory
>>>> Mellanox ConnectX-3 FDR adapter (but connects to a Mellanox QDR switch=
)
>>>> RHEL 6.7
>>>> OpenMPI development master branch (dated 8.2.17)
>>>> Intel MKL 2017.0 community edition
>>>> gcc 4.4
>>>>
>>>> Container:
>>>> Centos 6 and 7 both tested without noticeable performance difference
>>>> OpenMPI development master branch (dated 8.2.17)
>>>> Intel MKL 2017.0 community edition
>>>> gcc 4.4.7 (Centos-6), gcc 4.8.5 (Centos-7)
>>>>
>>>> Benchmarks:
>>>> 1. LINPACK 2.2
>>>> 2. OSU 5.3.2
>>>>
>>>> <LINPACK>
>>>> Single node. N=3D40000, P=3D5, Q=3D4
>>>> Container: 368 GFlops
>>>> Host: 368 GFLOPS
>>>> #A single node has 2x Intel E5-2680v2. So we are expecting 2 x 10 x 8 =
*
>>>> 2.8 =3D 448 GFlops
>>>> Efficiency =3D 368 / 448 =3D 82%. Not bad (given the small N (matrix s=
ize)
>>>> and that gcc instead of icc was used, and the executable was dynamical=
ly
>>>> linked -- by purpose)
>>>>
>>>> Dual-node, N=3D60000, P=3D8, Q=3D5
>>>> Container: 736 GFLOPS
>>>> Host:737 GFLOPS
>>>>
>>>>
>>>> <OSU-P2P-Bandwidth>
>>>> Container:
>>>> Msg size(bytes) BW (MB/s)
>>>> 65536                3738.89
>>>> 131072               3756.34
>>>> 262144               3767.35
>>>> 524288               3780.46
>>>> 1048576              3781.94
>>>> 2097152              3775.07
>>>> 4194304              3775.97
>>>>
>>>> Host:
>>>> Msg size(bytes) BW (MB/s)
>>>> 65536                3722.32
>>>> 131072               3751.33
>>>> 262144               3771.13
>>>> 524288               3774.33
>>>> 1048576              3781.43
>>>> 2097152              3775.00
>>>> 4194304              3773.68
>>>>
>>>> <OSU-P2P-Latency>
>>>> Container:
>>>> Msg size(bytes)  Latency (us)
>>>> 0                       1.61
>>>> 1                       1.67
>>>> 2                       1.66
>>>> 4                       1.66
>>>> 8                       1.70
>>>>
>>>> Host:
>>>> Msg size(bytes)  Latency (us)
>>>> 0                       1.57
>>>> 1                       1.63
>>>> 2                       1.63
>>>> 4                       1.63
>>>> 8                       1.65
>>>>
>>>> How were the benchmarks executed?
>>>> mpirun -n 20 -hostfile hostfile singularity exec /home/chih/containers=
/
>>>> container-centos6-demo.img xhpl
>>>> mpirun -n 2 -hostfile hostfile singularity exec
>>>> /home/chih/containers/container-centos6-demo.img osu_bw
>>>> mpirun -n 2 -hostfile hostfile singularity exec
>>>> /home/chih/containers/container-centos6-demo.img osu_latency
>>>>
>>>> My conclusion: No difference for HPL (1 & 2 nodes) and IB bandwidth.
>>>> There is a consistent 2% overhead in IB latency though, but this shoul=
d be
>>>> affordable by most users.
>>>>
>>>>
>>>> On Thursday, February 23, 2017 at 12:44:47 PM UTC+1, Chih-Song Kuo
>>>> wrote:
>>>>>
>>>>> I am not really sure if I can share the containers publicly as it
>>>>> contains an Intel MKL installation which is bound to a personalized s=
erial
>>>>> number (although that MKL is from the community edition, so it is
>>>>> essentially free).
>>>>>
>>>>> Still, I am wondering if installing OFED into the container is the
>>>>> right approach. There was a thread on a similar topic and Greg said n=
o. I
>>>>> hope I understood it correctly.
>>>>> https://groups.google.com/a/lbl.gov/forum/#!topic/singularit
>>>>> y/fsCO1_StjjA
>>>>>
>>>>> After all, although requiring the user to install OFED into the
>>>>> container might be technically feasible, it would be very awkward for=
 users
>>>>> who develop their applications on their own workstations without
>>>>> InfiniBand, not to mention that I am even not sure if one can install=
 OFED
>>>>> into a machine without IB adapters. And what if the OFED library in t=
he
>>>>> container differ from that on the host? I don't think that will work,=
 will
>>>>> it?
>>>>>
>>>>> Sorry but somehow OpenMPI (or any MPI) is intent to reach OFED
>>>>> libraries still remains a mystery for me. Please enlighten me.
>>>>>
>>>>> On Thursday, February 23, 2017 at 9:51:34 AM UTC+1, R=C3=A9my Dernat =
wrote:
>>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> You can try to copy your libraries directly from the host to the
>>>>>> container instead of a classical install ? I do not know what is the=
 best
>>>>>> way... But if you check woth solutions we will have an answer.
>>>>>> BTW, I am very interesting by your containers. Could you share it
>>>>>> (through singularity-hub ?) with your command line to run the benchm=
ark in
>>>>>> the "singularity" file inside the container ? Indeed, I will do some
>>>>>> performance tests also...
>>>>>>
>>>>>> Best regards,
>>>>>> R=C3=A9my
>>>>>>
>>>>>> 2017-02-23 0:58 GMT+01:00 Chihsong :
>>>>>>
>>>>>>> Hi Greg,
>>>>>>>
>>>>>>> The problem is that I don't feel I have IB libraries inside my
>>>>>>> container. How can I check that? Or did you simply install the ofed=
 into
>>>>>>> the container?
>>>>>>>
>>>>>>> Chiu-Song
>>>>>>>
>>>>>>> On Thursday, February 23, 2017, Gregory M. Kurtzer <gm...@lbl.gov>
>>>>>>> wrote:
>>>>>>>
>>>>>>>> Hi Chih-Song,
>>>>>>>>
>>>>>>>> Haha, every now and then I get lucky when a new mail comes in and
>>>>>>>> is at the top of my mbox and I have a moment.
>>>>>>>>
>>>>>>>> In summary, yes. The MPI inside the container must also link
>>>>>>>> against the IB libraries (also within the container).
>>>>>>>>
>>>>>>>> Hopefully that helps!
>>>>>>>>
>>>>>>>> On Wed, Feb 22, 2017 at 10:58 AM, Chih-Song Kuo  wrote:
>>>>>>>>
>>>>>>>>> Hi Greg,
>>>>>>>>>
>>>>>>>>> That reply was very prompt! Anyways, my answer follows.
>>>>>>>>>
>>>>>>>>> > * Make sure the MPI inside the container is properly linking
>>>>>>>>> against the IB libraries
>>>>>>>>> Did that mean that I need to install IB libraries (like Mellanox
>>>>>>>>> OFED) into the container? I guess not?
>>>>>>>>> But apparently openib is missing in the container.
>>>>>>>>> [me@cn03 ompi-rhel6-host]$ ompi_info | grep openib
>>>>>>>>>                  MCA btl: openib (MCA v2.1.0, API v3.0.0,
>>>>>>>>> Component v3.0.0)
>>>>>>>>>
>>>>>>>>> Singularity.container-centos6-demo.img> ompi_info | grep openib
>>>>>>>>> Singularity.container-centos6-demo.img>
>>>>>>>>> Singularity.container-centos6-demo.img> ls
>>>>>>>>> /etc/infiniband/openib.conf
>>>>>>>>> ls: cannot access /etc/infiniband/openib.conf: No such file or
>>>>>>>>> directory
>>>>>>>>>
>>>>>>>>> > * Make sure that the MPI configuration is configured to use MPI
>>>>>>>>> I think you meant "to use IB" instead.
>>>>>>>>> But still, did you mean that OpenMPI should be "configured"
>>>>>>>>> "--with-verbs"? (Did you do so or you never had my problem?)
>>>>>>>>> I did not use this flag when compiling Open MPI either on the hos=
t
>>>>>>>>> or in the container.
>>>>>>>>> > * Make sure you have Singularity configured properly to share
>>>>>>>>> the devices properly, tmp, and you are *NOT* using the IPC or PID=
 namespaces
>>>>>>>>> Can you provide more hint on how that can be done?
>>>>>>>>>
>>>>>>>>> Thank you once again for your time.
>>>>>>>>> Chih-Song
>>>>>>>>>
>>>>>>>>> On Wednesday, February 22, 2017 at 7:33:22 PM UTC+1, Gregory M.
>>>>>>>>> Kurtzer wrote:
>>>>>>>>>>
>>>>>>>>>> There are various things that *could* go wrong, and usage of
>>>>>>>>>> containers (any of the technologies) actually introduce complexi=
ties in
>>>>>>>>>> kernel and user space alignment that normally we don't consider.=
 For that
>>>>>>>>>> reason, my first suspicion is that your IB fabric is not being p=
roperly
>>>>>>>>>> utilized by the MPI within the container. That could be due to a=
nything
>>>>>>>>>> from build errors within the container to IB library/kmod API mi=
salignment.
>>>>>>>>>>
>>>>>>>>>> Things I would look at and check:
>>>>>>>>>>
>>>>>>>>>> * Make sure the MPI inside the container is properly linking
>>>>>>>>>> against the IB libraries
>>>>>>>>>> * Make sure that the IB libraries inside the container are
>>>>>>>>>> compatible with the host kernel
>>>>>>>>>> * Make sure that the MPI configuration is configured to use MPI
>>>>>>>>>> * Make sure you have Singularity configured properly to share th=
e
>>>>>>>>>> devices properly, tmp, and you are *NOT* using the IPC or PID na=
mespaces
>>>>>>>>>>
>>>>>>>>>> Hope that helps.
>>>>>>>>>>
>>>>>>>>>> Greg
>>>>>>>>>>
>>>>>>>>>> On Wed, Feb 22, 2017 at 10:19 AM, Chih-Song Kuo wrote:
>>>>>>>>>>
>>>>>>>>>>> Hello,
>>>>>>>>>>>
>>>>>>>>>>> This is again Chih-Song from Fujitsu. I decided to make another
>>>>>>>>>>> post to share my experience of performance impact with two kern=
el
>>>>>>>>>>> benchmarks: High Performance Linpack (HPL) and the OSU MPI benc=
hmark suit.
>>>>>>>>>>>
>>>>>>>>>>> Overall, there was no noticeable performance difference for
>>>>>>>>>>> benchmarks running on a single node. But for benchmarks running=
 across
>>>>>>>>>>> nodes, I did observe some difference, which was against to the =
claim of
>>>>>>>>>>> Singularity. Have anybody done any similar exercise? What are y=
our
>>>>>>>>>>> findings? Can you suspect whether I was doing anything wrong?
>>>>>>>>>>>
>>>>>>>>>>> Host configuration:
>>>>>>>>>>> 2x Intel E5-2680v2 (Ivybridge)
>>>>>>>>>>> 64GB memory
>>>>>>>>>>> Mellanox ConnectX-3 FDR adapter (but connects to a Mellanox QDR
>>>>>>>>>>> switch)
>>>>>>>>>>> RHEL 6.7
>>>>>>>>>>> OpenMPI development master branch (8.2.17)
>>>>>>>>>>> Intel MKL 2017.0 community edition
>>>>>>>>>>> gcc 4.4
>>>>>>>>>>>
>>>>>>>>>>> Container:
>>>>>>>>>>> Centos 6 and 7 both tested without noticeable performance
>>>>>>>>>>> difference
>>>>>>>>>>> OpenMPI development master branch (8.2.17)
>>>>>>>>>>> Intel MKL 2017.0 community edition
>>>>>>>>>>> gcc 4.4.7 (Centos-6), gcc 4.8.5 (Centos-7)
>>>>>>>>>>>
>>>>>>>>>>> Benchmarks:
>>>>>>>>>>> 1. LINPACK 2.2
>>>>>>>>>>> 2. OSU 5.3.2
>>>>>>>>>>>
>>>>>>>>>>> <LINPACK>
>>>>>>>>>>> Single node. N=3D40000, P=3D5, Q=3D4
>>>>>>>>>>> Container: 368 GFlops
>>>>>>>>>>> Host: 368 GFLOPS
>>>>>>>>>>> #A single node has 2x Intel E5-2680v2. So we are expecting 2 x
>>>>>>>>>>> 10 x 8 * 2.8 =3D 448 GFlops
>>>>>>>>>>> Efficiency =3D 368 / 448 =3D 82%. Not bad (given the small N (m=
atrix
>>>>>>>>>>> size) and that gcc instead of icc was used, and the executable =
was
>>>>>>>>>>> dynamically linked -- by purpose)
>>>>>>>>>>>
>>>>>>>>>>> Dual-node, N=3D60000, P=3D8, Q=3D5
>>>>>>>>>>> Container: 702 GFLOPS
>>>>>>>>>>> Host:737 GFLOPS
>>>>>>>>>>> There is roughly 5% of performance degradation with the
>>>>>>>>>>> container.
>>>>>>>>>>>
>>>>>>>>>>> <OSU-P2P-Bandwidth>
>>>>>>>>>>> The container only saw 50-65% of the total bandwidth.
>>>>>>>>>>>
>>>>>>>>>>> Container:
>>>>>>>>>>> Msg size(bytes) BW (MB/s)
>>>>>>>>>>> 65536                2142.28
>>>>>>>>>>> 131072               2363.45
>>>>>>>>>>> 262144               1705.79
>>>>>>>>>>> 524288               1592.56
>>>>>>>>>>> 1048576              1721.88
>>>>>>>>>>> 2097152              1557.42
>>>>>>>>>>> 4194304              1655.90
>>>>>>>>>>>
>>>>>>>>>>> Host:
>>>>>>>>>>> Msg size(bytes) BW (MB/s)
>>>>>>>>>>> 65536                3722.32
>>>>>>>>>>> 131072               3751.33
>>>>>>>>>>> 262144               3771.13
>>>>>>>>>>> 524288               3774.33
>>>>>>>>>>> 1048576              3781.43
>>>>>>>>>>> 2097152              3775.00
>>>>>>>>>>> 4194304              3773.68
>>>>>>>>>>>
>>>>>>>>>>> <OSU-P2P-Latency>
>>>>>>>>>>> Here the container was significantly slower.
>>>>>>>>>>>
>>>>>>>>>>> Container:
>>>>>>>>>>> Msg size(bytes)  Latency (us)
>>>>>>>>>>> 0                      31.59
>>>>>>>>>>> 1                      31.86
>>>>>>>>>>> 2                      31.83
>>>>>>>>>>>
>>>>>>>>>>> Host:
>>>>>>>>>>> Msg size(bytes)  Latency (us)
>>>>>>>>>>> 0                       1.55
>>>>>>>>>>> 1                       1.63
>>>>>>>>>>> 2                       1.63
>>>>>>>>>>>
>>>>>>>>>>> Note 1: Run-to-run variation of performance was much smaller
>>>>>>>>>>> than the difference on the host and in the container.
>>>>>>>>>>> Note 2: When Singularity was used, I could not instruct mpirun
>>>>>>>>>>> to use the ofed by specifying "--mca btl openib,self,vader" in =
the mpirun
>>>>>>>>>>> parameter list. Doing so would give me an error message stating=
 that the
>>>>>>>>>>> openib component is missing. However, from the bandwidth measur=
ed above,
>>>>>>>>>>> the container did seem to be able to use InfiniBand, otherwise =
the
>>>>>>>>>>> bandwidth would not be so high (the nodes only had InfiniBand a=
nd 1G
>>>>>>>>>>> Ethernet). Maybe container was using IPoIB? I did not check tha=
t yet.
>>>>>>>>>>>
>>>>>>>>>>> Reference: How the benchmarks were executed:
>>>>>>>>>>> mpirun -n 20 -hostfile hostfile singularity exec
>>>>>>>>>>> /home/chih/containers/container-centos6-demo.img xhpl
>>>>>>>>>>> mpirun -n 2 -hostfile hostfile singularity exec
>>>>>>>>>>> /home/chih/containers/container-centos6-demo.img osu_bw
>>>>>>>>>>> mpirun -n 2 -hostfile hostfile singularity exec
>>>>>>>>>>> /home/chih/containers/container-centos6-demo.img osu_latency
>>>>>>>>>>>
>>>>>>>>>>> Chih-Song
>>>>>>>>>>>
>>>>>>>>>>> --
>>>>>>>>>>> You received this message because you are subscribed to the
>>>>>>>>>>> Google Groups "singularity" group.
>>>>>>>>>>> To unsubscribe from this group and stop receiving emails from
>>>>>>>>>>> it, send an email to singu...@lbl.gov.
>>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> --
>>>>>>>>>> Gregory M. Kurtzer
>>>>>>>>>> HPC Systems Architect and Technology Developer
>>>>>>>>>> Lawrence Berkeley National Laboratory HPCS
>>>>>>>>>> University of California Berkeley Research IT
>>>>>>>>>> Singularity Linux Containers (http://singularity.lbl.gov/)
>>>>>>>>>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>>>>>>>>>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>>>>>>>>>> er.com/gmkurtzer
>>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> You received this message because you are subscribed to the Googl=
e
>>>>>>>>> Groups "singularity" group.
>>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> Gregory M. Kurtzer
>>>>>>>> HPC Systems Architect and Technology Developer
>>>>>>>> Lawrence Berkeley National Laboratory HPCS
>>>>>>>> University of California Berkeley Research IT
>>>>>>>> Singularity Linux Containers (http://singularity.lbl.gov/)
>>>>>>>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>>>>>>>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>>>>>>>> er.com/gmkurtzer
>>>>>>>>
>>>>>>>> --
>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>> Groups "singularity" group.
>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Chih-Song Kuo =E9=83=AD=E7=9F=A5=E9=A0=8C
>>>>>>> Senior Sales Consultant - HPC Benchmark Specialist at Fujitsu
>>>>>>> M.Sc. RWTH with distinction in Software Systems Engineering with HP=
C
>>>>>>> focus
>>>>>>> B.Sc. NTHU in Computer Science, B.S.M. NTHU in Quantitative Finance
>>>>>>> Tel:  +49-177-88949-28; +49-241-88949-155; +886-2-26629518
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>
>>>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>>
>>>
>>> --
>>> Tyler Trafford
>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>> --
>> You received this message because you are subscribed to the Google Group=
s
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n
>> email to singu...@lbl.gov.
>>
>
>
>
> --
> Gregory M. Kurtzer
> HPC Systems Architect and Technology Developer
> Lawrence Berkeley National Laboratory HPCS
> University of California Berkeley Research IT
> Singularity Linux Containers (http://singularity.lbl.gov/)
> Warewulf Cluster Management (http://warewulf.lbl.gov/)
> GitHub: https://github.com/gmkurtzer, Twitter: https://
> twitter.com/gmkurtzer
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a113d69bcf73d3f0549bb847f
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi Chih-Song,<div><br></div><div>I created a repository to=
 share benchmarks on containers on GitHub :</div><div><a href=3D"https://gi=
thub.com/remyd1/containers-benchs">https://github.com/remyd1/containers-ben=
chs</a><br></div><div><br></div><div>Could you please add your results with=
 all the details you gave in a markdown file, and the scripts you used ?</d=
iv><div><br></div><div>Best regards,</div><div><br></div><div>Remy</div></d=
iv><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">2017-02-23 22:=
26 GMT+01:00 Gregory M. Kurtzer <span dir=3D"ltr">&lt;<a href=3D"mailto:gmk=
u...@lbl.gov" target=3D"_blank">gmku...@lbl.gov</a>&gt;</span>:<br><blockqu=
ote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc s=
olid;padding-left:1ex"><div dir=3D"ltr">Hybrid mode being the MPI outside t=
he container is different then the MPI inside the container.<div><br></div>=
<div>Tyler, you technically don&#39;t &quot;have&quot; to worry about it...=
 unless, you want to use the IB (ducks and hides). Actually OFED is one of =
the major limitations of portability with containers. We&#39;ve mostly solv=
ed the GPU issues, but not OFED.</div><div><br></div><div>Greg</div></div><=
div class=3D"HOEnZb"><div class=3D"h5"><div class=3D"gmail_extra"><br><div =
class=3D"gmail_quote">On Thu, Feb 23, 2017 at 1:20 PM, Chihsong <span dir=
=3D"ltr">&lt;<a href=3D"mailto:chihs...@gmail.com" target=3D"_blank">chihs.=
..@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" sty=
le=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div d=
ir=3D"ltr">What did you mean by hybrid mode? MPI + OpenMP or something else=
?<span class=3D"m_5335290406642423689HOEnZb"><font color=3D"#888888"><br></=
font></span><div class=3D"gmail_extra"><span class=3D"m_5335290406642423689=
HOEnZb"><font color=3D"#888888"><br clear=3D"all"><div><div class=3D"m_5335=
290406642423689m_3988348498465513417gmail_signature" data-smartmail=3D"gmai=
l_signature"><div dir=3D"ltr"><span><div><div dir=3D"ltr"><div>Chih-Song<br=
></div></div></div></span></div></div></div></font></span><div><div class=
=3D"m_5335290406642423689h5">
<br><div class=3D"gmail_quote">On Thu, Feb 23, 2017 at 10:17 PM, Tyler Traf=
ford <span dir=3D"ltr">&lt;<a href=3D"mailto:ttra...@gmail.com" target=3D"_=
blank">ttra...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmai=
l_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left=
:1ex"><div dir=3D"ltr"><div style=3D"font-family:arial,helvetica,sans-serif=
">I also thought that when running in hybrid mode we wouldn&#39;t have to w=
orry about the interconnect inside the container....</div><div style=3D"fon=
t-family:arial,helvetica,sans-serif"><br></div><div style=3D"font-family:ar=
ial,helvetica,sans-serif">--=C2=A0</div><div style=3D"font-family:arial,hel=
vetica,sans-serif">Tyler Trafford</div></div><div class=3D"gmail_extra"><di=
v><div class=3D"m_5335290406642423689m_3988348498465513417h5"><br><div clas=
s=3D"gmail_quote">On Thu, Feb 23, 2017 at 4:05 PM, Chih-Song Kuo <span dir=
=3D"ltr">&lt;<a href=3D"mailto:chihs...@gmail.com" target=3D"_blank">chihs.=
..@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" sty=
le=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div d=
ir=3D"ltr">OK...Now after installing InfiniBand libraries things finally wo=
rk decently. From this lesson, I would suggest adding a remark about IB sup=
port to <a href=3D"http://singularity.lbl.gov/docs-hpc" target=3D"_blank">h=
ttp://singularity.lbl.gov/doc<wbr>s-hpc</a>, because otherwise new users ca=
n easily get confused about Singularity&#39;s support for InfiniBand. And H=
PC is obviously defined by such high-speed interconnects (IB, OPA, Cray, ..=
.)<br><br>To me, this does seem to be a serious issue which would potential=
ly decrease users&#39; feeling about the portability of Singularity contain=
ers. Think about a scientist developing codes on a workstation without Infi=
niBand, and later making a test run on a small departmental cluster with In=
finiBand, and eventually a production run on some white elephant with Intel=
 Omni-Path. Just missing one interconnect library in the container and not =
compiling the MPI against that library would immediately break portability.=
<br><br>Also I agree with the comment made in <a href=3D"https://groups.goo=
gle.com/a/lbl.gov/forum/#!topic/singularity/fsCO1_StjjA" target=3D"_blank">=
https://groups.google.com/a/lb<wbr>l.gov/forum/#!topic/singularit<wbr>y/fsC=
O1_StjjA</a> that Singularity should consider to include OFED drivers by de=
fault when creating a new container. Not sure if Greg you would change your=
 mind here. The problem was really not about orted. Yes, Open MPI worked wi=
thout the OFED driver, but only on Ethernet. Since Singularity is claimed t=
o be the container for HPC, including a well defined set of interconnect dr=
ivers and libraries truly makes sense.<br><br>For those who try to make you=
r containers work with InfiniBand, I can provide a few general hints. These=
 were not rigorously tested though and I doubt I have the time to do so.<br=
>1. Issue ibv_devices in the container. You must be able able to see the na=
me of your InfiniBand adpter. If not, then possibly some IB libraries and d=
rivers are missing<br>1.1. For Centos 7, the following rpm packages seem to=
 be the minimum requirement<br>libibverbs* <br>librdmacm*=C2=A0=C2=A0=C2=A0=
 <br>1.2. For Centos 6, the following rpm packages seem to be the minimum r=
equirement<br>libibverbs* <br>librdmacm*=C2=A0=C2=A0=C2=A0 <br>libmlx*<br>1=
.3. Nevertheless, in the end I installed more packages<br>yum -y install li=
bmthca <br>yum -y install libibcm*<br>yum -y install libibmad*<br>yum -y in=
stall libibumad*<br>1.4. Maybe the following will be useful, but I did not =
install them yet<br>yum -y install dapl*<br>yum -y install ibacm*<br>yum -y=
 install ibutils<br><br>2. After ./configure Open MPI, make sure you see th=
e following.<br>OpenFabrics Verbs: yes<br>If you have OmniPath, then it sho=
uld be<br>Intel Omnipath (PSM2): yes<br><br>There are also other components=
 like MXM=C2=A0 which can potentially be &quot;yes&quot; if you installed M=
ellanox MXM.<br><br>3. When make Open MPI, use serial compilation, i.e. do =
not add the -j flag. It sometimes causes explainable behaviors.<br><br>4. A=
fter make install Open MPI, make sure that the OpenIB component is indeed i=
nstalled.<br>ompi_info |grep openib <br>#Expect to see non-empty response<s=
pan><br>=C2=A0MCA btl: openib (MCA v2.1.0, API v3.0.0, Component v3.0.0)<br=
><br></span>5. Make sure that the MPI version is the same on the host and i=
n the container<br><br>My updated test result is provided below. If anybody=
 would like to put these figures into any other documents, please inform me=
.<span><br><br>Host configuration:<br>2x Intel E5-2680v2 (Ivybridge)<br>64G=
B memory<br>Mellanox ConnectX-3 FDR adapter (but connects to a Mellanox QDR=
 switch)<br>RHEL 6.7<br></span>OpenMPI development master branch (dated 8.2=
.17)<span><br>Intel MKL 2017.0 community edition<br>gcc 4.4<br><br>Containe=
r:<br>Centos 6 and 7 both tested without noticeable performance difference<=
br></span>OpenMPI development master branch (dated 8.2.17)<span><br>Intel M=
KL 2017.0 community edition<br>gcc 4.4.7 (Centos-6), gcc 4.8.5 (Centos-7)<b=
r><br>Benchmarks:<br>1. LINPACK 2.2<br>2. OSU 5.3.2<br><br>&lt;LINPACK&gt;<=
br>Single node. N=3D40000, P=3D5, Q=3D4<br>Container: 368 GFlops<br>Host: 3=
68 GFLOPS<br>#A single node has 2x Intel E5-2680v2. So we are expecting 2 x=
 10 x 8 * 2.8 =3D 448 GFlops<br>Efficiency
 =3D 368 / 448 =3D 82%. Not bad (given the small N (matrix size) and that=
=20
gcc instead of icc was used, and the executable was dynamically linked=20
-- by purpose)<br><br>Dual-node, N=3D60000, P=3D8, Q=3D5<br></span>Containe=
r: 736 GFLOPS<br>Host:737 GFLOPS<br><br><br>&lt;OSU-P2P-Bandwidth&gt;<span>=
<br>Container: <br>Msg size(bytes) BW (MB/s)<br></span>65536=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
 3738.89<br>131072=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0 3756.34<br>262144=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3767.35<br>524288=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0 3780.46<br>1048576=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3781.94<br>2097152=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3775.07<br>4194304=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0 3775.97<span><br><br>Host:<br>Msg size(bytes) BW (MB/s)<br>65536=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0 3722.32<br>131072=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3751.33<br>262144=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3771.13<br>=
524288=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0 3774.33<br>1048576=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3781.43<br>2097152=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3775.00<br>=
4194304=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0 3773.68<br><br>&lt;OSU-P2P-Latency&gt;<br></span><span>Contain=
er: <br>Msg size(bytes)=C2=A0 Latency (us)<br></span>0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.61<br>1=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.67<br>2=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0 1.66<br>4=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 1.66<br>8=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0 1.70<span><br><br>Host:<br>Msg size(bytes)=C2=A0 Latency (us)<=
br></span>0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.57<=
br>1=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.63<br>2=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.63<br>4=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.63<br>8=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.65<br><br>How were the benc=
hmarks executed?<span><br>mpirun -n 20 -hostfile hostfile singularity exec =
/home/chih/containers/<div dir=3D"ltr">container-centos6-demo.img xhpl<br>m=
pirun -n 2 -hostfile hostfile singularity exec /home/chih/containers/contai=
ne<wbr>r-centos6-demo.img osu_bw<br>mpirun -n 2 -hostfile hostfile singular=
ity exec /home/chih/containers/containe<wbr>r-centos6-demo.img osu_latency<=
br></div><br></span>My conclusion: No difference for HPL (1 &amp; 2 nodes) =
and IB bandwidth. There is a consistent 2% overhead in IB latency though, b=
ut this should be affordable by most users.<div><div class=3D"m_53352904066=
42423689m_3988348498465513417m_6026970709499655369h5"><br><br>On Thursday, =
February 23, 2017 at 12:44:47 PM UTC+1, Chih-Song Kuo wrote:<blockquote cla=
ss=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc=
 solid;padding-left:1ex"><div dir=3D"ltr">I am not really sure if I can sha=
re the containers publicly as it contains an Intel MKL installation which i=
s bound to a personalized serial number (although that MKL is from the comm=
unity edition, so it is essentially free).<br><br>Still, I am wondering if =
installing OFED into the container is the right approach. There was a threa=
d on a similar topic and Greg said no. I hope I understood it correctly.<br=
><a href=3D"https://groups.google.com/a/lbl.gov/forum/#!topic/singularity/f=
sCO1_StjjA" rel=3D"nofollow" target=3D"_blank">https://groups.google.com/a/=
lb<wbr>l.gov/forum/#!topic/singularit<wbr>y/fsCO1_StjjA</a><br><br>After al=
l, although requiring the user to install OFED  into the container might be=
 technically feasible, it would be very awkward for users who develop their=
 applications on their own workstations without InfiniBand, not to mention =
that I am even not sure if one can install OFED into a machine without IB a=
dapters. And what if the OFED library in the container differ from that on =
the host? I don&#39;t think that will work, will it?<br><br>Sorry but someh=
ow OpenMPI (or any MPI) is intent to reach OFED libraries still remains a m=
ystery for me. Please enlighten me.<br><br>On Thursday, February 23, 2017 a=
t 9:51:34 AM UTC+1, R=C3=A9my Dernat wrote:<blockquote class=3D"gmail_quote=
" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-le=
ft:1ex"><div dir=3D"ltr">Hi,<div><br></div><div>You can try to copy your li=
braries=C2=A0directly=C2=A0from the host to the container instead of a clas=
sical install ? I do not know what is the best way... But if you check woth=
 solutions we will have an answer.</div><div>BTW, I am very interesting by =
your containers. Could you share it (through singularity-hub ?) with your c=
ommand line to run the benchmark in the &quot;singularity&quot; file inside=
 the container ? Indeed, I will do some performance tests also...</div><div=
><br></div><div>Best regards,</div><div>R=C3=A9my</div></div><div><br><div =
class=3D"gmail_quote">2017-02-23 0:58 GMT+01:00 Chihsong <span dir=3D"ltr">=
</span>:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;bo=
rder-left:1px #ccc solid;padding-left:1ex">Hi Greg,<div><br></div><div>The =
problem is that I=C2=A0don&#39;t feel I=C2=A0have IB libraries inside my co=
ntainer. How can I=C2=A0check that? Or did you simply=C2=A0install the ofed=
 into the container?=C2=A0</div><div><br>Chiu-Song</div><div><div><div><br>=
On Thursday, February 23, 2017, Gregory M. Kurtzer &lt;<a rel=3D"nofollow">=
gm...@lbl.gov</a>&gt; wrote:<br><blockquote class=3D"gmail_quote" style=3D"=
margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"=
ltr">Hi Chih-Song,<div><br></div><div>Haha, every now and then I get lucky =
when a new mail comes in and is at the top of my mbox and I have a moment.<=
/div><div><br></div><div>In summary, yes. The MPI inside the container must=
 also link against the IB libraries (also within the container).</div><div>=
<br></div><div>Hopefully that helps!</div></div><div><br><div class=3D"gmai=
l_quote">On Wed, Feb 22, 2017 at 10:58 AM, Chih-Song Kuo=C2=A0 wrote:<br><b=
lockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px =
#ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Greg,<br><br>That reply wa=
s very prompt! Anyways, my answer follows.<span><br><br>&gt; * Make sure th=
e MPI inside the container is properly linking against the IB libraries<br>=
</span>Did that mean that I need to install IB libraries (like Mellanox OFE=
D) into the container? I guess not?<br>But apparently openib is missing in =
the container.<br>[me@cn03 ompi-rhel6-host]$ ompi_info | grep openib<br>=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 MCA btl: openib (MCA v2.1.0, API v3.0.0, Component v3.0.=
0)<br><br>Singularity.container-centos6-<wbr>demo.img&gt; ompi_info | grep =
openib<br>Singularity.container-centos6-<wbr>demo.img&gt;<br>Singularity.co=
ntainer-centos6-<wbr>demo.img&gt; ls /etc/infiniband/openib.conf<br>ls: can=
not access /etc/infiniband/openib.conf: No such file or directory<span><br>=
<br>&gt; * Make sure that the MPI configuration is configured to use MPI<br=
></span>I think you meant &quot;to use IB&quot; instead. <br>But still, did=
 you mean that OpenMPI should be &quot;configured&quot; &quot;--with-verbs&=
quot;? (Did you do so or you never had my problem?)<br>I did not use this f=
lag when compiling Open MPI either on the host or in the container.<span><b=
r>&gt; * Make sure you have Singularity configured properly to share the=20
devices properly, tmp, and you are *NOT* using the IPC or PID namespaces<br=
></span>Can you provide more hint on how that can be done?<br><br>Thank you=
 once again for your time.<br>Chih-Song<span><br><br>On Wednesday, February=
 22, 2017 at 7:33:22 PM UTC+1, Gregory M. Kurtzer wrote:</span><blockquote =
class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #=
ccc solid;padding-left:1ex"><span><div dir=3D"ltr">There are various things=
 that *could* go wrong, and usage of containers (any of the technologies) a=
ctually introduce complexities in kernel and user space alignment that norm=
ally we don&#39;t consider. For that reason, my first suspicion is that you=
r IB fabric is not being properly utilized by the MPI within the container.=
 That could be due to anything from build errors within the container to IB=
 library/kmod API misalignment.<div><br></div><div>Things I would look at a=
nd check:</div><div><br></div><div>* Make sure the MPI inside the container=
 is properly linking against the IB libraries</div><div>* Make sure that th=
e IB libraries inside the container are compatible with the host kernel</di=
v><div>* Make sure that the MPI configuration is configured to use MPI</div=
><div>* Make sure you have Singularity configured properly to share the dev=
ices properly, tmp, and you are *NOT* using the IPC or PID namespaces</div>=
<div><br></div><div>Hope that helps.</div><div><br></div><div>Greg</div></d=
iv></span><div><br><div class=3D"gmail_quote"><div><div>On Wed, Feb 22, 201=
7 at 10:19 AM, Chih-Song Kuo wrote:<br></div></div><blockquote class=3D"gma=
il_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-lef=
t:1ex"><div><div><div dir=3D"ltr">Hello,<br><br>This is again Chih-Song fro=
m Fujitsu. I decided to make another post to share my experience of perform=
ance impact with two kernel benchmarks: High Performance Linpack (HPL) and =
the OSU MPI benchmark suit.<br><br>Overall, there was no noticeable perform=
ance difference for benchmarks running on a single node. But for benchmarks=
 running across nodes, I did observe some difference, which was against to =
the claim of Singularity. Have anybody done any similar exercise? What are =
your findings? Can you suspect whether I was doing anything wrong?<br><br>H=
ost configuration:<br>2x Intel E5-2680v2 (Ivybridge)<br>64GB memory<br>Mell=
anox ConnectX-3 FDR adapter (but connects to a Mellanox QDR switch)<br>RHEL=
 6.7<br>OpenMPI development master branch (8.2.17)<br>Intel MKL 2017.0 comm=
unity edition<br>gcc 4.4<br><br>Container:<br>Centos 6 and 7 both tested wi=
thout noticeable performance difference<br>OpenMPI development master branc=
h (8.2.17)<br>Intel MKL 2017.0 community edition<br>gcc 4.4.7 (Centos-6), g=
cc 4.8.5 (Centos-7)<br><br>Benchmarks:<br>1. LINPACK 2.2<br>2. OSU 5.3.2<br=
><br>&lt;LINPACK&gt;<br>Single node. N=3D40000, P=3D5, Q=3D4<br>Container: =
368 GFlops<br>Host: 368 GFLOPS<br>#A single node has 2x Intel E5-2680v2. So=
 we are expecting 2 x 10 x 8 * 2.8 =3D 448 GFlops<br>Efficiency =3D 368 / 4=
48 =3D 82%. Not bad (given the small N (matrix size) and that gcc instead o=
f icc was used, and the executable was dynamically linked -- by purpose)<br=
><br>Dual-node, N=3D60000, P=3D8, Q=3D5<br>Container: 702 GFLOPS<br>Host:73=
7 GFLOPS<br>There is roughly 5% of performance degradation with the contain=
er.<br><br>&lt;OSU-P2P-Bandwidth&gt;<br>The container only saw 50-65% of th=
e total bandwidth.<br><br>Container: <br>Msg size(bytes) BW (MB/s)<br>65536=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0 2142.28<br>131072=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 2363.45<br>262144=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1705.=
79<br>524288=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0 1592.56<br>1048576=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1721.88<br>2097152=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1557.=
42<br>4194304=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 1655.90<br><br>Host:<br>Msg size(bytes) BW (MB/s)<br>655=
36=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 3722.32<br>131072=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3751.33<br>262144=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 37=
71.13<br>524288=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0 3774.33<br>1048576=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3781.43<br>2097152=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 37=
75.00<br>4194304=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0 3773.68<br><br>&lt;OSU-P2P-Latency&gt;<br>Here the co=
ntainer was significantly slower.<br><br>Container: <br>Msg size(bytes)=C2=
=A0 Latency (us)<br>0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 31=
.59<br>1=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 31.86<br>2=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 31.83<br><br>Host:<br>Msg =
size(bytes)=C2=A0 Latency (us)<br>0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 1.55<br>1=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0 1.63<br>2=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0 1.63<br><br>Note 1: Run-to-run variation of performance was much sma=
ller than the difference on the host and in the container.<br>Note 2: When =
Singularity was used, I could not instruct mpirun to use the ofed by specif=
ying &quot;--mca btl openib,self,vader&quot; in the mpirun parameter list. =
Doing so would give me an error message stating that the openib component i=
s missing. However, from the bandwidth measured above, the container did se=
em to be able to use InfiniBand, otherwise the bandwidth would not be so hi=
gh (the nodes only had InfiniBand and 1G Ethernet). Maybe container was usi=
ng IPoIB? I did not check that yet. <br><br>Reference: How the benchmarks w=
ere executed:<br>mpirun -n 20 -hostfile hostfile singularity exec /home/chi=
h/containers/containe<wbr>r-centos6-demo.img xhpl<br>mpirun -n 2 -hostfile =
hostfile singularity exec /home/chih/containers/containe<wbr>r-centos6-demo=
.img osu_bw<br>mpirun -n 2 -hostfile hostfile singularity exec /home/chih/c=
ontainers/containe<wbr>r-centos6-demo.img osu_latency<span><font color=3D"#=
888888"><br><br>Chih-Song<br><br></font></span></div></div></div><span><fon=
t color=3D"#888888"><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br></div></div>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</font></span></blockquote></div><span><br><br clear=3D"all"><div><br></div=
>-- <br><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><=
div><div dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurt=
zer</div><div>HPC Systems Architect and Technology Developer</div><div>Lawr=
ence Berkeley National Laboratory HPCS<br>University of California Berkeley=
 Research IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singul=
arity.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://singularity<wbr>.=
lbl.gov/</a>)</div><div>Warewulf Cluster Management=C2=A0(<a href=3D"http:/=
/warewulf.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://warewulf.lb<w=
br>l.gov/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.com/gmkurtz=
er" rel=3D"nofollow" target=3D"_blank">https://github.com/gmk<wbr>urtzer</a=
>,=C2=A0<span style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"ht=
tps://twitter.com/gmkurtzer" style=3D"font-size:12.8px" rel=3D"nofollow" ta=
rget=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</a></div></div></div></d=
iv></div></div></div></div></div></div></div>
</span></div>
</blockquote></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div=
 dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtzer</div=
><div>HPC Systems Architect and Technology Developer</div><div>Lawrence Ber=
keley National Laboratory HPCS<br>University of California Berkeley Researc=
h IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singularity.lb=
l.gov/" rel=3D"nofollow" target=3D"_blank">http://singularity<wbr>.lbl.gov/=
</a>)</div><div>Warewulf Cluster Management=C2=A0(<a href=3D"http://warewul=
f.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://warewulf.lb<wbr>l.gov=
/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.com/gmkurtzer" rel=
=3D"nofollow" target=3D"_blank">https://github.com/gmk<wbr>urtzer</a>,=C2=
=A0<span style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"https:/=
/twitter.com/gmkurtzer" style=3D"font-size:12.8px" rel=3D"nofollow" target=
=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</a></div></div></div></div><=
/div></div></div></div></div></div></div>
</div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div><br><br></div></div><span><font color=3D"#888888">-- <br=
><div dir=3D"ltr"><span><div><div dir=3D"ltr"><div>Chih-Song Kuo =E9=83=AD=
=E7=9F=A5=E9=A0=8C<br>Senior Sales Consultant - HPC Benchmark Specialist at=
 Fujitsu<br>M.Sc. RWTH with distinction in Software Systems Engineering wit=
h HPC focus<br>B.Sc. NTHU in Computer Science, B.S.M. NTHU in Quantitative =
Finance<br>Tel: =C2=A0<a value=3D"+491778894928">+49-177-88949-28</a>; <a v=
alue=3D"+4924188949155">+49-241-88949-155</a>; <a value=3D"+886226629518">+=
886-2-26629518</a></div></div></div></span></div></font></span><div><div><b=
r>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br></div>
</blockquote></div></blockquote></div></div></div><div class=3D"m_533529040=
6642423689m_3988348498465513417m_6026970709499655369HOEnZb"><div class=3D"m=
_5335290406642423689m_3988348498465513417m_6026970709499655369h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div></div><=
/div><span class=3D"m_5335290406642423689m_3988348498465513417HOEnZb"><font=
 color=3D"#888888">-- <br><div class=3D"m_5335290406642423689m_398834849846=
5513417m_6026970709499655369gmail_signature" data-smartmail=3D"gmail_signat=
ure">Tyler Trafford</div>
</font></span></div><div class=3D"m_5335290406642423689m_398834849846551341=
7HOEnZb"><div class=3D"m_5335290406642423689m_3988348498465513417h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div></div></div></div><div class=3D"m_=
5335290406642423689HOEnZb"><div class=3D"m_5335290406642423689h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div class=3D"m_5335290406642423689gmail_signature" data-smartmail=3D"gmail=
_signature"><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><d=
iv><div dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtz=
er</div><div>HPC Systems Architect and Technology Developer</div><div>Lawre=
nce Berkeley National Laboratory HPCS<br>University of California Berkeley =
Research IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singula=
rity.lbl.gov/" target=3D"_blank">http://<wbr>singularity.lbl.gov/</a>)</div=
><div>Warewulf Cluster Management=C2=A0(<a href=3D"http://warewulf.lbl.gov/=
" target=3D"_blank">http://warewulf.<wbr>lbl.gov/</a>)</div><div>GitHub:=C2=
=A0<a href=3D"https://github.com/gmkurtzer" target=3D"_blank">https://githu=
b.com/<wbr>gmkurtzer</a>,=C2=A0<span style=3D"font-size:12.8px">Twitter:=C2=
=A0</span><a href=3D"https://twitter.com/gmkurtzer" style=3D"font-size:12.8=
px" target=3D"_blank">https://<wbr>twitter.com/gmkurtzer</a></div></div></d=
iv></div></div></div></div></div></div></div></div>
</div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

--001a113d69bcf73d3f0549bb847f--

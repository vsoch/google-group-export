X-Received: by 10.107.33.140 with SMTP id h134mr62818321ioh.13.1470340961494;
        Thu, 04 Aug 2016 13:02:41 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.180.200 with SMTP id d191ls1617783iof.13.gmail; Thu, 04
 Aug 2016 13:02:41 -0700 (PDT)
X-Received: by 10.66.183.80 with SMTP id ek16mr128522660pac.21.1470340960799;
        Thu, 04 Aug 2016 13:02:40 -0700 (PDT)
Return-Path: <igor...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id ib2si5850180pad.209.2016.08.04.13.02.40
        for <singu...@lbl.gov>;
        Thu, 04 Aug 2016 13:02:40 -0700 (PDT)
Received-SPF: pass (google.com: domain of igor...@gmail.com designates 209.85.220.173 as permitted sender) client-ip=209.85.220.173;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of igor...@gmail.com designates 209.85.220.173 as permitted sender) smtp.mailfrom=igor...@gmail.com
X-Ironport-SBRS: 2.7
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2GFAAAinqNXf63cVdFdhBt8B4M4gQyjOYkuH4Q9giF2gT0aJiaBbFSBXEsBgQ8CgUEHOBQBAQEBAQEBAw8BAQkLCwkXMYJTOQoGKwEBAQEBAQEBASECDR4EFQELGwEBBAESCAEIHQEKAQIOHgMBCwYDAgsNIAEJAgICHwEBDgMBBQEcDgcEARwEAYd0AQMPCAUJkTuPRIEyPjGLO4FqgloFgQABhTsKGScNVINbAQEBBwEBAQEBAQESBgIGEIlkgQOCQ4FPEQEzFYJVgloFgUWER4ISB2CFEgtqP4k1KggBAYEighiBcm6CfIJzQ4I2gWsXN4c+hUmILIQFgjgSHoEPDw+CSByBah4yAQEBAQOFboE2AQEB
X-IPAS-Result: A2GFAAAinqNXf63cVdFdhBt8B4M4gQyjOYkuH4Q9giF2gT0aJiaBbFSBXEsBgQ8CgUEHOBQBAQEBAQEBAw8BAQkLCwkXMYJTOQoGKwEBAQEBAQEBASECDR4EFQELGwEBBAESCAEIHQEKAQIOHgMBCwYDAgsNIAEJAgICHwEBDgMBBQEcDgcEARwEAYd0AQMPCAUJkTuPRIEyPjGLO4FqgloFgQABhTsKGScNVINbAQEBBwEBAQEBAQESBgIGEIlkgQOCQ4FPEQEzFYJVgloFgUWER4ISB2CFEgtqP4k1KggBAYEighiBcm6CfIJzQ4I2gWsXN4c+hUmILIQFgjgSHoEPDw+CSByBah4yAQEBAQOFboE2AQEB
X-IronPort-AV: E=Sophos;i="5.28,471,1464678000"; 
   d="sh'?scan'208,217";a="31669507"
Received: from mail-qk0-f173.google.com ([209.85.220.173])
  by fe4.lbl.gov with ESMTP; 04 Aug 2016 13:02:37 -0700
Received: by mail-qk0-f173.google.com with SMTP id p74so243197958qka.0
        for <singu...@lbl.gov>; Thu, 04 Aug 2016 13:02:36 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=hS123/UJoymJxzWqZfgNt531phFRwQZ8uUp56hpf2XQ=;
        b=YAAI3N27gRE8fKpXeLAbkCkJdsO20PrIh9oVsGhJ5dEjZYuLMDAU37/ojYo4ClOoaa
         TaTuUKWK0w5umV7fmGPtviTFrhHmEXa2Qb5t/L93If0Pvz9RoMwR0848bcTcXES2fRPw
         n/Kyq2bv8DB1qnPTShtmy+YyMDcsd5+5NVVKbFwTeAtJEBCwqadBiF4/2LTrGf10hQOP
         MrHvgGCHqjk9RsE0FZpEVDw8rlCDfIr9jWuxAsX4pWsCByFf+3Fzo+qYaFSOo+JCZdSX
         DjjGc6+1ROyCK/d/f4UPr/qjyApijc0ZWJUNeqX3VK1uE1eRuzZ+ifMW2Bans9AIyZQb
         rxjA==
X-Gm-Message-State: AEkooutmGchJPSypmMP4eXItRO//Juok43xU0dAXmfHZU7uFjJlFZWo1CMa6VfDEMtrMvMdhLVNtKPr3EqlgnA==
X-Received: by 10.129.177.201 with SMTP id p192mr28872690ywh.102.1470340955498;
 Thu, 04 Aug 2016 13:02:35 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.37.161.34 with HTTP; Thu, 4 Aug 2016 13:02:33 -0700 (PDT)
In-Reply-To: <CAMfmYegA2BbQ6V-ZmUDRgm35GSoBXiMh82K7bAhZLvynGce7Cw@mail.gmail.com>
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
 <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov> <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
 <CAA8GL6BdE1TRBaPD-oM7qcj8QK1cBsmJsUzYyrvkRPBP9CX+hQ@mail.gmail.com>
 <CAMfmYehdPLtiouQqMGqOx4ZbEXFbbPRL5QOxsP_vQo0us1QLuA@mail.gmail.com>
 <B927B7F6-3CFB-452D-92AB-866F9B8024E4@gmail.com> <CAMfmYeiSvcReO4jvSGJkavnex64wGZ8Phxva2kAxJ7pcp48YiA@mail.gmail.com>
 <CAMfmYeiaTxVQSNqwprHe5ckcDHPcJXy3imdepiRL+KkDh12TCQ@mail.gmail.com>
 <65CD778F-6CD1-4DB4-9668-4D89839B7053@gmail.com> <CAMfmYeg_pnJcyKGetK7WVChToaWCgGYH-nrYY9v=2+RSkuWZuQ@mail.gmail.com>
 <C5AE54CB-2BA1-4E59-88FC-D20224A46086@gmail.com> <CAMfmYeg2rR9-U-zyviCeDXRt_QgKv_K0p9pf-+qgoGPQAjxjXA@mail.gmail.com>
 <95039222-908B-4AE8-8844-551646C9733C@gmail.com> <CAMfmYeh9m_Z7N5KQy5f5ocumCrG7bX33OjpsT4jh9KgOekWcWg@mail.gmail.com>
 <CAMfmYegA2BbQ6V-ZmUDRgm35GSoBXiMh82K7bAhZLvynGce7Cw@mail.gmail.com>
From: Igor Yakushin <igor...@gmail.com>
Date: Thu, 4 Aug 2016 15:02:33 -0500
Message-ID: <CAMfmYeg=OkyMa5_b5K30==3ww_sS1ONeA7oaNO-gU8B=yRnmUg@mail.gmail.com>
Subject: Re: [Singularity] How to use GPU in singularity?
To: singularity@lbl.gov
Content-Type: multipart/mixed; boundary=94eb2c13d65a5a0b940539446e45

--94eb2c13d65a5a0b940539446e45
Content-Type: multipart/alternative; boundary=94eb2c13d65a5a0b910539446e43

--94eb2c13d65a5a0b910539446e43
Content-Type: text/plain; charset=UTF-8

Forgot to attach one more file:

On Thu, Aug 4, 2016 at 9:34 AM, Igor Yakushin <igor...@gmail.com> wrote:

> Hi Rick,
>
> The scripts are attached. The driver script that calls others is build.sh.
> I found it the easiest to work with Scientific Linux 7, I had some issues
> with Ubuntu and CentOS containers. Several Nvidia drivers and cuda must be
> put in the same directory as the scripts for them to work.
> Once the image is build, you can choose which driver to use by executing:
> source /usr/local/nvidia.sh <driver version>
> inside the container. See /usr/local/NVIDIA* which drivers are provided
> but you can easily extend the script to any drivers.
> The container is built under singularity 2.1.
> I'll publish the image somewhere later today.
> The image contains a lot of other things not needed for TensorFlow.
> I tested it on my laptop (GeForce GTX 960M, 361.42) and on a few nodes on
> the cluster (Tesla K40m, K80 driver versions 352.55, 346.47). At first
> glance TensorFlow works but I do not know it well enough to try all the
> features.
> One thing that is still not clear to me: how does Nvidia distinguish
> drivers for different hardware? My guess is by version number since
> otherwise the names are the same for consumer cards and Tesla but when you
> try to download a driver from Nvidia some drivers support only Tesla and
> some only consumer cards.
>
> Igor
>
> On Mon, Aug 1, 2016 at 9:21 PM, Igor Yakushin <igor...@gmail.com> wrote:
>
>> Hi Rick,
>> 0) Don't use *.deb either for NVIDIA or cuda, use *.run.
>> 1) Get the same version of NVIDIA as on the host and extract it (there is
>> an option for that) into a single directory in /usr/local without
>> installing. Also pay attention to get NVIDIA*.run for your hardware.
>> Apparently Tesla cards require different driver  than consumer cards.
>> 2) Set both PATH and LD_LIBRARY_PATH to the same directory where NVIDIA
>> is unpacked. After that nvidia-smi should work on the singularity shell.
>> 3) Get latest cuda 7.5  *.run file and install only cuda and not the
>> driver (there is an option for that; by default it would install driver as
>> well which would most likely be a different version than what you need and
>> would conflict the version extracted from NVIDIA file)
>> 4) cuda by default will also be installed into /usr/local; set
>> LD_LIBRARY_PATH to point there
>> 5) install the latest gpu enabled tensorflow with pip getting it from
>> their website
>> I'll try to put all this into *def file
>> There might be some important prerequisite *deb files that I installed to
>> make all this work and forgot about them, so I would need to try to
>> reproduce it from scratch to rediscover them.
>> Thank you,
>> Igor
>>
>>
>> On Mon, Aug 1, 2016 at 12:43 AM, Rick Wagner <richard...@gmail.com>
>> wrote:
>>
>>> Igor,
>>>
>>> If you had a chance to post your definition file or the steps you took,
>>> I know several of us would appreciate it. Getting TensorFlow running on
>>> CentOS was a huge effort for our support staff. And that's just one of many
>>> GPU-enabled applications.
>>>
>>> --Rick
>>>
>>> On Jul 31, 2016, at 10:20 PM, Igor Yakushin <igor...@gmail.com> wrote:
>>>
>>> Thank you, Nathan. It finally works!
>>>
>>> On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin <nathan...@gmail.com>
>>> wrote:
>>>
>>>> Yes I do
>>>>
>>>> On Jul 31, 2016, at 5:03 PM, Igor Yakushin <igor...@gmail.com> wrote:
>>>>
>>>> Nathan,
>>>> When you import tensorflow in python, does it tell you what cuda
>>>> libraries it is loading or not?
>>>> Do you see these messages:
>>>> ======
>>>> >>> import tensorflow as tf
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>> CUDA library libcublas.so locally
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>> CUDA library libcudnn.so locally
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>> CUDA library libcufft.so locally
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>> CUDA library libcuda.so locally
>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>> CUDA library libcurand.so locally
>>>> ======
>>>> Thank you,
>>>> Igor
>>>>
>>>> On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin <nathan...@gmail.com>
>>>> wrote:
>>>>
>>>>> Hi Igor,
>>>>>
>>>>> In regards to your first questions, the OS/drivers of your building
>>>>> computer should not matter. I built an Ubuntu 14.04 image on my RHEL 7 box
>>>>> for our RHEL 6 cluster. I'm not sure that the toolkit is that version
>>>>> specific, my image seems to work fine and it's running 353.63. There is one
>>>>> thing that I do that may be helpful. I read it somewhere online and am not
>>>>> actually sure if it does anything, but I've included it in my image
>>>>> definitions just in case. Apparently there is something about initializing
>>>>> the CUDA Toolkit. As part of my definition file I run 'make' on the CUDA
>>>>> sample 'deviceQuery'. Maybe that will help?
>>>>>
>>>>> Best,
>>>>> Nathan
>>>>>
>>>>> On Jul 31, 2016, at 1:51 PM, Igor Yakushin <igor...@gmail.com>
>>>>> wrote:
>>>>>
>>>>> Hi Nathan,
>>>>> I got a little bit further: nvidia-smi is working now but tensorflow
>>>>> still complains:
>>>>> =========
>>>>>
>>>>> =========
>>>>> Singularity/ubuntu_14.04.img> nvidia-smi
>>>>> Sun Jul 31 17:33:44 2016
>>>>> +------------------------------------------------------+
>>>>>
>>>>> | NVIDIA-SMI 352.55     Driver Version: 352.55         |
>>>>>
>>>>> |-------------------------------+----------------------+----------------------+
>>>>>
>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile
>>>>> Uncorr. ECC |
>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util
>>>>>  Compute M. |
>>>>> |===============================+======================+======================|
>>>>>
>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>>>>>                    0 |
>>>>> | N/A   45C    P0    79W / 235W |    158MiB / 11519MiB |     45%
>>>>>      Default |
>>>>> +-------------------------------+----------------------+----------------------+
>>>>>
>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>>>>>                    0 |
>>>>> | N/A   23C    P8    18W / 235W |     61MiB / 11519MiB |      0%
>>>>>      Default |
>>>>> +-------------------------------+----------------------+----------------------+
>>>>>
>>>>>
>>>>>
>>>>> +-----------------------------------------------------------------------------+
>>>>>
>>>>> | Processes:                                                       GPU
>>>>> Memory |
>>>>> |  GPU       PID  Type  Process name                               Usage
>>>>>      |
>>>>> |=============================================================================|
>>>>>
>>>>> +-----------------------------------------------------------------------------+
>>>>>
>>>>> Singularity/ubuntu_14.04.img> python
>>>>> Python 2.7.6 (default, Mar 22 2014, 22:59:56)
>>>>> [GCC 4.8.2] on linux2
>>>>> Type "help", "copyright", "credits" or "license" for more information.
>>>>> >>> import tensorflow
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcublas.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcudnn.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcufft.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcuda.so.1 locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcurand.so locally
>>>>> >>> ss = tensorflow.Session()
>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to
>>>>> cuInit: CUDA_ERROR_NO_DEVICE
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving
>>>>> CUDA diagnostic information for host: midway-l34-02
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname:
>>>>> midway-l34-02
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
>>>>> reported version is: 352.93.0
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver
>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module
>>>>>  352.55  Thu Oct  8 15:18:00 PDT 2015
>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)
>>>>> """
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel
>>>>> reported version is: 352.55.0
>>>>> E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:296] kernel
>>>>> version 352.55.0 does not match DSO version 352.93.0 -- cannot find working
>>>>> devices in this configuration
>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices
>>>>> available on machine.
>>>>> >>>
>>>>> =================
>>>>> As far as I understand the problem is that cuda-7.5 was built or
>>>>> relies on nvidia 352.93 while I have NVIDIA driver 352.55 both on the host
>>>>> and container. So far I could not find cuda-7.5 built with 352.55.
>>>>> cuda-7.5 has stabs directory in which there is libcuda.so. The problem
>>>>> is probably coming from there. However, I doubt I can just replace
>>>>> libcuda.so in the stubs directory by a different version or turn it into
>>>>> symbolic link to a different version in the driver? Because its size is
>>>>> much smaller than the size of the real libcuda.so in the driver. So I
>>>>> suspect, it is really only some kind of interface to the real library?
>>>>>
>>>>> Thank you,
>>>>> Igor
>>>>>
>>>>>
>>>>> On Sun, Jul 31, 2016 at 9:36 AM, Igor Yakushin <igor...@gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Nathan,
>>>>>> When installing cuda libraries and tensorflow into the singularity
>>>>>> image, is it important to be on the same host with the same version of
>>>>>> CUDA/OS on which you are going to run later?
>>>>>> I do not have root on the machine I am going to run later and prepare
>>>>>> the image on a different machine with a different version of nvidia driver
>>>>>> and a different flavor of Linux.
>>>>>> Thank you,
>>>>>> Igor
>>>>>>
>>>>>>
>>>>>> On Sun, Jul 31, 2016 at 8:39 AM, Nathan Lin <nathan...@gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> Hi Igor,
>>>>>>>
>>>>>>> I don't necessarily have a great answer for you. If seems like you
>>>>>>> are doing everything right, yet it is still not working. In my case, yes
>>>>>>> nvidia-smi as well as TensorFlow both work correctly. I feel like your
>>>>>>> error still has to do with the version of libcuda.so you are using. Notice
>>>>>>> how Python seems to correctly load libcuda.so, yet there is later an error
>>>>>>> that is unable to find libcuda.so. My first suspicion is that there is
>>>>>>> still a version mismatch between the drivers installed on the image and on
>>>>>>> the host. If you are sure that is not true, it may be possible that the
>>>>>>> version of the driver that is installed on the machine isn't new enough for
>>>>>>> the GPU. That actually occurred on our cluster, and after a sysadmin
>>>>>>> updated the driver, it worked. Barring that I am not too sure. Maybe if you
>>>>>>> provide me with the full details of your installation (the versions of the
>>>>>>> packages that you have installed, the OS of your image and host), I might
>>>>>>> be able to think about something, but my suspicion is that the driver
>>>>>>> version on your host machine may not be new enough.
>>>>>>>
>>>>>>> Best,
>>>>>>> Nathan
>>>>>>>
>>>>>>> On Jul 31, 2016, at 12:17 AM, Igor Yakushin <igor...@gmail.com>
>>>>>>> wrote:
>>>>>>>
>>>>>>> Hi Nathan,
>>>>>>>
>>>>>>> I have found exactly the same version of NVIDIA driver and extracted
>>>>>>> from it the libraries and nvidia executables and copied them in
>>>>>>> /usr/lib64/nvidia and /usr/bin and created the corresponding symbolic
>>>>>>> links. However, I still cannot use GPU inside singularity: nvidia-smi says
>>>>>>> "GPU access blocked by the operating system" (does it work in your case?)
>>>>>>> and when tensorflow session starts it also complains that "No GPU devices
>>>>>>> available on machine". However, notice that tensorflow seems to think that
>>>>>>> a different version of NVIDIA driver is used. Not sure where it is coming
>>>>>>> from. The machine on which the image was built has version 361.42
>>>>>>>
>>>>>>> ============
>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>>>>> information.
>>>>>>> >>> import tensorflow
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcublas.so locally
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcudnn.so locally
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcufft.so locally
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcuda.so locally
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcurand.so locally
>>>>>>> >>> ss = tensorflow.Session()
>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call
>>>>>>> to cuInit: CUDA_ERROR_UNKNOWN
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>>> retrieving CUDA diagnostic information for host: midway230
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>>>>>>> hostname: midway230
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
>>>>>>> reported version is: Not found: was unable to find libcuda.so DSO loaded
>>>>>>> into this program
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver
>>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module
>>>>>>>  352.55  Thu Oct  8 15:18:00 PDT 2015
>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)
>>>>>>> """
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel
>>>>>>> reported version is: 352.55.0
>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices
>>>>>>> available on machine.
>>>>>>> >>>
>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>>>>> Failed to initialize NVML: GPU access blocked by the operating system
>>>>>>> ===========
>>>>>>>
>>>>>>> Thank you,
>>>>>>> Igor
>>>>>>>
>>>>>>>
>>>>>>> On Thu, Jul 28, 2016 at 9:34 PM, Nathan Lin <nathan...@gmail.com
>>>>>>> > wrote:
>>>>>>>
>>>>>>>> I am not sure how to find the correct driver version, but from my
>>>>>>>> testing, the version must match exactly. I will admit that I have had
>>>>>>>> problems finding specific versions of the driver from NVIDIA's website. I
>>>>>>>> had to ask a sysadmin for the installer that they used. In order to extract
>>>>>>>> the files, you need to use the --extract-only option. For instance, you
>>>>>>>> will have to run something like ' sh /NVIDIA-Linux-x86_64-352.63.run
>>>>>>>> --extract-only'/ . You will then be given a directory with all the
>>>>>>>> libraries that would have been installed. You will need to copy the
>>>>>>>> libcuda.so.###.## library (and you can copy any NVIDIA executables that you
>>>>>>>> want such as nvidia-smi). Good luck!
>>>>>>>>
>>>>>>>> On Thu, Jul 28, 2016 at 8:51 PM, Igor <igor...@gmail.com> wrote:
>>>>>>>>
>>>>>>>>> I mean I am using this file from NVIDIA website
>>>>>>>>> cuda_7.5.18_linux.run to install the driver, opengl, cuda. Driver
>>>>>>>>> installation fails, cuda succeeds.
>>>>>>>>> Also, when I run
>>>>>>>>> sh cuda_7.5.18_linux.run
>>>>>>>>> I am offered to install the driver version 352.39 while on the
>>>>>>>>> host it is 346.47. I cannot upgrade the host. Any idea where I
>>>>>>>>> can get 346.17?
>>>>>>>>> I tried using the same link just substitute 18 for something else
>>>>>>>>> but have not found the files:
>>>>>>>>> wget http://developer.download.nvidia.com/compute/cuda/7.5/Prod/
>>>>>>>>> local_installers/cuda_7.5.1X_linux.run
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:
>>>>>>>>>>
>>>>>>>>>> Hi Nathan,
>>>>>>>>>> When I try to install the driver by running NVIDIA*.run script
>>>>>>>>>> inside the image, it fails, probably because it tries to modify kernel that
>>>>>>>>>> belongs to host?
>>>>>>>>>> How do I extract just libcuda.so.345.67 without installing the
>>>>>>>>>> driver (which is obviously problematic) and why would copying the library
>>>>>>>>>> from the host would not work?
>>>>>>>>>> Thank you,
>>>>>>>>>> Igor
>>>>>>>>>>
>>>>>>>>>> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:
>>>>>>>>>>>
>>>>>>>>>>> Also if you are using the binary installation of TensorFlow you
>>>>>>>>>>> need CUDA toolkit 7.5 and cuDNN v4. These only need to be installed on our
>>>>>>>>>>> image. As I mentioned earlier you will need the libcuda.so.###.## library
>>>>>>>>>>> on your image. It is very important that this is the same version of the
>>>>>>>>>>> NVIDIA driver as you have on your nose (seemingly 346.67 for you). I
>>>>>>>>>>> should've have also mentioned that you want the libcuda.so.345.67 library
>>>>>>>>>>> that you get from extracting the NVIDIA installer. It will not work if you
>>>>>>>>>>> try to copy the libcuda.so library that from you node.
>>>>>>>>>>>
>>>>>>>>>>> Let me know if you have any more questions.
>>>>>>>>>>>
>>>>>>>>>>> Best,
>>>>>>>>>>> Nathan
>>>>>>>>>>>
>>>>>>>>>>> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com>
>>>>>>>>>>> wrote:
>>>>>>>>>>>
>>>>>>>>>>>> Hello,
>>>>>>>>>>>>
>>>>>>>>>>>> Yes you are correct. The NVIDIA driver must be installed on
>>>>>>>>>>>> your image as well. However, you honestly only need the libcuda.so.###.##
>>>>>>>>>>>> library and the appropriate links for that library. Once you have those
>>>>>>>>>>>> installed in your image, it should work.
>>>>>>>>>>>>
>>>>>>>>>>>> Best,
>>>>>>>>>>>> Nathan
>>>>>>>>>>>>
>>>>>>>>>>>> On Thursday, July 28, 2016, Igor <igor...@gmail.com> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>> Hi All,
>>>>>>>>>>>>>
>>>>>>>>>>>>> I am trying to use GPU-enabled tensorflow and it cannot find
>>>>>>>>>>>>> GPU card from inside the container.
>>>>>>>>>>>>>
>>>>>>>>>>>>> On the host:
>>>>>>>>>>>>> $ lspci | grep -i nvidia
>>>>>>>>>>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla
>>>>>>>>>>>>> K40m] (rev a1)
>>>>>>>>>>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla
>>>>>>>>>>>>> K40m] (rev a1)
>>>>>>>>>>>>>
>>>>>>>>>>>>> $ nvidia-smi
>>>>>>>>>>>>> Thu Jul 28 19:01:42 2016
>>>>>>>>>>>>> +------------------------------------------------------+
>>>>>>>>>>>>>
>>>>>>>>>>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47         |
>>>>>>>>>>>>>
>>>>>>>>>>>>> |-------------------------------+----------------------+----------------------+
>>>>>>>>>>>>>
>>>>>>>>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A |
>>>>>>>>>>>>> Volatile Uncorr. ECC |
>>>>>>>>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage |
>>>>>>>>>>>>> GPU-Util  Compute M. |
>>>>>>>>>>>>> |===============================+======================+======================|
>>>>>>>>>>>>>
>>>>>>>>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>>>>>>>>>>>>>                    0 |
>>>>>>>>>>>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB |
>>>>>>>>>>>>>      0%      Default |
>>>>>>>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>>>>>>>
>>>>>>>>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>>>>>>>>>>>>>                    0 |
>>>>>>>>>>>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB |
>>>>>>>>>>>>>      0%      Default |
>>>>>>>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> +-----------------------------------------------------------------------------+
>>>>>>>>>>>>>
>>>>>>>>>>>>> | Processes:                                                       GPU
>>>>>>>>>>>>> Memory |
>>>>>>>>>>>>> |  GPU       PID  Type  Process name
>>>>>>>>>>>>>                               Usage      |
>>>>>>>>>>>>> |=============================================================================|
>>>>>>>>>>>>>
>>>>>>>>>>>>> |    0     11671    G   /usr/bin/X
>>>>>>>>>>>>>                                       9MiB |
>>>>>>>>>>>>> |    1     11671    G   /usr/bin/X
>>>>>>>>>>>>>                                       3MiB |
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> Inside singularity:
>>>>>>>>>>>>> $ singularity shell /software/src/singularity_imag
>>>>>>>>>>>>> es/tensorflow_0.9.img
>>>>>>>>>>>>>
>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia
>>>>>>>>>>>>> bash: lspci: command not found
>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>>>>>>>>>>> bash: nvidia-smi: command not found
>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> python
>>>>>>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>>>>>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>>>>>>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>>>>>>>>>>> information.
>>>>>>>>>>>>> >>> import tensorflow as tf
>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>> opened CUDA library libcublas.so locally
>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>> opened CUDA library libcudnn.so locally
>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>> opened CUDA library libcufft.so locally
>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>> opened CUDA library libcuda.so locally
>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>> opened CUDA library libcurand.so locally
>>>>>>>>>>>>> >>> sess = tf.Session()
>>>>>>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed
>>>>>>>>>>>>> call to cuInit: CUDA_ERROR_UNKNOWN
>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>>>>>>>>> retrieving CUDA diagnostic information for host: midway-l34-01
>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>>>>>>>>>>>>> hostname: midway-l34-01
>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185]
>>>>>>>>>>>>> libcuda reported version is: Not found: was unable to find libcuda.so DSO
>>>>>>>>>>>>> loaded into this program
>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347]
>>>>>>>>>>>>> driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel
>>>>>>>>>>>>> Module  346.47  Thu Feb 19 18:56:03 PST 2015
>>>>>>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-11)
>>>>>>>>>>>>> (GCC)
>>>>>>>>>>>>> """
>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189]
>>>>>>>>>>>>> kernel reported version is: 346.47.0
>>>>>>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU
>>>>>>>>>>>>> devices available on machine.
>>>>>>>>>>>>>
>>>>>>>>>>>>> Must there be nvidia driver installed inside the container?
>>>>>>>>>>>>> Outside? The container shares the same kernel with the host and nvidia
>>>>>>>>>>>>> kernel module needs to be loaded... How this is handled? Any requirements
>>>>>>>>>>>>> on nvidia driver and cuda versions inside and outside of the container?
>>>>>>>>>>>>>
>>>>>>>>>>>>> Thank you,
>>>>>>>>>>>>> Igor
>>>>>>>>>>>>>
>>>>>>>>>>>>>
>>>>>>>>>>>>> --
>>>>>>>>>>>>> You received this message because you are subscribed to the
>>>>>>>>>>>>> Google Groups "singularity" group.
>>>>>>>>>>>>> To unsubscribe from this group and stop receiving emails from
>>>>>>>>>>>>> it, send an email to singu...@lbl.gov.
>>>>>>>>>>>>>
>>>>>>>>>>>> --
>>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>>> Groups "singularity" group.
>>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>> Groups "singularity" group.
>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>
>>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>>
>

--94eb2c13d65a5a0b910539446e43
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Forgot to attach one more file:</div><div class=3D"gmail_e=
xtra"><br><div class=3D"gmail_quote">On Thu, Aug 4, 2016 at 9:34 AM, Igor Y=
akushin <span dir=3D"ltr">&lt;<a href=3D"mailto:igor...@gmail.com" target=
=3D"_blank">igor...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D=
"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding=
-left:1ex"><div dir=3D"ltr">Hi Rick,<div><br><div>The scripts are attached.=
 The driver script that calls others is build.sh. I found it the easiest to=
 work with Scientific Linux 7, I had some issues with Ubuntu and CentOS con=
tainers. Several Nvidia drivers and cuda must be put in the same directory =
as the scripts for them to work.</div><div>Once the image is build, you can=
 choose which driver to use by executing:</div><div>source /usr/local/nvidi=
a.sh &lt;driver version&gt;</div><div>inside the container. See /usr/local/=
NVIDIA* which drivers are provided but you can easily extend the script to =
any drivers.</div><div>The container is built under singularity 2.1.</div><=
div>I&#39;ll publish the image somewhere later today.</div><div>The image c=
ontains a lot of other things not needed for TensorFlow.</div><div>I tested=
 it on my laptop (<span style=3D"color:rgb(0,0,0);font-family:monospace">Ge=
Force GTX 960M,=C2=A0</span><font color=3D"#000000" face=3D"monospace">361.=
42</font><span style=3D"color:rgb(0,0,0);font-family:monospace">)=C2=A0</sp=
an>and on a few nodes on the cluster (Tesla K40m, K80 driver versions 352.5=
5, 346.47). At first glance TensorFlow works but I do not know it well enou=
gh to try all the features.</div><div>One thing that is still not clear to =
me: how does Nvidia distinguish drivers for different hardware? My guess is=
 by version number since otherwise the names are the same for consumer card=
s and Tesla but when you try to download a driver from Nvidia some drivers =
support only Tesla and some only consumer cards.</div><span class=3D"HOEnZb=
"><font color=3D"#888888"><div><br></div><div>Igor</div></font></span></div=
></div><div class=3D"HOEnZb"><div class=3D"h5"><div class=3D"gmail_extra"><=
br><div class=3D"gmail_quote">On Mon, Aug 1, 2016 at 9:21 PM, Igor Yakushin=
 <span dir=3D"ltr">&lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blan=
k">igor...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_qu=
ote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex=
"><div dir=3D"ltr">Hi Rick,<div>0) Don&#39;t use *.deb either for NVIDIA or=
 cuda, use *.run.</div><div>1) Get the same version of NVIDIA as on the hos=
t and extract it (there is an option for that) into a single directory in /=
usr/local without installing. Also pay attention to get NVIDIA*.run for you=
r hardware. Apparently Tesla cards require different driver =C2=A0than cons=
umer cards.</div><div>2) Set both PATH and LD_LIBRARY_PATH to the same dire=
ctory where NVIDIA is unpacked. After that nvidia-smi should work on the si=
ngularity shell.</div><div>3) Get latest cuda 7.5 =C2=A0*.run file and inst=
all only cuda and not the driver (there is an option for that; by default i=
t would install driver as well which would most likely be a different versi=
on than what you need and would conflict the version extracted from NVIDIA =
file)</div><div>4) cuda by default will also be installed into /usr/local; =
set LD_LIBRARY_PATH to point there</div><div>5) install the latest gpu enab=
led tensorflow with pip getting it from their website</div><div>I&#39;ll tr=
y to put all this into *def file</div><div>There might be some important pr=
erequisite *deb files that I installed to make all this work and forgot abo=
ut them, so I would need to try to reproduce it from scratch to rediscover =
them.</div><div>Thank you,</div><div>Igor</div><div><br></div></div><div><d=
iv><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Mon, Aug 1,=
 2016 at 12:43 AM, Rick Wagner <span dir=3D"ltr">&lt;<a href=3D"mailto:rich=
ard...@gmail.com" target=3D"_blank">richard...@gmail.com</a>&gt;</span> wro=
te:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-=
left:1px #ccc solid;padding-left:1ex"><div dir=3D"auto"><div></div><div>Igo=
r,</div><div><br></div><div>If you had a chance to post your definition fil=
e or the steps you took, I know several of us would appreciate it. Getting =
TensorFlow running on CentOS was a huge effort for our support staff. And t=
hat&#39;s just one of many GPU-enabled applications.</div><span><font color=
=3D"#888888"><div><br></div><div>--Rick</div></font></span><div><div><div><=
br>On Jul 31, 2016, at 10:20 PM, Igor Yakushin &lt;<a href=3D"mailto:igor..=
.@gmail.com" target=3D"_blank">igor...@gmail.com</a>&gt; wrote:<br><br></di=
v><blockquote type=3D"cite"><div><div dir=3D"ltr">Thank you, Nathan. It fin=
ally works!</div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">=
On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin <span dir=3D"ltr">&lt;<a href=
=3D"mailto:nathan...@gmail.com" target=3D"_blank">nathan...@gmail.com</a>&g=
t;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0=
 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"auto"><div><=
/div><div>Yes I do</div><div><div><div><br>On Jul 31, 2016, at 5:03 PM, Igo=
r Yakushin &lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">igor.=
..@gmail.com</a>&gt; wrote:<br><br></div><blockquote type=3D"cite"><div><di=
v dir=3D"ltr">Nathan,<div>When you import tensorflow in python, does it tel=
l you what cuda libraries it is loading or not?</div><div>Do you see these =
messages:</div><div>=3D=3D=3D=3D=3D=3D</div><div><div>&gt;&gt;&gt; import t=
ensorflow as tf=C2=A0</div><div>I tensorflow/stream_executor/dso<wbr>_loade=
r.cc:108] successfully opened CUDA library libcublas.so locally=C2=A0</div>=
<div>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully open=
ed CUDA library libcudnn.so locally=C2=A0</div><div>I tensorflow/stream_exe=
cutor/dso<wbr>_loader.cc:108] successfully opened CUDA library libcufft.so =
locally=C2=A0</div><div>I tensorflow/stream_executor/dso<wbr>_loader.cc:108=
] successfully opened CUDA library libcuda.so locally=C2=A0</div><div>I ten=
sorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opened CUDA li=
brary libcurand.so locally=C2=A0</div></div><div>=3D=3D=3D=3D=3D=3D</div><d=
iv>Thank you,</div><div>Igor</div></div><div class=3D"gmail_extra"><br><div=
 class=3D"gmail_quote">On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin <span di=
r=3D"ltr">&lt;<a href=3D"mailto:nathan...@gmail.com" target=3D"_blank">nath=
an...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" =
style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><di=
v dir=3D"auto"><div></div><div>Hi Igor,</div><div><br></div><div>In regards=
 to your first questions, the OS/drivers of your building computer should n=
ot matter. I built an Ubuntu 14.04 image on my RHEL 7 box for our RHEL 6 cl=
uster. I&#39;m not sure that the toolkit is that version specific, my image=
 seems to work fine and it&#39;s running 353.63. There is one thing that I =
do that may be helpful. I read it somewhere online and am not actually sure=
 if it does anything, but I&#39;ve included it in my image definitions just=
 in case. Apparently there is something about initializing the CUDA Toolkit=
. As part of my definition file I run &#39;make&#39; on the CUDA sample &#3=
9;deviceQuery&#39;. Maybe that will help?</div><div><br></div><div>Best,</d=
iv><div>Nathan</div><div><div><div><br>On Jul 31, 2016, at 1:51 PM, Igor Ya=
kushin &lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">igor...@g=
mail.com</a>&gt; wrote:<br><br></div><blockquote type=3D"cite"><div><div di=
r=3D"ltr">Hi Nathan,<div>I got a little bit further: nvidia-smi is working =
now but tensorflow still complains:</div><div>=3D=3D=3D=3D=3D=3D=3D=3D=3D</=
div><div><br></div><div>=3D=3D=3D=3D=3D=3D=3D=3D=3D</div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">Singularity/ubu=
ntu_14.04.img&gt; nvidia-smi
</span><br>Sun Jul 31 17:33:44 2016 =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0<br>+-----------------------------<wbr>-------------------------+ =C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>| NVIDIA-SMI 3=
52.55 =C2=A0=C2=A0=C2=A0=C2=A0Driver Version: 352.55 =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0| =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0<br>|-----------------------------<wbr>--+---------------=
-------+----<wbr>------------------+
<br>| GPU =C2=A0Name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Persistence-=
M| Bus-Id =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan =C2=A0Temp =C2=A0Perf =C2=A0Pwr:Usage/Cap| =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0Memory-Usage | GPU-Util =C2=A0Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A00 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:20:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A045C =C2=A0=C2=A0=C2=A0P0 =C2=A0=C2=A0=C2=A079W / 235W=
 | =C2=A0=C2=A0=C2=A0158MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A045% =C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br>| =C2=A0=C2=A01 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:8B:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A023C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A018W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A061MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br> =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wb=
r>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>+----------------------------=
-<wbr>------------------------------<wbr>------------------+
<br>| Processes: =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0GPU Memory |
<br>| =C2=A0GPU =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0PID =C2=A0Type =C2=A0Pr=
ocess name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>Usage =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D|
<br>+-----------------------------<wbr>------------------------------<wbr>-=
-----------------+
<br>Singularity/ubuntu_14.04.img&gt; python
<br>Python 2.7.6 (default, Mar 22 2014, 22:59:56) =C2=A0<br>[GCC 4.8.2] on =
linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcuda.so.1 locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally
<br>&gt;&gt;&gt; ss =3D tensorflow.Session()
<br>E tensorflow/stream_executor/cud<wbr>a/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_NO_DEVICE
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway-l34-02
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:160] hostnam=
e: midway-l34-02
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:185] libcuda=
 reported version is: 352.93.0
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:356] driver =
version file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 K=
ernel Module =C2=A0352.55 =C2=A0Thu Oct =C2=A08 15:18:00 PDT 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:189] kernel =
reported version is: 352.55.0
<br>E tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:296] kernel =
version 352.55.0 does not match DSO version 352.93.0 -- cannot find working=
 devices in this configuration
<br>I tensorflow/core/common_runtime<wbr>/gpu/gpu_init.cc:81] No GPU device=
s available on machine.
<br>&gt;&gt;&gt; <br>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span></div><div><span =
style=3D"font-family:monospace">As far as I understand the problem is that =
cuda-7.5 was built or relies on nvidia 352.93 while I have NVIDIA driver 35=
2.55 both on the host and container. So far I could not find cuda-7.5 built=
 with 352.55.</span></div><div><span style=3D"font-family:monospace">cuda-7=
.5 has stabs directory in which there is libcuda.so. The problem is probabl=
y coming from there. However, I doubt I can just replace libcuda.so in the =
stubs directory by a different version or turn it into symbolic link to a d=
ifferent version in the driver? Because its size is much smaller than the s=
ize of the real libcuda.so in the driver. So I suspect, it is really only s=
ome kind of interface to the real library?</span></div><div><span style=3D"=
font-family:monospace"><br></span></div><div><span style=3D"font-family:mon=
ospace">Thank you,</span></div><div><span style=3D"font-family:monospace">I=
gor</span></div><div><span style=3D"font-family:monospace"><br></span></div=
></div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, Ju=
l 31, 2016 at 9:36 AM, Igor Yakushin <span dir=3D"ltr">&lt;<a href=3D"mailt=
o:igor...@gmail.com" target=3D"_blank">igor...@gmail.com</a>&gt;</span> wro=
te:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-=
left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Nathan,<div>When =
installing cuda libraries and tensorflow into the singularity image, is it =
important to be on the same host with the same version of CUDA/OS on which =
you are going to run later?</div><div>I do not have root on the machine I a=
m going to run later and prepare the image on a different machine with a di=
fferent version of nvidia driver and a different flavor of Linux.</div><div=
>Thank you,</div><div>Igor</div><div><br></div></div><div><div><div class=
=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, Jul 31, 2016 at 8:3=
9 AM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mailto:nathan...@gmail.co=
m" target=3D"_blank">nathan...@gmail.com</a>&gt;</span> wrote:<br><blockquo=
te class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc so=
lid;padding-left:1ex"><div dir=3D"auto"><div></div><div>Hi Igor,</div><div>=
<br></div><div>I don&#39;t necessarily have a great answer for you. If seem=
s like you are doing everything right, yet it is still not working. In my c=
ase, yes nvidia-smi as well as TensorFlow both work correctly. I feel like =
your error still has to do with the version of libcuda.so you are using. No=
tice how Python seems to correctly load libcuda.so, yet there is later an e=
rror that is unable to find libcuda.so. My first suspicion is that there is=
 still a version mismatch between the drivers installed on the image and on=
 the host. If you are sure that is not true, it may be possible that the ve=
rsion of the driver that is installed on the machine isn&#39;t new enough f=
or the GPU. That actually occurred on our cluster, and after a sysadmin upd=
ated the driver, it worked. Barring that I am not too sure. Maybe if you pr=
ovide me with the full details of your installation (the versions of the pa=
ckages that you have installed, the OS of your image and host), I might be =
able to think about something, but my suspicion is that the driver version =
on your host machine may not be new enough.=C2=A0</div><div><br></div><div>=
Best,</div><div>Nathan=C2=A0</div><div><div><div><br>On Jul 31, 2016, at 12=
:17 AM, Igor Yakushin &lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_b=
lank">igor...@gmail.com</a>&gt; wrote:<br><br></div><blockquote type=3D"cit=
e"><div><div dir=3D"ltr"><div><span style=3D"font-family:monospace"><span s=
tyle=3D"color:rgb(0,0,0)">Hi Nathan,</span></span></div><div><span style=3D=
"font-family:monospace"><span style=3D"color:rgb(0,0,0)"><br></span></span>=
</div><div><span style=3D"font-family:monospace"><span style=3D"color:rgb(0=
,0,0)">I have found exactly the same version of NVIDIA driver and extracted=
 from it the libraries and nvidia executables and copied them in /usr/lib64=
/nvidia and /usr/bin and created the corresponding symbolic links. However,=
 I still cannot use GPU inside singularity: nvidia-smi says &quot;GPU acces=
s blocked by the operating system&quot; (does it work in your case?) and wh=
en tensorflow session starts it also complains that &quot;No GPU devices av=
ailable on machine&quot;. However, notice that tensorflow seems to think th=
at a different version of NVIDIA driver is used. Not sure where it is comin=
g from. The machine on which the image was built has version=C2=A0</span></=
span><span style=3D"color:rgb(0,0,0);font-family:monospace">361.42</span></=
div><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">=
<div><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)"=
><br></span></span></div><div><span style=3D"font-family:monospace"><span s=
tyle=3D"color:rgb(0,0,0)">=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span></span=
></div>Python 2.7.12 (default, Jul =C2=A01 2016, 15:12:24) =C2=A0</span><br=
>[GCC 5.4.0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcuda.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally
<br>&gt;&gt;&gt; ss =3D tensorflow.Session()
<br>E tensorflow/stream_executor/cud<wbr>a/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway230
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:160] hostnam=
e: midway230
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:185] libcuda=
 reported version is: Not found: was unable to find libcuda.so DSO loaded i=
nto this program
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:347] driver =
version file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 K=
ernel Module =C2=A0352.55 =C2=A0Thu Oct =C2=A08 15:18:00 PDT 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:189] kernel =
reported version is: 352.55.0
<br>I tensorflow/core/common_runtime<wbr>/gpu/gpu_init.cc:81] No GPU device=
s available on machine.
<br>&gt;&gt;&gt; =C2=A0<br>Singularity/tensorflow_0.9.img<wbr>&gt; nvidia-s=
mi
<br>Failed to initialize NVML: GPU access blocked by the operating system<b=
r>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span><div><span style=3D"font-family:mon=
ospace"><br></span></div><div><span style=3D"font-family:monospace">Thank y=
ou,</span></div><div><span style=3D"font-family:monospace">Igor</span></div=
><div><span style=3D"font-family:monospace"><br></span></div></div><div cla=
ss=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Jul 28, 2016 at 9=
:34 PM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mailto:nathan...@gmail.=
com" target=3D"_blank">nathan...@gmail.com</a>&gt;</span> wrote:<br><blockq=
uote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc =
solid;padding-left:1ex"><div dir=3D"ltr">I am no<font face=3D"arial, helvet=
ica, sans-serif">t sure how to find the correct driver version, but from my=
 testing, the version must match exactly. I will admit that I have had prob=
lems finding specific versions of the driver from NVIDIA&#39;s website. I h=
ad to ask a sysadmin for the installer that they used. In order to extract =
the files, you need to use the --extract-only option. For instance, you wil=
l have to run something like &#39;

















sh /<a href=3D"http://NVIDIA-Linux-x86_64-352.63.ru">NVIDIA-Linux-x86_64-35=
2.63.ru</a><wbr>n
--extract-only&#39;/ . You will then be given a directory with all the libr=
aries that would have been installed. You will need to copy the libcuda.so.=
###.## library (and you can copy any NVIDIA executables that you want such =
as nvidia-smi). Good luck!</font></div><div><div><div class=3D"gmail_extra"=
><br><div class=3D"gmail_quote">On Thu, Jul 28, 2016 at 8:51 PM, Igor <span=
 dir=3D"ltr">&lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">igo=
r...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" s=
tyle=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div=
 dir=3D"ltr"><span style=3D"font-family:monospace"><span style=3D"color:rgb=
(0,0,0)">I mean I am using this file from NVIDIA website cuda_7.5.18_linux.=
run to install the driver, opengl, cuda. Driver installation fails, cuda su=
cceeds.=C2=A0</span></span><div><span style=3D"font-family:monospace"><font=
 color=3D"#000000">Also, when I run=C2=A0</font></span></div><div><span sty=
le=3D"font-family:monospace"><font color=3D"#000000">sh=C2=A0</font></span>=
<font color=3D"#000000" face=3D"monospace">cuda_7.5.18_linux.run</font></di=
v><div><span style=3D"font-family:monospace"><font color=3D"#000000">I am o=
ffered to install the driver version=C2=A0</font></span><span style=3D"font=
-family:monospace"><span style=3D"color:rgb(0,0,0)">352.39 while on the hos=
t it is=C2=A0</span></span><span style=3D"font-family:monospace"><span styl=
e=3D"color:rgb(0,0,0)">346.47. I cannot upgrade the host. Any idea where I =
can get 346.17?</span></span></div><div><span style=3D"font-family:monospac=
e"><font color=3D"#000000">I tried using the same link just substitute 18 f=
or something else but have not found the files:</font></span></div><div><sp=
an style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">wget <a=
 href=3D"http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_i=
nstallers/cuda_7.5.1X_linux.run" target=3D"_blank">http://developer.downloa=
d.nvid<wbr>ia.com/compute/cuda/7.5/Prod/<wbr>local_installers/cuda_7.5.1X_<=
wbr>linux.run</a></span><br></span><br></div><div><div><div><br></div><div>=
<br></div><div>On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:<=
blockquote class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border=
-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Nathan,<div>When=
 I try to install the driver by running NVIDIA*.run script inside the image=
, it fails, probably because it tries to modify kernel that belongs to host=
?</div><div>How do I extract just libcuda.so.345.67 without installing the =
driver (which is obviously problematic) and why would copying the library f=
rom the host would not work?</div><div>Thank you,</div><div>Igor<br><br>On =
Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:<blockquote c=
lass=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #c=
cc solid;padding-left:1ex">Also if you are using the binary installation of=
 TensorFlow you need CUDA toolkit 7.5 and cuDNN v4. These only need to be i=
nstalled on our image. As I mentioned earlier you will need the libcuda.so.=
###.## library on your image. It is very important that this is the same ve=
rsion of the NVIDIA driver as you have on your nose (seemingly 346.67 for y=
ou). I should&#39;ve have also mentioned that you want the libcuda.so.345.6=
7 library that you get from extracting the NVIDIA installer. It will not wo=
rk if you try to copy=C2=A0the libcuda.so library that from you node.=C2=A0=
<div><br></div><div>Let me know if you have any more questions.=C2=A0</div>=
<div><br></div><div>Best,</div><div>Nathan<span></span><br><br>On Thursday,=
 July 28, 2016, Nathan Lin &lt;<a rel=3D"nofollow">nat...@gmail.com</a>&gt;=
 wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;bor=
der-left:1px #ccc solid;padding-left:1ex">Hello,<div><br></div><div>Yes you=
 are correct. The NVIDIA driver must be installed on your image as well. Ho=
wever, you honestly only need the libcuda.so.###.## library and the appropr=
iate links for that library. Once you have those installed in your image, i=
t should work.=C2=A0</div><div><br></div><div>Best,</div><div>Nathan=C2=A0<=
span></span><br><br>On Thursday, July 28, 2016, Igor &lt;<a>igor...@gmail.c=
om</a>&gt; wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 =
0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi All=
,<div><br><div>I am trying to use GPU-enabled tensorflow and it cannot find=
 GPU card from inside the container.</div><div><br></div><div>On the host:<=
/div><div><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,=
0,0)">$ lspci | grep -i nvidia
</span><br>20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] =
(rev a1)
<br>8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1=
)<br>
<br></span></div><div><span style=3D"font-family:monospace"><span style=3D"=
color:rgb(0,0,0)">$ nvidia-smi
</span><br>Thu Jul 28 19:01:42 2016 =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0<br>+-----------------------------<wbr>-------------------------+ =C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>| NVIDIA-SMI 3=
46.47 =C2=A0=C2=A0=C2=A0=C2=A0Driver Version: 346.47 =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0| =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0<br>|-----------------------------<wbr>--+---------------=
-------+----<wbr>------------------+
<br>| GPU =C2=A0Name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Persistence-=
M| Bus-Id =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan =C2=A0Temp =C2=A0Perf =C2=A0Pwr:Usage/Cap| =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0Memory-Usage | GPU-Util =C2=A0Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A00 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:20:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A030C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A020W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A066MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br>| =C2=A0=C2=A01 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:8B:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A026C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A019W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A060MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br> =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wb=
r>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>+----------------------------=
-<wbr>------------------------------<wbr>------------------+
<br>| Processes: =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0GPU Memory |
<br>| =C2=A0GPU =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0PID =C2=A0Type =C2=A0Pr=
ocess name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>Usage =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A0=C2=A00 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A09MiB |
<br>| =C2=A0=C2=A0=C2=A01 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A03MiB |<br>
<br></span></div></div><div><font face=3D"monospace"><br></font></div><div>=
<font face=3D"monospace">Inside singularity:</font></div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ singularity s=
hell /software/src/singularity_imag<wbr>es/tensorflow_0.9.img</span><br></s=
pan></div><div><span style=3D"font-family:monospace"><span style=3D"color:r=
gb(0,0,0)"><br></span></span></div><div><span style=3D"font-family:monospac=
e"><span style=3D"color:rgb(0,0,0)">Singularity/tensorflow_0.9.img<wbr>&gt;=
 lspci | grep -i nvidia
</span><br>bash: lspci: command not found
<br>Singularity/tensorflow_0.9.img<wbr>&gt; nvidia-smi
<br>bash: nvidia-smi: command not found
<br>Singularity/tensorflow_0.9.img<wbr>&gt; python
<br>Python 2.7.12 (default, Jul =C2=A01 2016, 15:12:24) =C2=A0<br>[GCC 5.4.=
0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow as tf
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcuda.so locally
<br>I tensorflow/stream_executor/dso<wbr>_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally
<br>&gt;&gt;&gt; sess =3D tf.Session()
<br>E tensorflow/stream_executor/cud<wbr>a/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway-l34-01
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:160] hostnam=
e: midway-l34-01
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:185] libcuda=
 reported version is: Not found: was unable to find libcuda.so DSO loaded i=
nto this program
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:347] driver =
version file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 K=
ernel Module =C2=A0346.47 =C2=A0Thu Feb 19 18:56:03 PST 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/cud<wbr>a/cuda_diagnostics.cc:189] kernel =
reported version is: 346.47.0
<br>I tensorflow/core/common_runtime<wbr>/gpu/gpu_init.cc:81] No GPU device=
s available on machine.<br>
<br></span></div><div><span style=3D"font-family:monospace">Must there be n=
vidia driver installed inside the container? Outside? The container shares =
the same kernel with the host and nvidia kernel module needs to be loaded..=
. How this is handled? Any requirements on nvidia driver and cuda versions =
inside and outside of the container?</span></div><div><span style=3D"font-f=
amily:monospace"><br></span></div><div><span style=3D"font-family:monospace=
">Thank you,</span></div><div><span style=3D"font-family:monospace">Igor</s=
pan></div><div><span style=3D"font-family:monospace"><br></span></div><div>=
<font face=3D"monospace"><br></font></div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div>
</blockquote></div>
</blockquote></div></div></blockquote></div></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

--94eb2c13d65a5a0b910539446e43--

--94eb2c13d65a5a0b940539446e45
Content-Type: application/x-sh; name="sl7.sh"
Content-Disposition: attachment; filename="sl7.sh"
Content-Transfer-Encoding: base64
X-Attachment-Id: f_irgr1bm64

Zm9yIHYgaW4gMzQ2LjQ2IDM0Ni40NyAzNDYuOTYgMzUyLjM5IDM1Mi41NSAzNTIuOTkgMzYxLjQy
IDM2Ny4zNQpkbwogICAgc2ggTlZJRElBLUxpbnV4LXg4Nl82NC0kdi5ydW4gLXgKICAgIG12IE5W
SURJQS1MaW51eC14ODZfNjQtJHYgL3Vzci9sb2NhbC8KICAgIC4vbGlua3Muc2ggJHYKZG9uZQoK
c2ggLi9jdWRhXzcuNS4xOF9saW51eC5ydW4gLS10b29sa2l0IC0tc2lsZW50CnRhciB4dmYgLi9j
dWRubi03LjUtbGludXgteDY0LXY1LjAtZ2EudGd6IC1DIC91c3IvbG9jYWwKCnBpcCBpbnN0YWxs
IC0tdXBncmFkZSBwaXAKcGlwIGluc3RhbGwgbnVtcHkgc2NpcHkgbWF0cGxvdGxpYgpwaXAgaW5z
dGFsbCAtLXVwZ3JhZGUgaHR0cHM6Ly9zdG9yYWdlLmdvb2dsZWFwaXMuY29tL3RlbnNvcmZsb3cv
bGludXgvZ3B1L3RlbnNvcmZsb3ctMC4xMC4wcmMwLWNwMjctbm9uZS1saW51eF94ODZfNjQud2hs
Cgo=
--94eb2c13d65a5a0b940539446e45--

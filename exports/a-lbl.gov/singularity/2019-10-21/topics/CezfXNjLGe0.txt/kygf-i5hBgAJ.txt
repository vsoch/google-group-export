X-Received: by 10.98.204.142 with SMTP id j14mr43328296pfk.13.1469975788706;
        Sun, 31 Jul 2016 07:36:28 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.164.93 with SMTP id n90ls3399113ioe.22.gmail; Sun, 31 Jul
 2016 07:36:28 -0700 (PDT)
X-Received: by 10.98.35.145 with SMTP id q17mr86552499pfj.42.1469975788011;
        Sun, 31 Jul 2016 07:36:28 -0700 (PDT)
Return-Path: <igor...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTPS id ut14si27605281pab.53.2016.07.31.07.36.27
        for <singu...@lbl.gov>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Sun, 31 Jul 2016 07:36:28 -0700 (PDT)
Received-SPF: pass (google.com: domain of igor...@gmail.com designates 209.85.161.177 as permitted sender) client-ip=209.85.161.177;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of igor...@gmail.com designates 209.85.161.177 as permitted sender) smtp.mailfrom=igor...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2G/AABrDJ5XhrGhVdFdhBt8BoM4pC6JLR+GXXaBPUAmgWxUgicBgQ8CgR0HOBQBAQEBAQEBAw8BAQEICwsJGS+CUzkKBisBAQEBAQEBAQEhAisEFgsbAQEEARIICR0BDQ4eAwELBgMCCw0gCgICIQEBDgMBBQEcDgcEAQcVBAGHdAEDDwgFCZMUj0SBMj4xizuBaoJaBYYaChknDVSDQAEBCAEBAQEBGgIGEIlkgQOCQ4FPEQGDHYJaBYFFhlgHYIUSC2o/iTUqCAEBgSKEdoJ8gnNDgjWCAjeNBogrhAWCOBIegQ8PD4JIEQuBah4yAQEBAQOGRoE2AQEB
X-IronPort-AV: E=Sophos;i="5.28,450,1464678000"; 
   d="scan'208,217";a="31844828"
Received: from mail-yw0-f177.google.com ([209.85.161.177])
  by fe3.lbl.gov with ESMTP; 31 Jul 2016 07:36:25 -0700
Received: by mail-yw0-f177.google.com with SMTP id j12so152398131ywb.2
        for <singu...@lbl.gov>; Sun, 31 Jul 2016 07:36:25 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=0oCeC2X8Ro/LSusvoX3o0UGKAoObu7b8hAFzs86FQ5Y=;
        b=kURvIZVI5SFglCxprHklhq7aVeGewhajejvFcBEENyemYLYvcq/wFcT57Q2wGKsf6i
         G2iYY3Dncj3QiedUNU12Vcc33uel6QJJAKD9nQlCUUzChILwMpLAXdWsvg1FA4rKJYoC
         qqhwNqUX/M71o8Cc+/ZL513mZ8J2VNvwrr0gohVE7ayZcZsG/7gb+y119zLpMAFi6ixe
         +UfNUYeL+r7EujiaAX94n1SSUCc9jzHuISkPTNDZzlGbCKxBKFJkKKiVbRE6wwN2jw+C
         T3nhpbYPW36DlvBJXLQ0iRfElm8J/2NpECRS/W/cXBZziaqhb1PTKNsMlsbU/qAp4At9
         q+Mg==
X-Gm-Message-State: AEkoousaOLcatuuWagydzi3XMiQbPbgpQ9UKnpxlmx9VOt6GNygy01FCOkPh7LYkCZX/JAw6AOeayqTR5sQjYg==
X-Received: by 10.13.216.22 with SMTP id a22mr43651830ywe.5.1469975784499;
 Sun, 31 Jul 2016 07:36:24 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.37.161.34 with HTTP; Sun, 31 Jul 2016 07:36:23 -0700 (PDT)
In-Reply-To: <B927B7F6-3CFB-452D-92AB-866F9B8024E4@gmail.com>
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
 <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov> <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
 <CAA8GL6BdE1TRBaPD-oM7qcj8QK1cBsmJsUzYyrvkRPBP9CX+hQ@mail.gmail.com>
 <CAMfmYehdPLtiouQqMGqOx4ZbEXFbbPRL5QOxsP_vQo0us1QLuA@mail.gmail.com> <B927B7F6-3CFB-452D-92AB-866F9B8024E4@gmail.com>
From: Igor Yakushin <igor...@gmail.com>
Date: Sun, 31 Jul 2016 09:36:23 -0500
Message-ID: <CAMfmYeiSvcReO4jvSGJkavnex64wGZ8Phxva2kAxJ7pcp48YiA@mail.gmail.com>
Subject: Re: [Singularity] How to use GPU in singularity?
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=001a114e3e0876aec60538ef686d

--001a114e3e0876aec60538ef686d
Content-Type: text/plain; charset=UTF-8

Hi Nathan,
When installing cuda libraries and tensorflow into the singularity image,
is it important to be on the same host with the same version of CUDA/OS on
which you are going to run later?
I do not have root on the machine I am going to run later and prepare the
image on a different machine with a different version of nvidia driver and
a different flavor of Linux.
Thank you,
Igor


On Sun, Jul 31, 2016 at 8:39 AM, Nathan Lin <nathan...@gmail.com> wrote:

> Hi Igor,
>
> I don't necessarily have a great answer for you. If seems like you are
> doing everything right, yet it is still not working. In my case, yes
> nvidia-smi as well as TensorFlow both work correctly. I feel like your
> error still has to do with the version of libcuda.so you are using. Notice
> how Python seems to correctly load libcuda.so, yet there is later an error
> that is unable to find libcuda.so. My first suspicion is that there is
> still a version mismatch between the drivers installed on the image and on
> the host. If you are sure that is not true, it may be possible that the
> version of the driver that is installed on the machine isn't new enough for
> the GPU. That actually occurred on our cluster, and after a sysadmin
> updated the driver, it worked. Barring that I am not too sure. Maybe if you
> provide me with the full details of your installation (the versions of the
> packages that you have installed, the OS of your image and host), I might
> be able to think about something, but my suspicion is that the driver
> version on your host machine may not be new enough.
>
> Best,
> Nathan
>
> On Jul 31, 2016, at 12:17 AM, Igor Yakushin <igor...@gmail.com> wrote:
>
> Hi Nathan,
>
> I have found exactly the same version of NVIDIA driver and extracted from
> it the libraries and nvidia executables and copied them in
> /usr/lib64/nvidia and /usr/bin and created the corresponding symbolic
> links. However, I still cannot use GPU inside singularity: nvidia-smi says
> "GPU access blocked by the operating system" (does it work in your case?)
> and when tensorflow session starts it also complains that "No GPU devices
> available on machine". However, notice that tensorflow seems to think that
> a different version of NVIDIA driver is used. Not sure where it is coming
> from. The machine on which the image was built has version 361.42
>
> ============
> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
> [GCC 5.4.0 20160609] on linux2
> Type "help", "copyright", "credits" or "license" for more information.
> >>> import tensorflow
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA
> library libcublas.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA
> library libcudnn.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA
> library libcufft.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA
> library libcuda.so locally
> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA
> library libcurand.so locally
> >>> ss = tensorflow.Session()
> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to
> cuInit: CUDA_ERROR_UNKNOWN
> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA
> diagnostic information for host: midway230
> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname:
> midway230
> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
> reported version is: Not found: was unable to find libcuda.so DSO loaded
> into this program
> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version
> file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.55
>  Thu Oct  8 15:18:00 PDT 2015
> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)
> """
> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported
> version is: 352.55.0
> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices
> available on machine.
> >>>
> Singularity/tensorflow_0.9.img> nvidia-smi
> Failed to initialize NVML: GPU access blocked by the operating system
> ===========
>
> Thank you,
> Igor
>
>
> On Thu, Jul 28, 2016 at 9:34 PM, Nathan Lin <nathan...@gmail.com>
> wrote:
>
>> I am not sure how to find the correct driver version, but from my
>> testing, the version must match exactly. I will admit that I have had
>> problems finding specific versions of the driver from NVIDIA's website. I
>> had to ask a sysadmin for the installer that they used. In order to extract
>> the files, you need to use the --extract-only option. For instance, you
>> will have to run something like ' sh /NVIDIA-Linux-x86_64-352.63.run
>> --extract-only'/ . You will then be given a directory with all the
>> libraries that would have been installed. You will need to copy the
>> libcuda.so.###.## library (and you can copy any NVIDIA executables that you
>> want such as nvidia-smi). Good luck!
>>
>> On Thu, Jul 28, 2016 at 8:51 PM, Igor <igor...@gmail.com> wrote:
>>
>>> I mean I am using this file from NVIDIA website cuda_7.5.18_linux.run to
>>> install the driver, opengl, cuda. Driver installation fails, cuda succeeds.
>>> Also, when I run
>>> sh cuda_7.5.18_linux.run
>>> I am offered to install the driver version 352.39 while on the host it
>>> is 346.47. I cannot upgrade the host. Any idea where I can get 346.17?
>>> I tried using the same link just substitute 18 for something else but
>>> have not found the files:
>>> wget
>>> http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run
>>>
>>>
>>>
>>> On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:
>>>>
>>>> Hi Nathan,
>>>> When I try to install the driver by running NVIDIA*.run script inside
>>>> the image, it fails, probably because it tries to modify kernel that
>>>> belongs to host?
>>>> How do I extract just libcuda.so.345.67 without installing the driver
>>>> (which is obviously problematic) and why would copying the library from the
>>>> host would not work?
>>>> Thank you,
>>>> Igor
>>>>
>>>> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:
>>>>>
>>>>> Also if you are using the binary installation of TensorFlow you need
>>>>> CUDA toolkit 7.5 and cuDNN v4. These only need to be installed on our
>>>>> image. As I mentioned earlier you will need the libcuda.so.###.## library
>>>>> on your image. It is very important that this is the same version of the
>>>>> NVIDIA driver as you have on your nose (seemingly 346.67 for you). I
>>>>> should've have also mentioned that you want the libcuda.so.345.67 library
>>>>> that you get from extracting the NVIDIA installer. It will not work if you
>>>>> try to copy the libcuda.so library that from you node.
>>>>>
>>>>> Let me know if you have any more questions.
>>>>>
>>>>> Best,
>>>>> Nathan
>>>>>
>>>>> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com> wrote:
>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> Yes you are correct. The NVIDIA driver must be installed on your
>>>>>> image as well. However, you honestly only need the libcuda.so.###.##
>>>>>> library and the appropriate links for that library. Once you have those
>>>>>> installed in your image, it should work.
>>>>>>
>>>>>> Best,
>>>>>> Nathan
>>>>>>
>>>>>> On Thursday, July 28, 2016, Igor <igor...@gmail.com> wrote:
>>>>>>
>>>>>>> Hi All,
>>>>>>>
>>>>>>> I am trying to use GPU-enabled tensorflow and it cannot find GPU
>>>>>>> card from inside the container.
>>>>>>>
>>>>>>> On the host:
>>>>>>> $ lspci | grep -i nvidia
>>>>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev
>>>>>>> a1)
>>>>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev
>>>>>>> a1)
>>>>>>>
>>>>>>> $ nvidia-smi
>>>>>>> Thu Jul 28 19:01:42 2016
>>>>>>> +------------------------------------------------------+
>>>>>>>
>>>>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47         |
>>>>>>>
>>>>>>> |-------------------------------+----------------------+----------------------+
>>>>>>>
>>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile
>>>>>>> Uncorr. ECC |
>>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util
>>>>>>>  Compute M. |
>>>>>>> |===============================+======================+======================|
>>>>>>>
>>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>>>>>>>                    0 |
>>>>>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB |      0%
>>>>>>>      Default |
>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>
>>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>>>>>>>                    0 |
>>>>>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB |      0%
>>>>>>>      Default |
>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> +-----------------------------------------------------------------------------+
>>>>>>>
>>>>>>> | Processes:
>>>>>>>                                                       GPU Memory |
>>>>>>> |  GPU       PID  Type  Process name
>>>>>>>                               Usage      |
>>>>>>> |=============================================================================|
>>>>>>>
>>>>>>> |    0     11671    G   /usr/bin/X
>>>>>>>                                       9MiB |
>>>>>>> |    1     11671    G   /usr/bin/X
>>>>>>>                                       3MiB |
>>>>>>>
>>>>>>>
>>>>>>> Inside singularity:
>>>>>>> $ singularity shell
>>>>>>> /software/src/singularity_images/tensorflow_0.9.img
>>>>>>>
>>>>>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia
>>>>>>> bash: lspci: command not found
>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>>>>> bash: nvidia-smi: command not found
>>>>>>> Singularity/tensorflow_0.9.img> python
>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>>>>> information.
>>>>>>> >>> import tensorflow as tf
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcublas.so locally
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcudnn.so locally
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcufft.so locally
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcuda.so locally
>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>>> CUDA library libcurand.so locally
>>>>>>> >>> sess = tf.Session()
>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to
>>>>>>> cuInit: CUDA_ERROR_UNKNOWN
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>>> retrieving CUDA diagnostic information for host: midway-l34-01
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname:
>>>>>>> midway-l34-01
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
>>>>>>> reported version is: Not found: was unable to find libcuda.so DSO loaded
>>>>>>> into this program
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver
>>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module
>>>>>>>  346.47  Thu Feb 19 18:56:03 PST 2015
>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC)
>>>>>>> """
>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel
>>>>>>> reported version is: 346.47.0
>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices
>>>>>>> available on machine.
>>>>>>>
>>>>>>> Must there be nvidia driver installed inside the container? Outside?
>>>>>>> The container shares the same kernel with the host and nvidia kernel module
>>>>>>> needs to be loaded... How this is handled? Any requirements on nvidia
>>>>>>> driver and cuda versions inside and outside of the container?
>>>>>>>
>>>>>>> Thank you,
>>>>>>> Igor
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>> --
>> You received this message because you are subscribed to the Google Groups
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to singu...@lbl.gov.
>>
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a114e3e0876aec60538ef686d
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi Nathan,<div>When installing cuda libraries and tensorfl=
ow into the singularity image, is it important to be on the same host with =
the same version of CUDA/OS on which you are going to run later?</div><div>=
I do not have root on the machine I am going to run later and prepare the i=
mage on a different machine with a different version of nvidia driver and a=
 different flavor of Linux.</div><div>Thank you,</div><div>Igor</div><div><=
br></div></div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On=
 Sun, Jul 31, 2016 at 8:39 AM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"=
mailto:nathan...@gmail.com" target=3D"_blank">nathan...@gmail.com</a>&gt;</=
span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8e=
x;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"auto"><div></div=
><div>Hi Igor,</div><div><br></div><div>I don&#39;t necessarily have a grea=
t answer for you. If seems like you are doing everything right, yet it is s=
till not working. In my case, yes nvidia-smi as well as TensorFlow both wor=
k correctly. I feel like your error still has to do with the version of lib=
cuda.so you are using. Notice how Python seems to correctly load libcuda.so=
, yet there is later an error that is unable to find libcuda.so. My first s=
uspicion is that there is still a version mismatch between the drivers inst=
alled on the image and on the host. If you are sure that is not true, it ma=
y be possible that the version of the driver that is installed on the machi=
ne isn&#39;t new enough for the GPU. That actually occurred on our cluster,=
 and after a sysadmin updated the driver, it worked. Barring that I am not =
too sure. Maybe if you provide me with the full details of your installatio=
n (the versions of the packages that you have installed, the OS of your ima=
ge and host), I might be able to think about something, but my suspicion is=
 that the driver version on your host machine may not be new enough.=C2=A0<=
/div><div><br></div><div>Best,</div><div>Nathan=C2=A0</div><div><div class=
=3D"h5"><div><br>On Jul 31, 2016, at 12:17 AM, Igor Yakushin &lt;<a href=3D=
"mailto:igor...@gmail.com" target=3D"_blank">igor...@gmail.com</a>&gt; wrot=
e:<br><br></div><blockquote type=3D"cite"><div><div dir=3D"ltr"><div><span =
style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">Hi Nathan,=
</span></span></div><div><span style=3D"font-family:monospace"><span style=
=3D"color:rgb(0,0,0)"><br></span></span></div><div><span style=3D"font-fami=
ly:monospace"><span style=3D"color:rgb(0,0,0)">I have found exactly the sam=
e version of NVIDIA driver and extracted from it the libraries and nvidia e=
xecutables and copied them in /usr/lib64/nvidia and /usr/bin and created th=
e corresponding symbolic links. However, I still cannot use GPU inside sing=
ularity: nvidia-smi says &quot;GPU access blocked by the operating system&q=
uot; (does it work in your case?) and when tensorflow session starts it als=
o complains that &quot;No GPU devices available on machine&quot;. However, =
notice that tensorflow seems to think that a different version of NVIDIA dr=
iver is used. Not sure where it is coming from. The machine on which the im=
age was built has version=C2=A0</span></span><span style=3D"color:rgb(0,0,0=
);font-family:monospace">361.42</span></div><span style=3D"font-family:mono=
space"><span style=3D"color:rgb(0,0,0)"><div><span style=3D"font-family:mon=
ospace"><span style=3D"color:rgb(0,0,0)"><br></span></span></div><div><span=
 style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D</span></span></div>Python 2.7.12 (default, Jul =
=C2=A01 2016, 15:12:24) =C2=A0</span><br>[GCC 5.4.0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcublas.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcudnn.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcufft.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcuda.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcurand.so locally
<br>&gt;&gt;&gt; ss =3D tensorflow.Session()
<br>E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cu=
Init: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving C=
UDA diagnostic information for host: midway230
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: mi=
dway230
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda repo=
rted version is: Not found: was unable to find libcuda.so DSO loaded into t=
his program
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver versi=
on file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 Kernel=
 Module =C2=A0352.55 =C2=A0Thu Oct =C2=A08 15:18:00 PDT 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel repor=
ted version is: 352.55.0
<br>I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices ava=
ilable on machine.
<br>&gt;&gt;&gt; =C2=A0<br>Singularity/tensorflow_0.9.img&gt; nvidia-smi
<br>Failed to initialize NVML: GPU access blocked by the operating system<b=
r>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span><div><span style=3D"font-family:mon=
ospace"><br></span></div><div><span style=3D"font-family:monospace">Thank y=
ou,</span></div><div><span style=3D"font-family:monospace">Igor</span></div=
><div><span style=3D"font-family:monospace"><br></span></div></div><div cla=
ss=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Jul 28, 2016 at 9=
:34 PM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mailto:nathan...@gmail.=
com" target=3D"_blank">nathan...@gmail.com</a>&gt;</span> wrote:<br><blockq=
uote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc =
solid;padding-left:1ex"><div dir=3D"ltr">I am no<font face=3D"arial, helvet=
ica, sans-serif">t sure how to find the correct driver version, but from my=
 testing, the version must match exactly. I will admit that I have had prob=
lems finding specific versions of the driver from NVIDIA&#39;s website. I h=
ad to ask a sysadmin for the installer that they used. In order to extract =
the files, you need to use the --extract-only option. For instance, you wil=
l have to run something like &#39;

















sh /NVIDIA-Linux-x86_64-352.63.run
--extract-only&#39;/ . You will then be given a directory with all the libr=
aries that would have been installed. You will need to copy the libcuda.so.=
###.## library (and you can copy any NVIDIA executables that you want such =
as nvidia-smi). Good luck!</font></div><div><div><div class=3D"gmail_extra"=
><br><div class=3D"gmail_quote">On Thu, Jul 28, 2016 at 8:51 PM, Igor <span=
 dir=3D"ltr">&lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">igo=
r...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" s=
tyle=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div=
 dir=3D"ltr"><span style=3D"font-family:monospace"><span style=3D"color:rgb=
(0,0,0)">I mean I am using this file from NVIDIA website cuda_7.5.18_linux.=
run to install the driver, opengl, cuda. Driver installation fails, cuda su=
cceeds.=C2=A0</span></span><div><span style=3D"font-family:monospace"><font=
 color=3D"#000000">Also, when I run=C2=A0</font></span></div><div><span sty=
le=3D"font-family:monospace"><font color=3D"#000000">sh=C2=A0</font></span>=
<font color=3D"#000000" face=3D"monospace">cuda_7.5.18_linux.run</font></di=
v><div><span style=3D"font-family:monospace"><font color=3D"#000000">I am o=
ffered to install the driver version=C2=A0</font></span><span style=3D"font=
-family:monospace"><span style=3D"color:rgb(0,0,0)">352.39 while on the hos=
t it is=C2=A0</span></span><span style=3D"font-family:monospace"><span styl=
e=3D"color:rgb(0,0,0)">346.47. I cannot upgrade the host. Any idea where I =
can get 346.17?</span></span></div><div><span style=3D"font-family:monospac=
e"><font color=3D"#000000">I tried using the same link just substitute 18 f=
or something else but have not found the files:</font></span></div><div><sp=
an style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">wget <a=
 href=3D"http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_i=
nstallers/cuda_7.5.1X_linux.run" target=3D"_blank">http://developer.downloa=
d.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run</=
a></span><br></span><br></div><div><div><div><br></div><div><br></div><div>=
On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:<blockquote clas=
s=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc =
solid;padding-left:1ex"><div dir=3D"ltr">Hi Nathan,<div>When I try to insta=
ll the driver by running NVIDIA*.run script inside the image, it fails, pro=
bably because it tries to modify kernel that belongs to host?</div><div>How=
 do I extract just libcuda.so.345.67 without installing the driver (which i=
s obviously problematic) and why would copying the library from the host wo=
uld not work?</div><div>Thank you,</div><div>Igor<br><br>On Thursday, July =
28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:<blockquote class=3D"gmail_q=
uote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;paddin=
g-left:1ex">Also if you are using the binary installation of TensorFlow you=
 need CUDA toolkit 7.5 and cuDNN v4. These only need to be installed on our=
 image. As I mentioned earlier you will need the libcuda.so.###.## library =
on your image. It is very important that this is the same version of the NV=
IDIA driver as you have on your nose (seemingly 346.67 for you). I should&#=
39;ve have also mentioned that you want the libcuda.so.345.67 library that =
you get from extracting the NVIDIA installer. It will not work if you try t=
o copy=C2=A0the libcuda.so library that from you node.=C2=A0<div><br></div>=
<div>Let me know if you have any more questions.=C2=A0</div><div><br></div>=
<div>Best,</div><div>Nathan<span></span><br><br>On Thursday, July 28, 2016,=
 Nathan Lin &lt;<a rel=3D"nofollow">nat...@gmail.com</a>&gt; wrote:<br><blo=
ckquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #c=
cc solid;padding-left:1ex">Hello,<div><br></div><div>Yes you are correct. T=
he NVIDIA driver must be installed on your image as well. However, you hone=
stly only need the libcuda.so.###.## library and the appropriate links for =
that library. Once you have those installed in your image, it should work.=
=C2=A0</div><div><br></div><div>Best,</div><div>Nathan=C2=A0<span></span><b=
r><br>On Thursday, July 28, 2016, Igor &lt;<a>igor...@gmail.com</a>&gt; wro=
te:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-=
left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi All,<div><br><div=
>I am trying to use GPU-enabled tensorflow and it cannot find GPU card from=
 inside the container.</div><div><br></div><div>On the host:</div><div><spa=
n style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ lspci =
| grep -i nvidia
</span><br>20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] =
(rev a1)
<br>8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1=
)<br>
<br></span></div><div><span style=3D"font-family:monospace"><span style=3D"=
color:rgb(0,0,0)">$ nvidia-smi
</span><br>Thu Jul 28 19:01:42 2016 =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0<br>+------------------------------------------------------+ =C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>| NVIDIA-SMI 346.=
47 =C2=A0=C2=A0=C2=A0=C2=A0Driver Version: 346.47 =C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0| =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0<br>|-------------------------------+----------------------+=
----------------------+
<br>| GPU =C2=A0Name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Persistence-=
M| Bus-Id =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan =C2=A0Temp =C2=A0Perf =C2=A0Pwr:Usage/Cap| =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0Memory-Usage | GPU-Util =C2=A0Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D|
<br>| =C2=A0=C2=A00 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:20:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A030C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A020W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A066MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-------------------------------+----------------------+---------------=
-------+
<br>| =C2=A0=C2=A01 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:8B:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A026C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A019W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A060MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-------------------------------+----------------------+---------------=
-------+
<br> =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>+----------------------------------------=
-------------------------------------+
<br>| Processes: =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0GPU Memory |
<br>| =C2=A0GPU =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0PID =C2=A0Type =C2=A0Pr=
ocess name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Usage =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D|
<br>| =C2=A0=C2=A0=C2=A00 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A09MiB |
<br>| =C2=A0=C2=A0=C2=A01 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A03MiB |<br>
<br></span></div></div><div><font face=3D"monospace"><br></font></div><div>=
<font face=3D"monospace">Inside singularity:</font></div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ singularity s=
hell /software/src/singularity_images/tensorflow_0.9.img</span><br></span><=
/div><div><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,=
0,0)"><br></span></span></div><div><span style=3D"font-family:monospace"><s=
pan style=3D"color:rgb(0,0,0)">Singularity/tensorflow_0.9.img&gt; lspci | g=
rep -i nvidia
</span><br>bash: lspci: command not found
<br>Singularity/tensorflow_0.9.img&gt; nvidia-smi
<br>bash: nvidia-smi: command not found
<br>Singularity/tensorflow_0.9.img&gt; python
<br>Python 2.7.12 (default, Jul =C2=A01 2016, 15:12:24) =C2=A0<br>[GCC 5.4.=
0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow as tf
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcublas.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcudnn.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcufft.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcuda.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcurand.so locally
<br>&gt;&gt;&gt; sess =3D tf.Session()
<br>E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cu=
Init: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving C=
UDA diagnostic information for host: midway-l34-01
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: mi=
dway-l34-01
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda repo=
rted version is: Not found: was unable to find libcuda.so DSO loaded into t=
his program
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver versi=
on file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 Kernel=
 Module =C2=A0346.47 =C2=A0Thu Feb 19 18:56:03 PST 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel repor=
ted version is: 346.47.0
<br>I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices ava=
ilable on machine.<br>
<br></span></div><div><span style=3D"font-family:monospace">Must there be n=
vidia driver installed inside the container? Outside? The container shares =
the same kernel with the host and nvidia kernel module needs to be loaded..=
. How this is handled? Any requirements on nvidia driver and cuda versions =
inside and outside of the container?</span></div><div><span style=3D"font-f=
amily:monospace"><br></span></div><div><span style=3D"font-family:monospace=
">Thank you,</span></div><div><span style=3D"font-family:monospace">Igor</s=
pan></div><div><span style=3D"font-family:monospace"><br></span></div><div>=
<font face=3D"monospace"><br></font></div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singu...@lbl.gov</a>.<br>
</blockquote></div>
</blockquote></div>
</blockquote></div></div></blockquote></div></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></blockquote></div></div></div><div class=3D"HOEnZb"><div class=3D"h5=
">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

--001a114e3e0876aec60538ef686d--

Date: Wed, 22 Jun 2016 01:54:45 -0700 (PDT)
From: Raimon Bosch <raimo...@gmail.com>
To: singularity <singu...@lbl.gov>
Message-Id: <3998ac67-7f95-475d-ac75-ceb562e19e3b@lbl.gov>
In-Reply-To: <CAN7etTx+2ETq_aarfJfez_p4YzoNJ49zwO2CQe=KRwSSZkuR5Q@mail.gmail.com>
References: <6247ec64-6881-4978-82a0-f7d6e24039e9@lbl.gov>
 <CAN7etTx+2ETq_aarfJfez_p4YzoNJ49zwO2CQe=KRwSSZkuR5Q@mail.gmail.com>
Subject: Re: [Singularity] Communication between singularity containers
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_1486_651993433.1466585685440"

------=_Part_1486_651993433.1466585685440
Content-Type: multipart/alternative; 
	boundary="----=_Part_1487_886565833.1466585685441"

------=_Part_1487_886565833.1466585685441
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable


Hi Gregory,

Thank you for your answer. One of our experiments needs to run OpenMPI=20
among several servers. This means that we should put one of our containers=
=20
in host01, another in host02 and another in host03 and collect the results.=
=20

How can I do this execution in parallel if I need to communicate with more=
=20
than one server?

El martes, 21 de junio de 2016, 16:51:03 (UTC+2), Gregory M. Kurtzer=20
escribi=C3=B3:
>
> Hi Raimon,
>
> The communication model of a Singularity container is very different from=
=20
> that of a Docker implementation. This is because Docker for all practical=
=20
> purposes emulates a virtual machine as each container has it's own IP=20
> address and thus it's own ssh server. It also carries its own set of=20
> complexities, for example networks need to be segregated/VLan'ed, DNS/hos=
t=20
> resolution needs to be dynamic and passed down to the containers (so they=
=20
> can reach each other), ssh daemons and other process running inside the=
=20
> containers, management via an existing scheduling system, and the list go=
es=20
> on and on.
>
> Think of it this way, Singularity does not do any of that... It runs a=20
> program within the container as if it were running on the host itself, so=
=20
> to communicate between containers is as easy as communicating between=20
> programs. So for MPI, it would happen with the MPI on the physical host=
=20
> (outside the container) invoking the container subsystem which then invok=
es=20
> the MPI programs within the container and the MPI programs within the=20
> container communicate back to the MPI (orted) outside the container on th=
e=20
> host to get access to the host resources. In this model all available=20
> resources and infrastructure can be leveraged at full bandwidth by the=20
> contained processes and all of the aforementioned complexities akin to=20
> running on a virtualized mini-cluster are circumvented.
>
> There is additional information I have written at:
>
> http://singularity.lbl.gov/#hpc
>
> That page is still coming along, and needs more information still but if=
=20
> you have any questions, comments or change proposals please let us know!
>
> Thanks and hope that helps!
>
>
>
> On Tue, Jun 21, 2016 at 7:37 AM, Raimon Bosch <rai...@gmail.com=20
> <javascript:>> wrote:
>
>>
>>
>> Hi,
>>
>> We are trying to run experiments using singularity containers. The idea=
=20
>> is to run OpenMPI among several containers and check performance results=
.=20
>>
>> How can I communicate with another container? In docker this is clear=20
>> because every container gets an assigned IP and you can ping there, but=
=20
>> what is the situation in the case of singularity? Is it possible to assi=
gn=20
>> an IP to each container? Can I connect via ssh to them?
>>
>> Thanks in advance,
>>
>> --=20
>> You received this message because you are subscribed to the Google Group=
s=20
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n=20
>> email to singu...@lbl.gov <javascript:>.
>>
>
>
>
> --=20
> Gregory M. Kurtzer
> High Performance Computing Services (HPCS)
> University of California
> Lawrence Berkeley National Laboratory
> One Cyclotron Road, Berkeley, CA 94720
>

------=_Part_1487_886565833.1466585685441
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><br>Hi Gregory,<br><br>Thank you for your answer. One of o=
ur experiments needs to run OpenMPI among several servers. This means that =
we should put one of our containers in host01, another in host02 and anothe=
r in host03 and collect the results. <br><br>How can I do this execution in=
 parallel if I need to communicate with more than one server?<br><br>El mar=
tes, 21 de junio de 2016, 16:51:03 (UTC+2), Gregory M. Kurtzer  escribi=C3=
=B3:<blockquote class=3D"gmail_quote" style=3D"margin: 0;margin-left: 0.8ex=
;border-left: 1px #ccc solid;padding-left: 1ex;"><div dir=3D"ltr">Hi Raimon=
,<div><br></div><div>The communication model of a Singularity container is =
very different from that of a Docker implementation. This is because Docker=
 for all practical purposes emulates a virtual machine as each container ha=
s it&#39;s own IP address and thus it&#39;s own ssh server. It also carries=
 its own set of complexities, for example networks need to be segregated/VL=
an&#39;ed, DNS/host resolution needs to be dynamic and passed down to the c=
ontainers (so they can reach each other), ssh daemons and other process run=
ning inside the containers, management via an existing scheduling system, a=
nd the list goes on and on.</div><div><br></div><div>Think of it this way, =
Singularity does not do any of that... It runs a program within the contain=
er as if it were running on the host itself, so to communicate between cont=
ainers is as easy as communicating between programs. So for MPI, it would h=
appen with the MPI on the physical host (outside the container) invoking th=
e container subsystem which then invokes the MPI programs within the contai=
ner and the MPI programs within the container communicate back to the MPI (=
orted) outside the container on the host to get access to the host resource=
s. In this model all available resources and infrastructure can be leverage=
d at full bandwidth by the contained processes and all of the aforementione=
d complexities akin to running on a virtualized mini-cluster are circumvent=
ed.</div><div><br></div><div>There is additional information I have written=
 at:</div><div><br></div><div><a href=3D"http://singularity.lbl.gov/#hpc" t=
arget=3D"_blank" rel=3D"nofollow" onmousedown=3D"this.href=3D&#39;http://ww=
w.google.com/url?q\x3dhttp%3A%2F%2Fsingularity.lbl.gov%2F%23hpc\x26sa\x3dD\=
x26sntz\x3d1\x26usg\x3dAFQjCNEKXGCj-HN-lC0phcop4-SUwsYEjw&#39;;return true;=
" onclick=3D"this.href=3D&#39;http://www.google.com/url?q\x3dhttp%3A%2F%2Fs=
ingularity.lbl.gov%2F%23hpc\x26sa\x3dD\x26sntz\x3d1\x26usg\x3dAFQjCNEKXGCj-=
HN-lC0phcop4-SUwsYEjw&#39;;return true;">http://singularity.lbl.gov/#<wbr>h=
pc</a><br></div><div><br></div><div>That page is still coming along, and ne=
eds more information still but if you have any questions, comments or chang=
e proposals please let us know!</div><div><br></div><div>Thanks and hope th=
at helps!</div><div><br></div><div><br></div></div><div><br><div class=3D"g=
mail_quote">On Tue, Jun 21, 2016 at 7:37 AM, Raimon Bosch <span dir=3D"ltr"=
>&lt;<a href=3D"javascript:" target=3D"_blank" gdf-obfuscated-mailto=3D"5m1=
AC4FOAgAJ" rel=3D"nofollow" onmousedown=3D"this.href=3D&#39;javascript:&#39=
;;return true;" onclick=3D"this.href=3D&#39;javascript:&#39;;return true;">=
rai...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote"=
 style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><d=
iv dir=3D"ltr"><br><br>Hi,<br><br>We are trying to run experiments using si=
ngularity containers. The idea is to run OpenMPI among several containers a=
nd check performance results. <br><br>How can I communicate with another co=
ntainer? In docker this is clear because every container gets an assigned I=
P and you can ping there, but what is the situation in the case of singular=
ity? Is it possible to assign an IP to each container? Can I connect via ss=
h to them?<br><br>Thanks in advance,<span><font color=3D"#888888"><br></fon=
t></span></div><span><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"javascript:" target=3D"_blank" gdf-obfuscated-mailto=3D"=
5m1AC4FOAgAJ" rel=3D"nofollow" onmousedown=3D"this.href=3D&#39;javascript:&=
#39;;return true;" onclick=3D"this.href=3D&#39;javascript:&#39;;return true=
;">singularity...@lbl.<wbr>gov</a>.<br>
</font></span></blockquote></div><br><br clear=3D"all"><div><br></div>-- <b=
r><div><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>High Performance Computi=
ng Services (HPCS)<br>University of California<br>Lawrence Berkeley Nationa=
l Laboratory<br>One Cyclotron Road, Berkeley, CA 94720</div></div></div>
</div>
</blockquote></div>
------=_Part_1487_886565833.1466585685441--

------=_Part_1486_651993433.1466585685440--

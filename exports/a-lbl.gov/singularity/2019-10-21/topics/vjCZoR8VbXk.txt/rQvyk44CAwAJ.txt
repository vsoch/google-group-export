X-Received: by 10.237.59.26 with SMTP id p26mr813434qte.89.1476308273956;
        Wed, 12 Oct 2016 14:37:53 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.159.139 with SMTP id i133ls1598179ioe.54.gmail; Wed, 12
 Oct 2016 14:37:53 -0700 (PDT)
X-Received: by 10.99.141.76 with SMTP id z73mr4108809pgd.100.1476308272821;
        Wed, 12 Oct 2016 14:37:52 -0700 (PDT)
Return-Path: <gmku...@lbl.gov>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id o18si7676586pgc.54.2016.10.12.14.37.52
        for <singu...@lbl.gov>;
        Wed, 12 Oct 2016 14:37:52 -0700 (PDT)
Received-SPF: pass (google.com: domain of gmku...@lbl.gov designates 209.85.215.71 as permitted sender) client-ip=209.85.215.71;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of gmku...@lbl.gov designates 209.85.215.71 as permitted sender) smtp.mailfrom=gmku...@lbl.gov
IronPort-PHdr: 9a23:OAP5wRVbZBvf1qPtveF1Pe/KKU/V8LGtZVwlr6E/grcLSJyIuqrYZhOBt8tkgFKBZ4jH8fUM07OQ6PG6HzBaqs/c7zgrS99lb1c9k8IYnggtUoauKHbQC7rUVRE8B9lIT1R//nu2YgB/Ecf6YEDO8DXptWZBUiv2OQc9HOnpAIma153xjLHovcGJKFwV23KUWvBbFF2OtwLft80b08NJC50a7V/3mEZOYPlc3mhyJFiezF7W78a0+4N/oWwL46pyv/NaVe3GW4hwDfkGTWduD2dgrtbqsxbeSQKV52cNemEcllxHBBaPpEXhX5H+ry/zrOthyQGeN8mwQrcqD2eM9aBuHVXHkioIMCQouESRwu9tlr5JrQjr70hwxo3Jep2HOeBWeqnZO9wdWzwSDY5qSyVdD9bkPMM0BO0bMLMd8YQ=
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2FiAADpq/5XhkfXVdFcGgEBAQECAQEBAQgBAQEBFgEBAQMBAQEJAQEBglw1AQEBAQF0bQ8HgTKCBol0lwSCVoUFjFmBShskAxsBBoF0gjCBWgKBcwc4FAEBAQEBAQEBAQEBAhABAQEICwsJGSQLgjIEAxMFBAE5CjEBAQEBAQEBAQEBAQEBAQEBGgIIBSIPAw8CGQEBAQMBEggJKzALCQILDSAKAgIhAQ8DAQUBCxEGCAcEARwEAYdKSgMPCAWZC49NgTI+MotCiQkNg3IBAQEBBgEBAQEBAQEBIBCLAoJHgVIRAYMgglsFiDxkhhWEc4UlNQGGJoZLgwuBbk6EGYM3hWmIZYQUgj0THoERDw9bgmE7EQuBcx40B4Y9eIEoAQEB
X-IronPort-AV: E=Sophos;i="5.31,485,1473145200"; 
   d="scan'208,217";a="42945497"
Received: from mail-lf0-f71.google.com ([209.85.215.71])
  by fe4.lbl.gov with ESMTP; 12 Oct 2016 14:37:48 -0700
Received: by mail-lf0-f71.google.com with SMTP id i187so34543061lfe.4
        for <singu...@lbl.gov>; Wed, 12 Oct 2016 14:37:49 -0700 (PDT)
X-Gm-Message-State: AA6/9RlU/VWyfJb8T0xRRvAtx7rRMbpO4XgODMGWcAhXebGoHRYBXclKAJsD8aE4s9m6HNTXX11gZxk9sm+xPnttgKm44HSWCUUFoRKI5DlvGWf5Oa/WLkEx261b2M7DfN4b5JcHLla4GqeyWC8loUIpVZU=
X-Received: by 10.25.74.143 with SMTP id x137mr4095561lfa.10.1476308268098;
        Wed, 12 Oct 2016 14:37:48 -0700 (PDT)
X-Received: by 10.25.74.143 with SMTP id x137mr4095537lfa.10.1476308267752;
 Wed, 12 Oct 2016 14:37:47 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.167.67 with HTTP; Wed, 12 Oct 2016 14:37:47 -0700 (PDT)
In-Reply-To: <5cd8d8d2-44f5-47ab-8e02-838942890090@lbl.gov>
References: <04cccf38-72fb-49ef-b010-15fb80e71e8e@lbl.gov> <CAN7etTyY_+ytGXpY4Te-=xED4zHNzz4Pg7xkB4ULj2sZ=gk2WA@mail.gmail.com>
 <6e2a6338-f64e-4f2a-894b-d40f1f646113@lbl.gov> <CAN7etTzk47mf9bCo2S6Wp-9sYpS6u3JfwVgN2koRpKcamDtRWw@mail.gmail.com>
 <8689886f-9da7-4f40-8769-06dbfc0a547f@lbl.gov> <CAN7etTz0wBEjGweZXC_pcOzEULW7hmeBr7zY5ndtsXOL88jSdA@mail.gmail.com>
 <5cd8d8d2-44f5-47ab-8e02-838942890090@lbl.gov>
From: "Gregory M. Kurtzer" <gmku...@lbl.gov>
Date: Wed, 12 Oct 2016 14:37:47 -0700
Message-ID: <CAN7etTyWS+UGZa_EHc-J5at6ULUtFe=Jh3qPXksJNs4-dS5dVg@mail.gmail.com>
Subject: Re: [Singularity] Using singularity with MPI jobs
To: "singu...@lbl.gov" <singu...@lbl.gov>
Content-Type: multipart/alternative; boundary=94eb2c1a16f6e0f746053eb1cd8c

--94eb2c1a16f6e0f746053eb1cd8c
Content-Type: text/plain; charset=UTF-8

Weird how openmpi is actually throwing the session directory in /dev/shm. I
thought it usually uses /tmp.

Did you set that somewhere or am I confused?



On Wednesday, October 12, 2016, Steve Mehlberg <sgmeh...@gmail.com> wrote:

> Gregory,
>
> Yes, I was able to create a file on the host (non-root uid) in /dev/shm/
> test.it and then view it in the singularity shell.
>
> And, there is some stuff there too, is that normal?
>
> bash-4.2$ ls /dev/shm -la
> total 4
> drwxrwxrwt   4 root      root   100 Oct 12 17:34 .
> drwxr-xr-x  20 root      root  3580 Oct  7 22:04 ..
> -rwxr-xr-x   1 mehlberg  user   880 Oct 12 17:34 test.it
> drwx------  47 root      root   940 Sep 30 17:19 openmpi-sessions-0@node9_0
> drwx------ 561 mehlberg  user 11220 Oct 12 15:39
> openmpi-sessions-50342@node9_0
>
>
> Steve
>
> On Wednesday, October 12, 2016 at 11:18:20 AM UTC-6, Gregory M. Kurtzer
> wrote:
>>
>> Can you create a file in /dev/shm/... on the host, and then start a
>> Singularity container and confirm that you can see that file from within
>> the container please?
>>
>> Thanks!
>>
>> On Wed, Oct 12, 2016 at 9:45 AM, Steve Mehlberg <sg...@gmail.com>
>> wrote:
>>
>>> Wow, that was very interesting.  I indeed get the same problem with the
>>> singularity -n1 (srun - one task).  I created the strace, then wanted to
>>> compare the output to a non-singularity run.  But when I change the
>>> non-singularity run to use anything other than the required number of tasks
>>> I get the same error!  That seems to indicate that in the singularity run
>>> (srun with the correct number of tasks) for some reason the MPI processes
>>> can't communicate with one another.
>>>
>>> The strace doesn't show much - or at least not much that means something
>>> to me.  The program seems to be going along outputting data then aborts
>>> with exit 6:
>>>
>>> [pid 13573] write(27, "                    suppress iso"..., 56) = 56
>>> [pid 13573] write(27, "                    ------------"..., 56) = 56
>>> [pid 13573] write(27, "      no isolated ocean grid poi"..., 36) = 36
>>> [pid 13573] open("/opt/mpi/openmpi-icc/2.0.0/share/openmpi/help-mpi-errors.txt",
>>> O_RDONLY) = 28
>>> [pid 13573] ioctl(28, SNDCTL_TMR_TIMEBASE or
>>> SNDRV_TIMER_IOCTL_NEXT_DEVICE or TCGETS, 0x7ffec31d4d80) = -1 ENOTTY
>>> (Inappropriate ioctl for device)
>>> [pid 13573] fstat(28, {st_mode=S_IFREG|0644, st_size=1506, ...}) = 0
>>> [pid 13573] mmap(NULL, 4096, PROT_READ|PROT_WRITE,
>>> MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f4b65f45000
>>> [pid 13573] read(28, "# -*- text -*-\n#\n# Copyright (c)"..., 8192) =
>>> 1506
>>> [pid 13573] read(28, "", 4096)          = 0
>>> [pid 13573] close(28)                   = 0
>>> [pid 13573] munmap(0x7f4b65f45000, 4096) = 0
>>> [pid 13573] write(1, "[node9:13573] *** An error occ"..., 361) = 361
>>> [pid 13573] stat("/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0",
>>> {st_mode=S_IFDIR|0700, st_size=40, ...}) = 0
>>> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0",
>>> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
>>> [pid 13573] getdents(28, /* 2 entries */, 32768) = 48
>>> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
>>> [pid 13573] close(28)                   = 0
>>> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0",
>>> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
>>> [pid 13573] getdents(28, /* 2 entries */, 32768) = 48
>>> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
>>> [pid 13573] close(28)                   = 0
>>> [pid 13573] rmdir("/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0")
>>> = 0
>>> [pid 13573] stat("/dev/shm/openmpi-sessions-50342@node9_0/37255/1",
>>> {st_mode=S_IFDIR|0700, st_size=40, ...}) = 0
>>> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1",
>>> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
>>> [pid 13573] getdents(28, /* 2 entries */, 32768) = 48
>>> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
>>> [pid 13573] close(28)                   = 0
>>> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1",
>>> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
>>> [pid 13573] getdents(28, /* 2 entries */, 32768) = 48
>>> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
>>> [pid 13573] close(28)                   = 0
>>> [pid 13573] rmdir("/dev/shm/openmpi-sessions-50342@node9_0/37255/1") = 0
>>> [pid 13573] stat("/dev/shm/openmpi-sessions-50342@node9_0",
>>> {st_mode=S_IFDIR|0700, st_size=11080, ...}) = 0
>>> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0",
>>> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
>>> [pid 13573] getdents(28, /* 554 entries */, 32768) = 17424
>>> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
>>> [pid 13573] close(28)                   = 0
>>> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0",
>>> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
>>> [pid 13573] getdents(28, /* 554 entries */, 32768) = 17424
>>> [pid 13573] close(28)                   = 0
>>> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0",
>>> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = -1 ENOENT (No such file or
>>> directory)
>>> [pid 13573] exit_group(6)               = ?
>>> [pid 13574] +++ exited with 6 +++
>>> +++ exited with 6 +++
>>> srun: error: node9: task 0: Exited with exit code 6
>>>
>>>
>>>
>>> On Wednesday, October 12, 2016 at 8:53:12 AM UTC-6, Gregory M. Kurtzer
>>> wrote:
>>>>
>>>> Can you replicate the problem with a -np 1? If so can you strace it
>>>> from within the container:
>>>>
>>>> mpirun -np 1 singularity exec container.img strace -ff /path/to/mpi.exe
>>>> (opts)
>>>>
>>>> Yes you can try Singularity 2.2. Please install it to a different path
>>>> so we can test side by side if you don't mind (if really like to debug
>>>> this).
>>>>
>>>> Thanks!
>>>>
>>>>
>>>>
>>>> On Wednesday, October 12, 2016, Steve Mehlberg <sg...@gmail.com>
>>>> wrote:
>>>>
>>>>> Greg,
>>>>>
>>>>> I put a bind to /opt in the singularity.conf file so that /opt/intel
>>>>> is available in the container.
>>>>>
>>>>> All the tasks (16) immediately exit code 6.  The job exits after about
>>>>> 4 seconds.  It normally takes about 16 minutes to run with the
>>>>> configuration I'm using and I do see the start of some output.
>>>>>
>>>>> I am using openmpi 2.0.0.
>>>>>
>>>>> I tried an "export SINGULARITY_NO_NAMESPACE_PID=1" in the bash script
>>>>> that runs all of this for each process and I still get the problem.
>>>>>
>>>>> [node12:9779] *** An error occurred in MPI_Isend
>>>>> [node12:9779] *** reported by process [3025076225,0]
>>>>> [node12:9779] *** on communicator MPI COMMUNICATOR 3 DUP FROM 0
>>>>> [node12:9779] *** MPI_ERR_RANK: invalid rank
>>>>> [node12:9779] *** MPI_ERRORS_ARE_FATAL (processes in this communicator
>>>>> will now abort,
>>>>> [node12:9779] ***    and potentially your MPI job)
>>>>>
>>>>> I can try 2.2 - do you think it might behave differently?
>>>>>
>>>>> Thanks for the ideas and help.
>>>>>
>>>>> Regards,
>>>>>
>>>>> Steve
>>>>>
>>>>> On Tuesday, October 11, 2016 at 8:19:47 PM UTC-6, Gregory M. Kurtzer
>>>>> wrote:
>>>>>>
>>>>>> Hi Steve,
>>>>>>
>>>>>> I'm not sure at first glance, but just to touch on the basics... Is
>>>>>> /opt/intel available from within the container? Do all tasks exit code 6,
>>>>>> or just some of them?
>>>>>>
>>>>>> What version of OMPI are you using?
>>>>>>
>>>>>> I wonder if the PID namespace is causing a problem here... I'm not
>>>>>> sure it gets effectively disabled when running via srun and pmi. Can you
>>>>>> export the environment variable "SINGULARITY_NO_NAMESPACE_PID=1" in
>>>>>> a place where Singularity will pick it up definitively by all ranks? That
>>>>>> will ensure that the PID namespace is not being exported.
>>>>>>
>>>>>> Additionally, you could try version 2.2. I just released it, and by
>>>>>> default it does not unshare() out the PID namespace. But... It is the first
>>>>>> release in the 2.2 series so it may bring with it other issues that still
>>>>>> need resolving.... But we should debug those too! :)
>>>>>>
>>>>>> Greg
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Tue, Oct 11, 2016 at 2:40 PM, Steve Mehlberg <sg...@gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> Does singularity support MPI PMI-2 jobs?  I've had mixed success
>>>>>>> testing benchmark applications using a singularity container.
>>>>>>>
>>>>>>> Currently I'm struggling to get the NEMO benchmark to run using
>>>>>>> slurm 16.05 and pmi2.  I can run the exact same executable on bare metal
>>>>>>> with the same slurm, but I get Rank errors when I run using "srun
>>>>>>> --mpi=pmi2 singularity...".  The application aborts with an exit code 6.
>>>>>>>
>>>>>>> I tried pmix too, but that gets mpi aborts for both bare metal and
>>>>>>> singularity.
>>>>>>>
>>>>>>> The only way I could get the NEMO application to compile was to use
>>>>>>> the intel compilers and mpi:
>>>>>>>
>>>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/compilervars.sh
>>>>>>> intel64
>>>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/ifortvars.sh
>>>>>>> intel64
>>>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/iccvars.sh
>>>>>>> intel64
>>>>>>> source /opt/mpi/openmpi-icc/2.0.0/bin/mpivars.sh
>>>>>>>
>>>>>>> It runs fine when I use mpirun with or without singularity.
>>>>>>>
>>>>>>> Example run/error:
>>>>>>>
>>>>>>> sbatch ...
>>>>>>> srun --mpi=pmi2 -n16 singularity exec c7.img run.it > out_now
>>>>>>>
>>>>>>> .......
>>>>>>> srun: error: node11: tasks 0-7: Exited with exit code 6
>>>>>>> srun: error: node12: tasks 8-15: Exited with exit code 6
>>>>>>>
>>>>>>> $ cat run.it
>>>>>>> #!/bin/sh
>>>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/compilervars.sh
>>>>>>> intel64
>>>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/ifortvars.sh
>>>>>>> intel64
>>>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/iccvars.sh
>>>>>>> intel64
>>>>>>> source /opt/mpi/openmpi-icc/2.0.0/bin/mpivars.sh
>>>>>>> source env_bench
>>>>>>> export PATH=/opt/mpi/openmpi-icc/2.0.0/bin:/opt/pmix/1.1.5/bin:$PATH
>>>>>>> export LD_LIBRARY_PATH=/opt/openmpi-icc/2.0.0/lib:/opt/pmix/1.1.5/l
>>>>>>> ib:$LD_LIBRARY_PATH
>>>>>>> export OMPI_MCA_btl=self,sm,openib
>>>>>>>
>>>>>>> ./opa_8_2 namelist >out_now
>>>>>>>
>>>>>>> $ cat out_now
>>>>>>> [node12:29725] *** An error occurred in MPI_Isend
>>>>>>> [node12:29725] *** reported by process [3865116673,0]
>>>>>>> [node12:29725] *** on communicator MPI COMMUNICATOR 3 DUP FROM 0
>>>>>>> [node12:29725] *** MPI_ERR_RANK: invalid rank
>>>>>>> [node12:29725] *** MPI_ERRORS_ARE_FATAL (processes in this
>>>>>>> communicator will now abort,
>>>>>>> [node12:29725] ***    and potentially your MPI job)
>>>>>>>
>>>>>>> I am running singularity 2.1 - any ideas?
>>>>>>>
>>>>>>> -Steve
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Gregory M. Kurtzer
>>>>>> HPC Systems Architect and Technology Developer
>>>>>> Lawrence Berkeley National Laboratory HPCS
>>>>>> University of California Berkeley Research IT
>>>>>> Singularity Linux Containers (http://singularity.lbl.gov/)
>>>>>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>>>>>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>>>>>> er.com/gmkurtzer
>>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>
>>>>
>>>> --
>>>> Gregory M. Kurtzer
>>>> HPC Systems Architect and Technology Developer
>>>> Lawrence Berkeley National Laboratory HPCS
>>>> University of California Berkeley Research IT
>>>> Singularity Linux Containers (http://singularity.lbl.gov/)
>>>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>>>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>>>> er.com/gmkurtzer
>>>>
>>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>>
>>
>> --
>> Gregory M. Kurtzer
>> HPC Systems Architect and Technology Developer
>> Lawrence Berkeley National Laboratory HPCS
>> University of California Berkeley Research IT
>> Singularity Linux Containers (http://singularity.lbl.gov/)
>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>> er.com/gmkurtzer
>>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--94eb2c1a16f6e0f746053eb1cd8c
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Weird how openmpi is actually throwing the session directo=
ry in /dev/shm. I thought it usually uses /tmp.=C2=A0<div><br></div>Did you=
 set that somewhere or am I confused?<br><div><br></div><div><br><br>On Wed=
nesday, October 12, 2016, Steve Mehlberg &lt;<a href=3D"mailto:sgmeh...@gma=
il.com" target=3D"_blank">sgmeh...@gmail.com</a>&gt; wrote:<br><blockquote =
class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid=
;padding-left:1ex"><div dir=3D"ltr">Gregory,<br><br>Yes, I was able to crea=
te a file on the host (non-root uid) in /dev/shm/<a href=3D"http://test.it"=
 target=3D"_blank">test.it</a> and then view it in the singularity shell.<b=
r><br>And, there is some stuff there too, is that normal?<br><br><span styl=
e=3D"font-family:courier new,monospace">bash-4.2$ ls /dev/shm -la<br>total =
4<br>drwxrwxrwt=C2=A0=C2=A0 4 root=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 root=C2=A0=
=C2=A0 100 Oct 12 17:34 .<br>drwxr-xr-x=C2=A0 20 root=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0 root=C2=A0 3580 Oct=C2=A0 7 22:04 ..<br>-rwxr-xr-x=C2=A0=C2=A0 1 =
mehlberg=C2=A0 user =C2=A0 880 Oct 12 17:34 <a href=3D"http://test.it" targ=
et=3D"_blank">test.it</a><br>drwx------=C2=A0 47 root=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0 root=C2=A0=C2=A0 940 Sep 30 17:19 openmpi-sessions-0@node9_0<br>d=
rwx------ 561 mehlberg=C2=A0 user 11220 Oct 12 15:39 openmpi-sessions-50342=
@node9_0</span><br><br><br>Steve<br><br>On Wednesday, October 12, 2016 at 1=
1:18:20 AM UTC-6, Gregory M. Kurtzer wrote:<blockquote class=3D"gmail_quote=
" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-le=
ft:1ex"><div dir=3D"ltr">Can you create a file in /dev/shm/... on the host,=
 and then start a Singularity container and confirm that you can see that f=
ile from within the container please?<div><br></div><div>Thanks!</div></div=
><div><br><div class=3D"gmail_quote">On Wed, Oct 12, 2016 at 9:45 AM, Steve=
 Mehlberg <span dir=3D"ltr">&lt;<a rel=3D"nofollow">sg...@gmail.com</a>&gt;=
</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .=
8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Wow, that=
 was very interesting.=C2=A0 I indeed get the same problem with the singula=
rity -n1 (srun - one task).=C2=A0 I created the strace, then wanted to comp=
are the output to a non-singularity run.=C2=A0 But when I change the non-si=
ngularity run to use anything other than the required number of tasks I get=
 the same error!=C2=A0 That seems to indicate that in the singularity run (=
srun with the correct number of tasks) for some reason the MPI processes ca=
n&#39;t communicate with one another. <br><br>The strace doesn&#39;t show m=
uch - or at least not much that means something to me.=C2=A0 The program se=
ems to be going along outputting data then aborts with exit 6:<br><br><span=
 style=3D"font-family:courier new,monospace">[pid 13573] write(27, &quot;=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 suppress iso&quot;..., 56) =3D 56<b=
r>[pid 13573] write(27, &quot;=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 -----=
-------&quot;..., 56) =3D 56<br>[pid 13573] write(27, &quot;=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0 no isolated ocean grid poi&quot;..., 36) =3D 36<br>[pid 135=
73] open(&quot;/opt/mpi/openmpi-icc/2.0<wbr>.0/share/openmpi/help-mpi-erro<=
wbr>rs.txt&quot;, O_RDONLY) =3D 28<br>[pid 13573] ioctl(28, SNDCTL_TMR_TIME=
BASE or SNDRV_TIMER_IOCTL_NEXT_DEVICE or TCGETS, 0x7ffec31d4d80) =3D -1 ENO=
TTY (Inappropriate ioctl for device)<br>[pid 13573] fstat(28, {st_mode=3DS_=
IFREG|0644, st_size=3D1506, ...}) =3D 0<br>[pid 13573] mmap(NULL, 4096, PRO=
T_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) =3D 0x7f4b65f45000<br>=
[pid 13573] read(28, &quot;# -*- text -*-\n#\n# Copyright (c)&quot;..., 819=
2) =3D 1506<br>[pid 13573] read(28, &quot;&quot;, 4096)=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573] close(28)=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573] munmap(0x7f4b65f45000, 409=
6) =3D 0<br>[pid 13573] write(1, &quot;[node9:13573] *** An error occ&quot;=
..., 361) =3D 361<br>[pid 13573] stat(&quot;/dev/shm/openmpi-session<wbr>s-=
50342@node9_0/37255/1/0&quot;, {st_mode=3DS_IFDIR|0700, st_size=3D40, ...})=
 =3D 0<br>[pid 13573] openat(AT_FDCWD, &quot;/dev/shm/openmpi-sessions-503<=
wbr>42@node9_0/37255/1/0&quot;, O_RDONLY|O_NONBLOCK|O_DIRECTOR<wbr>Y|O_CLOE=
XEC) =3D 28<br>[pid 13573] getdents(28, /* 2 entries */, 32768) =3D 48<br>[=
pid 13573] getdents(28, /* 0 entries */, 32768) =3D 0<br>[pid 13573] close(=
28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573] openat(AT_FDCWD, =
&quot;/dev/shm/openmpi-sessions-503<wbr>42@node9_0/37255/1/0&quot;, O_RDONL=
Y|O_NONBLOCK|O_DIRECTOR<wbr>Y|O_CLOEXEC) =3D 28<br>[pid 13573] getdents(28,=
 /* 2 entries */, 32768) =3D 48<br>[pid 13573] getdents(28, /* 0 entries */=
, 32768) =3D 0<br>[pid 13573] close(28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =
=3D 0<br>[pid 13573] rmdir(&quot;/dev/shm/openmpi-sessio<wbr>ns-50342@node9=
_0/37255/1/0&quot;) =3D 0<br>[pid 13573] stat(&quot;/dev/shm/openmpi-sessio=
n<wbr>s-50342@node9_0/37255/1&quot;, {st_mode=3DS_IFDIR|0700, st_size=3D40,=
 ...}) =3D 0<br>[pid 13573] openat(AT_FDCWD, &quot;/dev/shm/openmpi-session=
s-503<wbr>42@node9_0/37255/1&quot;, O_RDONLY|O_NONBLOCK|O_DIRECTOR<wbr>Y|O_=
CLOEXEC) =3D 28<br>[pid 13573] getdents(28, /* 2 entries */, 32768) =3D 48<=
br>[pid 13573] getdents(28, /* 0 entries */, 32768) =3D 0<br>[pid 13573] cl=
ose(28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573] openat(AT_F=
DCWD, &quot;/dev/shm/openmpi-sessions-503<wbr>42@node9_0/37255/1&quot;, O_R=
DONLY|O_NONBLOCK|O_DIRECTOR<wbr>Y|O_CLOEXEC) =3D 28<br>[pid 13573] getdents=
(28, /* 2 entries */, 32768) =3D 48<br>[pid 13573] getdents(28, /* 0 entrie=
s */, 32768) =3D 0<br>[pid 13573] close(28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0 =3D 0<br>[pid 13573] rmdir(&quot;/dev/shm/openmpi-sessio<wbr>ns-50342@n=
ode9_0/37255/1&quot;) =3D 0<br>[pid 13573] stat(&quot;/dev/shm/openmpi-sess=
ion<wbr>s-50342@node9_0&quot;, {st_mode=3DS_IFDIR|0700, st_size=3D11080, ..=
.}) =3D 0<br>[pid 13573] openat(AT_FDCWD, &quot;/dev/shm/openmpi-sessions-5=
03<wbr>42@node9_0&quot;, O_RDONLY|O_NONBLOCK|O_DIRECTOR<wbr>Y|O_CLOEXEC) =
=3D 28<br>[pid 13573] getdents(28, /* 554 entries */, 32768) =3D 17424<br>[=
pid 13573] getdents(28, /* 0 entries */, 32768) =3D 0<br>[pid 13573] close(=
28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573] openat(AT_FDCWD, =
&quot;/dev/shm/openmpi-sessions-503<wbr>42@node9_0&quot;, O_RDONLY|O_NONBLO=
CK|O_DIRECTOR<wbr>Y|O_CLOEXEC) =3D 28<br>[pid 13573] getdents(28, /* 554 en=
tries */, 32768) =3D 17424<br>[pid 13573] close(28)=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0 =3D 0<br>[pid 13573] openat(AT_FDCWD, &quot;/dev/shm/openmpi-sess=
ions-503<wbr>42@node9_0/37255/1/0&quot;, O_RDONLY|O_NONBLOCK|O_DIRECTOR<wbr=
>Y|O_CLOEXEC) =3D -1 ENOENT (No such file or directory)<br>[pid 13573] exit=
_group(6)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 =3D ?<br>[pid 13574] +++ exited with 6 +++<br>+++ exited=
 with 6 +++<br>srun: error: node9: task 0: Exited with exit code 6</span><s=
pan><br><br><br><br>On Wednesday, October 12, 2016 at 8:53:12 AM UTC-6, Gre=
gory M. Kurtzer wrote:</span><blockquote class=3D"gmail_quote" style=3D"mar=
gin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex"><span>=
Can you replicate the problem with a -np 1? If so can you strace it from wi=
thin the container:<div><br></div><div>mpirun -np 1 singularity exec contai=
ner.img strace -ff /path/to/mpi.exe (opts)<span></span></div><div><br></div=
><div>Yes you can try Singularity 2.2. Please install it to a different pat=
h so we can test side by side if you don&#39;t mind (if really like to debu=
g this).=C2=A0</div><div><br></div><div>Thanks!</div><div><br></div></span>=
<div><div><div><br><br>On Wednesday, October 12, 2016, Steve Mehlberg &lt;<=
a rel=3D"nofollow">sg...@gmail.com</a>&gt; wrote:<br><blockquote class=3D"g=
mail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-l=
eft:1ex"><div dir=3D"ltr">Greg,<br><br>I put a bind to /opt in the singular=
ity.conf file so that /opt/intel is available in the container.<br><br>All =
the tasks (16) immediately exit code 6.=C2=A0 The job exits after about 4 s=
econds.=C2=A0 It normally takes about 16 minutes to run with the configurat=
ion I&#39;m using and I do see the start of some output.<br><br>I am using =
openmpi 2.0.0.<br><br>I tried an &quot;export <span>SINGULARITY_NO_NAMESPAC=
E_</span><span>PID=3D1<wbr>&quot; in the bash script that runs all of this =
for each process and I still get the problem.</span><br><br>[node12:9779] *=
** An error occurred in MPI_Isend<br>[node12:9779] *** reported by process =
<a value=3D"+13025076225">[3025076225</a>,0]<br>[node12:9779] *** on commun=
icator MPI COMMUNICATOR 3 DUP FROM 0<br>[node12:9779] *** MPI_ERR_RANK: inv=
alid rank<br>[node12:9779] *** MPI_ERRORS_ARE_FATAL (processes in this comm=
unicator will now abort,<br>[node12:9779] ***=C2=A0=C2=A0=C2=A0 and potenti=
ally your MPI job)<br><br>I can try 2.2 - do you think it might behave diff=
erently?<br><br>Thanks for the ideas and help.<br><br>Regards,<br><br>Steve=
<br><br>On Tuesday, October 11, 2016 at 8:19:47 PM UTC-6, Gregory M. Kurtze=
r wrote:<blockquote class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8=
ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Steve,<=
div><br></div><div>I&#39;m not sure at first glance, but just to touch on t=
he basics... Is /opt/intel available from within the container? Do all task=
s exit code 6, or just some of them?</div><div><br></div><div>What version =
of OMPI are you using?</div><div><br></div><div>I wonder if the PID namespa=
ce is causing a problem here... I&#39;m not sure it gets effectively disabl=
ed when running via srun and pmi. Can you export the environment variable &=
quot;<span>SINGULARITY_NO_NAMESPACE_</span><span>PID=3D<wbr>1&quot; in a pl=
ace where Singularity will pick it up definitively by all ranks? That will =
ensure that the PID namespace is not being exported.</span></div><div><span=
><br></span></div><div><span>Additionally, you could try version 2.2. I jus=
t released it, and by default it does not unshare() out the PID namespace. =
But... It is the first release in the 2.2 series so it may bring with it ot=
her issues that still need resolving.... But we should debug those too! :)<=
/span></div><div><span><br></span></div><div>Greg</div><div><br></div><div>=
<br></div>







</div><div><br><div class=3D"gmail_quote">On Tue, Oct 11, 2016 at 2:40 PM, =
Steve Mehlberg <span dir=3D"ltr">&lt;<a rel=3D"nofollow">sg...@gmail.com</a=
>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 =
0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Does=
 singularity support MPI PMI-2 jobs?=C2=A0 I&#39;ve had mixed success testi=
ng benchmark applications using a singularity container.=C2=A0 <br><br>Curr=
ently I&#39;m struggling to get the NEMO benchmark to run using slurm 16.05=
 and pmi2.=C2=A0 I can run the exact same executable on bare metal with the=
 same slurm, but I get Rank errors when I run using &quot;srun --mpi=3Dpmi2=
 singularity...&quot;.=C2=A0 The application aborts with an exit code 6.<br=
><br>I tried pmix too, but that gets mpi aborts for both bare metal and sin=
gularity.<br><br>The only way I could get the NEMO application to compile w=
as to use the intel compilers and mpi:<br><br><span style=3D"font-size:12.0=
pt;font-family:&quot;Times New Roman&quot;,&quot;serif&quot;;color:black">s=
ource
/opt/intel/compilers_and_libra<wbr>ries_2016.3.210/linux/bin/comp<wbr>ilerv=
ars.sh intel64<br>
source /opt/intel/compilers_and_libra<wbr>ries_2016.3.210/linux/bin/ifor<wb=
r>tvars.sh
intel64<br>
source /opt/intel/compilers_and_libra<wbr>ries_2016.3.210/linux/bin/iccv<wb=
r>ars.sh
intel64<br>
source /opt/mpi/openmpi-icc/2.0.0/bin<wbr>/mpivars.sh<br><br></span>It runs=
 fine when I use mpirun with or without singularity.<br><br>Example run/err=
or:<br><br>sbatch ...<br>srun --mpi=3Dpmi2 -n16 singularity exec c7.img <a =
href=3D"http://run.it" rel=3D"nofollow" target=3D"_blank">run.it</a> &gt; o=
ut_now<br><br>.......<br>srun: error: node11: tasks 0-7: Exited with exit c=
ode 6<br>srun: error: node12: tasks 8-15: Exited with exit code 6<br><br>$ =
cat <a href=3D"http://run.it" rel=3D"nofollow" target=3D"_blank">run.it</a>=
<br>#!/bin/sh<br>source /opt/intel/compilers_and_libra<wbr>ries_2016.3.210/=
linux/bin/comp<wbr>ilervars.sh intel64<br>source /opt/intel/compilers_and_l=
ibra<wbr>ries_2016.3.210/linux/bin/ifor<wbr>tvars.sh intel64<br>source /opt=
/intel/compilers_and_libra<wbr>ries_2016.3.210/linux/bin/iccv<wbr>ars.sh in=
tel64<br>source /opt/mpi/openmpi-icc/2.0.0/bin<wbr>/mpivars.sh<br>source en=
v_bench<br>export PATH=3D/opt/mpi/openmpi-icc/2.0.<wbr>0/bin:/opt/pmix/1.1.=
5/bin:$PAT<wbr>H<br>export LD_LIBRARY_PATH=3D/opt/openmpi-i<wbr>cc/2.0.0/li=
b:/opt/pmix/1.1.5/l<wbr>ib:$LD_LIBRARY_PATH<br>export OMPI_MCA_btl=3Dself,s=
m,openib<br><br>./opa_8_2 namelist &gt;out_now<br><br>$ cat out_now<br>[nod=
e12:29725] *** An error occurred in MPI_Isend<br>[node12:29725] *** reporte=
d by process <a value=3D"+13865116673">[3865116673</a>,0]<br>[node12:29725]=
 *** on communicator MPI COMMUNICATOR 3 DUP FROM 0<br>[node12:29725] *** MP=
I_ERR_RANK: invalid rank<br>[node12:29725] *** MPI_ERRORS_ARE_FATAL (proces=
ses in this communicator will now abort,<br>[node12:29725] ***=C2=A0=C2=A0=
=C2=A0 and potentially your MPI job)<br><br>I am running singularity 2.1 - =
any ideas?<span><font color=3D"#888888"><br><br>-Steve<br><br></font></span=
></div><span><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</font></span></blockquote></div><br><br clear=3D"all"><div><br></div>-- <b=
r><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><d=
iv dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtzer</d=
iv><div>HPC Systems Architect and Technology Developer</div><div>Lawrence B=
erkeley National Laboratory HPCS<br>University of California Berkeley Resea=
rch IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singularity.=
lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://singularity<wbr>.lbl.go=
v/</a>)</div><div>Warewulf Cluster Management=C2=A0(<a href=3D"http://warew=
ulf.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://warewulf.lb<wbr>l.g=
ov/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.com/gmkurtzer" re=
l=3D"nofollow" target=3D"_blank">https://github.com/gmk<wbr>urtzer</a>,=C2=
=A0<span style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"https:/=
/twitter.com/gmkurtzer" style=3D"font-size:12.8px" rel=3D"nofollow" target=
=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</a></div></div></div></div><=
/div></div></div></div></div></div></div>
</div>
</blockquote></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div><br><br>-- <br><div dir=3D"ltr"><div><div dir=3D"ltr"><d=
iv><div dir=3D"ltr"><div><div dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"=
><div>Gregory M. Kurtzer</div><div>HPC Systems Architect and Technology Dev=
eloper</div><div>Lawrence Berkeley National Laboratory HPCS<br>University o=
f California Berkeley Research IT<br>Singularity Linux Containers=C2=A0(<a =
href=3D"http://singularity.lbl.gov/" rel=3D"nofollow" target=3D"_blank">htt=
p://singularity<wbr>.lbl.gov/</a>)</div><div>Warewulf Cluster Management=C2=
=A0(<a href=3D"http://warewulf.lbl.gov/" rel=3D"nofollow" target=3D"_blank"=
>http://warewulf.lb<wbr>l.gov/</a>)</div><div>GitHub:=C2=A0<a href=3D"https=
://github.com/gmkurtzer" rel=3D"nofollow" target=3D"_blank">https://github.=
com/gmk<wbr>urtzer</a>,=C2=A0<span style=3D"font-size:12.8px">Twitter:=C2=
=A0</span><a href=3D"https://twitter.com/gmkurtzer" style=3D"font-size:12.8=
px" rel=3D"nofollow" target=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</=
a></div></div></div></div></div></div></div></div></div></div><br>
</div></div></blockquote></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div=
 dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtzer</div=
><div>HPC Systems Architect and Technology Developer</div><div>Lawrence Ber=
keley National Laboratory HPCS<br>University of California Berkeley Researc=
h IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singularity.lb=
l.gov/" rel=3D"nofollow" target=3D"_blank">http://singularity<wbr>.lbl.gov/=
</a>)</div><div>Warewulf Cluster Management=C2=A0(<a href=3D"http://warewul=
f.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://warewulf.lb<wbr>l.gov=
/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.com/gmkurtzer" rel=
=3D"nofollow" target=3D"_blank">https://github.com/gmk<wbr>urtzer</a>,=C2=
=A0<span style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"https:/=
/twitter.com/gmkurtzer" style=3D"font-size:12.8px" rel=3D"nofollow" target=
=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</a></div></div></div></div><=
/div></div></div></div></div></div></div>
</div>
</blockquote></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div>
</div>

--94eb2c1a16f6e0f746053eb1cd8c--

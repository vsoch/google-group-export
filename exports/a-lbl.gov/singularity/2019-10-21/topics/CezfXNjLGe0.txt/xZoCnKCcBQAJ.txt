X-Received: by 10.107.7.149 with SMTP id g21mr32957391ioi.11.1469759672103;
        Thu, 28 Jul 2016 19:34:32 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.36.227.134 with SMTP id d128ls158298ith.5.gmail; Thu, 28 Jul
 2016 19:34:31 -0700 (PDT)
X-Received: by 10.98.102.79 with SMTP id a76mr64885676pfc.75.1469759671664;
        Thu, 28 Jul 2016 19:34:31 -0700 (PDT)
Return-Path: <nathan...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTPS id x20si15555833pal.165.2016.07.28.19.34.31
        for <singu...@lbl.gov>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Thu, 28 Jul 2016 19:34:31 -0700 (PDT)
Received-SPF: pass (google.com: domain of nathan...@gmail.com designates 209.85.218.45 as permitted sender) client-ip=209.85.218.45;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of nathan...@gmail.com designates 209.85.218.45 as permitted sender) smtp.mailfrom=nathan...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2ECAQC5v5pXhi3aVdFdhBt8BoM4pCmJKoJqhA92gT1AJoFsVIFcSwGBDwKBKwc4FAEBAQEBAQEDDwEBAQgLCwkZL4JROQoGKwEBAQEBAQEBASECKwQWCxsBAQQBEhEdAQ0OHgMBCwYDAgsNKgICIQEBDgMBBQEcDgcEARwEAYd0AQMPCAUJkH2PRIEyPjGLO4FqgloFhDwKGScNVINAAQEIAQEBAQEaAgYQimeCQ4FPEQGDHYJaBYFFhlgHYIUSC4EpiTQ0hhiCfIM2gjSCOY0GiCiEBoI5Eh6BDw8PgkgRC4FoIDIBAQEBA4ZdgTUBAQE
X-IronPort-AV: E=Sophos;i="5.28,437,1464678000"; 
   d="scan'208,217";a="31701289"
Received: from mail-oi0-f45.google.com ([209.85.218.45])
  by fe3.lbl.gov with ESMTP; 28 Jul 2016 19:34:30 -0700
Received: by mail-oi0-f45.google.com with SMTP id j185so88767111oih.0
        for <singu...@lbl.gov>; Thu, 28 Jul 2016 19:34:30 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=qKhUgFlEMr/TZ2WjXXhrJlNwQpXmjHI3n5lSg/Rgl8I=;
        b=kORAkdTZj2xjx3rsywbarpGaN7TB/L+iIXv36xBFTHhDiip/r5VLgl+jEZe00D6hCE
         s92mZkygXHbT9CcVM90/EVWpsXq2b1/Y7qYW7fKdh1guIc6ODdcHC0fAFkeK4LCOHEbq
         LgxoDYKpln8y3EROwgqliVflhOV5jxeRQ7haQ8bMZO3SnWBjAbi+838SsRRadt4g8u3B
         tUAslO5y1aLtqzVX6HYaKfrM4Rd2LEi+qq2wCSwg8izKPbKvJKXPQXlXWpktQZ6Ny13c
         pztzdfSCnKl7Kwv8RIlSZrDAZad64h7+ms56WeMd8spPguuicaKwnLDdEZSatXBKIThR
         0ZEg==
X-Gm-Message-State: AEkooutin7hB6F5MnwTlKrltToZuYhxslH8tfklcioDuqI032pQi9qXnO+EQef9FjlfyRXvaLAjXM/6/7MnIqw==
X-Received: by 10.157.35.28 with SMTP id j28mr24845028otb.165.1469759669641;
 Thu, 28 Jul 2016 19:34:29 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.157.43.24 with HTTP; Thu, 28 Jul 2016 19:34:29 -0700 (PDT)
In-Reply-To: <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
 <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov> <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
From: Nathan Lin <nathan...@gmail.com>
Date: Thu, 28 Jul 2016 22:34:29 -0400
Message-ID: <CAA8GL6BdE1TRBaPD-oM7qcj8QK1cBsmJsUzYyrvkRPBP9CX+hQ@mail.gmail.com>
Subject: Re: [Singularity] How to use GPU in singularity?
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=001a113dd5dc03ad470538bd176d

--001a113dd5dc03ad470538bd176d
Content-Type: text/plain; charset=UTF-8

I am not sure how to find the correct driver version, but from my testing,
the version must match exactly. I will admit that I have had problems
finding specific versions of the driver from NVIDIA's website. I had to ask
a sysadmin for the installer that they used. In order to extract the files,
you need to use the --extract-only option. For instance, you will have to
run something like ' sh /NVIDIA-Linux-x86_64-352.63.run --extract-only'/ .
You will then be given a directory with all the libraries that would have
been installed. You will need to copy the libcuda.so.###.## library (and
you can copy any NVIDIA executables that you want such as nvidia-smi). Good
luck!

On Thu, Jul 28, 2016 at 8:51 PM, Igor <igor...@gmail.com> wrote:

> I mean I am using this file from NVIDIA website cuda_7.5.18_linux.run to
> install the driver, opengl, cuda. Driver installation fails, cuda succeeds.
> Also, when I run
> sh cuda_7.5.18_linux.run
> I am offered to install the driver version 352.39 while on the host it is 346.47.
> I cannot upgrade the host. Any idea where I can get 346.17?
> I tried using the same link just substitute 18 for something else but have
> not found the files:
> wget
> http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run
>
>
>
> On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:
>>
>> Hi Nathan,
>> When I try to install the driver by running NVIDIA*.run script inside the
>> image, it fails, probably because it tries to modify kernel that belongs to
>> host?
>> How do I extract just libcuda.so.345.67 without installing the driver
>> (which is obviously problematic) and why would copying the library from the
>> host would not work?
>> Thank you,
>> Igor
>>
>> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:
>>>
>>> Also if you are using the binary installation of TensorFlow you need
>>> CUDA toolkit 7.5 and cuDNN v4. These only need to be installed on our
>>> image. As I mentioned earlier you will need the libcuda.so.###.## library
>>> on your image. It is very important that this is the same version of the
>>> NVIDIA driver as you have on your nose (seemingly 346.67 for you). I
>>> should've have also mentioned that you want the libcuda.so.345.67 library
>>> that you get from extracting the NVIDIA installer. It will not work if you
>>> try to copy the libcuda.so library that from you node.
>>>
>>> Let me know if you have any more questions.
>>>
>>> Best,
>>> Nathan
>>>
>>> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com> wrote:
>>>
>>>> Hello,
>>>>
>>>> Yes you are correct. The NVIDIA driver must be installed on your image
>>>> as well. However, you honestly only need the libcuda.so.###.## library and
>>>> the appropriate links for that library. Once you have those installed in
>>>> your image, it should work.
>>>>
>>>> Best,
>>>> Nathan
>>>>
>>>> On Thursday, July 28, 2016, Igor <igor...@gmail.com> wrote:
>>>>
>>>>> Hi All,
>>>>>
>>>>> I am trying to use GPU-enabled tensorflow and it cannot find GPU card
>>>>> from inside the container.
>>>>>
>>>>> On the host:
>>>>> $ lspci | grep -i nvidia
>>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev
>>>>> a1)
>>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev
>>>>> a1)
>>>>>
>>>>> $ nvidia-smi
>>>>> Thu Jul 28 19:01:42 2016
>>>>> +------------------------------------------------------+
>>>>>
>>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47         |
>>>>>
>>>>> |-------------------------------+----------------------+----------------------+
>>>>>
>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile
>>>>> Uncorr. ECC |
>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util
>>>>>  Compute M. |
>>>>> |===============================+======================+======================|
>>>>>
>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>>>>>                    0 |
>>>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB |      0%
>>>>>      Default |
>>>>> +-------------------------------+----------------------+----------------------+
>>>>>
>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>>>>>                    0 |
>>>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB |      0%
>>>>>      Default |
>>>>> +-------------------------------+----------------------+----------------------+
>>>>>
>>>>>
>>>>>
>>>>> +-----------------------------------------------------------------------------+
>>>>>
>>>>> | Processes:                                                       GPU
>>>>> Memory |
>>>>> |  GPU       PID  Type  Process name
>>>>>                               Usage      |
>>>>> |=============================================================================|
>>>>>
>>>>> |    0     11671    G   /usr/bin/X
>>>>>                                       9MiB |
>>>>> |    1     11671    G   /usr/bin/X
>>>>>                                       3MiB |
>>>>>
>>>>>
>>>>> Inside singularity:
>>>>> $ singularity shell /software/src/singularity_images/tensorflow_0.9.img
>>>>>
>>>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia
>>>>> bash: lspci: command not found
>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>>> bash: nvidia-smi: command not found
>>>>> Singularity/tensorflow_0.9.img> python
>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>>> [GCC 5.4.0 20160609] on linux2
>>>>> Type "help", "copyright", "credits" or "license" for more information.
>>>>> >>> import tensorflow as tf
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcublas.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcudnn.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcufft.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcuda.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcurand.so locally
>>>>> >>> sess = tf.Session()
>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to
>>>>> cuInit: CUDA_ERROR_UNKNOWN
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving
>>>>> CUDA diagnostic information for host: midway-l34-01
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname:
>>>>> midway-l34-01
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
>>>>> reported version is: Not found: was unable to find libcuda.so DSO loaded
>>>>> into this program
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver
>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module
>>>>>  346.47  Thu Feb 19 18:56:03 PST 2015
>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC)
>>>>> """
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel
>>>>> reported version is: 346.47.0
>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices
>>>>> available on machine.
>>>>>
>>>>> Must there be nvidia driver installed inside the container? Outside?
>>>>> The container shares the same kernel with the host and nvidia kernel module
>>>>> needs to be loaded... How this is handled? Any requirements on nvidia
>>>>> driver and cuda versions inside and outside of the container?
>>>>>
>>>>> Thank you,
>>>>> Igor
>>>>>
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a113dd5dc03ad470538bd176d
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">I am no<font face=3D"arial, helvetica, sans-serif">t sure =
how to find the correct driver version, but from my testing, the version mu=
st match exactly. I will admit that I have had problems finding specific ve=
rsions of the driver from NVIDIA&#39;s website. I had to ask a sysadmin for=
 the installer that they used. In order to extract the files, you need to u=
se the --extract-only option. For instance, you will have to run something =
like &#39;

















sh /NVIDIA-Linux-x86_64-352.63.run
--extract-only&#39;/ . You will then be given a directory with all the libr=
aries that would have been installed. You will need to copy the libcuda.so.=
###.## library (and you can copy any NVIDIA executables that you want such =
as nvidia-smi). Good luck!</font></div><div class=3D"gmail_extra"><br><div =
class=3D"gmail_quote">On Thu, Jul 28, 2016 at 8:51 PM, Igor <span dir=3D"lt=
r">&lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">igor...@gmail=
.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"ma=
rgin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"lt=
r"><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">I=
 mean I am using this file from NVIDIA website cuda_7.5.18_linux.run to ins=
tall the driver, opengl, cuda. Driver installation fails, cuda succeeds.=C2=
=A0</span></span><div><span style=3D"font-family:monospace"><font color=3D"=
#000000">Also, when I run=C2=A0</font></span></div><div><span style=3D"font=
-family:monospace"><font color=3D"#000000">sh=C2=A0</font></span><font colo=
r=3D"#000000" face=3D"monospace">cuda_7.5.18_linux.run</font></div><div><sp=
an style=3D"font-family:monospace"><font color=3D"#000000">I am offered to =
install the driver version=C2=A0</font></span><span style=3D"font-family:mo=
nospace"><span style=3D"color:rgb(0,0,0)">352.39 while on the host it is=C2=
=A0</span></span><span style=3D"font-family:monospace"><span style=3D"color=
:rgb(0,0,0)">346.47. I cannot upgrade the host. Any idea where I can get 34=
6.17?</span></span></div><div><span style=3D"font-family:monospace"><font c=
olor=3D"#000000">I tried using the same link just substitute 18 for somethi=
ng else but have not found the files:</font></span></div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">wget <a href=3D=
"http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installer=
s/cuda_7.5.1X_linux.run" target=3D"_blank">http://developer.download.nvidia=
.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run</a></span=
><br></span><br></div><div><div class=3D"h5"><div><br></div><div><br></div>=
<div>On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:<blockquote=
 class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px =
#ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Nathan,<div>When I try to =
install the driver by running NVIDIA*.run script inside the image, it fails=
, probably because it tries to modify kernel that belongs to host?</div><di=
v>How do I extract just libcuda.so.345.67 without installing the driver (wh=
ich is obviously problematic) and why would copying the library from the ho=
st would not work?</div><div>Thank you,</div><div>Igor<br><br>On Thursday, =
July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:<blockquote class=3D"gm=
ail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;p=
adding-left:1ex">Also if you are using the binary installation of TensorFlo=
w you need CUDA toolkit 7.5 and cuDNN v4. These only need to be installed o=
n our image. As I mentioned earlier you will need the libcuda.so.###.## lib=
rary on your image. It is very important that this is the same version of t=
he NVIDIA driver as you have on your nose (seemingly 346.67 for you). I sho=
uld&#39;ve have also mentioned that you want the libcuda.so.345.67 library =
that you get from extracting the NVIDIA installer. It will not work if you =
try to copy=C2=A0the libcuda.so library that from you node.=C2=A0<div><br><=
/div><div>Let me know if you have any more questions.=C2=A0</div><div><br><=
/div><div>Best,</div><div>Nathan<span></span><br><br>On Thursday, July 28, =
2016, Nathan Lin &lt;<a rel=3D"nofollow">nat...@gmail.com</a>&gt; wrote:<br=
><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1=
px #ccc solid;padding-left:1ex">Hello,<div><br></div><div>Yes you are corre=
ct. The NVIDIA driver must be installed on your image as well. However, you=
 honestly only need the libcuda.so.###.## library and the appropriate links=
 for that library. Once you have those installed in your image, it should w=
ork.=C2=A0</div><div><br></div><div>Best,</div><div>Nathan=C2=A0<span></spa=
n><br><br>On Thursday, July 28, 2016, Igor &lt;<a>igor...@gmail.com</a>&gt;=
 wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;bor=
der-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi All,<div><br>=
<div>I am trying to use GPU-enabled tensorflow and it cannot find GPU card =
from inside the container.</div><div><br></div><div>On the host:</div><div>=
<span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ ls=
pci | grep -i nvidia
</span><br>20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] =
(rev a1)
<br>8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1=
)<br>
<br></span></div><div><span style=3D"font-family:monospace"><span style=3D"=
color:rgb(0,0,0)">$ nvidia-smi
</span><br>Thu Jul 28 19:01:42 2016 =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0<br>+------------------------------------------------------+ =C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>| NVIDIA-SMI 346.=
47 =C2=A0=C2=A0=C2=A0=C2=A0Driver Version: 346.47 =C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0| =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0<br>|-------------------------------+----------------------+=
----------------------+
<br>| GPU =C2=A0Name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Persistence-=
M| Bus-Id =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan =C2=A0Temp =C2=A0Perf =C2=A0Pwr:Usage/Cap| =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0Memory-Usage | GPU-Util =C2=A0Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D|
<br>| =C2=A0=C2=A00 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:20:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A030C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A020W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A066MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-------------------------------+----------------------+---------------=
-------+
<br>| =C2=A0=C2=A01 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:8B:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A026C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A019W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A060MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-------------------------------+----------------------+---------------=
-------+
<br> =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>+----------------------------------------=
-------------------------------------+
<br>| Processes: =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0GPU Memory |
<br>| =C2=A0GPU =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0PID =C2=A0Type =C2=A0Pr=
ocess name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Usage =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D|
<br>| =C2=A0=C2=A0=C2=A00 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A09MiB |
<br>| =C2=A0=C2=A0=C2=A01 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A03MiB |<br>
<br></span></div></div><div><font face=3D"monospace"><br></font></div><div>=
<font face=3D"monospace">Inside singularity:</font></div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ singularity s=
hell /software/src/singularity_images/tensorflow_0.9.img</span><br></span><=
/div><div><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,=
0,0)"><br></span></span></div><div><span style=3D"font-family:monospace"><s=
pan style=3D"color:rgb(0,0,0)">Singularity/tensorflow_0.9.img&gt; lspci | g=
rep -i nvidia
</span><br>bash: lspci: command not found
<br>Singularity/tensorflow_0.9.img&gt; nvidia-smi
<br>bash: nvidia-smi: command not found
<br>Singularity/tensorflow_0.9.img&gt; python
<br>Python 2.7.12 (default, Jul =C2=A01 2016, 15:12:24) =C2=A0<br>[GCC 5.4.=
0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow as tf
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcublas.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcudnn.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcufft.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcuda.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcurand.so locally
<br>&gt;&gt;&gt; sess =3D tf.Session()
<br>E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cu=
Init: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving C=
UDA diagnostic information for host: midway-l34-01
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: mi=
dway-l34-01
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda repo=
rted version is: Not found: was unable to find libcuda.so DSO loaded into t=
his program
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver versi=
on file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 Kernel=
 Module =C2=A0346.47 =C2=A0Thu Feb 19 18:56:03 PST 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel repor=
ted version is: 346.47.0
<br>I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices ava=
ilable on machine.<br>
<br></span></div><div><span style=3D"font-family:monospace">Must there be n=
vidia driver installed inside the container? Outside? The container shares =
the same kernel with the host and nvidia kernel module needs to be loaded..=
. How this is handled? Any requirements on nvidia driver and cuda versions =
inside and outside of the container?</span></div><div><span style=3D"font-f=
amily:monospace"><br></span></div><div><span style=3D"font-family:monospace=
">Thank you,</span></div><div><span style=3D"font-family:monospace">Igor</s=
pan></div><div><span style=3D"font-family:monospace"><br></span></div><div>=
<font face=3D"monospace"><br></font></div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singu...@lbl.gov</a>.<br>
</blockquote></div>
</blockquote></div>
</blockquote></div></div></blockquote></div></div></div></div><div class=3D=
"HOEnZb"><div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

--001a113dd5dc03ad470538bd176d--

X-Received: by 10.99.133.200 with SMTP id u191mr13846633pgd.93.1491484029021;
        Thu, 06 Apr 2017 06:07:09 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.16.211 with SMTP id 80ls10433411ioq.0.gmail; Thu, 06 Apr
 2017 06:07:08 -0700 (PDT)
X-Received: by 10.98.204.195 with SMTP id j64mr35385318pfk.213.1491484027976;
        Thu, 06 Apr 2017 06:07:07 -0700 (PDT)
Return-Path: <vijay...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id p66si1803989pfk.421.2017.04.06.06.07.07
        for <singu...@lbl.gov>;
        Thu, 06 Apr 2017 06:07:07 -0700 (PDT)
Received-SPF: pass (google.com: domain of vijay...@gmail.com designates 74.125.83.41 as permitted sender) client-ip=74.125.83.41;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of vijay...@gmail.com designates 74.125.83.41 as permitted sender) smtp.mailfrom=vijay...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2EUAAAMPeZYhilTfUpbHAEBBAEBCgEBF?=
 =?us-ascii?q?wEBBAEBCgEBgkM7An8LgQsHg1SKGpAKCAEBBoEfBIJkjT2FNIFMGygfAQaEIoF?=
 =?us-ascii?q?aAoM9Bz8YAQEBAQEBAQEBAQECEAEBAQgLCwgoL4IzBAIDGQUEBEYmAy8BAQEBA?=
 =?us-ascii?q?QEBAQEBAQEBAQEaAg0eEwMPAQEYAQEBAQIBIx0BDQ4eAwELBgULDSoCAiEBAQ4?=
 =?us-ascii?q?DAQUBHA4HBAEcBIgogSwBAwgFCAWcRz+KVBCBIIIEBQEcgwkFg1YKGScNVYJZA?=
 =?us-ascii?q?QEBBwEBAQEBAQEZAgYShXeFNYJRgVcRAUmCWYJfBZw4O4Z+hxyEOYJTjmqKe4c?=
 =?us-ascii?q?1FB+BFQ8QgQQyCFtWGIQKKiCCCyQ1B4cqR4FnAQEB?=
X-IronPort-AV: E=Sophos;i="5.37,159,1488873600"; 
   d="scan'208,217";a="70599132"
Received: from mail-pg0-f41.google.com ([74.125.83.41])
  by fe3.lbl.gov with ESMTP; 06 Apr 2017 06:06:51 -0700
Received: by mail-pg0-f41.google.com with SMTP id 81so35996142pgh.2
        for <singu...@lbl.gov>; Thu, 06 Apr 2017 06:06:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=s7Yk0Ew8LW+ERFDDmpbJosBwVZVZcP0ZosFzjf0G1Yw=;
        b=pV+N8BEpLcYDDBLq2Vd1sNqSsSsCNTZE507MQoO/gLgYSMid/twl1Pg9HZBKHPQpTf
         GdvDCtA/WeAx2jQgL++rt1aawBKPo8khpX5Hq8CGW1nZgUcBEXmJ5Oyxk95BDIVC5yaW
         45Ki9ZGuU4rMD/9p2Ili7EVTPrwRdNXmB667qpgLI1WQFTOfIEDc/xp9PN02Q1kNqMyO
         r1FA1NH+Vfx2DyEy7i5eVjAqnA07YobfzYI7j5LcdHbLj3evTzXnvZJ6qHCzCaJ23f4J
         HPtyqogTaNrUDgQhZ2mbSGbx9zHSrNGwZO13kO568Egkqnaui99mbsq0WgCctlbvF5KP
         F9sg==
X-Gm-Message-State: AFeK/H1agiur8HxnxpyeGqWv/zBohOPFT/WgtHmEdBBYDicqfK6hsphiBzmi/b0Nhj8jIzmmUMcbN0AXwr5qTw==
X-Received: by 10.98.27.204 with SMTP id b195mr35653242pfb.154.1491484010991;
 Thu, 06 Apr 2017 06:06:50 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.100.165.209 with HTTP; Thu, 6 Apr 2017 06:06:50 -0700 (PDT)
In-Reply-To: <CAN7etTw3tOrDaM_H6MUxzx4Wm1iHM8ny_vpbdDGoBDkkQgQNag@mail.gmail.com>
References: <2eba34a0-cd03-41dc-aff7-d47586ee6e79@lbl.gov> <CAN7etTw3tOrDaM_H6MUxzx4Wm1iHM8ny_vpbdDGoBDkkQgQNag@mail.gmail.com>
From: Sundar Vijayakumar <vijay...@gmail.com>
Date: Thu, 6 Apr 2017 09:06:50 -0400
Message-ID: <CAKT2xfYdeEbGshntE46tdSR=EgsYi6Lq-TzaNJuxFeTi3UONkg@mail.gmail.com>
Subject: Re: [Singularity] Container-to-container invocation with Singularity
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=94eb2c04bab2a9d597054c7f2e5c

--94eb2c04bab2a9d597054c7f2e5c
Content-Type: text/plain; charset=UTF-8

Greg,

Your understanding of our use case is correct. PsN does have the ability to
communicate directly with LSF.  To you latter point, the number of jobs to
be executed in total and in parallel are also controlled by PsN and doesn't
use MPI.  We will try to download and test from the development branch to
confirm.  For our planning, do you have a target date in mind for the next
release?

Thanks,

-Vijay

On Wed, Apr 5, 2017 at 11:20 AM, Gregory M. Kurtzer <gmku...@lbl.gov>
wrote:

> Hi Vijay,
>
> Thank you for your note, and I'm glad Singularity is working well for you.
>
> Am I understand correctly that you are having containers invoking other
> containers by means of the container submitting jobs to the resource
> manager (e.g. the PsN job that runs first has within it the means to
> communicate with the LSF daemon, and the LSF daemon then spawns the jobs on
> the compute resources)?
>
> I am not generally familiar with these apps (maybe others on the list
> are), but what you describe sounds reasonable. I do have a comment about
> the process flow... Why don't you request an allocation of multiple nodes,
> and use the rank 0 process to spin up the PsN container process, and the
> rest of the ranks to spin up workers that can communicate back to the PsN
> job at job completion? Is that possible with this compute model?
>
> Last comment I have is that the current development branch for Singularity
> has the ability to sanitize or clean the container's environment so you
> don't need to use `env -i ...`. Will that help you?
>
> Greg
>
> On Wed, Apr 5, 2017 at 7:38 AM, Sundar Vijayakumar <vijay...@gmail.com>
> wrote:
>
>> Hi Greg,
>>
>> First, we would like to thank you for leading this effort and making this
>> a reality for scientific computing ! We think Singularity will give us what
>> we have long desired (an immutable installation and reproducible runtime
>> environment) for our scientific tool collection no matter which host our
>> job lands for execution or infrastructural updates applied to the
>> underlying host, barring any major kernel updates.
>>
>> We, at Pfizer, are piloting a use case wherein container-to-container
>> invocation is desired in an HPC environment.  To give you some background
>> on our setup, we installed a set of our tools comprising R, Nonmem and PsN
>> into a single container. Our cluster manager is IBM/LSF (previously from
>> Platform computing).   We use "R" for plots and reporting via R markdown
>> and Latex.  We use Nonmem (NONlinear Mixed Effect Modeling) for modeling
>> and simulation and PsN (a collection of perl modules) that spin up a number
>> of NONMEM jobs in parallel.  In this use case, a user submits a PsN LSF job
>> on the first node, which then submits several child LSF jobs, each running
>> a Nonmem instance.  At the completion of all the Nonmem jobs, PsN collects
>> and summarizes the results via "R" plots and graphs.
>>
>> At the moment, we are able to execute such a job by re-initializing (env
>> -i) the child job submission environment.  But before we finalize an
>> approach, we want to understand if there is a different mechanism to
>> achieve the same within Singularity.  Also, we want to ensure any future
>> plans that may be on the table will NOT impede our implementation model.
>> Would very much appreciate your thoughts and comments on our approach.
>>
>> Many thanks,
>>
>> -Vijay
>>
>> --
>> You received this message because you are subscribed to the Google Groups
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to singu...@lbl.gov.
>>
>
>
>
> --
> Gregory M. Kurtzer
> HPC Systems Architect and Technology Developer
> Lawrence Berkeley National Laboratory HPCS
> University of California Berkeley Research IT
> Singularity Linux Containers (http://singularity.lbl.gov/)
> Warewulf Cluster Management (http://warewulf.lbl.gov/)
> GitHub: https://github.com/gmkurtzer, Twitter: https://
> twitter.com/gmkurtzer
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--94eb2c04bab2a9d597054c7f2e5c
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Greg,<div><br></div><div>Your understanding of our use cas=
e is correct. PsN does have the ability to communicate directly with LSF.=
=C2=A0 To you latter point, the number of jobs to be executed in total and =
in parallel are also controlled by PsN and doesn&#39;t use MPI.=C2=A0 We wi=
ll try to download and test from the development branch to confirm.=C2=A0 F=
or our planning, do you have a target date in mind for the next release?</d=
iv><div><br></div><div>Thanks,</div><div><br></div><div>-Vijay=C2=A0</div><=
/div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Wed, Apr =
5, 2017 at 11:20 AM, Gregory M. Kurtzer <span dir=3D"ltr">&lt;<a href=3D"ma=
ilto:gmku...@lbl.gov" target=3D"_blank">gmku...@lbl.gov</a>&gt;</span> wrot=
e:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-l=
eft:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Vijay,<div><br></d=
iv><div>Thank you for your note, and I&#39;m glad Singularity is working we=
ll for you.</div><div><br></div><div>Am I understand correctly that you are=
 having containers invoking other containers by means of the container subm=
itting jobs to the resource manager (e.g. the PsN job that runs first has w=
ithin it the means to communicate with the LSF daemon, and the LSF daemon t=
hen spawns the jobs on the compute resources)?</div><div><br></div><div>I a=
m not generally familiar with these apps (maybe others on the list are), bu=
t what you describe sounds reasonable. I do have a comment about the proces=
s flow... Why don&#39;t you request an allocation of multiple nodes, and us=
e the rank 0 process to spin up the PsN container process, and the rest of =
the ranks to spin up workers that can communicate back to the PsN job at jo=
b completion? Is that possible with this compute model?</div><div><br></div=
><div>Last comment I have is that the current development branch for Singul=
arity has the ability to sanitize or clean the container&#39;s environment =
so you don&#39;t need to use `env -i ...`. Will that help you?</div><div><b=
r></div><div>Greg</div></div><div class=3D"gmail_extra"><br><div class=3D"g=
mail_quote">On Wed, Apr 5, 2017 at 7:38 AM, Sundar Vijayakumar <span dir=3D=
"ltr">&lt;<a href=3D"mailto:vijay...@gmail.com" target=3D"_blank">vijay...@=
gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=
=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=
=3D"ltr">Hi Greg,<br><br>First, we would like to thank you for leading this=
 effort and making this a reality for scientific computing ! We think Singu=
larity will give us what we have long desired (an immutable installation an=
d reproducible runtime environment) for our scientific tool collection no m=
atter which host our job lands for execution or infrastructural updates app=
lied to the underlying host, barring any major kernel updates.<br><br>We, a=
t Pfizer, are piloting a use case wherein container-to-container invocation=
 is desired in an HPC environment.=C2=A0 To give you some background on our=
 setup, we installed a set of our tools comprising R, Nonmem and PsN into a=
 single container. Our cluster manager is IBM/LSF (previously from Platform=
 computing). =C2=A0 We use &quot;R&quot; for plots and reporting via R mark=
down and Latex.=C2=A0 We use Nonmem (NONlinear Mixed Effect Modeling) for m=
odeling and simulation and PsN (a collection of perl modules) that spin up =
a number of NONMEM jobs in parallel.=C2=A0 In this use case, a user submits=
 a PsN LSF job on the first node, which then submits several child LSF jobs=
, each running a Nonmem instance.=C2=A0 At the completion of all the Nonmem=
 jobs, PsN collects and summarizes the results via &quot;R&quot; plots and =
graphs.<br><br>At the moment, we are able to execute such a job by re-initi=
alizing (env -i) the child job submission environment.=C2=A0 But before we =
finalize an approach, we want to understand if there is a different mechani=
sm to achieve the same within Singularity.=C2=A0 Also, we want to ensure an=
y future plans that may be on the table will NOT impede our implementation =
model.=C2=A0 Would very much appreciate your thoughts and comments on our a=
pproach.<br><br>Many thanks,<br><br>-Vijay<span class=3D"m_-675193387673525=
8450HOEnZb"><font color=3D"#888888"><br></font></span></div><span class=3D"=
m_-6751933876735258450HOEnZb"><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<span class=3D"HOEnZb"><font color=3D"#888888">=
<br>
</font></span></font></span></blockquote></div><span class=3D"HOEnZb"><font=
 color=3D"#888888"><br><br clear=3D"all"><div><br></div>-- <br><div class=
=3D"m_-6751933876735258450gmail_signature" data-smartmail=3D"gmail_signatur=
e"><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div d=
ir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtzer</div><=
div>HPC Systems Architect and Technology Developer</div><div>Lawrence Berke=
ley National Laboratory HPCS<br>University of California Berkeley Research =
IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singularity.lbl.=
gov/" target=3D"_blank">http://<wbr>singularity.lbl.gov/</a>)</div><div>War=
ewulf Cluster Management=C2=A0(<a href=3D"http://warewulf.lbl.gov/" target=
=3D"_blank">http://warewulf.<wbr>lbl.gov/</a>)</div><div>GitHub:=C2=A0<a hr=
ef=3D"https://github.com/gmkurtzer" target=3D"_blank">https://github.com/<w=
br>gmkurtzer</a>,=C2=A0<span style=3D"font-size:12.8px">Twitter:=C2=A0</spa=
n><a href=3D"https://twitter.com/gmkurtzer" style=3D"font-size:12.8px" targ=
et=3D"_blank">https://<wbr>twitter.com/gmkurtzer</a></div></div></div></div=
></div></div></div></div></div></div></div>
</font></span></div><span class=3D"HOEnZb"><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</font></span></blockquote></div><br></div>

--94eb2c04bab2a9d597054c7f2e5c--

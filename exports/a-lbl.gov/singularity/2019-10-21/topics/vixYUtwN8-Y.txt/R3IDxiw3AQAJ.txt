Date: Thu, 14 Jul 2016 11:50:24 -0700 (PDT)
From: Steve Mehlberg <sgmeh...@gmail.com>
To: singularity <singu...@lbl.gov>
Message-Id: <90295845-ad9b-4670-97f2-91a76798ef5d@lbl.gov>
In-Reply-To: <CAN7etTwRbSe1MMh9wdQAMYoKVJTb_SGJeHto+WrZ=aU7NoBmhQ@mail.gmail.com>
References: <03a19fb0-27ce-43c4-9400-8e58cf726500@lbl.gov>
 <CAN7etTwRbSe1MMh9wdQAMYoKVJTb_SGJeHto+WrZ=aU7NoBmhQ@mail.gmail.com>
Subject: Re: [Singularity] Image is locked by another process
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_952_1536517306.1468522224456"

------=_Part_952_1536517306.1468522224456
Content-Type: multipart/alternative; 
	boundary="----=_Part_953_1844959646.1468522224457"

------=_Part_953_1844959646.1468522224457
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Gregory,

Thanks for the quick suggestions.  There don't seem to be any processes 
attached to the container and I can't seem to run other commands (in read 
mode). I'm not sure what's going on.

Just lazy with root right now, I need to create a normal uid.

Steve

[root@mach0 ~]# ls -la c7
-rwxr-xr-x 1 root root 1610612769 Jul 14 10:49 c7
[root@mach0 ~]# singularity shell -w c7
ERROR  : Image is locked by another process
[root@mach0 ~]# lsof c7
[root@mach0 ~]# singularity shell c7 whoami
/usr/bin/whoami: /usr/bin/whoami: cannot execute binary file
[root@mach0 ~]#
[root@mach0 ~]# ps -ef |grep c7
root      7479  2002  0 11:49 pts/0    00:00:00 grep --color=auto c7
[root@mach0 ~]#



On Thursday, July 14, 2016 at 12:30:01 PM UTC-6, Gregory M. Kurtzer wrote:
>
> Hi Steve,
>
> That means there is an active file descriptor/process still running and 
> attached to the container maintaining a shared lock. You can run other 
> commands against the container as long as long as the container is not 
> being requested as --writable(-w), because that will try and obtain an 
> exclusive lock and it will fail if there are any active shared locks. Try 
> an "lsof /path/to/c7" to see what processes are attached to it. You may see 
> a list like:
>
> # lsof /tmp/Demo-2.img 
> COMMAND    PID USER   FD   TYPE DEVICE   SIZE/OFF      NODE NAME
> sexec   107975 root    6rR  REG  253,0 1073741856 202112247 /tmp/Demo-2.img
> sexec   107977 root    6r   REG  253,0 1073741856 202112247 /tmp/Demo-2.img
> bash    107982 root    6r   REG  253,0 1073741856 202112247 /tmp/Demo-2.img
>
> Notice the two top ones are 'sexec' which are part of the Singularity 
> process stack. Kill the bottom one, and those should go away naturally.
>
> BTW, as long as you have installed Singularity as root, there is no need 
> to run Singularity commands as root (unless you want to make system changes 
> within the container).
>
> Hope that helps!
>
>
> On Thu, Jul 14, 2016 at 10:56 AM, Steve Mehlberg <sg...@gmail.com 
> <javascript:>> wrote:
>
>> Running mpirun tests, when an abort occurs, my image ends up locked.  Is 
>> there a way to clear the lock without rebooting?  I looked for processes 
>> that I could kill, but didn't see anything worthy.
>>
>> I'm using singularity v2.1 on Centos 7.2 (both host and container).
>>
>> Regards,
>>
>> Steve
>>
>> [root@mach0 ~]# mpirun --allow-run-as-root -n 2 -H mach1,mach2 
>> singularity exec c7 /usr/bin/ring
>> Process 0 sending 10 to 1, tag 201 (2 processes in ring)
>> Process 0 sent to 1
>> Process 0 decremented value: 9
>> Process 0 decremented value: 8
>> Process 0 decremented value: 7
>> Process 0 decremented value: 6
>> Process 0 decremented value: 5
>> Process 0 decremented value: 4
>> Process 0 decremented value: 3
>> Process 0 decremented value: 2
>> Process 0 decremented value: 1
>> Process 0 decremented value: 0
>> Process 0 exiting
>> Process 1 exiting
>> [root@mach0 ~]# mpirun --allow-run-as-root -n 3 -H mach0,mach1,mach2 
>> singularity exec c7 /usr/bin/ring
>> --------------------------------------------------------------------------
>> It appears as if there is not enough space for 
>> /tmp/ompi.mach0.2291/54935/1/0/vader_segment.mach0.0 (the shared-memory 
>> backing
>> file). It is likely that your MPI job will now either abort or experience
>> performance degradation.
>>
>>   Local host:  mach0
>>   Space Requested: 4194312 B
>>   Space Available: 0 B
>> --------------------------------------------------------------------------
>> [mach0:02308] create_and_attach: unable to create shared memory BTL 
>> coordinating structure :: size 134217728
>> [mach0:02291] 2 more processes have sent help message 
>> help-opal-shmem-mmap.txt / target full
>> [mach0:02291] Set MCA parameter "orte_base_help_aggregate" to 0 to see 
>> all help / error messages
>> ^CKilled by signal 2.
>> Killed by signal 2.
>> Singularity is sending SIGKILL to child pid: 2308
>> Singularity is sending SIGKILL to child pid: 2309
>> [warn] Epoll ADD(4) on fd 31 failed.  Old events were 0; read change was 
>> 0 (none); write change was 1 (add): Bad file descriptor
>> ^C[root@mach0 ~]singularity shell -w c7
>> ERROR  : Image is locked by another process
>> [root@mach0 ~]# tail -30 /var/log/messages
>> Jul 14 10:42:17 mach0 systemd: Started LSB: slurm daemon management.
>> Jul 14 10:42:17 mach0 systemd: Reached target Multi-User System.
>> Jul 14 10:42:17 mach0 systemd: Starting Multi-User System.
>> Jul 14 10:42:17 mach0 systemd: Starting Update UTMP about System Runlevel 
>> Changes...
>> Jul 14 10:42:17 mach0 systemd: Started Stop Read-Ahead Data Collection 
>> 10s After Completed Startup.
>> Jul 14 10:42:17 mach0 systemd: Started Update UTMP about System Runlevel 
>> Changes.
>> Jul 14 10:42:18 mach0 kdumpctl: kexec: loaded kdump kernel
>> Jul 14 10:42:18 mach0 kdumpctl: Starting kdump: [OK]
>> Jul 14 10:42:18 mach0 systemd: Started Crash recovery kernel arming.
>> Jul 14 10:42:18 mach0 systemd: Startup finished in 415ms (kernel) + 
>> 1.100s (initrd) + 4.931s (userspace) = 6.446s.
>> Jul 14 10:42:34 mach0 systemd: Created slice user-0.slice.
>> Jul 14 10:42:34 mach0 systemd: Starting user-0.slice.
>> Jul 14 10:42:34 mach0 systemd-logind: New session 1 of user root.
>> Jul 14 10:42:34 mach0 systemd: Started Session 1 of user root.
>> Jul 14 10:42:34 mach0 systemd: Starting Session 1 of user root.
>> Jul 14 10:42:36 mach0 Singularity: sexec (U=0,P=2023)> Command=exec, 
>> Container=c7, CWD=/root, Arg1=/usr/bin/ring
>> Jul 14 10:42:36 mach0 Singularity: sexec (U=0,P=2024)> Command=exec, 
>> Container=c7, CWD=/root, Arg1=/usr/bin/ring
>> Jul 14 10:42:36 mach0 Singularity: sexec (U=0,P=2024)> Image is locked by 
>> another process
>> Jul 14 10:42:36 mach0 kernel: loop: module loaded
>> Jul 14 10:43:38 mach0 Singularity: sexec (U=0,P=2050)> Command=shell, 
>> Container=c7, CWD=/root, Arg1=(null)
>> Jul 14 10:43:38 mach0 kernel: EXT4-fs (loop0): mounted filesystem with 
>> ordered data mode. Opts: discard
>> Jul 14 10:49:17 mach0 Singularity: sexec (U=0,P=2203)> Command=shell, 
>> Container=c7, CWD=/root, Arg1=(null)
>> Jul 14 10:49:17 mach0 kernel: EXT4-fs (loop0): mounted filesystem with 
>> ordered data mode. Opts: discard
>> Jul 14 10:50:39 mach0 Singularity: sexec (U=0,P=2244)> Command=exec, 
>> Container=c7, CWD=/root, Arg1=/usr/bin/ring
>> Jul 14 10:50:39 mach0 kernel: EXT4-fs (loop0): mounted filesystem with 
>> ordered data mode. Opts: discard
>> Jul 14 10:51:34 mach0 Singularity: sexec (U=0,P=2299)> Command=exec, 
>> Container=c7, CWD=/root, Arg1=/usr/bin/ring
>> Jul 14 10:51:34 mach0 Singularity: sexec (U=0,P=2300)> Command=exec, 
>> Container=c7, CWD=/root, Arg1=/usr/bin/ring
>> Jul 14 10:51:34 mach0 kernel: EXT4-fs (loop0): mounted filesystem with 
>> ordered data mode. Opts: discard
>> Jul 14 10:51:57 mach0 Singularity: sexec (U=0,P=2322)> Command=shell, 
>> Container=c7, CWD=/root, Arg1=(null)
>> Jul 14 10:51:57 mach0 Singularity: sexec (U=0,P=2322)> Image is locked by 
>> another process
>>
>>
>> -- 
>> You received this message because you are subscribed to the Google Groups 
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an 
>> email to singu...@lbl.gov <javascript:>.
>>
>
>
>
> -- 
> Gregory M. Kurtzer
> High Performance Computing Services (HPCS)
> University of California
> Lawrence Berkeley National Laboratory
> One Cyclotron Road, Berkeley, CA 94720
>

------=_Part_953_1844959646.1468522224457
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Gregory,<br><br>Thanks for the quick suggestions.=C2=A0 Th=
ere don&#39;t seem to be any processes attached to the container and I can&=
#39;t seem to run other commands (in read mode). I&#39;m not sure what&#39;=
s going on.<br><br>Just lazy with root right now, I need to create a normal=
 uid.<br><br>Steve<br><br><span style=3D"font-family: courier new,monospace=
;">[root@mach0 ~]# ls -la c7<br>-rwxr-xr-x 1 root root 1610612769 Jul 14 10=
:49 c7<br>[root@mach0 ~]# singularity shell -w c7<br>ERROR=C2=A0 : Image is=
 locked by another process<br>[root@mach0 ~]# lsof c7<br>[root@mach0 ~]# si=
ngularity shell c7 whoami<br>/usr/bin/whoami: /usr/bin/whoami: cannot execu=
te binary file<br>[root@mach0 ~]#<br>[root@mach0 ~]# ps -ef |grep c7<br>roo=
t=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 7479=C2=A0 2002=C2=A0 0 11:49 pts/0=C2=A0=
=C2=A0=C2=A0 00:00:00 grep --color=3Dauto c7<br>[root@mach0 ~]#</span><br><=
br><br><br>On Thursday, July 14, 2016 at 12:30:01 PM UTC-6, Gregory M. Kurt=
zer wrote:<blockquote class=3D"gmail_quote" style=3D"margin: 0;margin-left:=
 0.8ex;border-left: 1px #ccc solid;padding-left: 1ex;"><div dir=3D"ltr">Hi =
Steve,<div><br></div><div>That means there is an active file descriptor/pro=
cess still running and attached to the container maintaining a shared lock.=
 You can run other commands against the container as long as long as the co=
ntainer is not being requested as --writable(-w), because that will try and=
 obtain an exclusive lock and it will fail if there are any active shared l=
ocks. Try an &quot;lsof /path/to/c7&quot; to see what processes are attache=
d to it. You may see a list like:</div><div><br></div><div><div># lsof /tmp=
/Demo-2.img=C2=A0</div><div>COMMAND =C2=A0 =C2=A0PID USER =C2=A0 FD =C2=A0 =
TYPE DEVICE =C2=A0 SIZE/OFF =C2=A0 =C2=A0 =C2=A0NODE NAME</div><div>sexec =
=C2=A0 107975 root =C2=A0 =C2=A06rR =C2=A0REG =C2=A0253,0 1073741856 202112=
247 /tmp/Demo-2.img</div><div>sexec =C2=A0 107977 root =C2=A0 =C2=A06r =C2=
=A0 REG =C2=A0253,0 1073741856 202112247 /tmp/Demo-2.img</div><div>bash =C2=
=A0 =C2=A0107982 root =C2=A0 =C2=A06r =C2=A0 REG =C2=A0253,0 1073741856 202=
112247 /tmp/Demo-2.img</div></div><div><br></div><div>Notice the two top on=
es are &#39;sexec&#39; which are part of the Singularity process stack. Kil=
l the bottom one, and those should go away naturally.</div><div><br></div><=
div>BTW, as long as you have installed Singularity as root, there is no nee=
d to run Singularity commands as root (unless you want to make system chang=
es within the container).</div><div><br></div><div>Hope that helps!</div><d=
iv><br></div></div><div><br><div class=3D"gmail_quote">On Thu, Jul 14, 2016=
 at 10:56 AM, Steve Mehlberg <span dir=3D"ltr">&lt;<a href=3D"javascript:" =
target=3D"_blank" gdf-obfuscated-mailto=3D"9Oyj5Q82AQAJ" rel=3D"nofollow" o=
nmousedown=3D"this.href=3D&#39;javascript:&#39;;return true;" onclick=3D"th=
is.href=3D&#39;javascript:&#39;;return true;">sg...@gmail.com</a>&gt;</span=
> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;bo=
rder-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Running mpirun =
tests, when an abort occurs, my image ends up locked.=C2=A0 Is there a way =
to clear the lock without rebooting?=C2=A0 I looked for processes that I co=
uld kill, but didn&#39;t see anything worthy.<br><br>I&#39;m using singular=
ity v2.1 on Centos 7.2 (both host and container).<br><br>Regards,<br><br>St=
eve<br><br><span style=3D"font-family:courier new,monospace">[root@mach0 ~]=
# mpirun --allow-run-as-root -n 2 -H mach1,mach2 singularity exec c7 /usr/b=
in/ring<br>Process 0 sending 10 to 1, tag 201 (2 processes in ring)<br>Proc=
ess 0 sent to 1<br>Process 0 decremented value: 9<br>Process 0 decremented =
value: 8<br>Process 0 decremented value: 7<br>Process 0 decremented value: =
6<br>Process 0 decremented value: 5<br>Process 0 decremented value: 4<br>Pr=
ocess 0 decremented value: 3<br>Process 0 decremented value: 2<br>Process 0=
 decremented value: 1<br>Process 0 decremented value: 0<br>Process 0 exitin=
g<br>Process 1 exiting<br>[root@mach0 ~]# mpirun --allow-run-as-root -n 3 -=
H mach0,mach1,mach2 singularity exec c7 /usr/bin/ring<br>------------------=
------------<wbr>------------------------------<wbr>--------------<br>It ap=
pears as if there is not enough space for /tmp/ompi.mach0.2291/54935/1/<wbr=
>0/vader_segment.mach0.0 (the shared-memory backing<br>file). It is likely =
that your MPI job will now either abort or experience<br>performance degrad=
ation.<br><br>=C2=A0 Local host:=C2=A0 mach0<br>=C2=A0 Space Requested: 419=
4312 B<br>=C2=A0 Space Available: 0 B<br>------------------------------<wbr=
>------------------------------<wbr>--------------<br>[mach0:02308] create_=
and_attach: unable to create shared memory BTL coordinating structure :: si=
ze 134217728<br>[mach0:02291] 2 more processes have sent help message help-=
opal-shmem-mmap.txt / target full<br>[mach0:02291] Set MCA parameter &quot;=
orte_base_help_aggregate&quot; to 0 to see all help / error messages<br>^CK=
illed by signal 2.<br>Killed by signal 2.<br>Singularity is sending SIGKILL=
 to child pid: 2308<br>Singularity is sending SIGKILL to child pid: 2309<br=
>[warn] Epoll ADD(4) on fd 31 failed.=C2=A0 Old events were 0; read change =
was 0 (none); write change was 1 (add): Bad file descriptor<br>^C[root@mach=
0 ~]singularity shell -w c7<br>ERROR=C2=A0 : Image is locked by another pro=
cess<br>[root@mach0 ~]# tail -30 /var/log/messages<br>Jul 14 10:42:17 mach0=
 systemd: Started LSB: slurm daemon management.<br>Jul 14 10:42:17 mach0 sy=
stemd: Reached target Multi-User System.<br>Jul 14 10:42:17 mach0 systemd: =
Starting Multi-User System.<br>Jul 14 10:42:17 mach0 systemd: Starting Upda=
te UTMP about System Runlevel Changes...<br>Jul 14 10:42:17 mach0 systemd: =
Started Stop Read-Ahead Data Collection 10s After Completed Startup.<br>Jul=
 14 10:42:17 mach0 systemd: Started Update UTMP about System Runlevel Chang=
es.<br>Jul 14 10:42:18 mach0 kdumpctl: kexec: loaded kdump kernel<br>Jul 14=
 10:42:18 mach0 kdumpctl: Starting kdump: [OK]<br>Jul 14 10:42:18 mach0 sys=
temd: Started Crash recovery kernel arming.<br>Jul 14 10:42:18 mach0 system=
d: Startup finished in 415ms (kernel) + 1.100s (initrd) + 4.931s (userspace=
) =3D 6.446s.<br>Jul 14 10:42:34 mach0 systemd: Created slice user-0.slice.=
<br>Jul 14 10:42:34 mach0 systemd: Starting user-0.slice.<br>Jul 14 10:42:3=
4 mach0 systemd-logind: New session 1 of user root.<br>Jul 14 10:42:34 mach=
0 systemd: Started Session 1 of user root.<br>Jul 14 10:42:34 mach0 systemd=
: Starting Session 1 of user root.<br>Jul 14 10:42:36 mach0 Singularity: se=
xec (U=3D0,P=3D2023)&gt; Command=3Dexec, Container=3Dc7, CWD=3D/root, Arg1=
=3D/usr/bin/ring<br>Jul 14 10:42:36 mach0 Singularity: sexec (U=3D0,P=3D202=
4)&gt; Command=3Dexec, Container=3Dc7, CWD=3D/root, Arg1=3D/usr/bin/ring<br=
>Jul 14 10:42:36 mach0 Singularity: sexec (U=3D0,P=3D2024)&gt; Image is loc=
ked by another process<br>Jul 14 10:42:36 mach0 kernel: loop: module loaded=
<br>Jul 14 10:43:38 mach0 Singularity: sexec (U=3D0,P=3D2050)&gt; Command=
=3Dshell, Container=3Dc7, CWD=3D/root, Arg1=3D(null)<br>Jul 14 10:43:38 mac=
h0 kernel: EXT4-fs (loop0): mounted filesystem with ordered data mode. Opts=
: discard<br>Jul 14 10:49:17 mach0 Singularity: sexec (U=3D0,P=3D2203)&gt; =
Command=3Dshell, Container=3Dc7, CWD=3D/root, Arg1=3D(null)<br>Jul 14 10:49=
:17 mach0 kernel: EXT4-fs (loop0): mounted filesystem with ordered data mod=
e. Opts: discard<br>Jul 14 10:50:39 mach0 Singularity: sexec (U=3D0,P=3D224=
4)&gt; Command=3Dexec, Container=3Dc7, CWD=3D/root, Arg1=3D/usr/bin/ring<br=
>Jul 14 10:50:39 mach0 kernel: EXT4-fs (loop0): mounted filesystem with ord=
ered data mode. Opts: discard<br>Jul 14 10:51:34 mach0 Singularity: sexec (=
U=3D0,P=3D2299)&gt; Command=3Dexec, Container=3Dc7, CWD=3D/root, Arg1=3D/us=
r/bin/ring<br>Jul 14 10:51:34 mach0 Singularity: sexec (U=3D0,P=3D2300)&gt;=
 Command=3Dexec, Container=3Dc7, CWD=3D/root, Arg1=3D/usr/bin/ring<br>Jul 1=
4 10:51:34 mach0 kernel: EXT4-fs (loop0): mounted filesystem with ordered d=
ata mode. Opts: discard<br>Jul 14 10:51:57 mach0 Singularity: sexec (U=3D0,=
P=3D2322)&gt; Command=3Dshell, Container=3Dc7, CWD=3D/root, Arg1=3D(null)<b=
r>Jul 14 10:51:57 mach0 Singularity: sexec (U=3D0,P=3D2322)&gt; Image is lo=
cked by another process</span><span><font color=3D"#888888"><br><br><br></f=
ont></span></div><span><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"javascript:" target=3D"_blank" gdf-obfuscated-mailto=3D"=
9Oyj5Q82AQAJ" rel=3D"nofollow" onmousedown=3D"this.href=3D&#39;javascript:&=
#39;;return true;" onclick=3D"this.href=3D&#39;javascript:&#39;;return true=
;">singularity...@lbl.<wbr>gov</a>.<br>
</font></span></blockquote></div><br><br clear=3D"all"><div><br></div>-- <b=
r><div><div dir=3D"ltr"><div>Gregory M. Kurtzer<br>High Performance Computi=
ng Services (HPCS)<br>University of California<br>Lawrence Berkeley Nationa=
l Laboratory<br>One Cyclotron Road, Berkeley, CA 94720</div></div></div>
</div>
</blockquote></div>
------=_Part_953_1844959646.1468522224457--

------=_Part_952_1536517306.1468522224456--

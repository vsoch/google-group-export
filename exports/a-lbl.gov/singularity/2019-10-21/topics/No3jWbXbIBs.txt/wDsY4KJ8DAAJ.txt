X-Received: by 10.99.164.9 with SMTP id c9mr13709150pgf.4.1487885195272;
        Thu, 23 Feb 2017 13:26:35 -0800 (PST)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.52.140 with SMTP id b134ls1483042ioa.38.gmail; Thu, 23 Feb
 2017 13:26:34 -0800 (PST)
X-Received: by 10.98.130.2 with SMTP id w2mr29598938pfd.137.1487885194510;
        Thu, 23 Feb 2017 13:26:34 -0800 (PST)
Return-Path: <gmku...@lbl.gov>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id v80si5334311pgb.38.2017.02.23.13.26.34
        for <singu...@lbl.gov>;
        Thu, 23 Feb 2017 13:26:34 -0800 (PST)
Received-SPF: pass (google.com: domain of gmku...@lbl.gov designates 209.85.161.199 as permitted sender) client-ip=209.85.161.199;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of gmku...@lbl.gov designates 209.85.161.199 as permitted sender) smtp.mailfrom=gmku...@lbl.gov
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2HjAQCIUq9YhsehVdFcARwBAQQBAQoBARcBAQQBAQoBAYJDgUN4EQeDTAiKCJFcgmSFKIpJgl+BShslAx8BDIFtQxCBXIFaAoMeBz8YAQEBAQEBAQEBAQECEAEBAQgLCwodL4IqCQQCAwEdBAQ9CgECAwEBAQEBAQEBAQIBAQEBAQEBAQEBAQECAQEBAgEBAQIBAQEBAQMBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQESAgwBIg8DKQEBAQMBGgEIKzALCQILDRkCBQEJAgIhAQ8DAQUBCxEGCAcEARMHAgSHZwOBCEoDDQgFCZBCkRY/jAOCJoc5DYN+AQoBAQEBAQEhEodqgz+CUYFVEAIBeAGCKIJfBYkZYYVTf4UdhXE6AYZzfIYUhCCBe1OBB4NCiXqKRDGGbBQegRUPEHUNLwgZCjdNFwWDdjYDEQyCAh81AQaJWIFnAQEB
X-IronPort-AV: E=Sophos;i="5.35,198,1484035200"; 
   d="scan'208,217";a="65140442"
Received: from mail-yw0-f199.google.com ([209.85.161.199])
  by fe4.lbl.gov with ESMTP; 23 Feb 2017 13:26:31 -0800
Received: by mail-yw0-f199.google.com with SMTP id 204so5466330ywo.6
        for <singu...@lbl.gov>; Thu, 23 Feb 2017 13:26:31 -0800 (PST)
X-Gm-Message-State: AMke39nyy6lmGtRtTfWeZHAGO9K12KrnYCSiXHV1NZJh8gTHU0ZtSH1HrIG4UwVo6xVmzEIKzmMMEPli0nKkyUDG9WatX5Y7aFnRI0yOORQVepaPO8zsZryhJtUHjDpTsKV5oPQIQEJ4zn3pqJMXO8OhE+c=
X-Received: by 10.37.204.87 with SMTP id l84mr30179398ybf.158.1487885191238;
        Thu, 23 Feb 2017 13:26:31 -0800 (PST)
X-Received: by 10.37.204.87 with SMTP id l84mr30179380ybf.158.1487885190897;
 Thu, 23 Feb 2017 13:26:30 -0800 (PST)
MIME-Version: 1.0
Received: by 10.129.110.69 with HTTP; Thu, 23 Feb 2017 13:26:30 -0800 (PST)
In-Reply-To: <CABWwhHrj6MKLWt8+4Pq9=Xti9cKtQjR53_aS0p-Ldhetx87S0w@mail.gmail.com>
References: <d0a10fdc-f912-4e9c-8681-a54f5d53fd72@lbl.gov> <CAN7etTxxeYYxY7aB93H7E686y-8Qru-c_H3t1ANNQ_4oE1C-aA@mail.gmail.com>
 <887cfc8c-48ed-4720-8040-989e407f4203@lbl.gov> <CAN7etTwgGhbKjQw3EpWXMQN7jcQURt2tTHhWZn3FgZjij_=GDA@mail.gmail.com>
 <CABWwhHr9Z_h+nQM2SFq8Mhq=S1x+K9zCB74iPAn9tGdZKBUHNQ@mail.gmail.com>
 <CAA6Bz=fgxCcGtxQz7wVTTqgq_nyuLjNeuu2fOKMhJ3HTR6k5_g@mail.gmail.com>
 <edc73d0a-acb1-4cef-a23c-c4ab5f1b7289@lbl.gov> <a3f8cd92-cb6f-422a-8656-a127e48853f5@lbl.gov>
 <CAAfrVp0UHD+Adh40KeTSr6x1Evo7bKdtyqTN_ULdQSNwO+ATCg@mail.gmail.com> <CABWwhHrj6MKLWt8+4Pq9=Xti9cKtQjR53_aS0p-Ldhetx87S0w@mail.gmail.com>
From: "Gregory M. Kurtzer" <gmku...@lbl.gov>
Date: Thu, 23 Feb 2017 13:26:30 -0800
Message-ID: <CAN7etTwQYvZ2FdZx+NH9VRpD3daScBG+BKVPu0Tnijx9J3C9Kg@mail.gmail.com>
Subject: Re: [Singularity] Performance impact: My experience
To: singularity <singu...@lbl.gov>
Content-Type: multipart/alternative; boundary=94eb2c086b5e45376105493944bd

--94eb2c086b5e45376105493944bd
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Hybrid mode being the MPI outside the container is different then the MPI
inside the container.

Tyler, you technically don't "have" to worry about it... unless, you want
to use the IB (ducks and hides). Actually OFED is one of the major
limitations of portability with containers. We've mostly solved the GPU
issues, but not OFED.

Greg

On Thu, Feb 23, 2017 at 1:20 PM, Chihsong <chihs...@gmail.com> wrote:

> What did you mean by hybrid mode? MPI + OpenMP or something else?
>
> Chih-Song
>
> On Thu, Feb 23, 2017 at 10:17 PM, Tyler Trafford <ttra...@gmail.com>
> wrote:
>
>> I also thought that when running in hybrid mode we wouldn't have to worr=
y
>> about the interconnect inside the container....
>>
>> --
>> Tyler Trafford
>>
>> On Thu, Feb 23, 2017 at 4:05 PM, Chih-Song Kuo <chihs...@gmail.com>
>> wrote:
>>
>>> OK...Now after installing InfiniBand libraries things finally work
>>> decently. From this lesson, I would suggest adding a remark about IB
>>> support to http://singularity.lbl.gov/docs-hpc, because otherwise new
>>> users can easily get confused about Singularity's support for InfiniBan=
d.
>>> And HPC is obviously defined by such high-speed interconnects (IB, OPA,
>>> Cray, ...)
>>>
>>> To me, this does seem to be a serious issue which would potentially
>>> decrease users' feeling about the portability of Singularity containers=
.
>>> Think about a scientist developing codes on a workstation without
>>> InfiniBand, and later making a test run on a small departmental cluster
>>> with InfiniBand, and eventually a production run on some white elephant
>>> with Intel Omni-Path. Just missing one interconnect library in the
>>> container and not compiling the MPI against that library would immediat=
ely
>>> break portability.
>>>
>>> Also I agree with the comment made in https://groups.google.com/a/lb
>>> l.gov/forum/#!topic/singularity/fsCO1_StjjA that Singularity should
>>> consider to include OFED drivers by default when creating a new contain=
er.
>>> Not sure if Greg you would change your mind here. The problem was reall=
y
>>> not about orted. Yes, Open MPI worked without the OFED driver, but only=
 on
>>> Ethernet. Since Singularity is claimed to be the container for HPC,
>>> including a well defined set of interconnect drivers and libraries trul=
y
>>> makes sense.
>>>
>>> For those who try to make your containers work with InfiniBand, I can
>>> provide a few general hints. These were not rigorously tested though an=
d I
>>> doubt I have the time to do so.
>>> 1. Issue ibv_devices in the container. You must be able able to see the
>>> name of your InfiniBand adpter. If not, then possibly some IB libraries=
 and
>>> drivers are missing
>>> 1.1. For Centos 7, the following rpm packages seem to be the minimum
>>> requirement
>>> libibverbs*
>>> librdmacm*
>>> 1.2. For Centos 6, the following rpm packages seem to be the minimum
>>> requirement
>>> libibverbs*
>>> librdmacm*
>>> libmlx*
>>> 1.3. Nevertheless, in the end I installed more packages
>>> yum -y install libmthca
>>> yum -y install libibcm*
>>> yum -y install libibmad*
>>> yum -y install libibumad*
>>> 1.4. Maybe the following will be useful, but I did not install them yet
>>> yum -y install dapl*
>>> yum -y install ibacm*
>>> yum -y install ibutils
>>>
>>> 2. After ./configure Open MPI, make sure you see the following.
>>> OpenFabrics Verbs: yes
>>> If you have OmniPath, then it should be
>>> Intel Omnipath (PSM2): yes
>>>
>>> There are also other components like MXM  which can potentially be "yes=
"
>>> if you installed Mellanox MXM.
>>>
>>> 3. When make Open MPI, use serial compilation, i.e. do not add the -j
>>> flag. It sometimes causes explainable behaviors.
>>>
>>> 4. After make install Open MPI, make sure that the OpenIB component is
>>> indeed installed.
>>> ompi_info |grep openib
>>> #Expect to see non-empty response
>>>  MCA btl: openib (MCA v2.1.0, API v3.0.0, Component v3.0.0)
>>>
>>> 5. Make sure that the MPI version is the same on the host and in the
>>> container
>>>
>>> My updated test result is provided below. If anybody would like to put
>>> these figures into any other documents, please inform me.
>>>
>>> Host configuration:
>>> 2x Intel E5-2680v2 (Ivybridge)
>>> 64GB memory
>>> Mellanox ConnectX-3 FDR adapter (but connects to a Mellanox QDR switch)
>>> RHEL 6.7
>>> OpenMPI development master branch (dated 8.2.17)
>>> Intel MKL 2017.0 community edition
>>> gcc 4.4
>>>
>>> Container:
>>> Centos 6 and 7 both tested without noticeable performance difference
>>> OpenMPI development master branch (dated 8.2.17)
>>> Intel MKL 2017.0 community edition
>>> gcc 4.4.7 (Centos-6), gcc 4.8.5 (Centos-7)
>>>
>>> Benchmarks:
>>> 1. LINPACK 2.2
>>> 2. OSU 5.3.2
>>>
>>> <LINPACK>
>>> Single node. N=3D40000, P=3D5, Q=3D4
>>> Container: 368 GFlops
>>> Host: 368 GFLOPS
>>> #A single node has 2x Intel E5-2680v2. So we are expecting 2 x 10 x 8 *
>>> 2.8 =3D 448 GFlops
>>> Efficiency =3D 368 / 448 =3D 82%. Not bad (given the small N (matrix si=
ze)
>>> and that gcc instead of icc was used, and the executable was dynamicall=
y
>>> linked -- by purpose)
>>>
>>> Dual-node, N=3D60000, P=3D8, Q=3D5
>>> Container: 736 GFLOPS
>>> Host:737 GFLOPS
>>>
>>>
>>> <OSU-P2P-Bandwidth>
>>> Container:
>>> Msg size(bytes) BW (MB/s)
>>> 65536                3738.89
>>> 131072               3756.34
>>> 262144               3767.35
>>> 524288               3780.46
>>> 1048576              3781.94
>>> 2097152              3775.07
>>> 4194304              3775.97
>>>
>>> Host:
>>> Msg size(bytes) BW (MB/s)
>>> 65536                3722.32
>>> 131072               3751.33
>>> 262144               3771.13
>>> 524288               3774.33
>>> 1048576              3781.43
>>> 2097152              3775.00
>>> 4194304              3773.68
>>>
>>> <OSU-P2P-Latency>
>>> Container:
>>> Msg size(bytes)  Latency (us)
>>> 0                       1.61
>>> 1                       1.67
>>> 2                       1.66
>>> 4                       1.66
>>> 8                       1.70
>>>
>>> Host:
>>> Msg size(bytes)  Latency (us)
>>> 0                       1.57
>>> 1                       1.63
>>> 2                       1.63
>>> 4                       1.63
>>> 8                       1.65
>>>
>>> How were the benchmarks executed?
>>> mpirun -n 20 -hostfile hostfile singularity exec /home/chih/containers/
>>> container-centos6-demo.img xhpl
>>> mpirun -n 2 -hostfile hostfile singularity exec
>>> /home/chih/containers/container-centos6-demo.img osu_bw
>>> mpirun -n 2 -hostfile hostfile singularity exec
>>> /home/chih/containers/container-centos6-demo.img osu_latency
>>>
>>> My conclusion: No difference for HPL (1 & 2 nodes) and IB bandwidth.
>>> There is a consistent 2% overhead in IB latency though, but this should=
 be
>>> affordable by most users.
>>>
>>>
>>> On Thursday, February 23, 2017 at 12:44:47 PM UTC+1, Chih-Song Kuo wrot=
e:
>>>>
>>>> I am not really sure if I can share the containers publicly as it
>>>> contains an Intel MKL installation which is bound to a personalized se=
rial
>>>> number (although that MKL is from the community edition, so it is
>>>> essentially free).
>>>>
>>>> Still, I am wondering if installing OFED into the container is the
>>>> right approach. There was a thread on a similar topic and Greg said no=
. I
>>>> hope I understood it correctly.
>>>> https://groups.google.com/a/lbl.gov/forum/#!topic/singularit
>>>> y/fsCO1_StjjA
>>>>
>>>> After all, although requiring the user to install OFED into the
>>>> container might be technically feasible, it would be very awkward for =
users
>>>> who develop their applications on their own workstations without
>>>> InfiniBand, not to mention that I am even not sure if one can install =
OFED
>>>> into a machine without IB adapters. And what if the OFED library in th=
e
>>>> container differ from that on the host? I don't think that will work, =
will
>>>> it?
>>>>
>>>> Sorry but somehow OpenMPI (or any MPI) is intent to reach OFED
>>>> libraries still remains a mystery for me. Please enlighten me.
>>>>
>>>> On Thursday, February 23, 2017 at 9:51:34 AM UTC+1, R=C3=A9my Dernat w=
rote:
>>>>>
>>>>> Hi,
>>>>>
>>>>> You can try to copy your libraries directly from the host to the
>>>>> container instead of a classical install ? I do not know what is the =
best
>>>>> way... But if you check woth solutions we will have an answer.
>>>>> BTW, I am very interesting by your containers. Could you share it
>>>>> (through singularity-hub ?) with your command line to run the benchma=
rk in
>>>>> the "singularity" file inside the container ? Indeed, I will do some
>>>>> performance tests also...
>>>>>
>>>>> Best regards,
>>>>> R=C3=A9my
>>>>>
>>>>> 2017-02-23 0:58 GMT+01:00 Chihsong :
>>>>>
>>>>>> Hi Greg,
>>>>>>
>>>>>> The problem is that I don't feel I have IB libraries inside my
>>>>>> container. How can I check that? Or did you simply install the ofed =
into
>>>>>> the container?
>>>>>>
>>>>>> Chiu-Song
>>>>>>
>>>>>> On Thursday, February 23, 2017, Gregory M. Kurtzer <gm...@lbl.gov>
>>>>>> wrote:
>>>>>>
>>>>>>> Hi Chih-Song,
>>>>>>>
>>>>>>> Haha, every now and then I get lucky when a new mail comes in and i=
s
>>>>>>> at the top of my mbox and I have a moment.
>>>>>>>
>>>>>>> In summary, yes. The MPI inside the container must also link agains=
t
>>>>>>> the IB libraries (also within the container).
>>>>>>>
>>>>>>> Hopefully that helps!
>>>>>>>
>>>>>>> On Wed, Feb 22, 2017 at 10:58 AM, Chih-Song Kuo  wrote:
>>>>>>>
>>>>>>>> Hi Greg,
>>>>>>>>
>>>>>>>> That reply was very prompt! Anyways, my answer follows.
>>>>>>>>
>>>>>>>> > * Make sure the MPI inside the container is properly linking
>>>>>>>> against the IB libraries
>>>>>>>> Did that mean that I need to install IB libraries (like Mellanox
>>>>>>>> OFED) into the container? I guess not?
>>>>>>>> But apparently openib is missing in the container.
>>>>>>>> [me@cn03 ompi-rhel6-host]$ ompi_info | grep openib
>>>>>>>>                  MCA btl: openib (MCA v2.1.0, API v3.0.0, Componen=
t
>>>>>>>> v3.0.0)
>>>>>>>>
>>>>>>>> Singularity.container-centos6-demo.img> ompi_info | grep openib
>>>>>>>> Singularity.container-centos6-demo.img>
>>>>>>>> Singularity.container-centos6-demo.img> ls
>>>>>>>> /etc/infiniband/openib.conf
>>>>>>>> ls: cannot access /etc/infiniband/openib.conf: No such file or
>>>>>>>> directory
>>>>>>>>
>>>>>>>> > * Make sure that the MPI configuration is configured to use MPI
>>>>>>>> I think you meant "to use IB" instead.
>>>>>>>> But still, did you mean that OpenMPI should be "configured"
>>>>>>>> "--with-verbs"? (Did you do so or you never had my problem?)
>>>>>>>> I did not use this flag when compiling Open MPI either on the host
>>>>>>>> or in the container.
>>>>>>>> > * Make sure you have Singularity configured properly to share th=
e
>>>>>>>> devices properly, tmp, and you are *NOT* using the IPC or PID name=
spaces
>>>>>>>> Can you provide more hint on how that can be done?
>>>>>>>>
>>>>>>>> Thank you once again for your time.
>>>>>>>> Chih-Song
>>>>>>>>
>>>>>>>> On Wednesday, February 22, 2017 at 7:33:22 PM UTC+1, Gregory M.
>>>>>>>> Kurtzer wrote:
>>>>>>>>>
>>>>>>>>> There are various things that *could* go wrong, and usage of
>>>>>>>>> containers (any of the technologies) actually introduce complexit=
ies in
>>>>>>>>> kernel and user space alignment that normally we don't consider. =
For that
>>>>>>>>> reason, my first suspicion is that your IB fabric is not being pr=
operly
>>>>>>>>> utilized by the MPI within the container. That could be due to an=
ything
>>>>>>>>> from build errors within the container to IB library/kmod API mis=
alignment.
>>>>>>>>>
>>>>>>>>> Things I would look at and check:
>>>>>>>>>
>>>>>>>>> * Make sure the MPI inside the container is properly linking
>>>>>>>>> against the IB libraries
>>>>>>>>> * Make sure that the IB libraries inside the container are
>>>>>>>>> compatible with the host kernel
>>>>>>>>> * Make sure that the MPI configuration is configured to use MPI
>>>>>>>>> * Make sure you have Singularity configured properly to share the
>>>>>>>>> devices properly, tmp, and you are *NOT* using the IPC or PID nam=
espaces
>>>>>>>>>
>>>>>>>>> Hope that helps.
>>>>>>>>>
>>>>>>>>> Greg
>>>>>>>>>
>>>>>>>>> On Wed, Feb 22, 2017 at 10:19 AM, Chih-Song Kuo wrote:
>>>>>>>>>
>>>>>>>>>> Hello,
>>>>>>>>>>
>>>>>>>>>> This is again Chih-Song from Fujitsu. I decided to make another
>>>>>>>>>> post to share my experience of performance impact with two kerne=
l
>>>>>>>>>> benchmarks: High Performance Linpack (HPL) and the OSU MPI bench=
mark suit.
>>>>>>>>>>
>>>>>>>>>> Overall, there was no noticeable performance difference for
>>>>>>>>>> benchmarks running on a single node. But for benchmarks running =
across
>>>>>>>>>> nodes, I did observe some difference, which was against to the c=
laim of
>>>>>>>>>> Singularity. Have anybody done any similar exercise? What are yo=
ur
>>>>>>>>>> findings? Can you suspect whether I was doing anything wrong?
>>>>>>>>>>
>>>>>>>>>> Host configuration:
>>>>>>>>>> 2x Intel E5-2680v2 (Ivybridge)
>>>>>>>>>> 64GB memory
>>>>>>>>>> Mellanox ConnectX-3 FDR adapter (but connects to a Mellanox QDR
>>>>>>>>>> switch)
>>>>>>>>>> RHEL 6.7
>>>>>>>>>> OpenMPI development master branch (8.2.17)
>>>>>>>>>> Intel MKL 2017.0 community edition
>>>>>>>>>> gcc 4.4
>>>>>>>>>>
>>>>>>>>>> Container:
>>>>>>>>>> Centos 6 and 7 both tested without noticeable performance
>>>>>>>>>> difference
>>>>>>>>>> OpenMPI development master branch (8.2.17)
>>>>>>>>>> Intel MKL 2017.0 community edition
>>>>>>>>>> gcc 4.4.7 (Centos-6), gcc 4.8.5 (Centos-7)
>>>>>>>>>>
>>>>>>>>>> Benchmarks:
>>>>>>>>>> 1. LINPACK 2.2
>>>>>>>>>> 2. OSU 5.3.2
>>>>>>>>>>
>>>>>>>>>> <LINPACK>
>>>>>>>>>> Single node. N=3D40000, P=3D5, Q=3D4
>>>>>>>>>> Container: 368 GFlops
>>>>>>>>>> Host: 368 GFLOPS
>>>>>>>>>> #A single node has 2x Intel E5-2680v2. So we are expecting 2 x 1=
0
>>>>>>>>>> x 8 * 2.8 =3D 448 GFlops
>>>>>>>>>> Efficiency =3D 368 / 448 =3D 82%. Not bad (given the small N (ma=
trix
>>>>>>>>>> size) and that gcc instead of icc was used, and the executable w=
as
>>>>>>>>>> dynamically linked -- by purpose)
>>>>>>>>>>
>>>>>>>>>> Dual-node, N=3D60000, P=3D8, Q=3D5
>>>>>>>>>> Container: 702 GFLOPS
>>>>>>>>>> Host:737 GFLOPS
>>>>>>>>>> There is roughly 5% of performance degradation with the containe=
r.
>>>>>>>>>>
>>>>>>>>>> <OSU-P2P-Bandwidth>
>>>>>>>>>> The container only saw 50-65% of the total bandwidth.
>>>>>>>>>>
>>>>>>>>>> Container:
>>>>>>>>>> Msg size(bytes) BW (MB/s)
>>>>>>>>>> 65536                2142.28
>>>>>>>>>> 131072               2363.45
>>>>>>>>>> 262144               1705.79
>>>>>>>>>> 524288               1592.56
>>>>>>>>>> 1048576              1721.88
>>>>>>>>>> 2097152              1557.42
>>>>>>>>>> 4194304              1655.90
>>>>>>>>>>
>>>>>>>>>> Host:
>>>>>>>>>> Msg size(bytes) BW (MB/s)
>>>>>>>>>> 65536                3722.32
>>>>>>>>>> 131072               3751.33
>>>>>>>>>> 262144               3771.13
>>>>>>>>>> 524288               3774.33
>>>>>>>>>> 1048576              3781.43
>>>>>>>>>> 2097152              3775.00
>>>>>>>>>> 4194304              3773.68
>>>>>>>>>>
>>>>>>>>>> <OSU-P2P-Latency>
>>>>>>>>>> Here the container was significantly slower.
>>>>>>>>>>
>>>>>>>>>> Container:
>>>>>>>>>> Msg size(bytes)  Latency (us)
>>>>>>>>>> 0                      31.59
>>>>>>>>>> 1                      31.86
>>>>>>>>>> 2                      31.83
>>>>>>>>>>
>>>>>>>>>> Host:
>>>>>>>>>> Msg size(bytes)  Latency (us)
>>>>>>>>>> 0                       1.55
>>>>>>>>>> 1                       1.63
>>>>>>>>>> 2                       1.63
>>>>>>>>>>
>>>>>>>>>> Note 1: Run-to-run variation of performance was much smaller tha=
n
>>>>>>>>>> the difference on the host and in the container.
>>>>>>>>>> Note 2: When Singularity was used, I could not instruct mpirun t=
o
>>>>>>>>>> use the ofed by specifying "--mca btl openib,self,vader" in the =
mpirun
>>>>>>>>>> parameter list. Doing so would give me an error message stating =
that the
>>>>>>>>>> openib component is missing. However, from the bandwidth measure=
d above,
>>>>>>>>>> the container did seem to be able to use InfiniBand, otherwise t=
he
>>>>>>>>>> bandwidth would not be so high (the nodes only had InfiniBand an=
d 1G
>>>>>>>>>> Ethernet). Maybe container was using IPoIB? I did not check that=
 yet.
>>>>>>>>>>
>>>>>>>>>> Reference: How the benchmarks were executed:
>>>>>>>>>> mpirun -n 20 -hostfile hostfile singularity exec
>>>>>>>>>> /home/chih/containers/container-centos6-demo.img xhpl
>>>>>>>>>> mpirun -n 2 -hostfile hostfile singularity exec
>>>>>>>>>> /home/chih/containers/container-centos6-demo.img osu_bw
>>>>>>>>>> mpirun -n 2 -hostfile hostfile singularity exec
>>>>>>>>>> /home/chih/containers/container-centos6-demo.img osu_latency
>>>>>>>>>>
>>>>>>>>>> Chih-Song
>>>>>>>>>>
>>>>>>>>>> --
>>>>>>>>>> You received this message because you are subscribed to the
>>>>>>>>>> Google Groups "singularity" group.
>>>>>>>>>> To unsubscribe from this group and stop receiving emails from it=
,
>>>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> Gregory M. Kurtzer
>>>>>>>>> HPC Systems Architect and Technology Developer
>>>>>>>>> Lawrence Berkeley National Laboratory HPCS
>>>>>>>>> University of California Berkeley Research IT
>>>>>>>>> Singularity Linux Containers (http://singularity.lbl.gov/)
>>>>>>>>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>>>>>>>>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>>>>>>>>> er.com/gmkurtzer
>>>>>>>>>
>>>>>>>> --
>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>> Groups "singularity" group.
>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> --
>>>>>>> Gregory M. Kurtzer
>>>>>>> HPC Systems Architect and Technology Developer
>>>>>>> Lawrence Berkeley National Laboratory HPCS
>>>>>>> University of California Berkeley Research IT
>>>>>>> Singularity Linux Containers (http://singularity.lbl.gov/)
>>>>>>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>>>>>>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>>>>>>> er.com/gmkurtzer
>>>>>>>
>>>>>>> --
>>>>>>> You received this message because you are subscribed to the Google
>>>>>>> Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Chih-Song Kuo =E9=83=AD=E7=9F=A5=E9=A0=8C
>>>>>> Senior Sales Consultant - HPC Benchmark Specialist at Fujitsu
>>>>>> M.Sc. RWTH with distinction in Software Systems Engineering with HPC
>>>>>> focus
>>>>>> B.Sc. NTHU in Computer Science, B.S.M. NTHU in Quantitative Finance
>>>>>> Tel:  +49-177-88949-28; +49-241-88949-155; +886-2-26629518
>>>>>>
>>>>>> --
>>>>>> You received this message because you are subscribed to the Google
>>>>>> Groups "singularity" group.
>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>> send an email to singu...@lbl.gov.
>>>>>>
>>>>>
>>>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>>
>>
>> --
>> Tyler Trafford
>>
>> --
>> You received this message because you are subscribed to the Google Group=
s
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n
>> email to singu...@lbl.gov.
>>
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>



--=20
Gregory M. Kurtzer
HPC Systems Architect and Technology Developer
Lawrence Berkeley National Laboratory HPCS
University of California Berkeley Research IT
Singularity Linux Containers (http://singularity.lbl.gov/)
Warewulf Cluster Management (http://warewulf.lbl.gov/)
GitHub: https://github.com/gmkurtzer, Twitter: https://twitter.com/gmkurtze=
r

--94eb2c086b5e45376105493944bd
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hybrid mode being the MPI outside the container is differe=
nt then the MPI inside the container.<div><br></div><div>Tyler, you technic=
ally don&#39;t &quot;have&quot; to worry about it... unless, you want to us=
e the IB (ducks and hides). Actually OFED is one of the major limitations o=
f portability with containers. We&#39;ve mostly solved the GPU issues, but =
not OFED.</div><div><br></div><div>Greg</div></div><div class=3D"gmail_extr=
a"><br><div class=3D"gmail_quote">On Thu, Feb 23, 2017 at 1:20 PM, Chihsong=
 <span dir=3D"ltr">&lt;<a href=3D"mailto:chihs...@gmail.com" target=3D"_bla=
nk">chihs...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_=
quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1=
ex"><div dir=3D"ltr">What did you mean by hybrid mode? MPI + OpenMP or some=
thing else?<span class=3D"HOEnZb"><font color=3D"#888888"><br></font></span=
><div class=3D"gmail_extra"><span class=3D"HOEnZb"><font color=3D"#888888">=
<br clear=3D"all"><div><div class=3D"m_3988348498465513417gmail_signature" =
data-smartmail=3D"gmail_signature"><div dir=3D"ltr"><span><div><div dir=3D"=
ltr"><div>Chih-Song<br></div></div></div></span></div></div></div></font></=
span><div><div class=3D"h5">
<br><div class=3D"gmail_quote">On Thu, Feb 23, 2017 at 10:17 PM, Tyler Traf=
ford <span dir=3D"ltr">&lt;<a href=3D"mailto:ttra...@gmail.com" target=3D"_=
blank">ttra...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmai=
l_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left=
:1ex"><div dir=3D"ltr"><div style=3D"font-family:arial,helvetica,sans-serif=
">I also thought that when running in hybrid mode we wouldn&#39;t have to w=
orry about the interconnect inside the container....</div><div style=3D"fon=
t-family:arial,helvetica,sans-serif"><br></div><div style=3D"font-family:ar=
ial,helvetica,sans-serif">--=C2=A0</div><div style=3D"font-family:arial,hel=
vetica,sans-serif">Tyler Trafford</div></div><div class=3D"gmail_extra"><di=
v><div class=3D"m_3988348498465513417h5"><br><div class=3D"gmail_quote">On =
Thu, Feb 23, 2017 at 4:05 PM, Chih-Song Kuo <span dir=3D"ltr">&lt;<a href=
=3D"mailto:chihs...@gmail.com" target=3D"_blank">chihs...@gmail.com</a>&gt;=
</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .=
8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">OK...Now =
after installing InfiniBand libraries things finally work decently. From th=
is lesson, I would suggest adding a remark about IB support to <a href=3D"h=
ttp://singularity.lbl.gov/docs-hpc" target=3D"_blank">http://singularity.lb=
l.gov/doc<wbr>s-hpc</a>, because otherwise new users can easily get confuse=
d about Singularity&#39;s support for InfiniBand. And HPC is obviously defi=
ned by such high-speed interconnects (IB, OPA, Cray, ...)<br><br>To me, thi=
s does seem to be a serious issue which would potentially decrease users&#3=
9; feeling about the portability of Singularity containers. Think about a s=
cientist developing codes on a workstation without InfiniBand, and later ma=
king a test run on a small departmental cluster with InfiniBand, and eventu=
ally a production run on some white elephant with Intel Omni-Path. Just mis=
sing one interconnect library in the container and not compiling the MPI ag=
ainst that library would immediately break portability.<br><br>Also I agree=
 with the comment made in <a href=3D"https://groups.google.com/a/lbl.gov/fo=
rum/#!topic/singularity/fsCO1_StjjA" target=3D"_blank">https://groups.googl=
e.com/a/lb<wbr>l.gov/forum/#!topic/singularit<wbr>y/fsCO1_StjjA</a> that Si=
ngularity should consider to include OFED drivers by default when creating =
a new container. Not sure if Greg you would change your mind here. The prob=
lem was really not about orted. Yes, Open MPI worked without the OFED drive=
r, but only on Ethernet. Since Singularity is claimed to be the container f=
or HPC, including a well defined set of interconnect drivers and libraries =
truly makes sense.<br><br>For those who try to make your containers work wi=
th InfiniBand, I can provide a few general hints. These were not rigorously=
 tested though and I doubt I have the time to do so.<br>1. Issue ibv_device=
s in the container. You must be able able to see the name of your InfiniBan=
d adpter. If not, then possibly some IB libraries and drivers are missing<b=
r>1.1. For Centos 7, the following rpm packages seem to be the minimum requ=
irement<br>libibverbs* <br>librdmacm*=C2=A0=C2=A0=C2=A0 <br>1.2. For Centos=
 6, the following rpm packages seem to be the minimum requirement<br>libibv=
erbs* <br>librdmacm*=C2=A0=C2=A0=C2=A0 <br>libmlx*<br>1.3. Nevertheless, in=
 the end I installed more packages<br>yum -y install libmthca <br>yum -y in=
stall libibcm*<br>yum -y install libibmad*<br>yum -y install libibumad*<br>=
1.4. Maybe the following will be useful, but I did not install them yet<br>=
yum -y install dapl*<br>yum -y install ibacm*<br>yum -y install ibutils<br>=
<br>2. After ./configure Open MPI, make sure you see the following.<br>Open=
Fabrics Verbs: yes<br>If you have OmniPath, then it should be<br>Intel Omni=
path (PSM2): yes<br><br>There are also other components like MXM=C2=A0 whic=
h can potentially be &quot;yes&quot; if you installed Mellanox MXM.<br><br>=
3. When make Open MPI, use serial compilation, i.e. do not add the -j flag.=
 It sometimes causes explainable behaviors.<br><br>4. After make install Op=
en MPI, make sure that the OpenIB component is indeed installed.<br>ompi_in=
fo |grep openib <br>#Expect to see non-empty response<span><br>=C2=A0MCA bt=
l: openib (MCA v2.1.0, API v3.0.0, Component v3.0.0)<br><br></span>5. Make =
sure that the MPI version is the same on the host and in the container<br><=
br>My updated test result is provided below. If anybody would like to put t=
hese figures into any other documents, please inform me.<span><br><br>Host =
configuration:<br>2x Intel E5-2680v2 (Ivybridge)<br>64GB memory<br>Mellanox=
 ConnectX-3 FDR adapter (but connects to a Mellanox QDR switch)<br>RHEL 6.7=
<br></span>OpenMPI development master branch (dated 8.2.17)<span><br>Intel =
MKL 2017.0 community edition<br>gcc 4.4<br><br>Container:<br>Centos 6 and 7=
 both tested without noticeable performance difference<br></span>OpenMPI de=
velopment master branch (dated 8.2.17)<span><br>Intel MKL 2017.0 community =
edition<br>gcc 4.4.7 (Centos-6), gcc 4.8.5 (Centos-7)<br><br>Benchmarks:<br=
>1. LINPACK 2.2<br>2. OSU 5.3.2<br><br>&lt;LINPACK&gt;<br>Single node. N=3D=
40000, P=3D5, Q=3D4<br>Container: 368 GFlops<br>Host: 368 GFLOPS<br>#A sing=
le node has 2x Intel E5-2680v2. So we are expecting 2 x 10 x 8 * 2.8 =3D 44=
8 GFlops<br>Efficiency
 =3D 368 / 448 =3D 82%. Not bad (given the small N (matrix size) and that=
=20
gcc instead of icc was used, and the executable was dynamically linked=20
-- by purpose)<br><br>Dual-node, N=3D60000, P=3D8, Q=3D5<br></span>Containe=
r: 736 GFLOPS<br>Host:737 GFLOPS<br><br><br>&lt;OSU-P2P-Bandwidth&gt;<span>=
<br>Container: <br>Msg size(bytes) BW (MB/s)<br></span>65536=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
 3738.89<br>131072=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0 3756.34<br>262144=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3767.35<br>524288=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0 3780.46<br>1048576=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3781.94<br>2097152=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3775.07<br>4194304=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0 3775.97<span><br><br>Host:<br>Msg size(bytes) BW (MB/s)<br>65536=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0 3722.32<br>131072=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3751.33<br>262144=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3771.13<br>=
524288=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0 3774.33<br>1048576=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3781.43<br>2097152=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3775.00<br>=
4194304=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0 3773.68<br><br>&lt;OSU-P2P-Latency&gt;<br></span><span>Contain=
er: <br>Msg size(bytes)=C2=A0 Latency (us)<br></span>0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.61<br>1=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.67<br>2=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0 1.66<br>4=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 1.66<br>8=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0 1.70<span><br><br>Host:<br>Msg size(bytes)=C2=A0 Latency (us)<=
br></span>0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.57<=
br>1=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.63<br>2=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.63<br>4=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.63<br>8=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1.65<br><br>How were the benc=
hmarks executed?<span><br>mpirun -n 20 -hostfile hostfile singularity exec =
/home/chih/containers/<div dir=3D"ltr">container-centos6-demo.img xhpl<br>m=
pirun -n 2 -hostfile hostfile singularity exec /home/chih/containers/contai=
ne<wbr>r-centos6-demo.img osu_bw<br>mpirun -n 2 -hostfile hostfile singular=
ity exec /home/chih/containers/containe<wbr>r-centos6-demo.img osu_latency<=
br></div><br></span>My conclusion: No difference for HPL (1 &amp; 2 nodes) =
and IB bandwidth. There is a consistent 2% overhead in IB latency though, b=
ut this should be affordable by most users.<div><div class=3D"m_39883484984=
65513417m_6026970709499655369h5"><br><br>On Thursday, February 23, 2017 at =
12:44:47 PM UTC+1, Chih-Song Kuo wrote:<blockquote class=3D"gmail_quote" st=
yle=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-left:1=
ex"><div dir=3D"ltr">I am not really sure if I can share the containers pub=
licly as it contains an Intel MKL installation which is bound to a personal=
ized serial number (although that MKL is from the community edition, so it =
is essentially free).<br><br>Still, I am wondering if installing OFED into =
the container is the right approach. There was a thread on a similar topic =
and Greg said no. I hope I understood it correctly.<br><a href=3D"https://g=
roups.google.com/a/lbl.gov/forum/#!topic/singularity/fsCO1_StjjA" rel=3D"no=
follow" target=3D"_blank">https://groups.google.com/a/lb<wbr>l.gov/forum/#!=
topic/singularit<wbr>y/fsCO1_StjjA</a><br><br>After all, although requiring=
 the user to install OFED  into the container might be technically feasible=
, it would be very awkward for users who develop their applications on thei=
r own workstations without InfiniBand, not to mention that I am even not su=
re if one can install OFED into a machine without IB adapters. And what if =
the OFED library in the container differ from that on the host? I don&#39;t=
 think that will work, will it?<br><br>Sorry but somehow OpenMPI (or any MP=
I) is intent to reach OFED libraries still remains a mystery for me. Please=
 enlighten me.<br><br>On Thursday, February 23, 2017 at 9:51:34 AM UTC+1, R=
=C3=A9my Dernat wrote:<blockquote class=3D"gmail_quote" style=3D"margin:0;m=
argin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"l=
tr">Hi,<div><br></div><div>You can try to copy your libraries=C2=A0directly=
=C2=A0from the host to the container instead of a classical install ? I do =
not know what is the best way... But if you check woth solutions we will ha=
ve an answer.</div><div>BTW, I am very interesting by your containers. Coul=
d you share it (through singularity-hub ?) with your command line to run th=
e benchmark in the &quot;singularity&quot; file inside the container ? Inde=
ed, I will do some performance tests also...</div><div><br></div><div>Best =
regards,</div><div>R=C3=A9my</div></div><div><br><div class=3D"gmail_quote"=
>2017-02-23 0:58 GMT+01:00 Chihsong <span dir=3D"ltr"></span>:<br><blockquo=
te class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc so=
lid;padding-left:1ex">Hi Greg,<div><br></div><div>The problem is that I=C2=
=A0don&#39;t feel I=C2=A0have IB libraries inside my container. How can I=
=C2=A0check that? Or did you simply=C2=A0install the ofed into the containe=
r?=C2=A0</div><div><br>Chiu-Song</div><div><div><div><br>On Thursday, Febru=
ary 23, 2017, Gregory M. Kurtzer &lt;<a rel=3D"nofollow">gm...@lbl.gov</a>&=
gt; wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;=
border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Chih-Song,=
<div><br></div><div>Haha, every now and then I get lucky when a new mail co=
mes in and is at the top of my mbox and I have a moment.</div><div><br></di=
v><div>In summary, yes. The MPI inside the container must also link against=
 the IB libraries (also within the container).</div><div><br></div><div>Hop=
efully that helps!</div></div><div><br><div class=3D"gmail_quote">On Wed, F=
eb 22, 2017 at 10:58 AM, Chih-Song Kuo=C2=A0 wrote:<br><blockquote class=3D=
"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding=
-left:1ex"><div dir=3D"ltr">Hi Greg,<br><br>That reply was very prompt! Any=
ways, my answer follows.<span><br><br>&gt; * Make sure the MPI inside the c=
ontainer is properly linking against the IB libraries<br></span>Did that me=
an that I need to install IB libraries (like Mellanox OFED) into the contai=
ner? I guess not?<br>But apparently openib is missing in the container.<br>=
[me@cn03 ompi-rhel6-host]$ ompi_info | grep openib<br>=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
 MCA btl: openib (MCA v2.1.0, API v3.0.0, Component v3.0.0)<br><br>Singular=
ity.container-centos6-<wbr>demo.img&gt; ompi_info | grep openib<br>Singular=
ity.container-centos6-<wbr>demo.img&gt;<br>Singularity.container-centos6-<w=
br>demo.img&gt; ls /etc/infiniband/openib.conf<br>ls: cannot access /etc/in=
finiband/openib.conf: No such file or directory<span><br><br>&gt; * Make su=
re that the MPI configuration is configured to use MPI<br></span>I think yo=
u meant &quot;to use IB&quot; instead. <br>But still, did you mean that Ope=
nMPI should be &quot;configured&quot; &quot;--with-verbs&quot;? (Did you do=
 so or you never had my problem?)<br>I did not use this flag when compiling=
 Open MPI either on the host or in the container.<span><br>&gt; * Make sure=
 you have Singularity configured properly to share the=20
devices properly, tmp, and you are *NOT* using the IPC or PID namespaces<br=
></span>Can you provide more hint on how that can be done?<br><br>Thank you=
 once again for your time.<br>Chih-Song<span><br><br>On Wednesday, February=
 22, 2017 at 7:33:22 PM UTC+1, Gregory M. Kurtzer wrote:</span><blockquote =
class=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #=
ccc solid;padding-left:1ex"><span><div dir=3D"ltr">There are various things=
 that *could* go wrong, and usage of containers (any of the technologies) a=
ctually introduce complexities in kernel and user space alignment that norm=
ally we don&#39;t consider. For that reason, my first suspicion is that you=
r IB fabric is not being properly utilized by the MPI within the container.=
 That could be due to anything from build errors within the container to IB=
 library/kmod API misalignment.<div><br></div><div>Things I would look at a=
nd check:</div><div><br></div><div>* Make sure the MPI inside the container=
 is properly linking against the IB libraries</div><div>* Make sure that th=
e IB libraries inside the container are compatible with the host kernel</di=
v><div>* Make sure that the MPI configuration is configured to use MPI</div=
><div>* Make sure you have Singularity configured properly to share the dev=
ices properly, tmp, and you are *NOT* using the IPC or PID namespaces</div>=
<div><br></div><div>Hope that helps.</div><div><br></div><div>Greg</div></d=
iv></span><div><br><div class=3D"gmail_quote"><div><div>On Wed, Feb 22, 201=
7 at 10:19 AM, Chih-Song Kuo wrote:<br></div></div><blockquote class=3D"gma=
il_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-lef=
t:1ex"><div><div><div dir=3D"ltr">Hello,<br><br>This is again Chih-Song fro=
m Fujitsu. I decided to make another post to share my experience of perform=
ance impact with two kernel benchmarks: High Performance Linpack (HPL) and =
the OSU MPI benchmark suit.<br><br>Overall, there was no noticeable perform=
ance difference for benchmarks running on a single node. But for benchmarks=
 running across nodes, I did observe some difference, which was against to =
the claim of Singularity. Have anybody done any similar exercise? What are =
your findings? Can you suspect whether I was doing anything wrong?<br><br>H=
ost configuration:<br>2x Intel E5-2680v2 (Ivybridge)<br>64GB memory<br>Mell=
anox ConnectX-3 FDR adapter (but connects to a Mellanox QDR switch)<br>RHEL=
 6.7<br>OpenMPI development master branch (8.2.17)<br>Intel MKL 2017.0 comm=
unity edition<br>gcc 4.4<br><br>Container:<br>Centos 6 and 7 both tested wi=
thout noticeable performance difference<br>OpenMPI development master branc=
h (8.2.17)<br>Intel MKL 2017.0 community edition<br>gcc 4.4.7 (Centos-6), g=
cc 4.8.5 (Centos-7)<br><br>Benchmarks:<br>1. LINPACK 2.2<br>2. OSU 5.3.2<br=
><br>&lt;LINPACK&gt;<br>Single node. N=3D40000, P=3D5, Q=3D4<br>Container: =
368 GFlops<br>Host: 368 GFLOPS<br>#A single node has 2x Intel E5-2680v2. So=
 we are expecting 2 x 10 x 8 * 2.8 =3D 448 GFlops<br>Efficiency =3D 368 / 4=
48 =3D 82%. Not bad (given the small N (matrix size) and that gcc instead o=
f icc was used, and the executable was dynamically linked -- by purpose)<br=
><br>Dual-node, N=3D60000, P=3D8, Q=3D5<br>Container: 702 GFLOPS<br>Host:73=
7 GFLOPS<br>There is roughly 5% of performance degradation with the contain=
er.<br><br>&lt;OSU-P2P-Bandwidth&gt;<br>The container only saw 50-65% of th=
e total bandwidth.<br><br>Container: <br>Msg size(bytes) BW (MB/s)<br>65536=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0 2142.28<br>131072=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 2363.45<br>262144=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1705.=
79<br>524288=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0 1592.56<br>1048576=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1721.88<br>2097152=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 1557.=
42<br>4194304=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 1655.90<br><br>Host:<br>Msg size(bytes) BW (MB/s)<br>655=
36=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 3722.32<br>131072=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3751.33<br>262144=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 37=
71.13<br>524288=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0 3774.33<br>1048576=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 3781.43<br>2097152=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 37=
75.00<br>4194304=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0 3773.68<br><br>&lt;OSU-P2P-Latency&gt;<br>Here the co=
ntainer was significantly slower.<br><br>Container: <br>Msg size(bytes)=C2=
=A0 Latency (us)<br>0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 31=
.59<br>1=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 31.86<br>2=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 31.83<br><br>Host:<br>Msg =
size(bytes)=C2=A0 Latency (us)<br>0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 1.55<br>1=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0 1.63<br>2=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0 1.63<br><br>Note 1: Run-to-run variation of performance was much sma=
ller than the difference on the host and in the container.<br>Note 2: When =
Singularity was used, I could not instruct mpirun to use the ofed by specif=
ying &quot;--mca btl openib,self,vader&quot; in the mpirun parameter list. =
Doing so would give me an error message stating that the openib component i=
s missing. However, from the bandwidth measured above, the container did se=
em to be able to use InfiniBand, otherwise the bandwidth would not be so hi=
gh (the nodes only had InfiniBand and 1G Ethernet). Maybe container was usi=
ng IPoIB? I did not check that yet. <br><br>Reference: How the benchmarks w=
ere executed:<br>mpirun -n 20 -hostfile hostfile singularity exec /home/chi=
h/containers/containe<wbr>r-centos6-demo.img xhpl<br>mpirun -n 2 -hostfile =
hostfile singularity exec /home/chih/containers/containe<wbr>r-centos6-demo=
.img osu_bw<br>mpirun -n 2 -hostfile hostfile singularity exec /home/chih/c=
ontainers/containe<wbr>r-centos6-demo.img osu_latency<span><font color=3D"#=
888888"><br><br>Chih-Song<br><br></font></span></div></div></div><span><fon=
t color=3D"#888888"><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br></div></div>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</font></span></blockquote></div><span><br><br clear=3D"all"><div><br></div=
>-- <br><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><=
div><div dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurt=
zer</div><div>HPC Systems Architect and Technology Developer</div><div>Lawr=
ence Berkeley National Laboratory HPCS<br>University of California Berkeley=
 Research IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singul=
arity.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://singularity<wbr>.=
lbl.gov/</a>)</div><div>Warewulf Cluster Management=C2=A0(<a href=3D"http:/=
/warewulf.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://warewulf.lb<w=
br>l.gov/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.com/gmkurtz=
er" rel=3D"nofollow" target=3D"_blank">https://github.com/gmk<wbr>urtzer</a=
>,=C2=A0<span style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"ht=
tps://twitter.com/gmkurtzer" style=3D"font-size:12.8px" rel=3D"nofollow" ta=
rget=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</a></div></div></div></d=
iv></div></div></div></div></div></div></div>
</span></div>
</blockquote></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div=
 dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtzer</div=
><div>HPC Systems Architect and Technology Developer</div><div>Lawrence Ber=
keley National Laboratory HPCS<br>University of California Berkeley Researc=
h IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singularity.lb=
l.gov/" rel=3D"nofollow" target=3D"_blank">http://singularity<wbr>.lbl.gov/=
</a>)</div><div>Warewulf Cluster Management=C2=A0(<a href=3D"http://warewul=
f.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://warewulf.lb<wbr>l.gov=
/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.com/gmkurtzer" rel=
=3D"nofollow" target=3D"_blank">https://github.com/gmk<wbr>urtzer</a>,=C2=
=A0<span style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"https:/=
/twitter.com/gmkurtzer" style=3D"font-size:12.8px" rel=3D"nofollow" target=
=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</a></div></div></div></div><=
/div></div></div></div></div></div></div>
</div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div><br><br></div></div><span><font color=3D"#888888">-- <br=
><div dir=3D"ltr"><span><div><div dir=3D"ltr"><div>Chih-Song Kuo =E9=83=AD=
=E7=9F=A5=E9=A0=8C<br>Senior Sales Consultant - HPC Benchmark Specialist at=
 Fujitsu<br>M.Sc. RWTH with distinction in Software Systems Engineering wit=
h HPC focus<br>B.Sc. NTHU in Computer Science, B.S.M. NTHU in Quantitative =
Finance<br>Tel: =C2=A0<a value=3D"+491778894928">+49-177-88949-28</a>; <a v=
alue=3D"+4924188949155">+49-241-88949-155</a>; <a value=3D"+886226629518">+=
886-2-26629518</a></div></div></div></span></div></font></span><div><div><b=
r>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></div></blockquote></div><br></div>
</blockquote></div></blockquote></div></div></div><div class=3D"m_398834849=
8465513417m_6026970709499655369HOEnZb"><div class=3D"m_3988348498465513417m=
_6026970709499655369h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div></div><=
/div><span class=3D"m_3988348498465513417HOEnZb"><font color=3D"#888888">--=
 <br><div class=3D"m_3988348498465513417m_6026970709499655369gmail_signatur=
e" data-smartmail=3D"gmail_signature">Tyler Trafford</div>
</font></span></div><div class=3D"m_3988348498465513417HOEnZb"><div class=
=3D"m_3988348498465513417h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.go<wbr>v</a>.<br>
</div></div></blockquote></div><br></div></div></div></div><div class=3D"HO=
EnZb"><div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div class=3D"gmail_signature" data-smartmail=3D"gmail_signature"><div dir=
=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr">=
<div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtzer</div><div>HPC Sys=
tems Architect and Technology Developer</div><div>Lawrence Berkeley Nationa=
l Laboratory HPCS<br>University of California Berkeley Research IT<br>Singu=
larity Linux Containers=C2=A0(<a href=3D"http://singularity.lbl.gov/" targe=
t=3D"_blank">http://singularity.lbl.gov/</a>)</div><div>Warewulf Cluster Ma=
nagement=C2=A0(<a href=3D"http://warewulf.lbl.gov/" target=3D"_blank">http:=
//warewulf.lbl.gov/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.c=
om/gmkurtzer" target=3D"_blank">https://github.com/gmkurtzer</a>,=C2=A0<spa=
n style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"https://twitte=
r.com/gmkurtzer" style=3D"font-size:12.8px" target=3D"_blank">https://twitt=
er.com/gmkurtzer</a></div></div></div></div></div></div></div></div></div><=
/div></div>
</div>

--94eb2c086b5e45376105493944bd--

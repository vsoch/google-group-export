Date: Thu, 28 Jul 2016 17:34:54 -0700 (PDT)
From: Igor <igor...@gmail.com>
To: singularity <singu...@lbl.gov>
Message-Id: <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov>
In-Reply-To: <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
Subject: Re: [Singularity] How to use GPU in singularity?
MIME-Version: 1.0
Content-Type: multipart/mixed; 
	boundary="----=_Part_0_450261954.1469752494864"

------=_Part_0_450261954.1469752494864
Content-Type: multipart/alternative; 
	boundary="----=_Part_1_46408089.1469752494866"

------=_Part_1_46408089.1469752494866
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 7bit

Hi Nathan,
When I try to install the driver by running NVIDIA*.run script inside the 
image, it fails, probably because it tries to modify kernel that belongs to 
host?
How do I extract just libcuda.so.345.67 without installing the driver 
(which is obviously problematic) and why would copying the library from the 
host would not work?
Thank you,
Igor

On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:
>
> Also if you are using the binary installation of TensorFlow you need CUDA 
> toolkit 7.5 and cuDNN v4. These only need to be installed on our image. As 
> I mentioned earlier you will need the libcuda.so.###.## library on your 
> image. It is very important that this is the same version of the NVIDIA 
> driver as you have on your nose (seemingly 346.67 for you). I should've 
> have also mentioned that you want the libcuda.so.345.67 library that you 
> get from extracting the NVIDIA installer. It will not work if you try to 
> copy the libcuda.so library that from you node. 
>
> Let me know if you have any more questions. 
>
> Best,
> Nathan
>
> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com <javascript:>> 
> wrote:
>
>> Hello,
>>
>> Yes you are correct. The NVIDIA driver must be installed on your image as 
>> well. However, you honestly only need the libcuda.so.###.## library and the 
>> appropriate links for that library. Once you have those installed in your 
>> image, it should work. 
>>
>> Best,
>> Nathan 
>>
>> On Thursday, July 28, 2016, Igor <igor...@gmail.com> wrote:
>>
>>> Hi All,
>>>
>>> I am trying to use GPU-enabled tensorflow and it cannot find GPU card 
>>> from inside the container.
>>>
>>> On the host:
>>> $ lspci | grep -i nvidia 
>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1) 
>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1)
>>>
>>> $ nvidia-smi 
>>> Thu Jul 28 19:01:42 2016        
>>> +------------------------------------------------------+ 
>>>                        
>>> | NVIDIA-SMI 346.47     Driver Version: 346.47         | 
>>>                        
>>> |-------------------------------+----------------------+----------------------+ 
>>>
>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile 
>>> Uncorr. ECC | 
>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util 
>>>  Compute M. | 
>>> |===============================+======================+======================| 
>>>
>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off | 
>>>                    0 | 
>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB |      0% 
>>>      Default | 
>>> +-------------------------------+----------------------+----------------------+ 
>>>
>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off | 
>>>                    0 | 
>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB |      0% 
>>>      Default | 
>>> +-------------------------------+----------------------+----------------------+ 
>>>
>>>
>>>                                                                                
>>> +-----------------------------------------------------------------------------+ 
>>>
>>> | Processes:                                                       GPU 
>>> Memory | 
>>> |  GPU       PID  Type  Process name                               Usage 
>>>      | 
>>> |=============================================================================| 
>>>
>>> |    0     11671    G   /usr/bin/X 
>>>                                       9MiB | 
>>> |    1     11671    G   /usr/bin/X 
>>>                                       3MiB |
>>>
>>>
>>> Inside singularity:
>>> $ singularity shell /software/src/singularity_images/tensorflow_0.9.img
>>>
>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia 
>>> bash: lspci: command not found 
>>> Singularity/tensorflow_0.9.img> nvidia-smi 
>>> bash: nvidia-smi: command not found 
>>> Singularity/tensorflow_0.9.img> python 
>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)  
>>> [GCC 5.4.0 20160609] on linux2 
>>> Type "help", "copyright", "credits" or "license" for more information. 
>>> >>> import tensorflow as tf 
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA 
>>> library libcublas.so locally 
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA 
>>> library libcudnn.so locally 
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA 
>>> library libcufft.so locally 
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA 
>>> library libcuda.so locally 
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA 
>>> library libcurand.so locally 
>>> >>> sess = tf.Session() 
>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to 
>>> cuInit: CUDA_ERROR_UNKNOWN 
>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving 
>>> CUDA diagnostic information for host: midway-l34-01 
>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: 
>>> midway-l34-01 
>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda 
>>> reported version is: Not found: was unable to find libcuda.so DSO loaded 
>>> into this program 
>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver 
>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module 
>>>  346.47  Thu Feb 19 18:56:03 PST 2015 
>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC)  
>>> """ 
>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel 
>>> reported version is: 346.47.0 
>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices 
>>> available on machine.
>>>
>>> Must there be nvidia driver installed inside the container? Outside? The 
>>> container shares the same kernel with the host and nvidia kernel module 
>>> needs to be loaded... How this is handled? Any requirements on nvidia 
>>> driver and cuda versions inside and outside of the container?
>>>
>>> Thank you,
>>> Igor
>>>
>>>
>>> -- 
>>> You received this message because you are subscribed to the Google 
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send 
>>> an email to singu...@lbl.gov.
>>>
>>
------=_Part_1_46408089.1469752494866
Content-Type: text/html; charset=utf-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Hi Nathan,<div>When I try to install the driver by running=
 NVIDIA*.run script inside the image, it fails, probably because it tries t=
o modify kernel that belongs to host?</div><div>How do I extract just libcu=
da.so.345.67 without installing the driver (which is obviously problematic)=
 and why would copying the library from the host would not work?</div><div>=
Thank you,</div><div>Igor<br><br>On Thursday, July 28, 2016 at 7:18:26 PM U=
TC-5, Nathan Lin wrote:<blockquote class=3D"gmail_quote" style=3D"margin: 0=
;margin-left: 0.8ex;border-left: 1px #ccc solid;padding-left: 1ex;">Also if=
 you are using the binary installation of TensorFlow you need CUDA toolkit =
7.5 and cuDNN v4. These only need to be installed on our image. As I mentio=
ned earlier you will need the libcuda.so.###.## library on your image. It i=
s very important that this is the same version of the NVIDIA driver as you =
have on your nose (seemingly 346.67 for you). I should&#39;ve have also men=
tioned that you want the libcuda.so.345.67 library that you get from extrac=
ting the NVIDIA installer. It will not work if you try to copy=C2=A0the lib=
cuda.so library that from you node.=C2=A0<div><br></div><div>Let me know if=
 you have any more questions.=C2=A0</div><div><br></div><div>Best,</div><di=
v>Nathan<span></span><br><br>On Thursday, July 28, 2016, Nathan Lin &lt;<a =
href=3D"javascript:" target=3D"_blank" gdf-obfuscated-mailto=3D"ph39PzOVBQA=
J" rel=3D"nofollow" onmousedown=3D"this.href=3D&#39;javascript:&#39;;return=
 true;" onclick=3D"this.href=3D&#39;javascript:&#39;;return true;">nat...@g=
mail.com</a>&gt; wrote:<br><blockquote class=3D"gmail_quote" style=3D"margi=
n:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Hello,<div><br></=
div><div>Yes you are correct. The NVIDIA driver must be installed on your i=
mage as well. However, you honestly only need the libcuda.so.###.## library=
 and the appropriate links for that library. Once you have those installed =
in your image, it should work.=C2=A0</div><div><br></div><div>Best,</div><d=
iv>Nathan=C2=A0<span></span><br><br>On Thursday, July 28, 2016, Igor &lt;<a=
>igor...@gmail.com</a>&gt; wrote:<br><blockquote class=3D"gmail_quote" styl=
e=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div di=
r=3D"ltr">Hi All,<div><br><div>I am trying to use GPU-enabled tensorflow an=
d it cannot find GPU card from inside the container.</div><div><br></div><d=
iv>On the host:</div><div><span style=3D"font-family:monospace"><span style=
=3D"color:rgb(0,0,0)">$ lspci | grep -i nvidia
</span><br>20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] =
(rev a1)
<br>8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1=
)<br>
<br></span></div><div><span style=3D"font-family:monospace"><span style=3D"=
color:rgb(0,0,0)">$ nvidia-smi
</span><br>Thu Jul 28 19:01:42 2016 =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0<br>+-----------------------------<wbr>-------------------------+ =C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>| NVIDIA-SMI 3=
46.47 =C2=A0=C2=A0=C2=A0=C2=A0Driver Version: 346.47 =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0| =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0<br>|-----------------------------<wbr>--+---------------=
-------+----<wbr>------------------+
<br>| GPU =C2=A0Name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Persistence-=
M| Bus-Id =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan =C2=A0Temp =C2=A0Perf =C2=A0Pwr:Usage/Cap| =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0Memory-Usage | GPU-Util =C2=A0Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A00 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:20:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A030C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A020W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A066MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br>| =C2=A0=C2=A01 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:8B:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A026C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A019W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A060MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br> =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wb=
r>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>+----------------------------=
-<wbr>------------------------------<wbr>------------------+
<br>| Processes: =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0GPU Memory |
<br>| =C2=A0GPU =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0PID =C2=A0Type =C2=A0Pr=
ocess name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>Usage =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A0=C2=A00 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A09MiB |
<br>| =C2=A0=C2=A0=C2=A01 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A03MiB |<br>
<br></span></div></div><div><font face=3D"monospace"><br></font></div><div>=
<font face=3D"monospace">Inside singularity:</font></div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ singularity s=
hell /software/src/singularity_<wbr>images/tensorflow_0.9.img</span><br></s=
pan></div><div><span style=3D"font-family:monospace"><span style=3D"color:r=
gb(0,0,0)"><br></span></span></div><div><span style=3D"font-family:monospac=
e"><span style=3D"color:rgb(0,0,0)">Singularity/tensorflow_0.9.<wbr>img&gt;=
 lspci | grep -i nvidia
</span><br>bash: lspci: command not found
<br>Singularity/tensorflow_0.9.<wbr>img&gt; nvidia-smi
<br>bash: nvidia-smi: command not found
<br>Singularity/tensorflow_0.9.<wbr>img&gt; python
<br>Python 2.7.12 (default, Jul =C2=A01 2016, 15:12:24) =C2=A0<br>[GCC 5.4.=
0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow as tf
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcuda.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally
<br>&gt;&gt;&gt; sess =3D tf.Session()
<br>E tensorflow/stream_executor/<wbr>cuda/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway-l34-01
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:160] hostnam=
e: midway-l34-01
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:185] libcuda=
 reported version is: Not found: was unable to find libcuda.so DSO loaded i=
nto this program
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:347] driver =
version file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 K=
ernel Module =C2=A0346.47 =C2=A0Thu Feb 19 18:56:03 PST 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:189] kernel =
reported version is: 346.47.0
<br>I tensorflow/core/common_<wbr>runtime/gpu/gpu_init.cc:81] No GPU device=
s available on machine.<br>
<br></span></div><div><span style=3D"font-family:monospace">Must there be n=
vidia driver installed inside the container? Outside? The container shares =
the same kernel with the host and nvidia kernel module needs to be loaded..=
. How this is handled? Any requirements on nvidia driver and cuda versions =
inside and outside of the container?</span></div><div><span style=3D"font-f=
amily:monospace"><br></span></div><div><span style=3D"font-family:monospace=
">Thank you,</span></div><div><span style=3D"font-family:monospace">Igor</s=
pan></div><div><span style=3D"font-family:monospace"><br></span></div><div>=
<font face=3D"monospace"><br></font></div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</blockquote></div>
</blockquote></div>
</blockquote></div></div>
------=_Part_1_46408089.1469752494866--

------=_Part_0_450261954.1469752494864--

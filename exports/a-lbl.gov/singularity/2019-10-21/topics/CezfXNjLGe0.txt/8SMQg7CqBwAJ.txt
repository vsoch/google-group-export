X-Received: by 10.66.124.193 with SMTP id mk1mr64780882pab.21.1470338084313;
        Thu, 04 Aug 2016 12:14:44 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.36.236.132 with SMTP id g126ls229430ith.13.canary; Thu, 04 Aug
 2016 12:14:43 -0700 (PDT)
X-Received: by 10.66.82.42 with SMTP id f10mr129380023pay.17.1470338083562;
        Thu, 04 Aug 2016 12:14:43 -0700 (PDT)
Return-Path: <igor...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id b132si15918980pfb.196.2016.08.04.12.14.43
        for <singu...@lbl.gov>;
        Thu, 04 Aug 2016 12:14:43 -0700 (PDT)
Received-SPF: pass (google.com: domain of igor...@gmail.com designates 209.85.213.171 as permitted sender) client-ip=209.85.213.171;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of igor...@gmail.com designates 209.85.213.171 as permitted sender) smtp.mailfrom=igor...@gmail.com
X-Ironport-SBRS: 3.5
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2GBAADXk6NXh6vVVdFdhBt8B4M4gQyjM4kuH4Q9giF2gT0aJiaBbFSBXEsBgQ8CgUEHOBQBAQEBAQEBAw8BAQEIDQkJGS+CUgE5CgYrAQEBAQEBAQEBIQIrBAIUCxsBAQQBEggBCB0BDQ4eAwELBgMCCw0gAQkCAiEBAQ4DAQUBHA4HBAEcBAGHdAEDDwgFCQORPo9EgTI+MYs7gWqCWgWGPwoZJw1Ug1sBAQEHAQEBAQEBARgCBhCJZIEDgkOBTxEBSYJUgloFgUWER4ISB2CFEgtqP4QmhQ8qCAEBgSKEeIJ8gnNDgjaBaxc3hz6FSYgshAWCOBIegQ8PD4JIEQuBah4yAQEBAQOFboE2AQEB
X-IPAS-Result: A2GBAADXk6NXh6vVVdFdhBt8B4M4gQyjM4kuH4Q9giF2gT0aJiaBbFSBXEsBgQ8CgUEHOBQBAQEBAQEBAw8BAQEIDQkJGS+CUgE5CgYrAQEBAQEBAQEBIQIrBAIUCxsBAQQBEggBCB0BDQ4eAwELBgMCCw0gAQkCAiEBAQ4DAQUBHA4HBAEcBAGHdAEDDwgFCQORPo9EgTI+MYs7gWqCWgWGPwoZJw1Ug1sBAQEHAQEBAQEBARgCBhCJZIEDgkOBTxEBSYJUgloFgUWER4ISB2CFEgtqP4QmhQ8qCAEBgSKEeIJ8gnNDgjaBaxc3hz6FSYgshAWCOBIegQ8PD4JIEQuBah4yAQEBAQOFboE2AQEB
X-IronPort-AV: E=Sophos;i="5.28,471,1464678000"; 
   d="scan'208,217";a="31663050"
Received: from mail-yb0-f171.google.com ([209.85.213.171])
  by fe4.lbl.gov with ESMTP; 04 Aug 2016 12:14:40 -0700
Received: by mail-yb0-f171.google.com with SMTP id v8so7687474ybe.3
        for <singu...@lbl.gov>; Thu, 04 Aug 2016 12:14:40 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=oVpDGdkyVD1dw854ROJfLThbZzXalGqxo5mLIveM5lk=;
        b=pgYOWd0MlEkDGFBj/MLrkBXwVv+IS9bMJKIIu8k1LlLZqaQIqKOLm00UvhWjZpwu9Y
         9X38iwdVXmQZ9yJ095WYYa00wWjbG71/dywi9QGE9JmegSfX+wv3eGyfcWqziffds1MQ
         cVaZpE4Q0Uz+U5zitSldIPxIYD1MSLyFQSOOS08cG8qQ0Uzk5Hf1/jmNKAcY+MXKz7uV
         d2/l1UId3XT3IH9c7uSFocV9pETYnKJwBUVv21MDF4ZHzJnK0u+p133DAYcRK0SMEzqf
         U+1TwmLjol9r+4O0HIQch0dMnpYTwEuFEdI8hrT9e8H7IGRiPaZ8DhHA9rbXzsxi0Qf6
         b7dA==
X-Gm-Message-State: AEkoousMFaB6Q62jI4+RkD5RIWuYhIuDATGDiKs1HQOowG/D7njWp8m1/mRhviJQmrsD45N5HfF7ysaBQV4CHA==
X-Received: by 10.37.25.11 with SMTP id 11mr9271168ybz.13.1470338079422; Thu,
 04 Aug 2016 12:14:39 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.37.161.34 with HTTP; Thu, 4 Aug 2016 12:14:37 -0700 (PDT)
In-Reply-To: <CA+3XN_KmaVuaKqOCbCvocOrw0qghQZq3kiBh1S6T2NKyTgpDTA@mail.gmail.com>
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
 <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov> <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
 <CAA8GL6BdE1TRBaPD-oM7qcj8QK1cBsmJsUzYyrvkRPBP9CX+hQ@mail.gmail.com>
 <CAMfmYehdPLtiouQqMGqOx4ZbEXFbbPRL5QOxsP_vQo0us1QLuA@mail.gmail.com>
 <B927B7F6-3CFB-452D-92AB-866F9B8024E4@gmail.com> <CAMfmYeiSvcReO4jvSGJkavnex64wGZ8Phxva2kAxJ7pcp48YiA@mail.gmail.com>
 <CAMfmYeiaTxVQSNqwprHe5ckcDHPcJXy3imdepiRL+KkDh12TCQ@mail.gmail.com>
 <65CD778F-6CD1-4DB4-9668-4D89839B7053@gmail.com> <CAMfmYeg_pnJcyKGetK7WVChToaWCgGYH-nrYY9v=2+RSkuWZuQ@mail.gmail.com>
 <C5AE54CB-2BA1-4E59-88FC-D20224A46086@gmail.com> <CAMfmYeg2rR9-U-zyviCeDXRt_QgKv_K0p9pf-+qgoGPQAjxjXA@mail.gmail.com>
 <95039222-908B-4AE8-8844-551646C9733C@gmail.com> <CAA8GL6ATuT+zMyD9zrW5GBH3Br8bm8=RvjKm1PNAGbKGF3psMw@mail.gmail.com>
 <CAMfmYejEioybKBLNSv36dd7ma-Z1hatfssvFUOGiuehBZbk-Ug@mail.gmail.com> <CA+3XN_KmaVuaKqOCbCvocOrw0qghQZq3kiBh1S6T2NKyTgpDTA@mail.gmail.com>
From: Igor Yakushin <igor...@gmail.com>
Date: Thu, 4 Aug 2016 14:14:37 -0500
Message-ID: <CAMfmYejEW-OUrnFdxyCTqKZ7X2OGS-abZDgd=frfb00sycofVQ@mail.gmail.com>
Subject: Re: [Singularity] How to use GPU in singularity?
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=001a113edee4ec7fa7053943c2f1

--001a113edee4ec7fa7053943c2f1
Content-Type: text/plain; charset=UTF-8

Hi Bernard,

Here is the container:
https://uchicago.box.com/s/g2dwl6s8awvk96bku5ebifhyi396qd7u
It supports several driver versions.
Once you get into singularity shell, set the environment as follows:
source /usr/local/nvidia.sh 352.39
After that nvidia-smi should work and you can start python and do something
like:

import tensorflow as tf
s = tf.Session()

It should detect your card.

Let me know if it works on your cluster. So far I tested it on my laptop
and on a few cluster nodes with Tesla K40m with different driver versions.
Thank you,
Igor


On Mon, Aug 1, 2016 at 11:55 PM, Bernard Li <ber...@vanhpc.org> wrote:

> Hey Igor:
>
> If you can make the tensorflow Singularity container available, I'd like
> to try that out on our cluster.
>
> Thanks,
>
> Bernard
>
>
> On Monday, 1 August 2016, Igor Yakushin <igor...@gmail.com> wrote:
>
>> Hi Nathan,
>> The main problem was that if you try to install cuda, it would by default
>> install driver as well that might be of different version than the driver
>> installed with NVIDIA*.run file. So when installing cuda, use an option not
>> to install the driver. It is much easier to find NVIDIA*.run file of the
>> version you need than cuda*.run with the right driver.  When downloading
>> NVIDIA*.run, pay attention that you are asking for Tesla card (if that's
>> what you have). Consumer cards have different driver (I do not remember if
>> it is reflected in the file name but I suspect not, because I made this
>> mistake).
>> Thank you,
>> Igor
>>
>>
>> On Mon, Aug 1, 2016 at 8:56 AM, Nathan Lin <nathan...@gmail.com>
>> wrote:
>>
>>> That's great to hear Igor! What ended up being the problem?
>>>
>>> On Mon, Aug 1, 2016 at 1:43 AM, Rick Wagner <richard...@gmail.com>
>>> wrote:
>>>
>>>> Igor,
>>>>
>>>> If you had a chance to post your definition file or the steps you took,
>>>> I know several of us would appreciate it. Getting TensorFlow running on
>>>> CentOS was a huge effort for our support staff. And that's just one of many
>>>> GPU-enabled applications.
>>>>
>>>> --Rick
>>>>
>>>> On Jul 31, 2016, at 10:20 PM, Igor Yakushin <igor...@gmail.com>
>>>> wrote:
>>>>
>>>> Thank you, Nathan. It finally works!
>>>>
>>>> On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin <nathan...@gmail.com>
>>>> wrote:
>>>>
>>>>> Yes I do
>>>>>
>>>>> On Jul 31, 2016, at 5:03 PM, Igor Yakushin <igor...@gmail.com>
>>>>> wrote:
>>>>>
>>>>> Nathan,
>>>>> When you import tensorflow in python, does it tell you what cuda
>>>>> libraries it is loading or not?
>>>>> Do you see these messages:
>>>>> ======
>>>>> >>> import tensorflow as tf
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcublas.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcudnn.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcufft.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcuda.so locally
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>> CUDA library libcurand.so locally
>>>>> ======
>>>>> Thank you,
>>>>> Igor
>>>>>
>>>>> On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin <nathan...@gmail.com>
>>>>> wrote:
>>>>>
>>>>>> Hi Igor,
>>>>>>
>>>>>> In regards to your first questions, the OS/drivers of your building
>>>>>> computer should not matter. I built an Ubuntu 14.04 image on my RHEL 7 box
>>>>>> for our RHEL 6 cluster. I'm not sure that the toolkit is that version
>>>>>> specific, my image seems to work fine and it's running 353.63. There is one
>>>>>> thing that I do that may be helpful. I read it somewhere online and am not
>>>>>> actually sure if it does anything, but I've included it in my image
>>>>>> definitions just in case. Apparently there is something about initializing
>>>>>> the CUDA Toolkit. As part of my definition file I run 'make' on the CUDA
>>>>>> sample 'deviceQuery'. Maybe that will help?
>>>>>>
>>>>>> Best,
>>>>>> Nathan
>>>>>>
>>>>>> On Jul 31, 2016, at 1:51 PM, Igor Yakushin <igor...@gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>> Hi Nathan,
>>>>>> I got a little bit further: nvidia-smi is working now but tensorflow
>>>>>> still complains:
>>>>>> =========
>>>>>>
>>>>>> =========
>>>>>> Singularity/ubuntu_14.04.img> nvidia-smi
>>>>>> Sun Jul 31 17:33:44 2016
>>>>>> +------------------------------------------------------+
>>>>>>
>>>>>> | NVIDIA-SMI 352.55     Driver Version: 352.55         |
>>>>>>
>>>>>> |-------------------------------+----------------------+----------------------+
>>>>>>
>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile
>>>>>> Uncorr. ECC |
>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util
>>>>>>  Compute M. |
>>>>>> |===============================+======================+======================|
>>>>>>
>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>>>>>>                    0 |
>>>>>> | N/A   45C    P0    79W / 235W |    158MiB / 11519MiB |     45%
>>>>>>      Default |
>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>
>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>>>>>>                    0 |
>>>>>> | N/A   23C    P8    18W / 235W |     61MiB / 11519MiB |      0%
>>>>>>      Default |
>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>
>>>>>>
>>>>>>
>>>>>> +-----------------------------------------------------------------------------+
>>>>>>
>>>>>> | Processes:                                                       GPU
>>>>>> Memory |
>>>>>> |  GPU       PID  Type  Process name                               Usage
>>>>>>      |
>>>>>> |=============================================================================|
>>>>>>
>>>>>> +-----------------------------------------------------------------------------+
>>>>>>
>>>>>> Singularity/ubuntu_14.04.img> python
>>>>>> Python 2.7.6 (default, Mar 22 2014, 22:59:56)
>>>>>> [GCC 4.8.2] on linux2
>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>>>> information.
>>>>>> >>> import tensorflow
>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>> CUDA library libcublas.so locally
>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>> CUDA library libcudnn.so locally
>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>> CUDA library libcufft.so locally
>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>> CUDA library libcuda.so.1 locally
>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>>>>>> CUDA library libcurand.so locally
>>>>>> >>> ss = tensorflow.Session()
>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to
>>>>>> cuInit: CUDA_ERROR_NO_DEVICE
>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>> retrieving CUDA diagnostic information for host: midway-l34-02
>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname:
>>>>>> midway-l34-02
>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
>>>>>> reported version is: 352.93.0
>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver
>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module
>>>>>>  352.55  Thu Oct  8 15:18:00 PDT 2015
>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)
>>>>>> """
>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel
>>>>>> reported version is: 352.55.0
>>>>>> E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:296] kernel
>>>>>> version 352.55.0 does not match DSO version 352.93.0 -- cannot find working
>>>>>> devices in this configuration
>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices
>>>>>> available on machine.
>>>>>> >>>
>>>>>> =================
>>>>>> As far as I understand the problem is that cuda-7.5 was built or
>>>>>> relies on nvidia 352.93 while I have NVIDIA driver 352.55 both on the host
>>>>>> and container. So far I could not find cuda-7.5 built with 352.55.
>>>>>> cuda-7.5 has stabs directory in which there is libcuda.so. The
>>>>>> problem is probably coming from there. However, I doubt I can just replace
>>>>>> libcuda.so in the stubs directory by a different version or turn it into
>>>>>> symbolic link to a different version in the driver? Because its size is
>>>>>> much smaller than the size of the real libcuda.so in the driver. So I
>>>>>> suspect, it is really only some kind of interface to the real library?
>>>>>>
>>>>>> Thank you,
>>>>>> Igor
>>>>>>
>>>>>>
>>>>>> On Sun, Jul 31, 2016 at 9:36 AM, Igor Yakushin <igor...@gmail.com>
>>>>>> wrote:
>>>>>>
>>>>>>> Hi Nathan,
>>>>>>> When installing cuda libraries and tensorflow into the singularity
>>>>>>> image, is it important to be on the same host with the same version of
>>>>>>> CUDA/OS on which you are going to run later?
>>>>>>> I do not have root on the machine I am going to run later and
>>>>>>> prepare the image on a different machine with a different version of nvidia
>>>>>>> driver and a different flavor of Linux.
>>>>>>> Thank you,
>>>>>>> Igor
>>>>>>>
>>>>>>>
>>>>>>> On Sun, Jul 31, 2016 at 8:39 AM, Nathan Lin <nathan...@gmail.com
>>>>>>> > wrote:
>>>>>>>
>>>>>>>> Hi Igor,
>>>>>>>>
>>>>>>>> I don't necessarily have a great answer for you. If seems like you
>>>>>>>> are doing everything right, yet it is still not working. In my case, yes
>>>>>>>> nvidia-smi as well as TensorFlow both work correctly. I feel like your
>>>>>>>> error still has to do with the version of libcuda.so you are using. Notice
>>>>>>>> how Python seems to correctly load libcuda.so, yet there is later an error
>>>>>>>> that is unable to find libcuda.so. My first suspicion is that there is
>>>>>>>> still a version mismatch between the drivers installed on the image and on
>>>>>>>> the host. If you are sure that is not true, it may be possible that the
>>>>>>>> version of the driver that is installed on the machine isn't new enough for
>>>>>>>> the GPU. That actually occurred on our cluster, and after a sysadmin
>>>>>>>> updated the driver, it worked. Barring that I am not too sure. Maybe if you
>>>>>>>> provide me with the full details of your installation (the versions of the
>>>>>>>> packages that you have installed, the OS of your image and host), I might
>>>>>>>> be able to think about something, but my suspicion is that the driver
>>>>>>>> version on your host machine may not be new enough.
>>>>>>>>
>>>>>>>> Best,
>>>>>>>> Nathan
>>>>>>>>
>>>>>>>> On Jul 31, 2016, at 12:17 AM, Igor Yakushin <igor...@gmail.com>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>> Hi Nathan,
>>>>>>>>
>>>>>>>> I have found exactly the same version of NVIDIA driver and
>>>>>>>> extracted from it the libraries and nvidia executables and copied them in
>>>>>>>> /usr/lib64/nvidia and /usr/bin and created the corresponding symbolic
>>>>>>>> links. However, I still cannot use GPU inside singularity: nvidia-smi says
>>>>>>>> "GPU access blocked by the operating system" (does it work in your case?)
>>>>>>>> and when tensorflow session starts it also complains that "No GPU devices
>>>>>>>> available on machine". However, notice that tensorflow seems to think that
>>>>>>>> a different version of NVIDIA driver is used. Not sure where it is coming
>>>>>>>> from. The machine on which the image was built has version 361.42
>>>>>>>>
>>>>>>>> ============
>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>>>>>> information.
>>>>>>>> >>> import tensorflow
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened CUDA library libcublas.so locally
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened CUDA library libcudnn.so locally
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened CUDA library libcufft.so locally
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened CUDA library libcuda.so locally
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>> opened CUDA library libcurand.so locally
>>>>>>>> >>> ss = tensorflow.Session()
>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call
>>>>>>>> to cuInit: CUDA_ERROR_UNKNOWN
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>>>> retrieving CUDA diagnostic information for host: midway230
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>>>>>>>> hostname: midway230
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
>>>>>>>> reported version is: Not found: was unable to find libcuda.so DSO loaded
>>>>>>>> into this program
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver
>>>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module
>>>>>>>>  352.55  Thu Oct  8 15:18:00 PDT 2015
>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)
>>>>>>>> """
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel
>>>>>>>> reported version is: 352.55.0
>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU
>>>>>>>> devices available on machine.
>>>>>>>> >>>
>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>>>>>> Failed to initialize NVML: GPU access blocked by the operating
>>>>>>>> system
>>>>>>>> ===========
>>>>>>>>
>>>>>>>> Thank you,
>>>>>>>> Igor
>>>>>>>>
>>>>>>>>
>>>>>>>> On Thu, Jul 28, 2016 at 9:34 PM, Nathan Lin <
>>>>>>>> nathan...@gmail.com> wrote:
>>>>>>>>
>>>>>>>>> I am not sure how to find the correct driver version, but from my
>>>>>>>>> testing, the version must match exactly. I will admit that I have had
>>>>>>>>> problems finding specific versions of the driver from NVIDIA's website. I
>>>>>>>>> had to ask a sysadmin for the installer that they used. In order to extract
>>>>>>>>> the files, you need to use the --extract-only option. For instance, you
>>>>>>>>> will have to run something like ' sh /NVIDIA-Linux-x86_64-352.63.run
>>>>>>>>> --extract-only'/ . You will then be given a directory with all the
>>>>>>>>> libraries that would have been installed. You will need to copy the
>>>>>>>>> libcuda.so.###.## library (and you can copy any NVIDIA executables that you
>>>>>>>>> want such as nvidia-smi). Good luck!
>>>>>>>>>
>>>>>>>>> On Thu, Jul 28, 2016 at 8:51 PM, Igor <igor...@gmail.com> wrote:
>>>>>>>>>
>>>>>>>>>> I mean I am using this file from NVIDIA website
>>>>>>>>>> cuda_7.5.18_linux.run to install the driver, opengl, cuda. Driver
>>>>>>>>>> installation fails, cuda succeeds.
>>>>>>>>>> Also, when I run
>>>>>>>>>> sh cuda_7.5.18_linux.run
>>>>>>>>>> I am offered to install the driver version 352.39 while on the
>>>>>>>>>> host it is 346.47. I cannot upgrade the host. Any idea where I
>>>>>>>>>> can get 346.17?
>>>>>>>>>> I tried using the same link just substitute 18 for something else
>>>>>>>>>> but have not found the files:
>>>>>>>>>> wget http://developer.download.nvidia.com/compute/cuda/7.5/
>>>>>>>>>> Prod/local_installers/cuda_7.5.1X_linux.run
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:
>>>>>>>>>>>
>>>>>>>>>>> Hi Nathan,
>>>>>>>>>>> When I try to install the driver by running NVIDIA*.run script
>>>>>>>>>>> inside the image, it fails, probably because it tries to modify kernel that
>>>>>>>>>>> belongs to host?
>>>>>>>>>>> How do I extract just libcuda.so.345.67 without installing the
>>>>>>>>>>> driver (which is obviously problematic) and why would copying the library
>>>>>>>>>>> from the host would not work?
>>>>>>>>>>> Thank you,
>>>>>>>>>>> Igor
>>>>>>>>>>>
>>>>>>>>>>> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:
>>>>>>>>>>>>
>>>>>>>>>>>> Also if you are using the binary installation of TensorFlow you
>>>>>>>>>>>> need CUDA toolkit 7.5 and cuDNN v4. These only need to be installed on our
>>>>>>>>>>>> image. As I mentioned earlier you will need the libcuda.so.###.## library
>>>>>>>>>>>> on your image. It is very important that this is the same version of the
>>>>>>>>>>>> NVIDIA driver as you have on your nose (seemingly 346.67 for you). I
>>>>>>>>>>>> should've have also mentioned that you want the libcuda.so.345.67 library
>>>>>>>>>>>> that you get from extracting the NVIDIA installer. It will not work if you
>>>>>>>>>>>> try to copy the libcuda.so library that from you node.
>>>>>>>>>>>>
>>>>>>>>>>>> Let me know if you have any more questions.
>>>>>>>>>>>>
>>>>>>>>>>>> Best,
>>>>>>>>>>>> Nathan
>>>>>>>>>>>>
>>>>>>>>>>>> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com>
>>>>>>>>>>>> wrote:
>>>>>>>>>>>>
>>>>>>>>>>>>> Hello,
>>>>>>>>>>>>>
>>>>>>>>>>>>> Yes you are correct. The NVIDIA driver must be installed on
>>>>>>>>>>>>> your image as well. However, you honestly only need the libcuda.so.###.##
>>>>>>>>>>>>> library and the appropriate links for that library. Once you have those
>>>>>>>>>>>>> installed in your image, it should work.
>>>>>>>>>>>>>
>>>>>>>>>>>>> Best,
>>>>>>>>>>>>> Nathan
>>>>>>>>>>>>>
>>>>>>>>>>>>> On Thursday, July 28, 2016, Igor <igor...@gmail.com> wrote:
>>>>>>>>>>>>>
>>>>>>>>>>>>>> Hi All,
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> I am trying to use GPU-enabled tensorflow and it cannot find
>>>>>>>>>>>>>> GPU card from inside the container.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> On the host:
>>>>>>>>>>>>>> $ lspci | grep -i nvidia
>>>>>>>>>>>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla
>>>>>>>>>>>>>> K40m] (rev a1)
>>>>>>>>>>>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla
>>>>>>>>>>>>>> K40m] (rev a1)
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> $ nvidia-smi
>>>>>>>>>>>>>> Thu Jul 28 19:01:42 2016
>>>>>>>>>>>>>> +------------------------------------------------------+
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47         |
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> |-------------------------------+----------------------+----------------------+
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A |
>>>>>>>>>>>>>> Volatile Uncorr. ECC |
>>>>>>>>>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage |
>>>>>>>>>>>>>> GPU-Util  Compute M. |
>>>>>>>>>>>>>> |===============================+======================+======================|
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>>>>>>>>>>>>>>                    0 |
>>>>>>>>>>>>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB |
>>>>>>>>>>>>>>      0%      Default |
>>>>>>>>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>>>>>>>>>>>>>>                    0 |
>>>>>>>>>>>>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB |
>>>>>>>>>>>>>>      0%      Default |
>>>>>>>>>>>>>> +-------------------------------+----------------------+----------------------+
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> +-----------------------------------------------------------------------------+
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> | Processes:                                                       GPU
>>>>>>>>>>>>>> Memory |
>>>>>>>>>>>>>> |  GPU       PID  Type  Process name
>>>>>>>>>>>>>>                               Usage      |
>>>>>>>>>>>>>> |=============================================================================|
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> |    0     11671    G   /usr/bin/X
>>>>>>>>>>>>>>                                       9MiB |
>>>>>>>>>>>>>> |    1     11671    G   /usr/bin/X
>>>>>>>>>>>>>>                                       3MiB |
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Inside singularity:
>>>>>>>>>>>>>> $ singularity shell /software/src/singularity_
>>>>>>>>>>>>>> images/tensorflow_0.9.img
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia
>>>>>>>>>>>>>> bash: lspci: command not found
>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>>>>>>>>>>>>>> bash: nvidia-smi: command not found
>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> python
>>>>>>>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>>>>>>>>>>>>>> [GCC 5.4.0 20160609] on linux2
>>>>>>>>>>>>>> Type "help", "copyright", "credits" or "license" for more
>>>>>>>>>>>>>> information.
>>>>>>>>>>>>>> >>> import tensorflow as tf
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>>> opened CUDA library libcublas.so locally
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>>> opened CUDA library libcudnn.so locally
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>>> opened CUDA library libcufft.so locally
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>>> opened CUDA library libcuda.so locally
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>>>>>>>>>>>>>> opened CUDA library libcurand.so locally
>>>>>>>>>>>>>> >>> sess = tf.Session()
>>>>>>>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed
>>>>>>>>>>>>>> call to cuInit: CUDA_ERROR_UNKNOWN
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>>>>>>>>>>>>>> retrieving CUDA diagnostic information for host: midway-l34-01
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>>>>>>>>>>>>>> hostname: midway-l34-01
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185]
>>>>>>>>>>>>>> libcuda reported version is: Not found: was unable to find libcuda.so DSO
>>>>>>>>>>>>>> loaded into this program
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347]
>>>>>>>>>>>>>> driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel
>>>>>>>>>>>>>> Module  346.47  Thu Feb 19 18:56:03 PST 2015
>>>>>>>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-11)
>>>>>>>>>>>>>> (GCC)
>>>>>>>>>>>>>> """
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189]
>>>>>>>>>>>>>> kernel reported version is: 346.47.0
>>>>>>>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU
>>>>>>>>>>>>>> devices available on machine.
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Must there be nvidia driver installed inside the container?
>>>>>>>>>>>>>> Outside? The container shares the same kernel with the host and nvidia
>>>>>>>>>>>>>> kernel module needs to be loaded... How this is handled? Any requirements
>>>>>>>>>>>>>> on nvidia driver and cuda versions inside and outside of the container?
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> Thank you,
>>>>>>>>>>>>>> Igor
>>>>>>>>>>>>>>
>>>>>>>>>>>>>>
>>>>>>>>>>>>>> --
>>>>>>>>>>>>>> You received this message because you are subscribed to the
>>>>>>>>>>>>>> Google Groups "singularity" group.
>>>>>>>>>>>>>> To unsubscribe from this group and stop receiving emails from
>>>>>>>>>>>>>> it, send an email to singu...@lbl.gov.
>>>>>>>>>>>>>>
>>>>>>>>>>>>> --
>>>>>>>>>> You received this message because you are subscribed to the
>>>>>>>>>> Google Groups "singularity" group.
>>>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>>>
>>>>>>>>>
>>>>>>>>> --
>>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>>> Groups "singularity" group.
>>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>> Groups "singularity" group.
>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>
>>>>>>>> --
>>>>>>>> You received this message because you are subscribed to the Google
>>>>>>>> Groups "singularity" group.
>>>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>>>> send an email to singu...@lbl.gov.
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>> --
>>>>>> You received this message because you are subscribed to the Google
>>>>>> Groups "singularity" group.
>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>> send an email to singu...@lbl.gov.
>>>>>>
>>>>>> --
>>>>>> You received this message because you are subscribed to the Google
>>>>>> Groups "singularity" group.
>>>>>> To unsubscribe from this group and stop receiving emails from it,
>>>>>> send an email to singu...@lbl.gov.
>>>>>>
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>> --
>> You received this message because you are subscribed to the Google Groups
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to singu...@lbl.gov.
>>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a113edee4ec7fa7053943c2f1
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div>Hi Bernard,</div><div><br></div><div>Here is the cont=
ainer:</div><a href=3D"https://uchicago.box.com/s/g2dwl6s8awvk96bku5ebifhyi=
396qd7u">https://uchicago.box.com/s/g2dwl6s8awvk96bku5ebifhyi396qd7u</a><br=
><div>It supports several driver versions.</div><div>Once you get into sing=
ularity shell, set the environment as follows:</div><div>source /usr/local/=
nvidia.sh=C2=A0352.39</div><div>After that nvidia-smi should work and you c=
an start python and do something like:</div><div><br></div><div>import tens=
orflow as tf</div><div>s =3D tf.Session()</div><div><br></div><div>It shoul=
d detect your card.</div><div><br></div><div>Let me know if it works on you=
r cluster. So far I tested it on my laptop and on a few cluster nodes with =
Tesla K40m with different driver versions.</div><div>Thank you,</div><div>I=
gor</div><div><br></div></div><div class=3D"gmail_extra"><br><div class=3D"=
gmail_quote">On Mon, Aug 1, 2016 at 11:55 PM, Bernard Li <span dir=3D"ltr">=
&lt;<a href=3D"mailto:ber...@vanhpc.org" target=3D"_blank">ber...@vanhpc.or=
g</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margi=
n:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Hey Igor:<div><br=
></div><div>If you can make the tensorflow Singularity container available,=
 I&#39;d like to try that out on our cluster.</div><div><br></div><div>Than=
ks,</div><div><br></div><div>Bernard<div><div class=3D"h5"><br><br>On Monda=
y, 1 August 2016, Igor Yakushin &lt;<a href=3D"mailto:igor...@gmail.com" ta=
rget=3D"_blank">igor...@gmail.com</a>&gt; wrote:<br><blockquote class=3D"gm=
ail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-le=
ft:1ex"><div dir=3D"ltr">Hi Nathan,<div>The main problem was that if you tr=
y to install cuda, it would by default install driver as well that might be=
 of different version than the driver installed with NVIDIA*.run file. So w=
hen installing cuda, use an option not to install the driver. It is much ea=
sier to find NVIDIA*.run file of the version you need than cuda*.run with t=
he right driver.=C2=A0 When downloading NVIDIA*.run, pay attention that you=
 are asking for Tesla card (if that&#39;s what you have). Consumer cards ha=
ve different driver (I do not remember if it is reflected in the file name =
but I suspect not, because I made this mistake).</div><div>Thank you,</div>=
<div>Igor</div><div><br></div></div><div class=3D"gmail_extra"><br><div cla=
ss=3D"gmail_quote">On Mon, Aug 1, 2016 at 8:56 AM, Nathan Lin <span dir=3D"=
ltr">&lt;<a>nathan...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=
=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padd=
ing-left:1ex"><div dir=3D"ltr">That&#39;s great to hear Igor! What ended up=
 being the problem?</div><div><div><div class=3D"gmail_extra"><br><div clas=
s=3D"gmail_quote">On Mon, Aug 1, 2016 at 1:43 AM, Rick Wagner <span dir=3D"=
ltr">&lt;<a>richard...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=
=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padd=
ing-left:1ex"><div dir=3D"auto"><div></div><div>Igor,</div><div><br></div><=
div>If you had a chance to post your definition file or the steps you took,=
 I know several of us would appreciate it. Getting TensorFlow running on Ce=
ntOS was a huge effort for our support staff. And that&#39;s just one of ma=
ny GPU-enabled applications.</div><span><font color=3D"#888888"><div><br></=
div><div>--Rick</div></font></span><div><div><div><br>On Jul 31, 2016, at 1=
0:20 PM, Igor Yakushin &lt;<a>igor...@gmail.com</a>&gt; wrote:<br><br></div=
><blockquote type=3D"cite"><div><div dir=3D"ltr">Thank you, Nathan. It fina=
lly works!</div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">O=
n Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin <span dir=3D"ltr">&lt;<a>nathan.=
..@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" sty=
le=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div d=
ir=3D"auto"><div></div><div>Yes I do</div><div><div><div><br>On Jul 31, 201=
6, at 5:03 PM, Igor Yakushin &lt;<a>igor...@gmail.com</a>&gt; wrote:<br><br=
></div><blockquote type=3D"cite"><div><div dir=3D"ltr">Nathan,<div>When you=
 import tensorflow in python, does it tell you what cuda libraries it is lo=
ading or not?</div><div>Do you see these messages:</div><div>=3D=3D=3D=3D=
=3D=3D</div><div><div>&gt;&gt;&gt; import tensorflow as tf=C2=A0</div><div>=
I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opened CU=
DA library libcublas.so locally=C2=A0</div><div>I tensorflow/stream_executo=
r/<wbr>dso_loader.cc:108] successfully opened CUDA library libcudnn.so loca=
lly=C2=A0</div><div>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] su=
ccessfully opened CUDA library libcufft.so locally=C2=A0</div><div>I tensor=
flow/stream_executor/<wbr>dso_loader.cc:108] successfully opened CUDA libra=
ry libcuda.so locally=C2=A0</div><div>I tensorflow/stream_executor/<wbr>dso=
_loader.cc:108] successfully opened CUDA library libcurand.so locally=C2=A0=
</div></div><div>=3D=3D=3D=3D=3D=3D</div><div>Thank you,</div><div>Igor</di=
v></div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, J=
ul 31, 2016 at 1:26 PM, Nathan Lin <span dir=3D"ltr">&lt;<a>nathan...@gmail=
.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"ma=
rgin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"au=
to"><div></div><div>Hi Igor,</div><div><br></div><div>In regards to your fi=
rst questions, the OS/drivers of your building computer should not matter. =
I built an Ubuntu 14.04 image on my RHEL 7 box for our RHEL 6 cluster. I&#3=
9;m not sure that the toolkit is that version specific, my image seems to w=
ork fine and it&#39;s running 353.63. There is one thing that I do that may=
 be helpful. I read it somewhere online and am not actually sure if it does=
 anything, but I&#39;ve included it in my image definitions just in case. A=
pparently there is something about initializing the CUDA Toolkit. As part o=
f my definition file I run &#39;make&#39; on the CUDA sample &#39;deviceQue=
ry&#39;. Maybe that will help?</div><div><br></div><div>Best,</div><div>Nat=
han</div><div><div><div><br>On Jul 31, 2016, at 1:51 PM, Igor Yakushin &lt;=
<a>igor...@gmail.com</a>&gt; wrote:<br><br></div><blockquote type=3D"cite">=
<div><div dir=3D"ltr">Hi Nathan,<div>I got a little bit further: nvidia-smi=
 is working now but tensorflow still complains:</div><div>=3D=3D=3D=3D=3D=
=3D=3D=3D=3D</div><div><br></div><div>=3D=3D=3D=3D=3D=3D=3D=3D=3D</div><div=
><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">Sin=
gularity/ubuntu_14.04.img&gt; nvidia-smi
</span><br>Sun Jul 31 17:33:44 2016 =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0<br>+-----------------------------<wbr>-------------------------+ =C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>| NVIDIA-SMI 3=
52.55 =C2=A0=C2=A0=C2=A0=C2=A0Driver Version: 352.55 =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0| =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0<br>|-----------------------------<wbr>--+---------------=
-------+----<wbr>------------------+
<br>| GPU =C2=A0Name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Persistence-=
M| Bus-Id =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan =C2=A0Temp =C2=A0Perf =C2=A0Pwr:Usage/Cap| =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0Memory-Usage | GPU-Util =C2=A0Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A00 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:20:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A045C =C2=A0=C2=A0=C2=A0P0 =C2=A0=C2=A0=C2=A079W / 235W=
 | =C2=A0=C2=A0=C2=A0158MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A045% =C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br>| =C2=A0=C2=A01 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:8B:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A023C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A018W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A061MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br> =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wb=
r>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>+----------------------------=
-<wbr>------------------------------<wbr>------------------+
<br>| Processes: =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0GPU Memory |
<br>| =C2=A0GPU =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0PID =C2=A0Type =C2=A0Pr=
ocess name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>Usage =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D|
<br>+-----------------------------<wbr>------------------------------<wbr>-=
-----------------+
<br>Singularity/ubuntu_14.04.img&gt; python
<br>Python 2.7.6 (default, Mar 22 2014, 22:59:56) =C2=A0<br>[GCC 4.8.2] on =
linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcuda.so.1 locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally
<br>&gt;&gt;&gt; ss =3D tensorflow.Session()
<br>E tensorflow/stream_executor/<wbr>cuda/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_NO_DEVICE
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway-l34-02
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:160] hostnam=
e: midway-l34-02
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:185] libcuda=
 reported version is: 352.93.0
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:356] driver =
version file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 K=
ernel Module =C2=A0352.55 =C2=A0Thu Oct =C2=A08 15:18:00 PDT 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:189] kernel =
reported version is: 352.55.0
<br>E tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:296] kernel =
version 352.55.0 does not match DSO version 352.93.0 -- cannot find working=
 devices in this configuration
<br>I tensorflow/core/common_<wbr>runtime/gpu/gpu_init.cc:81] No GPU device=
s available on machine.
<br>&gt;&gt;&gt; <br>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span></div><div><span =
style=3D"font-family:monospace">As far as I understand the problem is that =
cuda-7.5 was built or relies on nvidia 352.93 while I have NVIDIA driver 35=
2.55 both on the host and container. So far I could not find cuda-7.5 built=
 with 352.55.</span></div><div><span style=3D"font-family:monospace">cuda-7=
.5 has stabs directory in which there is libcuda.so. The problem is probabl=
y coming from there. However, I doubt I can just replace libcuda.so in the =
stubs directory by a different version or turn it into symbolic link to a d=
ifferent version in the driver? Because its size is much smaller than the s=
ize of the real libcuda.so in the driver. So I suspect, it is really only s=
ome kind of interface to the real library?</span></div><div><span style=3D"=
font-family:monospace"><br></span></div><div><span style=3D"font-family:mon=
ospace">Thank you,</span></div><div><span style=3D"font-family:monospace">I=
gor</span></div><div><span style=3D"font-family:monospace"><br></span></div=
></div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, Ju=
l 31, 2016 at 9:36 AM, Igor Yakushin <span dir=3D"ltr">&lt;<a>igor...@gmail=
.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"ma=
rgin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"lt=
r">Hi Nathan,<div>When installing cuda libraries and tensorflow into the si=
ngularity image, is it important to be on the same host with the same versi=
on of CUDA/OS on which you are going to run later?</div><div>I do not have =
root on the machine I am going to run later and prepare the image on a diff=
erent machine with a different version of nvidia driver and a different fla=
vor of Linux.</div><div>Thank you,</div><div>Igor</div><div><br></div></div=
><div><div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun=
, Jul 31, 2016 at 8:39 AM, Nathan Lin <span dir=3D"ltr">&lt;<a>nathan...@gm=
ail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D=
"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D=
"auto"><div></div><div>Hi Igor,</div><div><br></div><div>I don&#39;t necess=
arily have a great answer for you. If seems like you are doing everything r=
ight, yet it is still not working. In my case, yes nvidia-smi as well as Te=
nsorFlow both work correctly. I feel like your error still has to do with t=
he version of libcuda.so you are using. Notice how Python seems to correctl=
y load libcuda.so, yet there is later an error that is unable to find libcu=
da.so. My first suspicion is that there is still a version mismatch between=
 the drivers installed on the image and on the host. If you are sure that i=
s not true, it may be possible that the version of the driver that is insta=
lled on the machine isn&#39;t new enough for the GPU. That actually occurre=
d on our cluster, and after a sysadmin updated the driver, it worked. Barri=
ng that I am not too sure. Maybe if you provide me with the full details of=
 your installation (the versions of the packages that you have installed, t=
he OS of your image and host), I might be able to think about something, bu=
t my suspicion is that the driver version on your host machine may not be n=
ew enough.=C2=A0</div><div><br></div><div>Best,</div><div>Nathan=C2=A0</div=
><div><div><div><br>On Jul 31, 2016, at 12:17 AM, Igor Yakushin &lt;<a>igor=
...@gmail.com</a>&gt; wrote:<br><br></div><blockquote type=3D"cite"><div><d=
iv dir=3D"ltr"><div><span style=3D"font-family:monospace"><span style=3D"co=
lor:rgb(0,0,0)">Hi Nathan,</span></span></div><div><span style=3D"font-fami=
ly:monospace"><span style=3D"color:rgb(0,0,0)"><br></span></span></div><div=
><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">I h=
ave found exactly the same version of NVIDIA driver and extracted from it t=
he libraries and nvidia executables and copied them in /usr/lib64/nvidia an=
d /usr/bin and created the corresponding symbolic links. However, I still c=
annot use GPU inside singularity: nvidia-smi says &quot;GPU access blocked =
by the operating system&quot; (does it work in your case?) and when tensorf=
low session starts it also complains that &quot;No GPU devices available on=
 machine&quot;. However, notice that tensorflow seems to think that a diffe=
rent version of NVIDIA driver is used. Not sure where it is coming from. Th=
e machine on which the image was built has version=C2=A0</span></span><span=
 style=3D"color:rgb(0,0,0);font-family:monospace">361.42</span></div><span =
style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)"><div><span=
 style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)"><br></spa=
n></span></div><div><span style=3D"font-family:monospace"><span style=3D"co=
lor:rgb(0,0,0)">=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span></span></div>Pyt=
hon 2.7.12 (default, Jul =C2=A01 2016, 15:12:24) =C2=A0</span><br>[GCC 5.4.=
0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcuda.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally
<br>&gt;&gt;&gt; ss =3D tensorflow.Session()
<br>E tensorflow/stream_executor/<wbr>cuda/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway230
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:160] hostnam=
e: midway230
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:185] libcuda=
 reported version is: Not found: was unable to find libcuda.so DSO loaded i=
nto this program
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:347] driver =
version file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 K=
ernel Module =C2=A0352.55 =C2=A0Thu Oct =C2=A08 15:18:00 PDT 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:189] kernel =
reported version is: 352.55.0
<br>I tensorflow/core/common_<wbr>runtime/gpu/gpu_init.cc:81] No GPU device=
s available on machine.
<br>&gt;&gt;&gt; =C2=A0<br>Singularity/tensorflow_0.9.<wbr>img&gt; nvidia-s=
mi
<br>Failed to initialize NVML: GPU access blocked by the operating system<b=
r>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span><div><span style=3D"font-family:mon=
ospace"><br></span></div><div><span style=3D"font-family:monospace">Thank y=
ou,</span></div><div><span style=3D"font-family:monospace">Igor</span></div=
><div><span style=3D"font-family:monospace"><br></span></div></div><div cla=
ss=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Jul 28, 2016 at 9=
:34 PM, Nathan Lin <span dir=3D"ltr">&lt;<a>nathan...@gmail.com</a>&gt;</sp=
an> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;=
border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">I am no<font =
face=3D"arial, helvetica, sans-serif">t sure how to find the correct driver=
 version, but from my testing, the version must match exactly. I will admit=
 that I have had problems finding specific versions of the driver from NVID=
IA&#39;s website. I had to ask a sysadmin for the installer that they used.=
 In order to extract the files, you need to use the --extract-only option. =
For instance, you will have to run something like &#39;

















sh /NVIDIA-Linux-x86_64-352.63.<wbr>run
--extract-only&#39;/ . You will then be given a directory with all the libr=
aries that would have been installed. You will need to copy the libcuda.so.=
###.## library (and you can copy any NVIDIA executables that you want such =
as nvidia-smi). Good luck!</font></div><div><div><div class=3D"gmail_extra"=
><br><div class=3D"gmail_quote">On Thu, Jul 28, 2016 at 8:51 PM, Igor <span=
 dir=3D"ltr">&lt;<a>igor...@gmail.com</a>&gt;</span> wrote:<br><blockquote =
class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid=
;padding-left:1ex"><div dir=3D"ltr"><span style=3D"font-family:monospace"><=
span style=3D"color:rgb(0,0,0)">I mean I am using this file from NVIDIA web=
site cuda_7.5.18_linux.run to install the driver, opengl, cuda. Driver inst=
allation fails, cuda succeeds.=C2=A0</span></span><div><span style=3D"font-=
family:monospace"><font color=3D"#000000">Also, when I run=C2=A0</font></sp=
an></div><div><span style=3D"font-family:monospace"><font color=3D"#000000"=
>sh=C2=A0</font></span><font color=3D"#000000" face=3D"monospace">cuda_7.5.=
18_linux.run</font></div><div><span style=3D"font-family:monospace"><font c=
olor=3D"#000000">I am offered to install the driver version=C2=A0</font></s=
pan><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">=
352.39 while on the host it is=C2=A0</span></span><span style=3D"font-famil=
y:monospace"><span style=3D"color:rgb(0,0,0)">346.47. I cannot upgrade the =
host. Any idea where I can get 346.17?</span></span></div><div><span style=
=3D"font-family:monospace"><font color=3D"#000000">I tried using the same l=
ink just substitute 18 for something else but have not found the files:</fo=
nt></span></div><div><span style=3D"font-family:monospace"><span style=3D"c=
olor:rgb(0,0,0)">wget <a href=3D"http://developer.download.nvidia.com/compu=
te/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run" target=3D"_blank">=
http://developer.download.<wbr>nvidia.com/compute/cuda/7.5/<wbr>Prod/local_=
installers/cuda_7.<wbr>5.1X_linux.run</a></span><br></span><br></div><div><=
div><div><br></div><div><br></div><div>On Thursday, July 28, 2016 at 7:34:5=
5 PM UTC-5, Igor wrote:<blockquote class=3D"gmail_quote" style=3D"margin:0;=
margin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"=
ltr">Hi Nathan,<div>When I try to install the driver by running NVIDIA*.run=
 script inside the image, it fails, probably because it tries to modify ker=
nel that belongs to host?</div><div>How do I extract just libcuda.so.345.67=
 without installing the driver (which is obviously problematic) and why wou=
ld copying the library from the host would not work?</div><div>Thank you,</=
div><div>Igor<br><br>On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan=
 Lin wrote:<blockquote class=3D"gmail_quote" style=3D"margin:0;margin-left:=
0.8ex;border-left:1px #ccc solid;padding-left:1ex">Also if you are using th=
e binary installation of TensorFlow you need CUDA toolkit 7.5 and cuDNN v4.=
 These only need to be installed on our image. As I mentioned earlier you w=
ill need the libcuda.so.###.## library on your image. It is very important =
that this is the same version of the NVIDIA driver as you have on your nose=
 (seemingly 346.67 for you). I should&#39;ve have also mentioned that you w=
ant the libcuda.so.345.67 library that you get from extracting the NVIDIA i=
nstaller. It will not work if you try to copy=C2=A0the libcuda.so library t=
hat from you node.=C2=A0<div><br></div><div>Let me know if you have any mor=
e questions.=C2=A0</div><div><br></div><div>Best,</div><div>Nathan<span></s=
pan><br><br>On Thursday, July 28, 2016, Nathan Lin &lt;<a rel=3D"nofollow">=
nat...@gmail.com</a>&gt; wrote:<br><blockquote class=3D"gmail_quote" style=
=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex">Hello,<d=
iv><br></div><div>Yes you are correct. The NVIDIA driver must be installed =
on your image as well. However, you honestly only need the libcuda.so.###.#=
# library and the appropriate links for that library. Once you have those i=
nstalled in your image, it should work.=C2=A0</div><div><br></div><div>Best=
,</div><div>Nathan=C2=A0<span></span><br><br>On Thursday, July 28, 2016, Ig=
or &lt;<a>igor...@gmail.com</a>&gt; wrote:<br><blockquote class=3D"gmail_qu=
ote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex=
"><div dir=3D"ltr">Hi All,<div><br><div>I am trying to use GPU-enabled tens=
orflow and it cannot find GPU card from inside the container.</div><div><br=
></div><div>On the host:</div><div><span style=3D"font-family:monospace"><s=
pan style=3D"color:rgb(0,0,0)">$ lspci | grep -i nvidia
</span><br>20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] =
(rev a1)
<br>8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1=
)<br>
<br></span></div><div><span style=3D"font-family:monospace"><span style=3D"=
color:rgb(0,0,0)">$ nvidia-smi
</span><br>Thu Jul 28 19:01:42 2016 =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0<br>+-----------------------------<wbr>-------------------------+ =C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>| NVIDIA-SMI 3=
46.47 =C2=A0=C2=A0=C2=A0=C2=A0Driver Version: 346.47 =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0| =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0<br>|-----------------------------<wbr>--+---------------=
-------+----<wbr>------------------+
<br>| GPU =C2=A0Name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Persistence-=
M| Bus-Id =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan =C2=A0Temp =C2=A0Perf =C2=A0Pwr:Usage/Cap| =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0Memory-Usage | GPU-Util =C2=A0Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A00 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:20:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A030C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A020W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A066MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br>| =C2=A0=C2=A01 =C2=A0Tesla K40m =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0Off =C2=A0| 0000:8B:00.0 =C2=A0=C2=A0=C2=A0=C2=A0Off | =
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A00 |
<br>| N/A =C2=A0=C2=A026C =C2=A0=C2=A0=C2=A0P8 =C2=A0=C2=A0=C2=A019W / 235W=
 | =C2=A0=C2=A0=C2=A0=C2=A060MiB / 11519MiB | =C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A00% =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0Default |
<br>+-----------------------------<wbr>--+----------------------+----<wbr>-=
-----------------+
<br> =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wb=
r>=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<br>+----------------------------=
-<wbr>------------------------------<wbr>------------------+
<br>| Processes: =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0GPU Memory |
<br>| =C2=A0GPU =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0PID =C2=A0Type =C2=A0Pr=
ocess name =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>Usage =C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D<wbr>=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D|
<br>| =C2=A0=C2=A0=C2=A00 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A09MiB |
<br>| =C2=A0=C2=A0=C2=A01 =C2=A0=C2=A0=C2=A0=C2=A011671 =C2=A0=C2=A0=C2=A0G=
 =C2=A0=C2=A0/usr/bin/X =C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0<wbr>=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A03MiB |<br>
<br></span></div></div><div><font face=3D"monospace"><br></font></div><div>=
<font face=3D"monospace">Inside singularity:</font></div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ singularity s=
hell /software/src/singularity_<wbr>images/tensorflow_0.9.img</span><br></s=
pan></div><div><span style=3D"font-family:monospace"><span style=3D"color:r=
gb(0,0,0)"><br></span></span></div><div><span style=3D"font-family:monospac=
e"><span style=3D"color:rgb(0,0,0)">Singularity/tensorflow_0.9.<wbr>img&gt;=
 lspci | grep -i nvidia
</span><br>bash: lspci: command not found
<br>Singularity/tensorflow_0.9.<wbr>img&gt; nvidia-smi
<br>bash: nvidia-smi: command not found
<br>Singularity/tensorflow_0.9.<wbr>img&gt; python
<br>Python 2.7.12 (default, Jul =C2=A01 2016, 15:12:24) =C2=A0<br>[GCC 5.4.=
0 20160609] on linux2
<br>Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &q=
uot;license&quot; for more information.
<br>&gt;&gt;&gt; import tensorflow as tf
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcuda.so locally
<br>I tensorflow/stream_executor/<wbr>dso_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally
<br>&gt;&gt;&gt; sess =3D tf.Session()
<br>E tensorflow/stream_executor/<wbr>cuda/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway-l34-01
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:160] hostnam=
e: midway-l34-01
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:185] libcuda=
 reported version is: Not found: was unable to find libcuda.so DSO loaded i=
nto this program
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:347] driver =
version file contents: &quot;&quot;&quot;NVRM version: NVIDIA UNIX x86_64 K=
ernel Module =C2=A0346.47 =C2=A0Thu Feb 19 18:56:03 PST 2015
<br>GCC version: =C2=A0gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) =
=C2=A0<br>&quot;&quot;&quot;
<br>I tensorflow/stream_executor/<wbr>cuda/cuda_diagnostics.cc:189] kernel =
reported version is: 346.47.0
<br>I tensorflow/core/common_<wbr>runtime/gpu/gpu_init.cc:81] No GPU device=
s available on machine.<br>
<br></span></div><div><span style=3D"font-family:monospace">Must there be n=
vidia driver installed inside the container? Outside? The container shares =
the same kernel with the host and nvidia kernel module needs to be loaded..=
. How this is handled? Any requirements on nvidia driver and cuda versions =
inside and outside of the container?</span></div><div><span style=3D"font-f=
amily:monospace"><br></span></div><div><span style=3D"font-family:monospace=
">Thank you,</span></div><div><span style=3D"font-family:monospace">Igor</s=
pan></div><div><span style=3D"font-family:monospace"><br></span></div><div>=
<font face=3D"monospace"><br></font></div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</blockquote></div>
</blockquote></div>
</blockquote></div></div></blockquote></div></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
</blockquote></div></div></div><div class=3D"HOEnZb"><div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br></div>

--001a113edee4ec7fa7053943c2f1--

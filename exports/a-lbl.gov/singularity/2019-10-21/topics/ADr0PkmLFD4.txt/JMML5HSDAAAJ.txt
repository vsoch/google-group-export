X-Received: by 2002:a17:902:1126:: with SMTP id d35mr2103908pla.8.1551467438930;
        Fri, 01 Mar 2019 11:10:38 -0800 (PST)
X-BeenThere: singularity@lbl.gov
Received: by 2002:a17:902:5c1:: with SMTP id f59ls4794064plf.1.gmail; Fri, 01
 Mar 2019 11:10:37 -0800 (PST)
X-Received: by 2002:a17:902:44c:: with SMTP id 70mr7119135ple.318.1551467437705;
        Fri, 01 Mar 2019 11:10:37 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1551467437; cv=none;
        d=google.com; s=arc-20160816;
        b=uaglbwGAcAnsP8YkG5gnisfiWonIgCi+a4MNpbslqPKU2v5m344nMbcrIXv4Rt/S3T
         /HY2ETBbbcm4vTOqoDx1098mBFm5ZdY70um/gLIO0fw6xpkBjrLon2mOF9SOwCjQJMB8
         7PUDhescitL2kBkspmExbAUJwp5KiClcFADfR/lUanhoZcZx+v5AG86Pt66wa9po5POe
         XdOH9M9WNHpGD029mHguPQoQHMF6CQwENmhp5gISa+zzcvLzQJ8Cq3s3Ic8d314EUWfa
         GbhXkWJmNpm1oro3oqE6i+zFQOUEe8492ofr+91GImPeG2Amzbnp83jlzdWwvkmEG2k9
         h/Mg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:in-reply-to:references:mime-version
         :dkim-signature;
        bh=uZYT1jdWw3FGMec+u9kCD5noqRWZZ7skMi0HeUvxdsw=;
        b=IE48kJ0GesLlZW1+0k2H3g0nFUeYAZpydHJ5TxIgFUJ7wwerREmioAIDyQUUaWPqmi
         tl77zMmpk0AV+ovFWWdPbt3Zrl+LxW5qzumao/KjEJ2ckJbda6TCsXb883PZreKxItX2
         DSurdeRzvdZhV3ccjJDjnXeSlJecciJjksUll0C236gcc267OU7tPXzj/cn1GvQ9pHqV
         C7ifXB25dskY49ct0vZ3wko2VMJglWZNX7Khdu+EV1IhfBZ2vXXfsnsNA9wS3wFRteq6
         E54vrAhOSaTGEO9SWfjuEpto6/+vvXLOM5JXCdb26DalB71Jhd3Jlw1cUbodLsSEAuHh
         Qm8w==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=tIfAXqKN;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.166.43 as permitted sender) smtp.mailfrom=vso...@gmail.com
Return-Path: <vso...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [131.243.228.53])
        by mx.google.com with ESMTP id m2si21587282pfj.111.2019.03.01.11.10.37
        for <singu...@lbl.gov>;
        Fri, 01 Mar 2019 11:10:37 -0800 (PST)
Received-SPF: pass (google.com: domain of vso...@gmail.com designates 209.85.166.43 as permitted sender) client-ip=209.85.166.43;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=tIfAXqKN;
       spf=pass (google.com: domain of vso...@gmail.com designates 209.85.166.43 as permitted sender) smtp.mailfrom=vso...@gmail.com
X-Ironport-SBRS: 2.8
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2FEAwC/gnlcgCumVdFhA4IXgVYFgRJQM?=
 =?us-ascii?q?yeEAQeBHYJej2mCDZIuhXIUgSs8JQEKC4FJgT6BNwKEIiI0CQ0BAwEBAwEDAgE?=
 =?us-ascii?q?BAhABAQkNCQgnJQyCOgUCAx8HCgRNOwMBAQEBAQEBAQEkAQEBAQEBAQEBAQEBA?=
 =?us-ascii?q?QEBGgINIEMBAQEDASMEGQENDh4DAQsGBQsNKgICIQEBDgMBBQELEQ4HBAEaAgS?=
 =?us-ascii?q?DAiYBgTUBAw0IBQqfaDyJXRqBJnwWBQEXgnkFgTEBgwsKGScNX4E3AgEFEow5F?=
 =?us-ascii?q?4F/g3Uugx4CAoEsARIBCQI1DBqCQ4I1IgKKDTJUhlKRYjMJh0ODdYc3GZMhjyu?=
 =?us-ascii?q?BD4xdMIEmbjBxcBVsgjsJgW8wFxODOIpxJDABD41uDhcwgXcBAQ?=
X-IronPort-AV: E=Sophos;i="5.58,428,1544515200"; 
   d="scan'208,217";a="53348865"
Received: from mail-io1-f43.google.com ([209.85.166.43])
  by fe4.lbl.gov with ESMTP; 01 Mar 2019 11:06:43 -0800
Received: by mail-io1-f43.google.com with SMTP id y6so20411587ioq.10
        for <singu...@lbl.gov>; Fri, 01 Mar 2019 11:06:43 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to;
        bh=uZYT1jdWw3FGMec+u9kCD5noqRWZZ7skMi0HeUvxdsw=;
        b=tIfAXqKN4eQyM477asDesyfzxTcgVa39AE5cL5+bzPN94rEKe1wpq/ruKwymfkVydR
         m7whuhhPkgh729t/G5oAGzC+JBwGXWzVwLywekfDgt052DvPz6Lg8qa7Orx1eMVwLEp7
         5D90G7X3rGf9THoLtI/ndLXjIXZAPKevFaU6Z31qc6qt8q8grNbBdjy5JSAn6K+sN+cS
         uKkWpUpYEH44Ij3Sr0NenVf5ML21nXCqQ3A1tXsloVIuV37PAhKEPA4FOGZKYJvN5KhO
         1pYWfdQFQ0E2RYhlXQEhpQwzTt+Eh3K5Ewb453W6Q1sXOBuao5tYOC1qTRCqgte4OnUW
         2Xxg==
X-Gm-Message-State: APjAAAUXJGkxKJ0Vp2a/w8azLce0WbMbQL2jo+4RibfgsyrkuRLEhFQY
	hABZKJGklF+yb2EDoAK2j1V0AD6NuaTbRM4o+gpYWQjx
X-Received: by 2002:a6b:e00b:: with SMTP id z11mr3607202iog.211.1551467201948;
 Fri, 01 Mar 2019 11:06:41 -0800 (PST)
MIME-Version: 1.0
References: <a94c4768-8cd7-43aa-8bb9-b21b3ccf950c@lbl.gov> <CAApQTTh9E=oNwfTLFmjmH6rAXDH2Q+X29D0Ur_Y3VMXvGvsDtg@mail.gmail.com>
 <710b4b5e-f209-41da-bfcb-c19043201fa4@lbl.gov> <CAM=pu++geyfoQ+HWGtWVOStYfuH3+b49VLSk6zwQS0pH7V_WCA@mail.gmail.com>
 <54a4fb06-9c3c-46f0-bcf8-7d788fb7d381@lbl.gov>
In-Reply-To: <54a4fb06-9c3c-46f0-bcf8-7d788fb7d381@lbl.gov>
From: v <vso...@gmail.com>
Date: Fri, 1 Mar 2019 14:06:30 -0500
Message-ID: <CAM=pu+K3LpHL-MbQ==RMumDX7_gADoui=MBmRmTmeGc7JxPn_w@mail.gmail.com>
Subject: Re: [Singularity] Singularity image download syncronization during
 multiple job startup
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="00000000000073f90e05830d1bea"

--00000000000073f90e05830d1bea
Content-Type: text/plain; charset="UTF-8"

HPC and cloud are very different use cases, and that seems to be the edge
we are hitting here!

>
>   There are several issues with a Job dependencies approach.  The first is
> that the job to download and cache the image would have to be run on all
> nodes. We don't explicitly assign jobs to a select group of hosts. It's a
> batch processing environment.  Every CPU compute node can run every CPU
> compute job, and the same is true for our GPU nodes. There is no guarantee
> that the node that runs the download job will take the tasks.
>
> This would be rationale for a shared filesystem, which is fairly common in
HPC


>   From the admin side, we are trying to slide in containerization between
> the existing system image and the applications without requiring a massive
> change to the user workflows.  A lot of our users are researchers who just
> run a tool provided to them from the tool builders. They are not cluster
> aware application developers. We are working with our toolbuilders on this
> project, but their focus is on new work, not trying to rework old
> workflows. So we have to make this as seamless as possible to the existing
> job submission workflows. Introducing job dependencies will likely break
> these workflows.
>
> Singularity was (first) optimized for this use case (HPC), so a shared
cache would be a good solution. The only other alternative would be through
educating your users to pull to a file first, and then submit the file to
the jobs. You don't need to use dependencies exactly, but the simple
example that @gmk gave pulling first You are saying this isn't an option?


>   Our prolog wrapper is how we are going to force the workflows into
> containerization. We have two "default" container images (one for CPU jobs,
> one for GPU jobs) that are almost 100% identical to our current images.
> That 9 GB container image I mentioned in our collection is one of those
> default. Our toolbuilders have pushed back against the slow download times
> already. The efforts to enable caching, object storage backends, etc. were
> attempts to reduce the download times.
>
> A shared filesystem cache, so you could download once, would be a typical
HPC use case (sharing binaries between jobs) and help this, no? I see that
you opened a PR to do that here:
https://github.com/sylabs/singularity/pull/2776


> I had hoped that by enabling shub caching in Singularity that it would
> help, and it does so long as we don't run into this corner case. But
> knowing our workflows, users, and operational procedures, we are going to
> hit it regularly.  Thats why I am trying to figure out any alternatives
> short of putting our containers into a shared directory. The shared
> directory model would work for today.  But we have to move to the cloud and
> having a running shared directory that is not object based is costly.
>
> If you need to run a file, and the file is in some external server, it
seems logical that you either need to download a gazillion copies of the
same thing (not ideal) or share a few copies via shared systems (more
ideal).  The cloud is a different use case because it won't be too costly
on the instance to download, but it would be a burden on the registry. This
is good rationale for having a service that can handle that kind of
concurrency - whether it means deploying multiple front ends to your own
storage, or using something like Google Storage that can handle it. What
could be other solutions? You could set up something complicated with
Globus and then have a shared folder "somewhere else" but that just makes
it more complicated. You could provide a wrapper for users that enforces a
pull first, but it sounds like you don't want to do that.


> On Thursday, February 28, 2019 at 12:37:43 PM UTC-5, vanessa wrote:
>>
>> What if you used job dependencies, with a job do handle a single pull of
>> all required containers coming before the batch?
>>
>> https://slurm.schedmd.com/job_array.html#job-dependencies
>>
>> [image: image.png]
>>
>> On Thu, Feb 28, 2019 at 8:36 AM Mike Moore <wx...@gmail.com> wrote:
>>
>>> Hi Greg,
>>>
>>>   So, our current workloads are batch jobs. There is very little MPI at
>>> all currently. We use Univa Grid Engine for our scheduler. Our users submit
>>> job arrays with 100->1000s of tasks per job.  Each task is similar, just on
>>> different data sets. We do have multiple (up to 20) tasks that can start on
>>> a node almost simultaneously.
>>>
>>>   We are deploying singularity images to convert our very large and
>>> customized bare metal image into a container. This is the first step in
>>> decoupling our applications from our bare metal installation and start a
>>> path to computing in the cloud. We went with Singularity because our shared
>>> environment makes docker a non-starter with our security dept.
>>>
>>>   I have been trying to get Sregistry working fast enough to move the
>>> project out of a POC for functional testing and into production use.
>>> However, the time to download the image to the system is unacceptably
>>> slow.  I've patched Singularity 3.1.0 to address the missing Shub local
>>> caching support, which makes everything better if the image is locally
>>> cached.  If the image is not cached and begins to download by the first
>>> task on a node, any additional tasks that are released to the node will
>>> fail when starting singularity because the image is incomplete. I have test
>>> cases (up to 500 tasks) with only a handful of tasks successfully
>>> completing because the first tasks are downloading the image and the
>>> additional tasks die because the download is in progress.  Our image is on
>>> the order of 1.5-9.0GB depending on the software included and the function
>>> of the image. So, time to download the image is significant.
>>>
>>>   So, the way we have essentially been running our jobs are:
>>>
>>> qsub -q all.q -t1-500 singularity run shub://sregistry/image
>>> <application>
>>>
>>> Once the scheduler releases the job to the compute node, it starts
>>> singularity which downloads image from sregistry. We have written a wrapper
>>> that we will be using to force all jobs to run in singularity once our
>>> users have completed acceptance testing. But the issue of singularity
>>> crashing because the cached image is incomplete is a blocker.
>>>
>>> I was trying to get an idea of what others were doing for storing and
>>> starting their containers in their HPC environments and if they have a
>>> similar issue with trying to start multiple instances of a container on the
>>> same system at the same time if the container is not cached yet.
>>>
>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>>
>> --
>> Vanessa Villamia Sochat
>> Stanford University '16
>> (603) 321-0676
>>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>


-- 
Vanessa Villamia Sochat
Stanford University '16
(603) 321-0676

--00000000000073f90e05830d1bea
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr">HPC and cloud are very d=
ifferent use cases, and that seems to be the edge we are hitting here!</div=
></div><div class=3D"gmail_quote"><blockquote class=3D"gmail_quote" style=
=3D"margin:0px 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding=
-left:1ex"><div dir=3D"ltr"><br>=C2=A0 There are several issues with a Job =
dependencies approach.=C2=A0 The first is that the job to download and cach=
e the image would have to be run on all nodes. We don&#39;t explicitly assi=
gn jobs to a select group of hosts. It&#39;s a batch processing environment=
.=C2=A0 Every CPU compute node can run every CPU compute job, and the same =
is true for our GPU nodes. There is no guarantee that the node that runs th=
e download job will take the tasks. <br><br></div></blockquote><div>This wo=
uld be rationale for a shared filesystem, which is fairly common in HPC</di=
v><div>=C2=A0</div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0p=
x 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"><div d=
ir=3D"ltr">=C2=A0 From the admin side, we are trying to slide in containeri=
zation between the existing system image and the applications without requi=
ring a massive change to the user workflows.=C2=A0 A lot of our users are r=
esearchers who just run a tool provided to them from the tool builders. The=
y are not cluster aware application developers. We are working with our too=
lbuilders on this project, but their focus is on new work, not trying to re=
work old workflows. So we have to make this as seamless as possible to the =
existing job submission workflows. Introducing job dependencies will likely=
 break these workflows. <br><br></div></blockquote><div>Singularity was (fi=
rst) optimized for this use case (HPC), so a shared cache would be a good s=
olution. The only other alternative would be through educating your users t=
o pull to a file first, and then submit the file to the jobs. You don&#39;t=
 need to use dependencies exactly, but the simple example that @gmk gave pu=
lling first You are saying this isn&#39;t an option?=C2=A0</div><div>=C2=A0=
<br></div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8=
ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr=
">=C2=A0 Our prolog wrapper is how we are going to force the workflows into=
 containerization. We have two &quot;default&quot; container images (one fo=
r CPU jobs, one for GPU jobs) that are almost 100% identical to our current=
 images. That 9 GB container image I mentioned in our collection is one of =
those default. Our toolbuilders have pushed back against the slow download =
times already. The efforts to enable caching, object storage backends, etc.=
 were attempts to reduce the download times. <br><br></div></blockquote><di=
v>A shared filesystem cache, so you could download once, would be a typical=
 HPC use case (sharing binaries between jobs) and help this, no? I see that=
 you opened a PR to do that here: <a href=3D"https://github.com/sylabs/sing=
ularity/pull/2776">https://github.com/sylabs/singularity/pull/2776</a></div=
><div>=C2=A0</div><blockquote class=3D"gmail_quote" style=3D"margin:0px 0px=
 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"><div di=
r=3D"ltr">I had hoped that by enabling shub caching in Singularity that it =
would help, and it does so long as we don&#39;t run into this corner case. =
But knowing our workflows, users, and operational procedures, we are going =
to hit it regularly.=C2=A0 Thats why I am trying to figure out any alternat=
ives short of putting our containers into a shared directory. The shared di=
rectory model would work for today.=C2=A0 But we have to move to the cloud =
and having a running shared directory that is not object based is costly. <=
br><br></div></blockquote><div>If you need to run a file, and the file is i=
n some external server, it seems logical that you either need to download a=
 gazillion copies of the same thing (not ideal) or share a few copies via s=
hared systems (more ideal).=C2=A0 The cloud is a different use case because=
 it won&#39;t be too costly on the instance to download, but it would be a =
burden on the registry. This is good rationale for having a service that ca=
n handle that kind of concurrency - whether it means deploying multiple fro=
nt ends to your own storage, or using something like Google Storage that ca=
n handle it. What could be other solutions? You could set up something comp=
licated with Globus and then have a shared folder &quot;somewhere else&quot=
; but that just makes it more complicated. You could provide a wrapper for =
users that enforces a pull first, but it sounds like you don&#39;t want to =
do that.=C2=A0</div><div><br></div><blockquote class=3D"gmail_quote" style=
=3D"margin:0px 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding=
-left:1ex"><div dir=3D"ltr"><br>On Thursday, February 28, 2019 at 12:37:43 =
PM UTC-5, vanessa wrote:<blockquote class=3D"gmail_quote" style=3D"margin:0=
px 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"><=
div dir=3D"ltr"><div dir=3D"ltr">What if you used job dependencies, with a =
job do handle a single pull of all required containers coming before the ba=
tch?<div><br></div><div><a href=3D"https://slurm.schedmd.com/job_array.html=
#job-dependencies" rel=3D"nofollow" target=3D"_blank">https://slurm.schedmd=
.com/job_array.html#job-dependencies</a><br><div><br></div><div><div><img a=
lt=3D"image.png" style=3D"margin-right: 0px;" width=3D"701" height=3D"495">=
<br></div></div></div></div></div><br><div class=3D"gmail_quote"><div dir=
=3D"ltr">On Thu, Feb 28, 2019 at 8:36 AM Mike Moore &lt;<a rel=3D"nofollow"=
>wx...@gmail.com</a>&gt; wrote:<br></div><blockquote class=3D"gmail_quote" =
style=3D"margin:0px 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);pa=
dding-left:1ex"><div dir=3D"ltr">Hi Greg,<br><br>=C2=A0 So, our current wor=
kloads are batch jobs. There is very little MPI at all currently. We use Un=
iva Grid Engine for our scheduler. Our users submit job arrays with 100-&gt=
;1000s of tasks per job.=C2=A0 Each task is similar, just on different data=
 sets. We do have multiple (up to 20) tasks that can start on a node almost=
 simultaneously. <br><br>=C2=A0 We are deploying singularity images to conv=
ert our very large and customized bare metal image into a container. This i=
s the first step in decoupling our applications from our bare metal install=
ation and start a path to computing in the cloud. We went with Singularity =
because our shared environment makes docker a non-starter with our security=
 dept. <br><br>=C2=A0 I have been trying to get Sregistry working fast enou=
gh to move the project out of a POC for functional testing and into product=
ion use. However, the time to download the image to the system is unaccepta=
bly slow.=C2=A0 I&#39;ve patched Singularity 3.1.0 to address the missing S=
hub local caching support, which makes everything better if the image is lo=
cally cached.=C2=A0 If the image is not cached and begins to download by th=
e first task on a node, any additional tasks that are released to the node =
will fail when starting singularity because the image is incomplete. I have=
 test cases (up to 500 tasks) with only a handful of tasks successfully com=
pleting because the first tasks are downloading the image and the additiona=
l tasks die because the download is in progress.=C2=A0 Our image is on the =
order of 1.5-9.0GB depending on the software included and the function of t=
he image. So, time to download the image is significant. <br><br>=C2=A0 So,=
 the way we have essentially been running our jobs are:<br><br>qsub -q all.=
q -t1-500 singularity run shub://sregistry/image &lt;application&gt;<br><br=
>Once the scheduler releases the job to the compute node, it starts singula=
rity which downloads image from sregistry. We have written a wrapper that w=
e will be using to force all jobs to run in singularity once our users have=
 completed acceptance testing. But the issue of singularity crashing becaus=
e the cached image is incomplete is a blocker.<br><br>I was trying to get a=
n idea of what others were doing for storing and starting their containers =
in their HPC environments and if they have a similar issue with trying to s=
tart multiple instances of a container on the same system at the same time =
if the container is not cached yet.<br><br><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</blockquote></div><br clear=3D"all"><div><br></div>-- <br><div dir=3D"ltr"=
>Vanessa Villamia Sochat<br>Stanford University &#39;16<br><div><div><div>(=
603) 321-0676</div></div></div></div>
</blockquote></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</blockquote></div><br clear=3D"all"><div><br></div>-- <br><div dir=3D"ltr"=
 class=3D"gmail_signature" data-smartmail=3D"gmail_signature">Vanessa Villa=
mia Sochat<br>Stanford University &#39;16<br><div><div><div>(603) 321-0676<=
/div></div></div></div></div>

--00000000000073f90e05830d1bea--

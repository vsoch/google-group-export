X-Received: by 10.157.37.83 with SMTP id j19mr54870017otd.23.1470195060802;
        Tue, 02 Aug 2016 20:31:00 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.36.73.68 with SMTP id z65ls268561ita.21.gmail; Tue, 02 Aug
 2016 20:31:00 -0700 (PDT)
X-Received: by 10.66.62.226 with SMTP id b2mr111885919pas.119.1470195060316;
        Tue, 02 Aug 2016 20:31:00 -0700 (PDT)
Return-Path: <jason...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id xk3si6429647pab.97.2016.08.02.20.31.00
        for <singu...@lbl.gov>;
        Tue, 02 Aug 2016 20:31:00 -0700 (PDT)
Received-SPF: pass (google.com: domain of jason...@gmail.com designates 209.85.161.170 as permitted sender) client-ip=209.85.161.170;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of jason...@gmail.com designates 209.85.161.170 as permitted sender) smtp.mailfrom=jason...@gmail.com
X-Ironport-SBRS: 3.5
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2GCAABVZKFXh6qhVdFdhBt8B4M4rX6GfHaBPUAmgWxUgicBgQ8CgT4HOBQBAQEBAQEBAw8BAQEIDQkJGS+CUzkKBisBAQEBAQEBAQEhAisEFgscAQUSCAEIHQENDh4DDAYFCw0CAiYCAiEBAQ4DAQUBHA4HBAEcBAGHdAEDFwUJoV6BMj4xizuBaoJaBYZEChknDVSCeQwBHAIGEHGFKYNKgQOCQ4FPEQGDHYJaBYYMghIHhXILaj+JNTSBYIQ4gnyCc0OCNYFrFzeHPYVJiCuEBYI4Eh6BDx6CSBELgWoeMgEBAQEDhneBNgEBAQ
X-IPAS-Result: A2GCAABVZKFXh6qhVdFdhBt8B4M4rX6GfHaBPUAmgWxUgicBgQ8CgT4HOBQBAQEBAQEBAw8BAQEIDQkJGS+CUzkKBisBAQEBAQEBAQEhAisEFgscAQUSCAEIHQENDh4DDAYFCw0CAiYCAiEBAQ4DAQUBHA4HBAEcBAGHdAEDFwUJoV6BMj4xizuBaoJaBYZEChknDVSCeQwBHAIGEHGFKYNKgQOCQ4FPEQGDHYJaBYYMghIHhXILaj+JNTSBYIQ4gnyCc0OCNYFrFzeHPYVJiCuEBYI4Eh6BDx6CSBELgWoeMgEBAQEDhneBNgEBAQ
X-IronPort-AV: E=Sophos;i="5.28,464,1464678000"; 
   d="scan'208";a="31473033"
Received: from mail-yw0-f170.google.com ([209.85.161.170])
  by fe4.lbl.gov with ESMTP; 02 Aug 2016 20:30:58 -0700
Received: by mail-yw0-f170.google.com with SMTP id u134so216866224ywg.3
        for <singu...@lbl.gov>; Tue, 02 Aug 2016 20:30:58 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=sw9KhWn8PiCnYQ4dWh6RhLSE2NzUokgsN2PDWovR6JQ=;
        b=SXa9anTbjgk+BHEsPgs16DHHNCh3xLTbVsQacuRnBHQ3pW4lrklCl8Wt3muWu/sOr/
         i5nw9bczIWqtgAGteOgML9HXDpceH+co7Wa25WF4Nfx1h/XM2kqXP74DuP2erUiRlV+G
         IFd0FUg8+YU3qHOtj/u7N70PIEFTN3FVxc1UtABdCYFeWnXyULQB1FhwOejI3QC680Sc
         xZLPSuwhmoLdUDm6A44cznef6GbZMO0Sts6bWNjHvUNzjoUni9VYmnbz7jJKUGspoTQy
         Hh2uj0epBLFwB2NnsYnvRQANoHurluFXKrOfWqkbE5o/02Kc8mgh6yqPc3YfBcfVJsdk
         QsEA==
X-Gm-Message-State: AEkooust2SPD7Kiu5nuxkLLUF8V2hq480NJN4DWAENp0QkU+ijfqU4xSasf/c0bm/ccF+h6bp0X/dW/n0+4FYQ==
X-Received: by 10.37.68.68 with SMTP id r65mr48809281yba.177.1470195056246;
 Tue, 02 Aug 2016 20:30:56 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.37.43.69 with HTTP; Tue, 2 Aug 2016 20:30:54 -0700 (PDT)
In-Reply-To: <CAMfmYejUACf_N60-2Lv29kaW2Ba2yUvz2GD50AnR7Cm3jA3b+g@mail.gmail.com>
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com>
 <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com>
 <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov> <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov>
 <CAA8GL6BdE1TRBaPD-oM7qcj8QK1cBsmJsUzYyrvkRPBP9CX+hQ@mail.gmail.com>
 <CAMfmYehdPLtiouQqMGqOx4ZbEXFbbPRL5QOxsP_vQo0us1QLuA@mail.gmail.com>
 <B927B7F6-3CFB-452D-92AB-866F9B8024E4@gmail.com> <CAMfmYeiSvcReO4jvSGJkavnex64wGZ8Phxva2kAxJ7pcp48YiA@mail.gmail.com>
 <CAMfmYeiaTxVQSNqwprHe5ckcDHPcJXy3imdepiRL+KkDh12TCQ@mail.gmail.com>
 <65CD778F-6CD1-4DB4-9668-4D89839B7053@gmail.com> <CAMfmYeg_pnJcyKGetK7WVChToaWCgGYH-nrYY9v=2+RSkuWZuQ@mail.gmail.com>
 <C5AE54CB-2BA1-4E59-88FC-D20224A46086@gmail.com> <CAMfmYeg2rR9-U-zyviCeDXRt_QgKv_K0p9pf-+qgoGPQAjxjXA@mail.gmail.com>
 <95039222-908B-4AE8-8844-551646C9733C@gmail.com> <CAA8GL6ATuT+zMyD9zrW5GBH3Br8bm8=RvjKm1PNAGbKGF3psMw@mail.gmail.com>
 <CAMfmYejEioybKBLNSv36dd7ma-Z1hatfssvFUOGiuehBZbk-Ug@mail.gmail.com>
 <CA+3XN_KmaVuaKqOCbCvocOrw0qghQZq3kiBh1S6T2NKyTgpDTA@mail.gmail.com>
 <CAMfmYeiia1H27LL8q72LgrsgBV8PF8+QL03DK922PVM6WO0FDg@mail.gmail.com>
 <CA+3XN_Lb6DT4zNfuzTdbL276SsKUumResXsheJ0P9UK1j8KTMA@mail.gmail.com> <CAMfmYejUACf_N60-2Lv29kaW2Ba2yUvz2GD50AnR7Cm3jA3b+g@mail.gmail.com>
From: Jason Stover <jason...@gmail.com>
Date: Tue, 2 Aug 2016 22:30:54 -0500
Message-ID: <CAGfAqt8E5w0xNMwd7WcjOT5VEZMhxjA=k=GXyOTjSEFDC4O4Mg@mail.gmail.com>
Subject: Re: [Singularity] How to use GPU in singularity?
To: singularity@lbl.gov
Content-Type: text/plain; charset=UTF-8

Hi Igor,

  If you can dig up the file: cuda_7.5.18_linux.run

  That has the 352.39 driver in it.

    $ sh ./cuda_7.5.18_linux.run --extract=`pwd`/tmp/
    $ ls tmp/
    NVIDIA-Linux-x86_64-352.39.run  cuda-linux64-rel-7.5.18-19867135.run
    cuda-samples-linux-7.5.18-19867135.run

-J

On Tue, Aug 2, 2016 at 10:13 PM, Igor Yakushin <igor...@gmail.com> wrote:
> Bernard,
> Do you have the corresponding NVIDIA*.run file for Tesla K80? I could not
> find it on nvidia site.
> Thank you,
> Igor
>
> On Tue, Aug 2, 2016 at 12:53 AM, Bernard Li <ber...@vanhpc.org> wrote:
>>
>> Hi Igor:
>>
>> 352.39 and Tesla K80.
>>
>> Thanks,
>>
>> Bernard
>>
>> On Mon, Aug 1, 2016 at 10:21 PM, Igor Yakushin <igor...@gmail.com>
>> wrote:
>> > Hi Bernard,
>> > What nvidia driver version is on your host?  What card model?
>> > Thank you,
>> > Igor
>> >
>> >
>> > On Aug 1, 2016 11:55 PM, "Bernard Li" <ber...@vanhpc.org> wrote:
>> >>
>> >> Hey Igor:
>> >>
>> >> If you can make the tensorflow Singularity container available, I'd
>> >> like
>> >> to try that out on our cluster.
>> >>
>> >> Thanks,
>> >>
>> >> Bernard
>> >>
>> >> On Monday, 1 August 2016, Igor Yakushin <igor...@gmail.com> wrote:
>> >>>
>> >>> Hi Nathan,
>> >>> The main problem was that if you try to install cuda, it would by
>> >>> default
>> >>> install driver as well that might be of different version than the
>> >>> driver
>> >>> installed with NVIDIA*.run file. So when installing cuda, use an
>> >>> option not
>> >>> to install the driver. It is much easier to find NVIDIA*.run file of
>> >>> the
>> >>> version you need than cuda*.run with the right driver.  When
>> >>> downloading
>> >>> NVIDIA*.run, pay attention that you are asking for Tesla card (if
>> >>> that's
>> >>> what you have). Consumer cards have different driver (I do not
>> >>> remember if
>> >>> it is reflected in the file name but I suspect not, because I made
>> >>> this
>> >>> mistake).
>> >>> Thank you,
>> >>> Igor
>> >>>
>> >>>
>> >>> On Mon, Aug 1, 2016 at 8:56 AM, Nathan Lin <nathan...@gmail.com>
>> >>> wrote:
>> >>>>
>> >>>> That's great to hear Igor! What ended up being the problem?
>> >>>>
>> >>>> On Mon, Aug 1, 2016 at 1:43 AM, Rick Wagner
>> >>>> <richard...@gmail.com>
>> >>>> wrote:
>> >>>>>
>> >>>>> Igor,
>> >>>>>
>> >>>>> If you had a chance to post your definition file or the steps you
>> >>>>> took,
>> >>>>> I know several of us would appreciate it. Getting TensorFlow running
>> >>>>> on
>> >>>>> CentOS was a huge effort for our support staff. And that's just one
>> >>>>> of many
>> >>>>> GPU-enabled applications.
>> >>>>>
>> >>>>> --Rick
>> >>>>>
>> >>>>> On Jul 31, 2016, at 10:20 PM, Igor Yakushin <igor...@gmail.com>
>> >>>>> wrote:
>> >>>>>
>> >>>>> Thank you, Nathan. It finally works!
>> >>>>>
>> >>>>> On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin
>> >>>>> <nathan...@gmail.com>
>> >>>>> wrote:
>> >>>>>>
>> >>>>>> Yes I do
>> >>>>>>
>> >>>>>> On Jul 31, 2016, at 5:03 PM, Igor Yakushin <igor...@gmail.com>
>> >>>>>> wrote:
>> >>>>>>
>> >>>>>> Nathan,
>> >>>>>> When you import tensorflow in python, does it tell you what cuda
>> >>>>>> libraries it is loading or not?
>> >>>>>> Do you see these messages:
>> >>>>>> ======
>> >>>>>> >>> import tensorflow as tf
>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>> >>>>>> CUDA library libcublas.so locally
>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>> >>>>>> CUDA library libcudnn.so locally
>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>> >>>>>> CUDA library libcufft.so locally
>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>> >>>>>> CUDA library libcuda.so locally
>> >>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened
>> >>>>>> CUDA library libcurand.so locally
>> >>>>>> ======
>> >>>>>> Thank you,
>> >>>>>> Igor
>> >>>>>>
>> >>>>>> On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin
>> >>>>>> <nathan...@gmail.com>
>> >>>>>> wrote:
>> >>>>>>>
>> >>>>>>> Hi Igor,
>> >>>>>>>
>> >>>>>>> In regards to your first questions, the OS/drivers of your
>> >>>>>>> building
>> >>>>>>> computer should not matter. I built an Ubuntu 14.04 image on my
>> >>>>>>> RHEL 7 box
>> >>>>>>> for our RHEL 6 cluster. I'm not sure that the toolkit is that
>> >>>>>>> version
>> >>>>>>> specific, my image seems to work fine and it's running 353.63.
>> >>>>>>> There is one
>> >>>>>>> thing that I do that may be helpful. I read it somewhere online
>> >>>>>>> and am not
>> >>>>>>> actually sure if it does anything, but I've included it in my
>> >>>>>>> image
>> >>>>>>> definitions just in case. Apparently there is something about
>> >>>>>>> initializing
>> >>>>>>> the CUDA Toolkit. As part of my definition file I run 'make' on
>> >>>>>>> the CUDA
>> >>>>>>> sample 'deviceQuery'. Maybe that will help?
>> >>>>>>>
>> >>>>>>> Best,
>> >>>>>>> Nathan
>> >>>>>>>
>> >>>>>>> On Jul 31, 2016, at 1:51 PM, Igor Yakushin <igor...@gmail.com>
>> >>>>>>> wrote:
>> >>>>>>>
>> >>>>>>> Hi Nathan,
>> >>>>>>> I got a little bit further: nvidia-smi is working now but
>> >>>>>>> tensorflow
>> >>>>>>> still complains:
>> >>>>>>> =========
>> >>>>>>>
>> >>>>>>> =========
>> >>>>>>> Singularity/ubuntu_14.04.img> nvidia-smi
>> >>>>>>> Sun Jul 31 17:33:44 2016
>> >>>>>>> +------------------------------------------------------+
>> >>>>>>> | NVIDIA-SMI 352.55     Driver Version: 352.55         |
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> |-------------------------------+----------------------+----------------------+
>> >>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile
>> >>>>>>> Uncorr. ECC |
>> >>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util
>> >>>>>>> Compute M. |
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> |===============================+======================+======================|
>> >>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>> >>>>>>> 0 |
>> >>>>>>> | N/A   45C    P0    79W / 235W |    158MiB / 11519MiB |     45%
>> >>>>>>> Default |
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> +-------------------------------+----------------------+----------------------+
>> >>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>> >>>>>>> 0 |
>> >>>>>>> | N/A   23C    P8    18W / 235W |     61MiB / 11519MiB |      0%
>> >>>>>>> Default |
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> +-------------------------------+----------------------+----------------------+
>> >>>>>>>
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> +-----------------------------------------------------------------------------+
>> >>>>>>> | Processes:
>> >>>>>>> GPU Memory |
>> >>>>>>> |  GPU       PID  Type  Process name
>> >>>>>>> Usage      |
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> |=============================================================================|
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> +-----------------------------------------------------------------------------+
>> >>>>>>> Singularity/ubuntu_14.04.img> python
>> >>>>>>> Python 2.7.6 (default, Mar 22 2014, 22:59:56)
>> >>>>>>> [GCC 4.8.2] on linux2
>> >>>>>>> Type "help", "copyright", "credits" or "license" for more
>> >>>>>>> information.
>> >>>>>>> >>> import tensorflow
>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>> opened
>> >>>>>>> CUDA library libcublas.so locally
>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>> opened
>> >>>>>>> CUDA library libcudnn.so locally
>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>> opened
>> >>>>>>> CUDA library libcufft.so locally
>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>> opened
>> >>>>>>> CUDA library libcuda.so.1 locally
>> >>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>> opened
>> >>>>>>> CUDA library libcurand.so locally
>> >>>>>>> >>> ss = tensorflow.Session()
>> >>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call
>> >>>>>>> to
>> >>>>>>> cuInit: CUDA_ERROR_NO_DEVICE
>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>> >>>>>>> retrieving
>> >>>>>>> CUDA diagnostic information for host: midway-l34-02
>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>> >>>>>>> hostname:
>> >>>>>>> midway-l34-02
>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda
>> >>>>>>> reported version is: 352.93.0
>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver
>> >>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel
>> >>>>>>> Module
>> >>>>>>> 352.55  Thu Oct  8 15:18:00 PDT 2015
>> >>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC)
>> >>>>>>> """
>> >>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel
>> >>>>>>> reported version is: 352.55.0
>> >>>>>>> E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:296] kernel
>> >>>>>>> version 352.55.0 does not match DSO version 352.93.0 -- cannot
>> >>>>>>> find working
>> >>>>>>> devices in this configuration
>> >>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU
>> >>>>>>> devices
>> >>>>>>> available on machine.
>> >>>>>>> >>>
>> >>>>>>> =================
>> >>>>>>> As far as I understand the problem is that cuda-7.5 was built or
>> >>>>>>> relies on nvidia 352.93 while I have NVIDIA driver 352.55 both on
>> >>>>>>> the host
>> >>>>>>> and container. So far I could not find cuda-7.5 built with 352.55.
>> >>>>>>> cuda-7.5 has stabs directory in which there is libcuda.so. The
>> >>>>>>> problem is probably coming from there. However, I doubt I can just
>> >>>>>>> replace
>> >>>>>>> libcuda.so in the stubs directory by a different version or turn
>> >>>>>>> it into
>> >>>>>>> symbolic link to a different version in the driver? Because its
>> >>>>>>> size is much
>> >>>>>>> smaller than the size of the real libcuda.so in the driver. So I
>> >>>>>>> suspect, it
>> >>>>>>> is really only some kind of interface to the real library?
>> >>>>>>>
>> >>>>>>> Thank you,
>> >>>>>>> Igor
>> >>>>>>>
>> >>>>>>>
>> >>>>>>> On Sun, Jul 31, 2016 at 9:36 AM, Igor Yakushin
>> >>>>>>> <igor...@gmail.com>
>> >>>>>>> wrote:
>> >>>>>>>>
>> >>>>>>>> Hi Nathan,
>> >>>>>>>> When installing cuda libraries and tensorflow into the
>> >>>>>>>> singularity
>> >>>>>>>> image, is it important to be on the same host with the same
>> >>>>>>>> version of
>> >>>>>>>> CUDA/OS on which you are going to run later?
>> >>>>>>>> I do not have root on the machine I am going to run later and
>> >>>>>>>> prepare the image on a different machine with a different version
>> >>>>>>>> of nvidia
>> >>>>>>>> driver and a different flavor of Linux.
>> >>>>>>>> Thank you,
>> >>>>>>>> Igor
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>> On Sun, Jul 31, 2016 at 8:39 AM, Nathan Lin
>> >>>>>>>> <nathan...@gmail.com> wrote:
>> >>>>>>>>>
>> >>>>>>>>> Hi Igor,
>> >>>>>>>>>
>> >>>>>>>>> I don't necessarily have a great answer for you. If seems like
>> >>>>>>>>> you
>> >>>>>>>>> are doing everything right, yet it is still not working. In my
>> >>>>>>>>> case, yes
>> >>>>>>>>> nvidia-smi as well as TensorFlow both work correctly. I feel
>> >>>>>>>>> like your error
>> >>>>>>>>> still has to do with the version of libcuda.so you are using.
>> >>>>>>>>> Notice how
>> >>>>>>>>> Python seems to correctly load libcuda.so, yet there is later an
>> >>>>>>>>> error that
>> >>>>>>>>> is unable to find libcuda.so. My first suspicion is that there
>> >>>>>>>>> is still a
>> >>>>>>>>> version mismatch between the drivers installed on the image and
>> >>>>>>>>> on the host.
>> >>>>>>>>> If you are sure that is not true, it may be possible that the
>> >>>>>>>>> version of the
>> >>>>>>>>> driver that is installed on the machine isn't new enough for the
>> >>>>>>>>> GPU. That
>> >>>>>>>>> actually occurred on our cluster, and after a sysadmin updated
>> >>>>>>>>> the driver,
>> >>>>>>>>> it worked. Barring that I am not too sure. Maybe if you provide
>> >>>>>>>>> me with the
>> >>>>>>>>> full details of your installation (the versions of the packages
>> >>>>>>>>> that you
>> >>>>>>>>> have installed, the OS of your image and host), I might be able
>> >>>>>>>>> to think
>> >>>>>>>>> about something, but my suspicion is that the driver version on
>> >>>>>>>>> your host
>> >>>>>>>>> machine may not be new enough.
>> >>>>>>>>>
>> >>>>>>>>> Best,
>> >>>>>>>>> Nathan
>> >>>>>>>>>
>> >>>>>>>>> On Jul 31, 2016, at 12:17 AM, Igor Yakushin
>> >>>>>>>>> <igor...@gmail.com>
>> >>>>>>>>> wrote:
>> >>>>>>>>>
>> >>>>>>>>> Hi Nathan,
>> >>>>>>>>>
>> >>>>>>>>> I have found exactly the same version of NVIDIA driver and
>> >>>>>>>>> extracted from it the libraries and nvidia executables and
>> >>>>>>>>> copied them in
>> >>>>>>>>> /usr/lib64/nvidia and /usr/bin and created the corresponding
>> >>>>>>>>> symbolic links.
>> >>>>>>>>> However, I still cannot use GPU inside singularity: nvidia-smi
>> >>>>>>>>> says "GPU
>> >>>>>>>>> access blocked by the operating system" (does it work in your
>> >>>>>>>>> case?) and
>> >>>>>>>>> when tensorflow session starts it also complains that "No GPU
>> >>>>>>>>> devices
>> >>>>>>>>> available on machine". However, notice that tensorflow seems to
>> >>>>>>>>> think that a
>> >>>>>>>>> different version of NVIDIA driver is used. Not sure where it is
>> >>>>>>>>> coming
>> >>>>>>>>> from. The machine on which the image was built has version
>> >>>>>>>>> 361.42
>> >>>>>>>>>
>> >>>>>>>>> ============
>> >>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>> >>>>>>>>> [GCC 5.4.0 20160609] on linux2
>> >>>>>>>>> Type "help", "copyright", "credits" or "license" for more
>> >>>>>>>>> information.
>> >>>>>>>>> >>> import tensorflow
>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>>>> opened
>> >>>>>>>>> CUDA library libcublas.so locally
>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>>>> opened
>> >>>>>>>>> CUDA library libcudnn.so locally
>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>>>> opened
>> >>>>>>>>> CUDA library libcufft.so locally
>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>>>> opened
>> >>>>>>>>> CUDA library libcuda.so locally
>> >>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully
>> >>>>>>>>> opened
>> >>>>>>>>> CUDA library libcurand.so locally
>> >>>>>>>>> >>> ss = tensorflow.Session()
>> >>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed
>> >>>>>>>>> call
>> >>>>>>>>> to cuInit: CUDA_ERROR_UNKNOWN
>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>> >>>>>>>>> retrieving CUDA diagnostic information for host: midway230
>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>> >>>>>>>>> hostname: midway230
>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185]
>> >>>>>>>>> libcuda
>> >>>>>>>>> reported version is: Not found: was unable to find libcuda.so
>> >>>>>>>>> DSO loaded
>> >>>>>>>>> into this program
>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347]
>> >>>>>>>>> driver
>> >>>>>>>>> version file contents: """NVRM version: NVIDIA UNIX x86_64
>> >>>>>>>>> Kernel Module
>> >>>>>>>>> 352.55  Thu Oct  8 15:18:00 PDT 2015
>> >>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16)
>> >>>>>>>>> (GCC)
>> >>>>>>>>> """
>> >>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189]
>> >>>>>>>>> kernel
>> >>>>>>>>> reported version is: 352.55.0
>> >>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU
>> >>>>>>>>> devices
>> >>>>>>>>> available on machine.
>> >>>>>>>>> >>>
>> >>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>> >>>>>>>>> Failed to initialize NVML: GPU access blocked by the operating
>> >>>>>>>>> system
>> >>>>>>>>> ===========
>> >>>>>>>>>
>> >>>>>>>>> Thank you,
>> >>>>>>>>> Igor
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> On Thu, Jul 28, 2016 at 9:34 PM, Nathan Lin
>> >>>>>>>>> <nathan...@gmail.com> wrote:
>> >>>>>>>>>>
>> >>>>>>>>>> I am not sure how to find the correct driver version, but from
>> >>>>>>>>>> my
>> >>>>>>>>>> testing, the version must match exactly. I will admit that I
>> >>>>>>>>>> have had
>> >>>>>>>>>> problems finding specific versions of the driver from NVIDIA's
>> >>>>>>>>>> website. I
>> >>>>>>>>>> had to ask a sysadmin for the installer that they used. In
>> >>>>>>>>>> order to extract
>> >>>>>>>>>> the files, you need to use the --extract-only option. For
>> >>>>>>>>>> instance, you will
>> >>>>>>>>>> have to run something like ' sh /NVIDIA-Linux-x86_64-352.63.run
>> >>>>>>>>>> --extract-only'/ . You will then be given a directory with all
>> >>>>>>>>>> the libraries
>> >>>>>>>>>> that would have been installed. You will need to copy the
>> >>>>>>>>>> libcuda.so.###.##
>> >>>>>>>>>> library (and you can copy any NVIDIA executables that you want
>> >>>>>>>>>> such as
>> >>>>>>>>>> nvidia-smi). Good luck!
>> >>>>>>>>>>
>> >>>>>>>>>> On Thu, Jul 28, 2016 at 8:51 PM, Igor <igor...@gmail.com>
>> >>>>>>>>>> wrote:
>> >>>>>>>>>>>
>> >>>>>>>>>>> I mean I am using this file from NVIDIA website
>> >>>>>>>>>>> cuda_7.5.18_linux.run to install the driver, opengl, cuda.
>> >>>>>>>>>>> Driver
>> >>>>>>>>>>> installation fails, cuda succeeds.
>> >>>>>>>>>>> Also, when I run
>> >>>>>>>>>>> sh cuda_7.5.18_linux.run
>> >>>>>>>>>>> I am offered to install the driver version 352.39 while on the
>> >>>>>>>>>>> host it is 346.47. I cannot upgrade the host. Any idea where I
>> >>>>>>>>>>> can get
>> >>>>>>>>>>> 346.17?
>> >>>>>>>>>>> I tried using the same link just substitute 18 for something
>> >>>>>>>>>>> else
>> >>>>>>>>>>> but have not found the files:
>> >>>>>>>>>>> wget
>> >>>>>>>>>>>
>> >>>>>>>>>>> http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run
>> >>>>>>>>>>>
>> >>>>>>>>>>>
>> >>>>>>>>>>>
>> >>>>>>>>>>> On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> Hi Nathan,
>> >>>>>>>>>>>> When I try to install the driver by running NVIDIA*.run
>> >>>>>>>>>>>> script
>> >>>>>>>>>>>> inside the image, it fails, probably because it tries to
>> >>>>>>>>>>>> modify kernel that
>> >>>>>>>>>>>> belongs to host?
>> >>>>>>>>>>>> How do I extract just libcuda.so.345.67 without installing
>> >>>>>>>>>>>> the
>> >>>>>>>>>>>> driver (which is obviously problematic) and why would copying
>> >>>>>>>>>>>> the library
>> >>>>>>>>>>>> from the host would not work?
>> >>>>>>>>>>>> Thank you,
>> >>>>>>>>>>>> Igor
>> >>>>>>>>>>>>
>> >>>>>>>>>>>> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin
>> >>>>>>>>>>>> wrote:
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> Also if you are using the binary installation of TensorFlow
>> >>>>>>>>>>>>> you
>> >>>>>>>>>>>>> need CUDA toolkit 7.5 and cuDNN v4. These only need to be
>> >>>>>>>>>>>>> installed on our
>> >>>>>>>>>>>>> image. As I mentioned earlier you will need the
>> >>>>>>>>>>>>> libcuda.so.###.## library on
>> >>>>>>>>>>>>> your image. It is very important that this is the same
>> >>>>>>>>>>>>> version of the NVIDIA
>> >>>>>>>>>>>>> driver as you have on your nose (seemingly 346.67 for you).
>> >>>>>>>>>>>>> I should've have
>> >>>>>>>>>>>>> also mentioned that you want the libcuda.so.345.67 library
>> >>>>>>>>>>>>> that you get from
>> >>>>>>>>>>>>> extracting the NVIDIA installer. It will not work if you try
>> >>>>>>>>>>>>> to copy the
>> >>>>>>>>>>>>> libcuda.so library that from you node.
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> Let me know if you have any more questions.
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> Best,
>> >>>>>>>>>>>>> Nathan
>> >>>>>>>>>>>>>
>> >>>>>>>>>>>>> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com>
>> >>>>>>>>>>>>> wrote:
>> >>>>>>>>>>>>>>
>> >>>>>>>>>>>>>> Hello,
>> >>>>>>>>>>>>>>
>> >>>>>>>>>>>>>> Yes you are correct. The NVIDIA driver must be installed on
>> >>>>>>>>>>>>>> your image as well. However, you honestly only need the
>> >>>>>>>>>>>>>> libcuda.so.###.##
>> >>>>>>>>>>>>>> library and the appropriate links for that library. Once
>> >>>>>>>>>>>>>> you have those
>> >>>>>>>>>>>>>> installed in your image, it should work.
>> >>>>>>>>>>>>>>
>> >>>>>>>>>>>>>> Best,
>> >>>>>>>>>>>>>> Nathan
>> >>>>>>>>>>>>>>
>> >>>>>>>>>>>>>> On Thursday, July 28, 2016, Igor <igor...@gmail.com>
>> >>>>>>>>>>>>>> wrote:
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> Hi All,
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> I am trying to use GPU-enabled tensorflow and it cannot
>> >>>>>>>>>>>>>>> find
>> >>>>>>>>>>>>>>> GPU card from inside the container.
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> On the host:
>> >>>>>>>>>>>>>>> $ lspci | grep -i nvidia
>> >>>>>>>>>>>>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla
>> >>>>>>>>>>>>>>> K40m] (rev a1)
>> >>>>>>>>>>>>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla
>> >>>>>>>>>>>>>>> K40m] (rev a1)
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> $ nvidia-smi
>> >>>>>>>>>>>>>>> Thu Jul 28 19:01:42 2016
>> >>>>>>>>>>>>>>> +------------------------------------------------------+
>> >>>>>>>>>>>>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47         |
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> |-------------------------------+----------------------+----------------------+
>> >>>>>>>>>>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A |
>> >>>>>>>>>>>>>>> Volatile Uncorr. ECC |
>> >>>>>>>>>>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage |
>> >>>>>>>>>>>>>>> GPU-Util  Compute M. |
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> |===============================+======================+======================|
>> >>>>>>>>>>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |
>> >>>>>>>>>>>>>>> 0 |
>> >>>>>>>>>>>>>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB |
>> >>>>>>>>>>>>>>> 0%      Default |
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> +-------------------------------+----------------------+----------------------+
>> >>>>>>>>>>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |
>> >>>>>>>>>>>>>>> 0 |
>> >>>>>>>>>>>>>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB |
>> >>>>>>>>>>>>>>> 0%      Default |
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> +-------------------------------+----------------------+----------------------+
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> +-----------------------------------------------------------------------------+
>> >>>>>>>>>>>>>>> | Processes:
>> >>>>>>>>>>>>>>> GPU Memory |
>> >>>>>>>>>>>>>>> |  GPU       PID  Type  Process name
>> >>>>>>>>>>>>>>> Usage      |
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> |=============================================================================|
>> >>>>>>>>>>>>>>> |    0     11671    G   /usr/bin/X
>> >>>>>>>>>>>>>>> 9MiB |
>> >>>>>>>>>>>>>>> |    1     11671    G   /usr/bin/X
>> >>>>>>>>>>>>>>> 3MiB |
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> Inside singularity:
>> >>>>>>>>>>>>>>> $ singularity shell
>> >>>>>>>>>>>>>>> /software/src/singularity_images/tensorflow_0.9.img
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia
>> >>>>>>>>>>>>>>> bash: lspci: command not found
>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi
>> >>>>>>>>>>>>>>> bash: nvidia-smi: command not found
>> >>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> python
>> >>>>>>>>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24)
>> >>>>>>>>>>>>>>> [GCC 5.4.0 20160609] on linux2
>> >>>>>>>>>>>>>>> Type "help", "copyright", "credits" or "license" for more
>> >>>>>>>>>>>>>>> information.
>> >>>>>>>>>>>>>>> >>> import tensorflow as tf
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>> >>>>>>>>>>>>>>> successfully
>> >>>>>>>>>>>>>>> opened CUDA library libcublas.so locally
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>> >>>>>>>>>>>>>>> successfully
>> >>>>>>>>>>>>>>> opened CUDA library libcudnn.so locally
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>> >>>>>>>>>>>>>>> successfully
>> >>>>>>>>>>>>>>> opened CUDA library libcufft.so locally
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>> >>>>>>>>>>>>>>> successfully
>> >>>>>>>>>>>>>>> opened CUDA library libcuda.so locally
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108]
>> >>>>>>>>>>>>>>> successfully
>> >>>>>>>>>>>>>>> opened CUDA library libcurand.so locally
>> >>>>>>>>>>>>>>> >>> sess = tf.Session()
>> >>>>>>>>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491]
>> >>>>>>>>>>>>>>> failed
>> >>>>>>>>>>>>>>> call to cuInit: CUDA_ERROR_UNKNOWN
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153]
>> >>>>>>>>>>>>>>> retrieving CUDA diagnostic information for host:
>> >>>>>>>>>>>>>>> midway-l34-01
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160]
>> >>>>>>>>>>>>>>> hostname: midway-l34-01
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185]
>> >>>>>>>>>>>>>>> libcuda reported version is: Not found: was unable to find
>> >>>>>>>>>>>>>>> libcuda.so DSO
>> >>>>>>>>>>>>>>> loaded into this program
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347]
>> >>>>>>>>>>>>>>> driver version file contents: """NVRM version: NVIDIA UNIX
>> >>>>>>>>>>>>>>> x86_64 Kernel
>> >>>>>>>>>>>>>>> Module  346.47  Thu Feb 19 18:56:03 PST 2015
>> >>>>>>>>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat
>> >>>>>>>>>>>>>>> 4.4.7-11)
>> >>>>>>>>>>>>>>> (GCC)
>> >>>>>>>>>>>>>>> """
>> >>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189]
>> >>>>>>>>>>>>>>> kernel reported version is: 346.47.0
>> >>>>>>>>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No
>> >>>>>>>>>>>>>>> GPU
>> >>>>>>>>>>>>>>> devices available on machine.
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> Must there be nvidia driver installed inside the
>> >>>>>>>>>>>>>>> container?
>> >>>>>>>>>>>>>>> Outside? The container shares the same kernel with the
>> >>>>>>>>>>>>>>> host and nvidia
>> >>>>>>>>>>>>>>> kernel module needs to be loaded... How this is handled?
>> >>>>>>>>>>>>>>> Any requirements on
>> >>>>>>>>>>>>>>> nvidia driver and cuda versions inside and outside of the
>> >>>>>>>>>>>>>>> container?
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> Thank you,
>> >>>>>>>>>>>>>>> Igor
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>>
>> >>>>>>>>>>>>>>> --
>> >>>>>>>>>>>>>>> You received this message because you are subscribed to
>> >>>>>>>>>>>>>>> the
>> >>>>>>>>>>>>>>> Google Groups "singularity" group.
>> >>>>>>>>>>>>>>> To unsubscribe from this group and stop receiving emails
>> >>>>>>>>>>>>>>> from
>> >>>>>>>>>>>>>>> it, send an email to singu...@lbl.gov.
>> >>>>>>>>>>>
>> >>>>>>>>>>> --
>> >>>>>>>>>>> You received this message because you are subscribed to the
>> >>>>>>>>>>> Google Groups "singularity" group.
>> >>>>>>>>>>> To unsubscribe from this group and stop receiving emails from
>> >>>>>>>>>>> it,
>> >>>>>>>>>>> send an email to singu...@lbl.gov.
>> >>>>>>>>>>
>> >>>>>>>>>>
>> >>>>>>>>>> --
>> >>>>>>>>>> You received this message because you are subscribed to the
>> >>>>>>>>>> Google
>> >>>>>>>>>> Groups "singularity" group.
>> >>>>>>>>>> To unsubscribe from this group and stop receiving emails from
>> >>>>>>>>>> it,
>> >>>>>>>>>> send an email to singu...@lbl.gov.
>> >>>>>>>>>
>> >>>>>>>>>
>> >>>>>>>>> --
>> >>>>>>>>> You received this message because you are subscribed to the
>> >>>>>>>>> Google
>> >>>>>>>>> Groups "singularity" group.
>> >>>>>>>>> To unsubscribe from this group and stop receiving emails from
>> >>>>>>>>> it,
>> >>>>>>>>> send an email to singu...@lbl.gov.
>> >>>>>>>>>
>> >>>>>>>>> --
>> >>>>>>>>> You received this message because you are subscribed to the
>> >>>>>>>>> Google
>> >>>>>>>>> Groups "singularity" group.
>> >>>>>>>>> To unsubscribe from this group and stop receiving emails from
>> >>>>>>>>> it,
>> >>>>>>>>> send an email to singu...@lbl.gov.
>> >>>>>>>>
>> >>>>>>>>
>> >>>>>>>
>> >>>>>>> --
>> >>>>>>> You received this message because you are subscribed to the Google
>> >>>>>>> Groups "singularity" group.
>> >>>>>>> To unsubscribe from this group and stop receiving emails from it,
>> >>>>>>> send an email to singu...@lbl.gov.
>> >>>>>>>
>> >>>>>>> --
>> >>>>>>> You received this message because you are subscribed to the Google
>> >>>>>>> Groups "singularity" group.
>> >>>>>>> To unsubscribe from this group and stop receiving emails from it,
>> >>>>>>> send an email to singu...@lbl.gov.
>> >>>>>>
>> >>>>>>
>> >>>>>> --
>> >>>>>> You received this message because you are subscribed to the Google
>> >>>>>> Groups "singularity" group.
>> >>>>>> To unsubscribe from this group and stop receiving emails from it,
>> >>>>>> send
>> >>>>>> an email to singu...@lbl.gov.
>> >>>>>>
>> >>>>>> --
>> >>>>>> You received this message because you are subscribed to the Google
>> >>>>>> Groups "singularity" group.
>> >>>>>> To unsubscribe from this group and stop receiving emails from it,
>> >>>>>> send
>> >>>>>> an email to singu...@lbl.gov.
>> >>>>>
>> >>>>>
>> >>>>> --
>> >>>>> You received this message because you are subscribed to the Google
>> >>>>> Groups "singularity" group.
>> >>>>> To unsubscribe from this group and stop receiving emails from it,
>> >>>>> send
>> >>>>> an email to singu...@lbl.gov.
>> >>>>>
>> >>>>> --
>> >>>>> You received this message because you are subscribed to the Google
>> >>>>> Groups "singularity" group.
>> >>>>> To unsubscribe from this group and stop receiving emails from it,
>> >>>>> send
>> >>>>> an email to singu...@lbl.gov.
>> >>>>
>> >>>>
>> >>>> --
>> >>>> You received this message because you are subscribed to the Google
>> >>>> Groups "singularity" group.
>> >>>> To unsubscribe from this group and stop receiving emails from it,
>> >>>> send
>> >>>> an email to singu...@lbl.gov.
>> >>>
>> >>>
>> >>> --
>> >>> You received this message because you are subscribed to the Google
>> >>> Groups
>> >>> "singularity" group.
>> >>> To unsubscribe from this group and stop receiving emails from it, send
>> >>> an
>> >>> email to singu...@lbl.gov.
>> >>
>> >> --
>> >> You received this message because you are subscribed to the Google
>> >> Groups
>> >> "singularity" group.
>> >> To unsubscribe from this group and stop receiving emails from it, send
>> >> an
>> >> email to singu...@lbl.gov.
>> >
>> > --
>> > You received this message because you are subscribed to the Google
>> > Groups
>> > "singularity" group.
>> > To unsubscribe from this group and stop receiving emails from it, send
>> > an
>> > email to singu...@lbl.gov.
>>
>> --
>> You received this message because you are subscribed to the Google Groups
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send an
>> email to singu...@lbl.gov.
>
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.

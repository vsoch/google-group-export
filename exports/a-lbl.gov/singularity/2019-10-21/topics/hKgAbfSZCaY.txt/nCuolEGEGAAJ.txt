X-Received: by 2002:a17:902:fc3:: with SMTP id 61mr7562345plz.105.1549685956403;
        Fri, 08 Feb 2019 20:19:16 -0800 (PST)
X-BeenThere: singularity@lbl.gov
Received: by 2002:a65:63d0:: with SMTP id n16ls1271648pgv.6.gmail; Fri, 08 Feb
 2019 20:19:15 -0800 (PST)
X-Received: by 2002:a63:e051:: with SMTP id n17mr23980477pgj.258.1549685954939;
        Fri, 08 Feb 2019 20:19:14 -0800 (PST)
ARC-Seal: i=1; a=rsa-sha256; t=1549685954; cv=none;
        d=google.com; s=arc-20160816;
        b=Pn3CSUAYXvF4NOMhlNLZ2Q5j8fkkfymwJK3JGgmgcZ4SMPiTTlDstM7gVoXihhhpDA
         XDbpx8O0iY6Vc6WBm+P6Je8M2vP5BacXToN/L7yVBw0WhUMBpgFeXy+0c/1HlPVOhStT
         6oPUGWZFDqFSxbVRusuc6sm4aIAKd3mK+6qfJjZfrD7SqchMRMAoiaF5uIFAYvhnt7jd
         tuNqF+7a124YwW/XYbZGVddX9GtSGv79/rFI2iCEQAqFq/Hc12OQjzR521G048y4nDLD
         ITR7e8dVPt0tZuXskUNXVPm3ez2kPt9lnlwiaPLK2wuGumoFvE72ee24La5U7STmb7o+
         m4EQ==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:in-reply-to:references:mime-version
         :dkim-signature;
        bh=BPBMK3I/dVuWBbfzqEjXwZwM5OhnMyM/JxY/ZKhyYTc=;
        b=kACkHv/QIeR7uSNEPuB1r9tWbnKZt7AN9Ts4dwgT9CoAgi0l1xLPD559cctvhhR3xP
         XiBnUeE12xhTlKV9VAlx4/+PKs9fRTYLqge1qYGzxwx4RQDQVnKe9bWaJh8pHBCghI0c
         9zUpXdtiGB1OBxtaxkh3dZBGhhL6SQ+TSrg7vxRDxyDLO2gGoThUSZQw8gkLAMaZx58a
         /A5ZxN0pyZfTQLjlz+KSy2Lb4MxnP8tMDbv7JATMEBXrzWSA3TvDZoYpiTVVYIzAWlVR
         sVgn3wUYUcNoxKyLmjxCfqrFNPVKYus+vqtVX1ClIiZSnhPdnIp39Cw1cYaFtZ6Ryp81
         9p6g==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=RE2e2tYH;
       spf=pass (google.com: domain of fert...@gmail.com designates 209.85.210.52 as permitted sender) smtp.mailfrom=fert...@gmail.com
Return-Path: <fert...@gmail.com>
Received: from fe4.lbl.gov (fe4.lbl.gov. [131.243.228.53])
        by mx.google.com with ESMTP id 128si4320508pfe.4.2019.02.08.20.19.14
        for <singu...@lbl.gov>;
        Fri, 08 Feb 2019 20:19:14 -0800 (PST)
Received-SPF: pass (google.com: domain of fert...@gmail.com designates 209.85.210.52 as permitted sender) client-ip=209.85.210.52;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com header.s=20161025 header.b=RE2e2tYH;
       spf=pass (google.com: domain of fert...@gmail.com designates 209.85.210.52 as permitted sender) smtp.mailfrom=fert...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2GAAQBfVF5chjTSVdFjHQEBBQEHBQGBZ?=
 =?us-ascii?q?YFWBYEQTAQzJ4N+BoEdgl6QDoINmCeBKzwlARWBSYJ1AoMsIjgSAQMBAQIBAQI?=
 =?us-ascii?q?BAQIQAQEBCAsLCCkjDII6BQIDHwcOTTswAQEBAQEBAQEBAR8CLSkBARgBAQEBA?=
 =?us-ascii?q?gEjBBkBDQ4PDwMBCwYFCw0VCwoCAiEBAQ4DAQUBCxEOBwQBGgIEgwMBJwGBQAE?=
 =?us-ascii?q?DDQgFnGc8ixt8FgUBF4J5BYQ7ChknDV+BNwIGEowxF4FAP4ERgmQugleBZQ0FA?=
 =?us-ascii?q?RIBXoJKglcCiXUKgQCGP1mFFIs5MwmNBYILgzsZklqHSYlMiD+CTjCBPFcwcTM?=
 =?us-ascii?q?aCBsVOzGCOwmCEwwOCYEAAQmCQYpxJDAQixlHgXcBAQ?=
X-IronPort-AV: E=Sophos;i="5.58,349,1544515200"; 
   d="scan'208,217";a="51068781"
Received: from mail-ot1-f52.google.com ([209.85.210.52])
  by fe4.lbl.gov with ESMTP; 08 Feb 2019 20:18:54 -0800
Received: by mail-ot1-f52.google.com with SMTP id u16so9398945otk.8
        for <singu...@lbl.gov>; Fri, 08 Feb 2019 20:18:54 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=mime-version:references:in-reply-to:from:date:message-id:subject:to;
        bh=BPBMK3I/dVuWBbfzqEjXwZwM5OhnMyM/JxY/ZKhyYTc=;
        b=RE2e2tYHfT40y1/cvwmd9UQMwFWTCUFx+YNxOYd7LtwaRM4bs4hpQtCepS4gvUU+5/
         D+CRV/GCVWk6qMEarZwapk94Kd4MLIGAY8udLQZKYq1VQy0acv43k8s/keZjr2PJvgiL
         /kgUPs4xt32HdSfuykSrVwGksghLSdtonLC8Yg6ezCftPEBdrhrmujEzz0ByDzs7vnBy
         MXAkzV4Ku+nODvilXzS/SwETy+fZ1a4EHvEogOmKGV6S8A3x6LQBEsteB0AKzZz8NpK1
         fq/NGHE/KhJ7xhlGuLeMxmSo52IOgu/rFq8Cwx7d2g0GDcmRQTck89a/WOp5ilKbxdnM
         HhgQ==
X-Gm-Message-State: AHQUAuYmRE6rItGHQOhpT4ayWIwWQRLIx0FH0mxEl18Y74f/E7MaQ85/
	w3GhybzcSWDHoDRGQZ218Rxm1LqgcuX/RgiWymPrVVI8
X-Received: by 2002:a9d:6019:: with SMTP id h25mr10906981otj.193.1549685933176;
 Fri, 08 Feb 2019 20:18:53 -0800 (PST)
MIME-Version: 1.0
References: <71fec772-2642-4b6e-98a3-8801b2ae0cf7@lbl.gov> <59709108-447E-491F-BB5A-C04D3F5AB654@gmail.com>
 <7A55B410-CD7D-4360-A1F3-44E1EF1ECA1B@gmail.com> <cbd878fc-f1a6-4548-8dd2-3ac380da2ecd@lbl.gov>
 <CAJk3+YVedLNPT6=hxrQtAR6xJG3NtERLRFRBCO3M4JL6YXS9Yg@mail.gmail.com>
 <2d3a29da-6518-4643-aef6-6664a21b2dc3@lbl.gov> <8a6e555b-8763-469f-aa4d-6f1b07521f93@lbl.gov>
In-Reply-To: <8a6e555b-8763-469f-aa4d-6f1b07521f93@lbl.gov>
From: Fatih Ertinaz <fert...@gmail.com>
Date: Fri, 8 Feb 2019 23:18:15 -0500
Message-ID: <CAJk3+YV6_KmOJoo+7gJ50izAxe_zAYQWhvrWxR8+5GfhGskcNw@mail.gmail.com>
Subject: Re: [Singularity] Error when running OpenFoam over Singularity using Slurm
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="0000000000008f7da905816e5fab"

--0000000000008f7da905816e5fab
Content-Type: text/plain; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

Ok, this is really interesting to me. So as a summary -- if I'm not
mistaken:

xx You can run parallel OF on a single node using OMPI through Singularity
without Slurm
xx You can run basic parallel MPI tasks using Slurm with and without
Singularity
xx You cannot run multi-node basic parallel jobs using Singularity -- I
don't know if you used Slurm, so maybe fails with both

Should Slurm have a special configuration to run mpi programs in parallel
> with singularity, apart from OpenMPI and PMIx?


I don't think Slurm is the problematic part because of the item 2 above.
For sure Slurm needs information about compute nodes and user account, but
if that was the issue you wouldn't be able to run any tasks even on a
single node. With that being said, I never configured Slurm from scratch,
so I am not a Slurm expert.

Also, I don't think this is an OF issue because of the item 1. However you
might want to make sure if OF is built with "SYSTEMOPENMPI" option. But
again, even though restricted to 1 node, you managed to run it without
Slurm so OF should be fine imho.

If you cannot run multi-node jobs, I guess that's a clear indication of a
potential OMPI problem. Check how OMPI is installed, which fabrics are
being used etc. Additionally, you can also check if Slurm flag is
explicitly defined, sth. like "--with-slurm=3D/opt/slurm".

Moreover can you give some information about the cluster you're working on?
I mean, is this a typical cluster with many users running their
simulations? If that's the case, then I think Slurm or OMPI should be quite
reliable. If this is a cloud cluster that you're experimenting, I bet it is
OMPI :)

Hope this helps

On Fri, Feb 8, 2019 at 2:51 PM Samy <smahan...@gmail.com> wrote:

> Can you try to run the same command on single node and see? like: mpirun
> -n *1* singularity exec .....
> Also, if you have access to interactive mode nodes, it would be a good
> test to run OF with mpirun interactively on 2 or more nodes. It sounds to
> me that it's an issue running your OF on multinode not a slurm problem.
>
> Good luck,
>
>
> On Friday, February 8, 2019 at 12:09:26 AM UTC-8, ccvera wrote:
>>
>> Hi!
>>
>> I didn't say it in my first post (sorry) but, in case it serves as
>> information, the problem appears only when I execute OF in parallel (usi=
ng
>> the -parallel option, that is what I need).
>>
>> Regarding the options you mention to me, Fatih:
>> xx I don`t have problems executing simple works (and even some more
>> complicated) e.g. variable printing and information (all without
>> singularity). Also, I run singularity basic programs and, normally, I us=
e
>> then to train CNN (no need MPI) and all work fine.
>> xx I have replicated the OpenMPI and PMIx host installation in the
>> container, so they have the same versions and libraries were copied.
>>
>> In the logs, both slurmd and slurmctl or the nodes logs I'm not seeing
>> nothing that gives me light.
>> I think you're right when you tell me that it can be an openmpi problem.
>> I'm trying again to execute a "hello world" on singularity and when
>> requesting several nodes I have the same problems :(
>>
>> Should Slurm have a special configuration to run mpi programs in paralle=
l
>> with singularity, apart from OpenMPI and PMIx? Also, should I include ot=
her
>> configuration in my container?
>>
>> Thax for your help.
>>
>> Carmen.
>>
>> El mi=C3=A9rcoles, 6 de febrero de 2019, 15:33:36 (UTC+1), Fatih Ertinaz
>> escribi=C3=B3:
>>>
>>> Hello Carmen
>>>
>>> To me this looks like an OpenMPI & Slurm issue rather than an OF & Slur=
m
>>> problem.
>>>
>>> Few things you can check;
>>> xx Try to execute simple jobs using Slurm, e.g. printing hostnames or
>>> mpi ping-pong stuff.
>>> xx Do you know how OpenMPI is installed in the host? Maybe it is built
>>> with some other underlying libraries regarding IB that you don't have i=
n
>>> your container.
>>>
>>> I'd say if the first one works with hostnames then I'd say focus on the
>>> OpenMPI installation.
>>>
>>> On Wed, Feb 6, 2019 at 4:44 AM 'ccvera' via singularity <
>>> si...@lbl.gov> wrote:
>>>
>>>> Thanks a lot for your quickly reply :)
>>>>
>>>> This solution doesn't work for me. I tried to unset all SLURM
>>>> environment variables (first SLURM_JOBID, then SLURM_NODELIST and fina=
lly
>>>> all as you told me) and i obtain the same MPI error.
>>>>
>>>> Carmen
>>>>
>>>> El martes, 5 de febrero de 2019, 17:56:27 (UTC+1), Shenglong Wang
>>>> escribi=C3=B3:
>>>>>
>>>>> It seems
>>>>>
>>>>> unset SLURM_JOBID
>>>>>
>>>>> is enough to cheat mpiexec
>>>>>
>>>>> Shenglong
>>>>>
>>>>> On Feb 5, 2019, at 11:37 AM, Shenglong Wang <wa...@gmail.com>
>>>>> wrote:
>>>>>
>>>>> Can you try to unset all SLURM environment variables?
>>>>>
>>>>> for e in $(env | egrep ^SLURM_ | cut -d=3D -f1); do unset $e; done
>>>>>
>>>>> or
>>>>>
>>>>> unset SLURM_NODELIST
>>>>>
>>>>> But you=E2=80=99ll have to manually generate host file.
>>>>>
>>>>> Best,
>>>>> Shenglong
>>>>>
>>>>>
>>>>> On Feb 5, 2019, at 11:30 AM, 'ccvera' via singularity <
>>>>> si...@lbl.gov> wrote:
>>>>>
>>>>> Dear all,
>>>>>
>>>>> I'm experiencing some issues running OpenFOAM over singularity with
>>>>> slurm.
>>>>>
>>>>> I've several images based on Ubuntu and within several versions of
>>>>> OpenMPI and PMIx and i'm able to run OpenFOAM correctly without use s=
lurm
>>>>> (directly on the node) using next command:
>>>>>
>>>>> $ mpirun -n 16 singularity exec -B /home ../../of6/openfoam6.x.img
>>>>> simpleFoam -parallel -case
>>>>> /home/carmen/test_singularity/OpenFOAM/pruebaOF6_16cores_SLURM/prueba=
OF6_16cores
>>>>>
>>>>> My problem comes when I run my program with slurm. Whether I make
>>>>> salloc or execute a script with sbatch, it shows me the following err=
or:
>>>>>
>>>>> It looks like MPI_INIT failed for some reason; your parallel process =
is
>>>>>
>>>>> likely to abort.  There are many reasons that a parallel process can
>>>>>
>>>>> fail during MPI_INIT; some of which are due to configuration or
>>>>> environment
>>>>>
>>>>> problems.  This failure appears to be an internal failure; here's som=
e
>>>>>
>>>>> additional information (which may only be relevant to an Open MPI
>>>>>
>>>>> developer):
>>>>>
>>>>>
>>>>>   ompi_mpi_init: ompi_rte_init failed
>>>>>
>>>>>   --> Returned "(null)" (-43) instead of "Success" (0)
>>>>>
>>>>>
>>>>> and
>>>>>
>>>>> *** An error occurred in MPI_Init_thread
>>>>>
>>>>> *** on a NULL communicator
>>>>>
>>>>> *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now
>>>>> abort,
>>>>>
>>>>> ***    and potentially your MPI job)
>>>>>
>>>>> [cn3045:369] Local abort before MPI_INIT completed completed
>>>>> successfully, but am not able to aggregate error messages, and not ab=
le to
>>>>> guarantee that all other processes were killed!
>>>>>
>>>>>
>>>>> I know I must have the same openMPI versions on both (host and
>>>>> container) and I have also tried other versions of OpenMPI (2.X.X) an=
d in
>>>>> all cases OpenFOAM works correctly, but at the moment I want to run i=
t with
>>>>> slurm it show me the errors.
>>>>>
>>>>> I have also tried other ways to run the program with srun using the
>>>>> option --mpi=3Dpmi2 (among others) but I always find the same problem=
.
>>>>>
>>>>> I use the following script to run OpenFoam:
>>>>>
>>>>> ----------------------------
>>>>>
>>>>> #!/bin/bash
>>>>>
>>>>>
>>>>> #SBATCH -N 1
>>>>>
>>>>> #SBATCH -p haswell
>>>>>
>>>>> #SBATCH -J test_OpenFOAM
>>>>>
>>>>> #SBATCH --output=3D"singularity.%j.o"
>>>>>
>>>>> #SBATCH --error=3D"singularity.%j.e"
>>>>>
>>>>>
>>>>> module load haswell/singularity_2.6.0
>>>>>
>>>>> module load haswell/openmpi_3.1.2_gcc8.2.0_pmix
>>>>>
>>>>>
>>>>> ulimit -s unlimited
>>>>>
>>>>>
>>>>> mpirun -n 16 singularity exec ../../of6/openfoam6.x.img simpleFoam
>>>>> -parallel -case
>>>>> /home/software/test_singularity/OpenFOAM/pruebaOF6_16cores_SLURM/prue=
baOF6_16cores
>>>>>
>>>>> ----------------------------
>>>>>
>>>>>
>>>>> The versions that I'm using are:
>>>>>
>>>>> *Host: *
>>>>>
>>>>> OS: CentOS7.5
>>>>>
>>>>> OpenMPI: 3.1.2
>>>>>
>>>>> PMIx: 2.1.4
>>>>>
>>>>>
>>>>> *Container:*
>>>>>
>>>>> OS: Ubuntu16.04
>>>>>
>>>>> OpenMPI: 3.1.2
>>>>>
>>>>> PMIx: 2.1.4
>>>>>
>>>>>
>>>>> Can it be a configuration problem of SLURM? Is there any limitation o=
f
>>>>> SLURM that is affecting OpenFOAM?
>>>>>
>>>>> Some info about slurm:
>>>>>
>>>>> # srun --version
>>>>> slurm 18.08.3
>>>>> # srun --mpi=3Dlist
>>>>> srun: MPI types are...
>>>>> srun: pmi2
>>>>> srun: openmpi
>>>>> srun: none
>>>>>
>>>>>
>>>>> I'm a little bit lost with this issue :(
>>>>> Can someone give me some lights?
>>>>>
>>>>> Thanks a lot in advance,
>>>>> Carmen
>>>>>
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, sen=
d
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>>
>>>>>
>>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--0000000000008f7da905816e5fab
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div dir=3D"ltr">Ok, this is really interesting to me. So =
as a summary -- if I&#39;m not mistaken:<div><br><div>xx You can run parall=
el OF on a single node using OMPI through Singularity without Slurm=C2=A0</=
div><div>xx You can run basic parallel MPI tasks using Slurm with and witho=
ut Singularity</div><div>xx You cannot run multi-node basic parallel jobs u=
sing Singularity -- I don&#39;t know if you used Slurm, so maybe fails with=
 both</div><div><div><br></div></div><blockquote class=3D"gmail_quote" styl=
e=3D"margin:0px 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);paddin=
g-left:1ex">Should Slurm have a special configuration to run mpi programs i=
n parallel with singularity, apart from OpenMPI and PMIx?</blockquote><div>=
<br></div><div>I don&#39;t think Slurm is the problematic part because of t=
he item 2 above. For sure Slurm needs information about compute nodes and u=
ser account, but if that was the issue you wouldn&#39;t be able to run any =
tasks even on a single node. With that being said, I never configured Slurm=
 from scratch, so I am not a Slurm expert.</div><div><br></div><div>Also, I=
 don&#39;t think this is an OF issue because of the item 1. However you mig=
ht want to make sure if OF is built with &quot;SYSTEMOPENMPI&quot; option. =
But again, even though restricted to 1 node, you managed to run it without =
Slurm so OF should be fine imho.=C2=A0</div><div><br></div><div>If you cann=
ot run multi-node jobs, I guess that&#39;s a clear indication of a potentia=
l OMPI problem. Check how OMPI is installed, which fabrics are being used e=
tc. Additionally, you can also check if Slurm flag is explicitly defined, s=
th. like &quot;--with-slurm=3D/opt/slurm&quot;.=C2=A0</div><div><br></div><=
div>Moreover can you give some information about the cluster you&#39;re wor=
king on? I mean, is this a typical cluster with many users running their si=
mulations? If that&#39;s the case, then I think Slurm or OMPI should be qui=
te reliable. If this is a cloud cluster that you&#39;re experimenting, I be=
t it is OMPI :)</div><div><br></div><div>Hope this helps=C2=A0</div></div><=
/div></div><br><div class=3D"gmail_quote"><div dir=3D"ltr">On Fri, Feb 8, 2=
019 at 2:51 PM Samy &lt;<a href=3D"mailto:smahan...@gmail.com" target=3D"_b=
lank">smahan...@gmail.com</a>&gt; wrote:<br></div><blockquote class=3D"gmai=
l_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left:1px solid rgb(204,20=
4,204);padding-left:1ex"><div dir=3D"ltr">Can you try to run the same comma=
nd on single node and see? like: mpirun -n <b>1</b> singularity exec .....<=
div>Also, if you have access to interactive mode nodes, it would be a good =
test to run OF with mpirun interactively on 2 or more nodes. It sounds to m=
e that it&#39;s an issue running your OF on multinode not a slurm problem.<=
/div><div><br></div><div>Good luck,</div><div><br></div><div><br>On Friday,=
 February 8, 2019 at 12:09:26 AM UTC-8, ccvera wrote:<blockquote class=3D"g=
mail_quote" style=3D"margin:0px 0px 0px 0.8ex;border-left:1px solid rgb(204=
,204,204);padding-left:1ex"><div dir=3D"ltr"><div>Hi!</div><div><br></div><=
div>I didn&#39;t say it in my first post (sorry) but, in case it serves as =
information, the problem appears only when I execute OF in parallel (using =
the -parallel option, that is what I need).</div><div><br></div><div>Regard=
ing the options you mention to me, Fatih:</div><div>xx I don`t have problem=
s executing simple works (and even some more complicated) e.g. variable pri=
nting and information (all without singularity). Also, I run singularity ba=
sic programs and, normally, I use then to train CNN (no need MPI) and all w=
ork fine.</div><div>xx I have replicated the OpenMPI and PMIx host installa=
tion in the container, so they have the same versions and libraries were co=
pied.=C2=A0</div><div><br></div><div>In the logs, both slurmd and slurmctl =
or the nodes logs I&#39;m not seeing nothing that gives me light.=C2=A0</di=
v><div>I think you&#39;re right when you tell me that it can be an openmpi =
problem. I&#39;m trying again to execute a &quot;hello world&quot; on singu=
larity and when requesting several nodes I have the same problems :(</div><=
div><br></div><div>Should Slurm have a special configuration to run mpi pro=
grams in parallel with singularity, apart from OpenMPI and PMIx? Also, shou=
ld I include other configuration in my container?=C2=A0</div><div><br></div=
><div>Thax for your help.</div><div><br></div><div>Carmen.</div><br>El mi=
=C3=A9rcoles, 6 de febrero de 2019, 15:33:36 (UTC+1), Fatih Ertinaz  escrib=
i=C3=B3:<blockquote class=3D"gmail_quote" style=3D"margin:0px 0px 0px 0.8ex=
;border-left:1px solid rgb(204,204,204);padding-left:1ex"><div dir=3D"ltr">=
Hello Carmen<div><br></div><div>To me this looks like an OpenMPI &amp; Slur=
m issue rather than an OF &amp; Slurm problem.=C2=A0</div><div><br></div><d=
iv>Few things you can check;</div><div>xx Try to execute simple jobs using =
Slurm, e.g. printing hostnames or mpi ping-pong stuff.=C2=A0</div><div>xx D=
o you know how OpenMPI is installed in the host? Maybe it is built with som=
e other underlying libraries regarding IB that you don&#39;t have in your c=
ontainer.</div><div><br></div><div>I&#39;d say if the first one works with =
hostnames then I&#39;d say focus on the OpenMPI installation.</div></div><b=
r><div class=3D"gmail_quote"><div dir=3D"ltr">On Wed, Feb 6, 2019 at 4:44 A=
M &#39;ccvera&#39; via singularity &lt;<a rel=3D"nofollow">si...@lbl.gov</a=
>&gt; wrote:<br></div><blockquote class=3D"gmail_quote" style=3D"margin:0px=
 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1ex"><di=
v dir=3D"ltr"><div>Thanks a lot for your quickly reply :)</div><div><br></d=
iv><div>This solution doesn&#39;t work for me. I tried to unset all SLURM e=
nvironment variables (first SLURM_JOBID, then SLURM_NODELIST and finally al=
l as you told me) and i obtain the same MPI error.=C2=A0</div><div><br></di=
v><div>Carmen</div><br>El martes, 5 de febrero de 2019, 17:56:27 (UTC+1), S=
henglong Wang  escribi=C3=B3:<blockquote class=3D"gmail_quote" style=3D"mar=
gin:0px 0px 0px 0.8ex;border-left:1px solid rgb(204,204,204);padding-left:1=
ex"><div>It seems=C2=A0<div><br></div><div>unset SLURM_JOBID</div><div><br>=
</div><div>is enough to cheat mpiexec</div><div><br></div><div>Shenglong<br=
><div><br><blockquote type=3D"cite"><div>On Feb 5, 2019, at 11:37 AM, Sheng=
long Wang &lt;<a rel=3D"nofollow">wa...@gmail.com</a>&gt; wrote:</div><br><=
div><div>Can you try to unset all SLURM environment variables?<div><br></di=
v><div><div>for e in $(env | egrep ^SLURM_ | cut -d=3D -f1); do unset $e; d=
one</div><div><br></div><div>or</div><div><br></div><div>unset SLURM_NODELI=
ST</div><div><br></div><div>But you=E2=80=99ll have to manually generate ho=
st file.</div><div><br></div><div>Best,</div><div>Shenglong</div><div><br><=
div><br><blockquote type=3D"cite"><div>On Feb 5, 2019, at 11:30 AM, &#39;cc=
vera&#39; via singularity &lt;<a rel=3D"nofollow">si...@lbl.gov</a>&gt; wro=
te:</div><br><div><div dir=3D"ltr"><div><div>Dear all,</div><div><br></div>=
<div>I&#39;m experiencing some issues running OpenFOAM over singularity wit=
h slurm.=C2=A0</div><div><br></div><div>I&#39;ve several images based on Ub=
untu and within several versions of OpenMPI and PMIx and i&#39;m able to ru=
n OpenFOAM correctly without use slurm (directly on the node) using next co=
mmand:</div><div><br></div><div>$ mpirun -n 16 singularity exec -B /home ..=
/../of6/openfoam6.x.img simpleFoam -parallel -case /home/carmen/test_singul=
arity/OpenFOAM/pruebaOF6_16cores_SLURM/pruebaOF6_16cores</div><div><br></di=
v><div>My problem comes when I run my program with slurm. Whether I make sa=
lloc or execute a script with sbatch, it shows me the following error:</div=
><div><br></div></div><blockquote style=3D"margin:0px 0px 0px 40px;border:n=
one;padding:0px"><blockquote style=3D"margin:0px 0px 0px 40px;border:none;p=
adding:0px"><div><div><font color=3D"#666666">It looks like MPI_INIT failed=
 for some reason; your parallel process is</font></div></div></blockquote><=
blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><=
div><font color=3D"#666666">likely to abort.=C2=A0 There are many reasons t=
hat a parallel process can</font></div></div></blockquote><blockquote style=
=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div><font color=
=3D"#666666">fail during MPI_INIT; some of which are due to configuration o=
r environment</font></div></div></blockquote><blockquote style=3D"margin:0p=
x 0px 0px 40px;border:none;padding:0px"><div><div><font color=3D"#666666">p=
roblems.=C2=A0 This failure appears to be an internal failure; here&#39;s s=
ome</font></div></div></blockquote><blockquote style=3D"margin:0px 0px 0px =
40px;border:none;padding:0px"><div><div><font color=3D"#666666">additional =
information (which may only be relevant to an Open MPI</font></div></div></=
blockquote><blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding=
:0px"><div><div><font color=3D"#666666">developer):</font></div></div></blo=
ckquote><blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0p=
x"><div><div><font color=3D"#666666"><br></font></div></div></blockquote><b=
lockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><d=
iv><font color=3D"#666666">=C2=A0 ompi_mpi_init: ompi_rte_init failed</font=
></div></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;bord=
er:none;padding:0px"><div><div><font color=3D"#666666">=C2=A0 --&gt; Return=
ed &quot;(null)&quot; (-43) instead of &quot;Success&quot; (0)</font></div>=
</div></blockquote></blockquote><div><div><br></div><div>and</div><div><br>=
</div></div><blockquote style=3D"margin:0px 0px 0px 40px;border:none;paddin=
g:0px"><blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px=
"><div><div><font color=3D"#666666">*** An error occurred in MPI_Init_threa=
d</font></div></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40=
px;border:none;padding:0px"><div><div><font color=3D"#666666">*** on a NULL=
 communicator</font></div></div></blockquote><blockquote style=3D"margin:0p=
x 0px 0px 40px;border:none;padding:0px"><div><div><font color=3D"#666666">*=
** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,</fo=
nt></div></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;bo=
rder:none;padding:0px"><div><div><font color=3D"#666666">***=C2=A0 =C2=A0 a=
nd potentially your MPI job)</font></div></div></blockquote><blockquote sty=
le=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div><font colo=
r=3D"#666666">[cn3045:369] Local abort before MPI_INIT completed completed =
successfully, but am not able to aggregate error messages, and not able to =
guarantee that all other processes were killed!</font></div></div></blockqu=
ote></blockquote><div><div><br></div><div>I know I must have the same openM=
PI versions on both (host and container) and I have also tried other versio=
ns of OpenMPI (2.X.X) and in all cases OpenFOAM works correctly, but at the=
 moment I want to run it with slurm it show me the errors.</div><div><br></=
div><div>I have also tried other ways to run the program with srun using th=
e option --mpi=3Dpmi2 (among others) but I always find the same problem.</d=
iv><div><br></div><div>I use the following script to run OpenFoam:</div></d=
iv><blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><d=
iv><div>----------------------------</div></div></blockquote><blockquote st=
yle=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><blockquote style=
=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div>#!/bin/bash<=
/div></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;border=
:none;padding:0px"><div><div><br></div></div></blockquote><blockquote style=
=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div>#SBATCH -N 1=
</div></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;borde=
r:none;padding:0px"><div><div>#SBATCH -p haswell=C2=A0</div></div></blockqu=
ote><blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><=
div><div>#SBATCH -J test_OpenFOAM</div></div></blockquote><blockquote style=
=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div>#SBATCH --ou=
tput=3D&quot;singularity.%j.o&quot;=C2=A0</div></div></blockquote><blockquo=
te style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div>#SBA=
TCH --error=3D&quot;singularity.%j.e&quot;</div></div></blockquote><blockqu=
ote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div><br=
></div></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;bord=
er:none;padding:0px"><div><div>module load haswell/singularity_2.6.0</div><=
/div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;border:none;=
padding:0px"><div><div>module load haswell/openmpi_3.1.2_gcc8.2.0_pmix</div=
></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;border:non=
e;padding:0px"><div><div><br></div></div></blockquote><blockquote style=3D"=
margin:0px 0px 0px 40px;border:none;padding:0px"><div><div>ulimit -s unlimi=
ted</div></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;bo=
rder:none;padding:0px"><div><div><br></div></div></blockquote><blockquote s=
tyle=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div>mpirun -=
n 16=C2=A0singularity exec ../../of6/openfoam6.x.img simpleFoam -parallel -=
case /home/software/test_singularity/OpenFOAM/pruebaOF6_16cores_SLURM/prueb=
aOF6_16cores</div></div></blockquote></blockquote><blockquote style=3D"marg=
in:0px 0px 0px 40px;border:none;padding:0px"><div><div>--------------------=
--------</div></div></blockquote><div><div><br></div><div>The versions that=
 I&#39;m using are:</div></div><blockquote style=3D"margin:0px 0px 0px 40px=
;border:none;padding:0px"><div><div><b>Host:=C2=A0</b></div></div></blockqu=
ote><blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><=
blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><=
div>OS: CentOS7.5</div></div></blockquote><blockquote style=3D"margin:0px 0=
px 0px 40px;border:none;padding:0px"><div><div>OpenMPI: 3.1.2</div></div></=
blockquote><blockquote style=3D"margin:0px 0px 0px 40px;border:none;padding=
:0px"><div><div>PMIx: 2.1.4</div></div></blockquote></blockquote><blockquot=
e style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div><br><=
/div></div><div><div><b>Container:</b></div></div></blockquote><blockquote =
style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><blockquote style=
=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><div>OS: Ubuntu16=
.04</div></div></blockquote><blockquote style=3D"margin:0px 0px 0px 40px;bo=
rder:none;padding:0px"><div><div>OpenMPI: 3.1.2</div></div></blockquote><bl=
ockquote style=3D"margin:0px 0px 0px 40px;border:none;padding:0px"><div><di=
v>PMIx: 2.1.4</div></div></blockquote></blockquote><div><div><br></div><div=
>Can it be a configuration problem of SLURM? Is there any limitation of SLU=
RM that is affecting OpenFOAM?</div><div><br></div><div>Some info about slu=
rm:</div></div><blockquote style=3D"margin:0px 0px 0px 40px;border:none;pad=
ding:0px"><div><div># srun --version</div></div><div><div>slurm 18.08.3</di=
v></div><div><div># srun --mpi=3Dlist</div></div><div><div>srun: MPI types =
are...</div></div><div><div>srun: pmi2</div></div><div><div>srun: openmpi</=
div></div><div><div>srun: none</div></div></blockquote><div><div><br></div>=
<div>I&#39;m a little bit lost with this issue :(</div><div>Can someone giv=
e me some lights?</div><div><br></div><div>Thanks a lot in advance,</div><d=
iv>Carmen</div></div><div><br></div></div><div><br></div>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</div></blockquote></div><br></div></div></div></div></blockquote></div><br=
></div></div></blockquote></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</blockquote></div>
</blockquote></div></blockquote></div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</blockquote></div>

--0000000000008f7da905816e5fab--

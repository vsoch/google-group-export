X-Received: by 2002:a65:4d8d:: with SMTP id p13-v6mr6119681pgq.179.1530631426599;
        Tue, 03 Jul 2018 08:23:46 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 2002:a65:6495:: with SMTP id e21-v6ls1509553pgv.1.gmail; Tue, 03
 Jul 2018 08:23:45 -0700 (PDT)
X-Received: by 2002:a62:c0c4:: with SMTP id g65-v6mr24504308pfk.72.1530631425263;
        Tue, 03 Jul 2018 08:23:45 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1530631425; cv=none;
        d=google.com; s=arc-20160816;
        b=DzIBX6lHcV+oyNLXiyCPfODFuF9Z56AqJ/IMIRIqEFLNosG/ZCtuQL9h1S7fnmu1kB
         k4Yi6eT/WnLUQ9HTYI45MO39LaVnPR2V/EYxC+s1Q4Hca80cNyp4BHtz1uQgDE2svilX
         6x9F9R8bTWMrHt6l3oa7I824ki6G+IGs7GO0yWg2FQEWzTTJPCU2up6ddY38FOBAJ3Di
         OYNvO/6UEYY9eIOaPPNPQgnBKAmt5tN0AYIVUUQ7bBcf7iK22QrIaUs3LD3/RYmSMhWk
         r1M4CZeiqtxtVZSDIPK1Ed4er6fVo0Gx4H6KrFkEnTUMFCneIA9+lb7FwNyUUoGxYcEQ
         heLw==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20160816;
        h=to:subject:message-id:date:from:references:in-reply-to:mime-version
         :dkim-signature:arc-authentication-results;
        bh=8+pkubnxfgY75ZC5nMkKI8uT+Xgs0/OtjNdgGUll7T8=;
        b=nCioZ5L1DwEcFMoieeg0BnKj5+gxyjadwUabnPYoeNb2J1WdrihKvKmu+kQEbqflEg
         182rRQPohE/nXmL3nsffd3VBFlWPaNgbnyc35zZrMRWVdktoP3lEYXaIOWqGjduN95U8
         t18b6JsMWRtMXoetqzsh+5LKcrPeNVVX2BA+zCaKS5ncw7ikeiDoLv5QPLALbikvL82L
         fIc/mmityZbD0Ahy5v/BnlI3q3nv9QC5zeDa6JWl1968QYI6Unz0FcyK4sKLVNfcHWvn
         P2hhV0wfE6WEZ6BI/gK5uMCgCHTPVJQ2FAbf1OZqJekzTZn2BKqb1FpSu5XltktJowTU
         0M7w==
ARC-Authentication-Results: i=1; mx.google.com;
       dkim=pass head...@cornell.edu header.s=g.20171207 header.b=GlAAKSrE;
       spf=pass (google.com: domain of be...@cornell.edu designates 209.85.214.46 as permitted sender) smtp.mailfrom=be...@cornell.edu
Return-Path: <be...@cornell.edu>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTP id s22-v6si1217633pgs.396.2018.07.03.08.23.44
        for <singu...@lbl.gov>;
        Tue, 03 Jul 2018 08:23:45 -0700 (PDT)
Received-SPF: pass (google.com: domain of be...@cornell.edu designates 209.85.214.46 as permitted sender) client-ip=209.85.214.46;
Authentication-Results: mx.google.com;
       dkim=pass head...@cornell.edu header.s=g.20171207 header.b=GlAAKSrE;
       spf=pass (google.com: domain of be...@cornell.edu designates 209.85.214.46 as permitted sender) smtp.mailfrom=be...@cornell.edu
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: =?us-ascii?q?A2BDAgAflDtbhi7WVdFQBAUDg1CBDH8og?=
 =?us-ascii?q?3MGgR2TDhmCB4gwjHgUgWMEIgEOgVCBPoE3ghohNBgBAgEBAgEBAgETAQEBCAs?=
 =?us-ascii?q?LCCkjDII1BQIDAh6CVwEBAgIBGgECBgQKDwEBDBcLCgQLCwsNIAEJAgIhAQ8DA?=
 =?us-ascii?q?QUBHA4HBAEUBgIEgjRLASiBPwMNCAUKnRI8iVcRM26BaTOBSoEnAQEFaYMzDUM?=
 =?us-ascii?q?BB2OBMggSiDUmgVY/gQ+CEX6CVjcLAQEBAYEfDAENBQEDBgJBGoI6glWHSQ0RC?=
 =?us-ascii?q?BWBMoMcjFArBwKBboQYhg5vghyBQEODSYJrhSCKNU+GdjCBIGsuPxsDDAgzGiV?=
 =?us-ascii?q?/BoIyCRaBVTAXg0VqgXqCMIJmglcdIzABCwSOIQEBDRcEAymBbQUBAQ?=
X-IronPort-AV: E=Sophos;i="5.51,304,1526367600"; 
   d="scan'208,217";a="28366443"
Received: from mail-it0-f46.google.com ([209.85.214.46])
  by fe4.lbl.gov with ESMTP; 03 Jul 2018 08:23:42 -0700
Received: by mail-it0-f46.google.com with SMTP id 16-v6so3633360itl.5
        for <singu...@lbl.gov>; Tue, 03 Jul 2018 08:23:42 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=cornell.edu; s=g.20171207;
        h=mime-version:in-reply-to:references:from:date:message-id:subject:to;
        bh=8+pkubnxfgY75ZC5nMkKI8uT+Xgs0/OtjNdgGUll7T8=;
        b=GlAAKSrENas1BoKmKVA9Kygukc4s9M7VGMRRy1Bb0labYtjG8M+YBogH28JAWsJley
         31oBqsvhhs5wQCy8QOWLKgsIhxxr2cUV6xYTLMK6aGN9v4MTvuN+wKP28tV/rqKltikD
         dKUc1ZiJoLq2zEP5SYo+3WylJd/EJ5MY8wkafm5oouSxcVAQLT0PHKmI9eGXY3C3jP8p
         5hpggatxySRnoNruuS09wasJ+q0XPij6VkdF1KGARIlmm12wrmU7D+bLqkcFc5XRB5l9
         ZbyOBmN+iMQ1ipnADYB6PS6is/cKrdCBmwmHTEaFrYyY81DzeTZ8JHAwKO9xXN+jf5H4
         Z5AA==
X-Gm-Message-State: APt69E1HP4bNaw866gZBAuxxzrlj/zx2Ql8kRlovGz6CJEdEWbwze5qO
	fntr8M+r70OOjz4tKuJMEGIZXQxx5ozHjcpiIBAhJ19UUzs=
X-Received: by 2002:a02:1cd:: with SMTP id 74-v6mr7392370jak.83.1530631421229;
 Tue, 03 Jul 2018 08:23:41 -0700 (PDT)
MIME-Version: 1.0
Received: by 2002:a6b:8e4d:0:0:0:0:0 with HTTP; Tue, 3 Jul 2018 08:23:40 -0700 (PDT)
In-Reply-To: <CAM=pu+JRrCB0+Xc+A9ogXvDbdqqkqzjsZwOhy3n7-WNH-ZV3tg@mail.gmail.com>
References: <4d550130-4d54-4d4f-bf9f-a46f34132e96@lbl.gov> <CAJZ53CkoPup6sXotzVLO_toCu2c+rwK-A6Y0+TU277Y9km8N9w@mail.gmail.com>
 <CAM=pu+Jq2HcgVEBoYJ-USVQomnT6=pmd_16UdEpz2nniPQewdw@mail.gmail.com>
 <CADf5cTEmD1BEEg=jQHf2rrK1h+cwPYYqSD3Tz0UKS-RpumNNRA@mail.gmail.com>
 <CAMsq4T1c4vA5Yv6_bWJhpNC=UCze1reP2yPQa2YUtutJRPzQbA@mail.gmail.com>
 <CAM=pu+L-DXgQJ4eSUqSEnriDX9U2+dwOU-e2P2gWFxW3jsPcWQ@mail.gmail.com>
 <CAPqNE2VEL6oOB2NMP89=BxHqQj5k=Mbg2C=7O=oZuRvN5Q-pnQ@mail.gmail.com>
 <CAPqNE2UYU6+k3k6eef49t1gUegbDRSAD5XyDAf28bQWEBKjCqg@mail.gmail.com>
 <CAM=pu++GTFfSA5riN7F7KmLzGR=U-TdbX1C9hJzD9x=-h-M_cw@mail.gmail.com>
 <CAMsq4T2BrK5ro0wuLdELmOTOeEgafW_OZ7c=s7QERA4K5_atwg@mail.gmail.com>
 <CAM=pu++W=8VQDYNfUbZhhNHtEHpYGXRgYre6_Aj_hPafHmr_DQ@mail.gmail.com>
 <CAM=pu+Jg+k=YZninbi8Wf4b-BVoW4R536rqAFJn6su_o-+0wOA@mail.gmail.com> <CAM=pu+JRrCB0+Xc+A9ogXvDbdqqkqzjsZwOhy3n7-WNH-ZV3tg@mail.gmail.com>
From: Brandon Barker <brando...@cornell.edu>
Date: Tue, 3 Jul 2018 11:23:40 -0400
Message-ID: <CAJZ53C=88GZCGuw-=uMkMwQiPTt5Qm6j2rkBAhW+p_EjfY484g@mail.gmail.com>
Subject: Re: [Singularity] Research data and containers
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary="000000000000251ee1057019e6a5"

--000000000000251ee1057019e6a5
Content-Type: text/plain; charset="UTF-8"

Sorry for the short reply earlier. Here is the service I was referring to:
https://codeocean.com/
Of course, there can be costs: https://codeocean.com/plans


On Thu, Jun 28, 2018 at 6:47 AM, v <vso...@gmail.com> wrote:

> Oh, and Chris (@chrisfilo on GitHub) wrote a nice article about data
> sharing:
>
> https://medium.com/@ChrisFiloG/liberating-data-an-
> interview-with-john-ioannidis-a71262047f17
>
> Good insights :)
>
> On Thu, Jun 28, 2018, 3:38 AM v <vso...@gmail.com> wrote:
>
>> There's also the interplanetary filesystem (peer to peer) idea...
>>
>> https://ipfs.io/
>>
>> But not sure that is taking feet yet?
>>
>> On Thu, Jun 28, 2018 at 3:37 AM v <vso...@gmail.com> wrote:
>>
>>> Figure out some model where you get some yuuuge company to host it via
>>> cloud storage, then mount the data easily as an instance. Grab the analysis
>>> container (and be sudo if you like, it's your cloud node to be
>>> irresponsible with) and run-all-the-things.
>>>
>>> And get your credit card bill after forgetting about the GPU node(s)
>>> over the weekend, cry softly, have a snack, feel better :)
>>>
>>> In all seriousness, this is a non-trivial problem. Someone has to pay
>>> for storage! It's not even a one time thing, it's a long term commitment to
>>> management of the data and access / tooling around it..
>>>
>>> On Thu, Jun 28, 2018 at 3:31 AM Maxime Hebrard <maxime...@gmail.com>
>>> wrote:
>>>
>>>> but that is the point ...
>>>> to say "yes, I ran the pipeline with your data, and can verify what
>>>> you claimed in the paper, I have replicated the result."
>>>> we need a way to get the hand on the original dataset
>>>>
>>>> well my personal problem is not really on "dataset" per se but more
>>>> with references data
>>>> like reference genome / indexes / annotation files
>>>> that are Huge and hard to manage :-/
>>>>
>>>> I could point to public repo for that, but still it is a pain for the
>>>> user to download (or let the container download for him) this huge
>>>> files :-/
>>>>
>>>> looking for a "better solution" ...
>>>>
>>>>
>>>>
>>>> On Thu, Jun 28, 2018 at 6:08 PM, v <vso...@gmail.com> wrote:
>>>> > All the cool kids are signing things these days!
>>>> > https://docs.docker.com/engine/security/trust/content_
>>>> trust/#image-tags-and-content-trust
>>>> > :P
>>>> >
>>>> > Dataset signing, especially for these fantastic "actually large"
>>>> datasets,
>>>> > seems to be taken with the same importance for reproducibility as the
>>>> tools
>>>> > that go into the anayses. To play devil's advocate, given that we
>>>> want to
>>>> > prove some phenomena, wouldn't we want to be able to show the same (or
>>>> > comparable within some range of confidence) result across different
>>>> > datasets? It doesn't strengthen the hypothsis to do the same thing
>>>> again on
>>>> > the exact same data, it strengthens the confidence in the
>>>> reproducibility of
>>>> > the pipeline (two separate things). So perhaps a small bit of data
>>>> could be
>>>> > stored with the container to validate the pipeline, but then new
>>>> samples
>>>> > encouraged to show if the hypothsis holds?
>>>> >
>>>> > And I'm probably off here, but I think the sharing of datasets is
>>>> less about
>>>> > "run it again on exactly the same data" but more about "share the
>>>> data so we
>>>> > can all learn from it and increase overall N for better power." A
>>>> culture of
>>>> > data sharing, along with validation of method + published result, also
>>>> > allows for checks and balances ("yes, I ran the pipeline with your
>>>> data, and
>>>> > can verify what you claimed in the paper, I have replicated the
>>>> result."
>>>> >
>>>> > On Thu, Jun 28, 2018 at 12:20 AM 'John Hearns' via singularity
>>>> > <singu...@lbl.gov> wrote:
>>>> >>
>>>> >> Chris Hines mentions signing of tool packages.  In danger of
>>>> crossing the
>>>> >> streams, I am an enthusiast for the Julia language.
>>>> >> the new Pkg3 infrastructure for Julia, which is the default package
>>>> >> manager now, implements UUIDs for packages
>>>> >> https://github.com/JuliaLang/Juleps/blob/master/Pkg3.md#registries
>>>> >>
>>>> >> On 28 June 2018 at 09:15, John Hearns <hea...@googlemail.com>
>>>> wrote:
>>>> >>>
>>>> >>> I think this a very, very interesting topic.  Please allow me to
>>>> explore
>>>> >>> and hopefully bring out some responses?
>>>> >>>
>>>> >>> Are we talking about large public datasets here - for instance I
>>>> worked
>>>> >>> on a CERN experiment (ahem) many years ago.
>>>> >>> One hopes that huge, public datasets do not change. For instance if
>>>> I
>>>> >>> went back to analyze what was tagged at the time with a run number
>>>> and an
>>>> >>> event number I hope I would get the same data.
>>>> >>> OK, it is clear that some large institutiosn worldwide will store
>>>> that
>>>> >>> data. And that bitrot or the scarcity of the tape drives to read
>>>> the data
>>>> >>> has not rendered it beyond recovery.
>>>> >>>
>>>> >>> I also worked with the JASMIN project in the UK, where several
>>>> institutes
>>>> >>> have banded together to create a central data store for climate
>>>> modelling.
>>>> >>> Again large public datasets.
>>>> >>>
>>>> >>> I also worked in Formula 1 with CFD engineers, and managed over a
>>>> >>> petabyte of data from CFD studies. Those studies were catalogued by
>>>> year and
>>>> >>> then case number.
>>>> >>> Again, we assume that the data is held on tape somewhere and if you
>>>> ind
>>>> >>> the correctly named directory you will get the same data back.
>>>> >>>
>>>> >>> I guess here we are talking about reproducibility. So we have a
>>>> >>> Singularity container, which is signed, and captures the packages
>>>> and
>>>> >>> libraries needed to run that analysis.
>>>> >>> We also have to have the same data available to run on.  Do we need
>>>> to
>>>> >>> physically keep that data 'beside' the container? Maybe, for
>>>> certain data
>>>> >>> and certain values of 'not too large'.
>>>> >>> but how about analyses of (say) CERN or JASMIN data? Is it enough
>>>> to make
>>>> >>> a pointer towards those datasets somehow?
>>>> >>> I would say URL's or URIs here, but we have seen how the Web is
>>>> dynamic
>>>> >>> and sites disappear and links change.
>>>> >>>
>>>> >>>
>>>> >>> Its worth saying that in the UK there is a lot of effort in this
>>>> space.
>>>> >>> The Research Councils there mandated that if they fund research the
>>>> data
>>>> >>> must be retained for N years (I forget N)
>>>> >>> So many Universities now have specific services for research data,
>>>> for
>>>> >>> instance:
>>>> >>> http://www.ucl.ac.uk/research-it-services/research-data-service
>>>> >>> https://www.ukdataservice.ac.uk/
>>>> >>>
>>>> >>> Arkivum https://arkivum.com/ works closely with the UK academic
>>>> network
>>>> >>> to provide large data storage. I just found this blog on their
>>>> website -
>>>> >>> well worth reading.
>>>> >>>
>>>> >>> https://arkivum.com/articles/blog-series-part-1-four-
>>>> economic-factors-make-cost-nothing-expensive-something/
>>>> >>>
>>>> >>> https://arkivum.com/pharma/blog-series-part-4-final-
>>>> economic-fallacy-long-term-data-temporarily-dynamic-path-dependent/
>>>> >>>
>>>> >>>
>>>> >>> To end up, I guess what we are aiming towards is an S3 compatible
>>>> storage
>>>> >>> bucket, whether this is hosted in-house, by Amazon or by a
>>>> compatible
>>>> >>> provider.
>>>> >>> Such a bucket would have to be locked, and signed.  Ideas??
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>>
>>>> >>> On 28 June 2018 at 03:44, v <vso...@gmail.com> wrote:
>>>> >>>>
>>>> >>>> Your description of the different components is on point.
>>>> >>>>
>>>> >>>> Finding hosting for large data is, and will continue to be, always
>>>> one
>>>> >>>> of the biggest problems. It's expensive. Someone has to pay for
>>>> it. Nobody
>>>> >>>> will do it for you for free. We are lucky to have things like
>>>> Github repos,
>>>> >>>> Google Drive, Dropbox, that gives some (mediocre) access to small
>>>> data. For
>>>> >>>> large data, everyone is pretty much on their own. Most academics
>>>> have a
>>>> >>>> university that provides some sort of web space / library data
>>>> archive, and
>>>> >>>> if you are publishing, some journals will support it too -->
>>>> >>>> https://www.nature.com/sdata/policies/repositories. I try to
>>>> figure out
>>>> >>>> hacks to get everything hosted, for free, in version control, but
>>>> that
>>>> >>>> breaks when anything gets large.
>>>> >>>>
>>>> >>>> The entity that manages a data respository, if this is a thing,
>>>> must
>>>> >>>> have incentive to do it. The datasets have to bring in money in
>>>> some way, or
>>>> >>>> someone has to value it enough to pay for it. That's sort of what
>>>> most
>>>> >>>> things come down to, unfortunately.
>>>> >>>>
>>>> >>>>
>>>> >>>> On Wed, Jun 27, 2018 at 6:38 PM Maxime Hebrard
>>>> >>>> <maxime...@gmail.com> wrote:
>>>> >>>>>
>>>> >>>>> I start to use singularity / containers and obviously I ran into
>>>> the
>>>> >>>>> same question ...
>>>> >>>>>
>>>> >>>>> a half solution that I found by exploring existing solution
>>>> (thanks to
>>>> >>>>> nf-core and SciLifeLab to share their workflow / containers) is (
>>>> as
>>>> >>>>> far I understand ):
>>>> >>>>>
>>>> >>>>> the container encapsulate only the sorftware.
>>>> >>>>> the data are store in external repositories.
>>>> >>>>>
>>>> >>>>> the user receive the container.
>>>> >>>>>
>>>> >>>>> case 1:
>>>> >>>>> the user download the data by himself and point his files to the
>>>> >>>>> container
>>>> >>>>> the container use local files as resources
>>>> >>>>> pros:
>>>> >>>>>  * the container is slim
>>>> >>>>>  * user can store the data on machine A (data server) and run the
>>>> >>>>> software on machine B (analyse server)
>>>> >>>>> cons:
>>>> >>>>> * user is involved in downloading the right data
>>>> >>>>>
>>>> >>>>> case 2:
>>>> >>>>> the user do not have the data
>>>> >>>>> the container download the data from the external repository
>>>> >>>>> the container use the data it just download
>>>> >>>>> pro:
>>>> >>>>> * the container manage everything
>>>> >>>>> cons:
>>>> >>>>> * the step of downloading the data require bandwith + disk space =
>>>> >>>>> time and resources
>>>> >>>>>
>>>> >>>>> a general worry for both scenarii is:
>>>> >>>>> who manage the data repository ? can we ensure the version of the
>>>> data
>>>> >>>>> package will be maintain ?
>>>> >>>>>
>>>> >>>>> Waiting for your feedback ;)
>>>> >>>>> Maxime
>>>> >>>>>
>>>> >>>>> On Thu, Jun 28, 2018 at 8:15 AM, 'Chris Hines' via singularity
>>>> >>>>> <singu...@lbl.gov> wrote:
>>>> >>>>> > To quote 90's band "The Offspring" IMHO "You gotta keep 'em
>>>> >>>>> > separated"
>>>> >>>>> >
>>>> >>>>> > Personally I think this is a larger question: How do we (as
>>>> research
>>>> >>>>> > software engineers, or whatever you would like to call us today)
>>>> >>>>> > catalog and
>>>> >>>>> > attach references (DOI's I guess) to larger data sets. Does it
>>>> make
>>>> >>>>> > sense to
>>>> >>>>> > mksquashfs or tar.bz2? What if they are already in a single hdf5
>>>> >>>>> > file? And
>>>> >>>>> > what about the output data set? we obviously want that to land
>>>> >>>>> > outside the
>>>> >>>>> > computational container, but how should we package the output
>>>> so it
>>>> >>>>> > can be
>>>> >>>>> > referenced directly? How do we make that whole thing
>>>> discoverable and
>>>> >>>>> > encourage researchers to attach sufficient metadata to make it
>>>> >>>>> > searchable?
>>>> >>>>> >
>>>> >>>>> > I'm wondering if part of the solution is some sort of "meta
>>>> >>>>> > container" that
>>>> >>>>> > downloads a set of versioned data with specific checksums, and a
>>>> >>>>> > versioned
>>>> >>>>> > tool container with a specific checksum, and attaches them in a
>>>> >>>>> > reproducible
>>>> >>>>> > way.
>>>> >>>>> >
>>>> >>>>> > To address Dominque's question directly: I'd keep the
>>>> >>>>> > "semi-separated".
>>>> >>>>> > Whatever your researchers use for archiving/cataloging/managing
>>>> their
>>>> >>>>> > data
>>>> >>>>> > sets, keep that in place and add the singularity container to
>>>> the
>>>> >>>>> > data set
>>>> >>>>> > (rather than adding the data set to the singularity container).
>>>> >>>>> >
>>>> >>>>> > Regards,
>>>> >>>>> > --
>>>> >>>>> > Chris.
>>>> >>>>> > Monash eResearch Centre, Monash University, Australia
>>>> >>>>> >
>>>> >>>>> > On Thu, 28 Jun 2018 at 01:19, v <vso...@gmail.com> wrote:
>>>> >>>>> >>
>>>> >>>>> >> If you are making containers with singularity (and using
>>>> Squashfs
>>>> >>>>> >> anyway)
>>>> >>>>> >> it wouldn't be so nutty to just compress with mksquashfs and
>>>> then
>>>> >>>>> >> mount
>>>> >>>>> >> where needed - I did this with a huge dataset and it worked
>>>> pretty
>>>> >>>>> >> nicely
>>>> >>>>> >> :_) It relies on FUSE then and all the issues around that, but
>>>> it's
>>>> >>>>> >> an
>>>> >>>>> >> option!
>>>> >>>>> >>
>>>> >>>>> >> This is good showing of how use use mksquashfs (it's really
>>>> >>>>> >> simple,actually!) -->
>>>> >>>>> >> http://tldp.org/HOWTO/SquashFS-HOWTO/creatingandusing.html
>>>> >>>>> >> And then mount -->
>>>> >>>>> >> https://vsoch.github.io/datasets/2018/zenodo/#mount-with-sudo
>>>> >>>>> >>
>>>> >>>>> >> On Wed, Jun 27, 2018 at 8:14 AM Brandon Barker
>>>> >>>>> >> <brando...@cornell.edu> wrote:
>>>> >>>>> >>>
>>>> >>>>> >>> I seem to recall code ocean may have explored this idea.
>>>> Sorry I
>>>> >>>>> >>> can't
>>>> >>>>> >>> say more, at the moment.
>>>> >>>>> >>>
>>>> >>>>> >>> On Wed, Jun 27, 2018, 8:50 AM Dominique Hansen
>>>> >>>>> >>> <dominiqu...@gmail.com> wrote:
>>>> >>>>> >>>>
>>>> >>>>> >>>> Hello everyone,
>>>> >>>>> >>>>
>>>> >>>>> >>>> I am seeking for tips and experience on how to handle
>>>> research
>>>> >>>>> >>>> data,
>>>> >>>>> >>>> especially bigger sets of data (inside the GB range), in
>>>> >>>>> >>>> combination with
>>>> >>>>> >>>> containers.
>>>> >>>>> >>>>
>>>> >>>>> >>>> I am a student assistant working in the IT department of a
>>>> >>>>> >>>> research
>>>> >>>>> >>>> institute. And I am involved in building the infrastructure
>>>> for
>>>> >>>>> >>>> singularity
>>>> >>>>> >>>> containerization and introducing researchers to the
>>>> technology. We
>>>> >>>>> >>>> have
>>>> >>>>> >>>> already build a few base images containing frequently used
>>>> tools.
>>>> >>>>> >>>> Recently a
>>>> >>>>> >>>> research group approached us, wishing to integrate data, they
>>>> >>>>> >>>> created for
>>>> >>>>> >>>> one tool, into a container with the tool. The data takes up
>>>> >>>>> >>>> several GB of
>>>> >>>>> >>>> disk space and we are unsure how to handle this and similar
>>>> future
>>>> >>>>> >>>> use
>>>> >>>>> >>>> cases.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Does anyone have a set of best practices or is there an
>>>> intended
>>>> >>>>> >>>> way to
>>>> >>>>> >>>> use singularity with big research data?
>>>> >>>>> >>>>
>>>> >>>>> >>>> The options we considered are:
>>>> >>>>> >>>>
>>>> >>>>> >>>> Moving the data into the container at build time.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Pro:
>>>> >>>>> >>>>
>>>> >>>>> >>>> Keeps the whole thing mobile
>>>> >>>>> >>>> Keeps work away from the researchers
>>>> >>>>> >>>> Can be referenced as a single entity in a publication.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Con:
>>>> >>>>> >>>>
>>>> >>>>> >>>> Where would you store such big containers, especially
>>>> several of
>>>> >>>>> >>>> them?
>>>> >>>>> >>>> What would happen, if separate versions of the tool are
>>>> needed?
>>>> >>>>> >>>> Keep the
>>>> >>>>> >>>> old and accumulate redundant data? Delete the old and risk
>>>> >>>>> >>>> reproducibility
>>>> >>>>> >>>> problems? (Maybe container Apps can be used to minimize
>>>> this.)
>>>> >>>>> >>>>
>>>> >>>>> >>>> Let the researchers mount the data into the container at
>>>> startup.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Pro:
>>>> >>>>> >>>>
>>>> >>>>> >>>> Keeps the containers slimmer, the tools more modular.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Con:
>>>> >>>>> >>>>
>>>> >>>>> >>>> Adds to the workload and the things the researchers have to
>>>> keep
>>>> >>>>> >>>> track
>>>> >>>>> >>>> of.
>>>> >>>>> >>>> Spreads the parts needed for reproduction over at least two
>>>> >>>>> >>>> points.
>>>> >>>>> >>>> Hampers mobility.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Mounting during early phases and publish with a container,
>>>> >>>>> >>>> containing
>>>> >>>>> >>>> the data.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Pro:
>>>> >>>>> >>>>
>>>> >>>>> >>>> Reduces amount of containers with redundant and deprecated
>>>> data.
>>>> >>>>> >>>> Makes reproduction of results easier after publication.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Con:
>>>> >>>>> >>>>
>>>> >>>>> >>>> Ads to the workload.
>>>> >>>>> >>>> When is the point when its time to "freeze" the data inside
>>>> the
>>>> >>>>> >>>> container?
>>>> >>>>> >>>> Storage of the container is still problematic.
>>>> >>>>> >>>> Might introduce reproducibility problems, since you change
>>>> the
>>>> >>>>> >>>> original
>>>> >>>>> >>>> container to put the data into it.
>>>> >>>>> >>>>
>>>> >>>>> >>>> Are there any recommendations from experience?
>>>> >>>>> >>>>
>>>> >>>>> >>>> Thank you and best regards,
>>>> >>>>> >>>> Dominique
>>>> >>>>> >>>>
>>>> >>>>> >>>> --
>>>> >>>>> >>>> You received this message because you are subscribed to the
>>>> Google
>>>> >>>>> >>>> Groups "singularity" group.
>>>> >>>>> >>>> To unsubscribe from this group and stop receiving emails
>>>> from it,
>>>> >>>>> >>>> send
>>>> >>>>> >>>> an email to singu...@lbl.gov.
>>>> >>>>> >>>
>>>> >>>>> >>> --
>>>> >>>>> >>> You received this message because you are subscribed to the
>>>> Google
>>>> >>>>> >>> Groups
>>>> >>>>> >>> "singularity" group.
>>>> >>>>> >>> To unsubscribe from this group and stop receiving emails from
>>>> it,
>>>> >>>>> >>> send an
>>>> >>>>> >>> email to singu...@lbl.gov.
>>>> >>>>> >>>
>>>> >>>>> >>> --
>>>> >>>>> >>> Vanessa Villamia Sochat
>>>> >>>>> >>> Stanford University '16
>>>> >>>>> >>> (603) 321-0676
>>>> >>>>> >>
>>>> >>>>> >> --
>>>> >>>>> >> You received this message because you are subscribed to the
>>>> Google
>>>> >>>>> >> Groups
>>>> >>>>> >> "singularity" group.
>>>> >>>>> >> To unsubscribe from this group and stop receiving emails from
>>>> it,
>>>> >>>>> >> send an
>>>> >>>>> >> email to singu...@lbl.gov.
>>>> >>>>> >
>>>> >>>>> > --
>>>> >>>>> > You received this message because you are subscribed to the
>>>> Google
>>>> >>>>> > Groups
>>>> >>>>> > "singularity" group.
>>>> >>>>> > To unsubscribe from this group and stop receiving emails from
>>>> it,
>>>> >>>>> > send an
>>>> >>>>> > email to singu...@lbl.gov.
>>>> >>>>>
>>>> >>>>> --
>>>> >>>>> You received this message because you are subscribed to the Google
>>>> >>>>> Groups "singularity" group.
>>>> >>>>> To unsubscribe from this group and stop receiving emails from it,
>>>> send
>>>> >>>>> an email to singu...@lbl.gov.
>>>> >>>>
>>>> >>>>
>>>> >>>>
>>>> >>>> --
>>>> >>>> Vanessa Villamia Sochat
>>>> >>>> Stanford University '16
>>>> >>>> (603) 321-0676
>>>> >>>>
>>>> >>>> --
>>>> >>>> You received this message because you are subscribed to the Google
>>>> >>>> Groups "singularity" group.
>>>> >>>> To unsubscribe from this group and stop receiving emails from it,
>>>> send
>>>> >>>> an email to singu...@lbl.gov.
>>>> >>>
>>>> >>>
>>>> >>
>>>> >> --
>>>> >> You received this message because you are subscribed to the Google
>>>> Groups
>>>> >> "singularity" group.
>>>> >> To unsubscribe from this group and stop receiving emails from it,
>>>> send an
>>>> >> email to singu...@lbl.gov.
>>>> >>
>>>> >> --
>>>> >> Vanessa Villamia Sochat
>>>> >> Stanford University '16
>>>> >> (603) 321-0676
>>>> >
>>>> > --
>>>> > You received this message because you are subscribed to the Google
>>>> Groups
>>>> > "singularity" group.
>>>> > To unsubscribe from this group and stop receiving emails from it,
>>>> send an
>>>> > email to singu...@lbl.gov.
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>> --
>>>> Vanessa Villamia Sochat
>>>> Stanford University '16
>>>> (603) 321-0676
>>>>
>>>> --
>>>> Vanessa Villamia Sochat
>>>> Stanford University '16
>>>> (603) 321-0676
>>>>
>>> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>



-- 
Brandon E. Barker
http://www.cac.cornell.edu/barker/

--000000000000251ee1057019e6a5
Content-Type: text/html; charset="UTF-8"
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div>Sorry for the short reply earlier. Here is the servic=
e I was referring to: <a href=3D"https://codeocean.com/">https://codeocean.=
com/</a></div><div>Of course, there can be costs: <a href=3D"https://codeoc=
ean.com/plans">https://codeocean.com/plans</a><br></div><br></div><div clas=
s=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Jun 28, 2018 at 6:=
47 AM, v <span dir=3D"ltr">&lt;<a href=3D"mailto:vso...@gmail.com" target=
=3D"_blank">vso...@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"=
gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-=
left:1ex"><div dir=3D"auto">Oh, and Chris (@chrisfilo on GitHub) wrote a ni=
ce article about data sharing:<div dir=3D"auto"><br></div><div dir=3D"auto"=
><a href=3D"https://medium.com/@ChrisFiloG/liberating-data-an-interview-wit=
h-john-ioannidis-a71262047f17" target=3D"_blank">https://medium.com/@<wbr>C=
hrisFiloG/liberating-data-an-<wbr>interview-with-john-ioannidis-<wbr>a71262=
047f17</a><br></div><div dir=3D"auto"><br></div><div dir=3D"auto">Good insi=
ghts :)</div></div><div class=3D"HOEnZb"><div class=3D"h5"><br><div class=
=3D"gmail_quote"><div dir=3D"ltr">On Thu, Jun 28, 2018, 3:38 AM v &lt;<a hr=
ef=3D"mailto:vso...@gmail.com" target=3D"_blank">vso...@gmail.com</a>&gt; w=
rote:<br></div><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex=
;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">There&#39;s =
also the interplanetary filesystem (peer to peer) idea...<div><br></div><di=
v><a href=3D"https://ipfs.io/" rel=3D"noreferrer" target=3D"_blank">https:/=
/ipfs.io/</a><br></div><div><br></div><div>But not sure that is taking feet=
 yet?</div></div><br><div class=3D"gmail_quote"><div dir=3D"ltr">On Thu, Ju=
n 28, 2018 at 3:37 AM v &lt;<a href=3D"mailto:vso...@gmail.com" rel=3D"nore=
ferrer" target=3D"_blank">vso...@gmail.com</a>&gt; wrote:<br></div><blockqu=
ote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc s=
olid;padding-left:1ex"><div dir=3D"ltr">Figure out some model where you get=
 some yuuuge company to host it via cloud storage, then mount the data easi=
ly as an instance. Grab the analysis container (and be sudo if you like, it=
&#39;s your cloud node to be irresponsible with) and run-all-the-things.<di=
v><br></div><div>And get your credit card bill after forgetting about the G=
PU node(s) over the weekend, cry softly, have a snack, feel better :)</div>=
<div><br></div><div>In all seriousness, this is a non-trivial problem. Some=
one has to pay for storage! It&#39;s not even a one time thing, it&#39;s a =
long term commitment to management of the data and access / tooling around =
it..=C2=A0</div></div><br><div class=3D"gmail_quote"><div dir=3D"ltr">On Th=
u, Jun 28, 2018 at 3:31 AM Maxime Hebrard &lt;<a href=3D"mailto:maxime...@g=
mail.com" rel=3D"noreferrer" target=3D"_blank">maxime...@gmail.com</a>&gt; =
wrote:<br></div><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8e=
x;border-left:1px #ccc solid;padding-left:1ex">but that is the point ...<br=
>
to say &quot;yes, I ran the pipeline with your data, and can verify what<br=
>
you claimed in the paper, I have replicated the result.&quot;<br>
we need a way to get the hand on the original dataset<br>
<br>
well my personal problem is not really on &quot;dataset&quot; per se but mo=
re<br>
with references data<br>
like reference genome / indexes / annotation files<br>
that are Huge and hard to manage :-/<br>
<br>
I could point to public repo for that, but still it is a pain for the<br>
user to download (or let the container download for him) this huge<br>
files :-/<br>
<br>
looking for a &quot;better solution&quot; ...<br>
<br>
<br>
<br>
On Thu, Jun 28, 2018 at 6:08 PM, v &lt;<a href=3D"mailto:vso...@gmail.com" =
rel=3D"noreferrer" target=3D"_blank">vso...@gmail.com</a>&gt; wrote:<br>
&gt; All the cool kids are signing things these days!<br>
&gt; <a href=3D"https://docs.docker.com/engine/security/trust/content_trust=
/#image-tags-and-content-trust" rel=3D"noreferrer noreferrer" target=3D"_bl=
ank">https://docs.docker.com/<wbr>engine/security/trust/content_<wbr>trust/=
#image-tags-and-content-<wbr>trust</a><br>
&gt; :P<br>
&gt;<br>
&gt; Dataset signing, especially for these fantastic &quot;actually large&q=
uot; datasets,<br>
&gt; seems to be taken with the same importance for reproducibility as the =
tools<br>
&gt; that go into the anayses. To play devil&#39;s advocate, given that we =
want to<br>
&gt; prove some phenomena, wouldn&#39;t we want to be able to show the same=
 (or<br>
&gt; comparable within some range of confidence) result across different<br=
>
&gt; datasets? It doesn&#39;t strengthen the hypothsis to do the same thing=
 again on<br>
&gt; the exact same data, it strengthens the confidence in the reproducibil=
ity of<br>
&gt; the pipeline (two separate things). So perhaps a small bit of data cou=
ld be<br>
&gt; stored with the container to validate the pipeline, but then new sampl=
es<br>
&gt; encouraged to show if the hypothsis holds?<br>
&gt;<br>
&gt; And I&#39;m probably off here, but I think the sharing of datasets is =
less about<br>
&gt; &quot;run it again on exactly the same data&quot; but more about &quot=
;share the data so we<br>
&gt; can all learn from it and increase overall N for better power.&quot; A=
 culture of<br>
&gt; data sharing, along with validation of method + published result, also=
<br>
&gt; allows for checks and balances (&quot;yes, I ran the pipeline with you=
r data, and<br>
&gt; can verify what you claimed in the paper, I have replicated the result=
.&quot;<br>
&gt;<br>
&gt; On Thu, Jun 28, 2018 at 12:20 AM &#39;John Hearns&#39; via singularity=
<br>
&gt; &lt;<a href=3D"mailto:singu...@lbl.gov" rel=3D"noreferrer" target=3D"_=
blank">singu...@lbl.gov</a>&gt; wrote:<br>
&gt;&gt;<br>
&gt;&gt; Chris Hines mentions signing of tool packages.=C2=A0 In danger of =
crossing the<br>
&gt;&gt; streams, I am an enthusiast for the Julia language.<br>
&gt;&gt; the new Pkg3 infrastructure for Julia, which is the default packag=
e<br>
&gt;&gt; manager now, implements UUIDs for packages<br>
&gt;&gt; <a href=3D"https://github.com/JuliaLang/Juleps/blob/master/Pkg3.md=
#registries" rel=3D"noreferrer noreferrer" target=3D"_blank">https://github=
.com/JuliaLang/<wbr>Juleps/blob/master/Pkg3.md#<wbr>registries</a><br>
&gt;&gt;<br>
&gt;&gt; On 28 June 2018 at 09:15, John Hearns &lt;<a href=3D"mailto:hea...=
@googlemail.com" rel=3D"noreferrer" target=3D"_blank">hea...@googlemail.com=
</a>&gt; wrote:<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I think this a very, very interesting topic.=C2=A0 Please allo=
w me to explore<br>
&gt;&gt;&gt; and hopefully bring out some responses?<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Are we talking about large public datasets here - for instance=
 I worked<br>
&gt;&gt;&gt; on a CERN experiment (ahem) many years ago.<br>
&gt;&gt;&gt; One hopes that huge, public datasets do not change. For instan=
ce if I<br>
&gt;&gt;&gt; went back to analyze what was tagged at the time with a run nu=
mber and an<br>
&gt;&gt;&gt; event number I hope I would get the same data.<br>
&gt;&gt;&gt; OK, it is clear that some large institutiosn worldwide will st=
ore that<br>
&gt;&gt;&gt; data. And that bitrot or the scarcity of the tape drives to re=
ad the data<br>
&gt;&gt;&gt; has not rendered it beyond recovery.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I also worked with the JASMIN project in the UK, where several=
 institutes<br>
&gt;&gt;&gt; have banded together to create a central data store for climat=
e modelling.<br>
&gt;&gt;&gt; Again large public datasets.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I also worked in Formula 1 with CFD engineers, and managed ove=
r a<br>
&gt;&gt;&gt; petabyte of data from CFD studies. Those studies were catalogu=
ed by year and<br>
&gt;&gt;&gt; then case number.<br>
&gt;&gt;&gt; Again, we assume that the data is held on tape somewhere and i=
f you ind<br>
&gt;&gt;&gt; the correctly named directory you will get the same data back.=
<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; I guess here we are talking about reproducibility. So we have =
a<br>
&gt;&gt;&gt; Singularity container, which is signed, and captures the packa=
ges and<br>
&gt;&gt;&gt; libraries needed to run that analysis.<br>
&gt;&gt;&gt; We also have to have the same data available to run on.=C2=A0 =
Do we need to<br>
&gt;&gt;&gt; physically keep that data &#39;beside&#39; the container? Mayb=
e, for certain data<br>
&gt;&gt;&gt; and certain values of &#39;not too large&#39;.<br>
&gt;&gt;&gt; but how about analyses of (say) CERN or JASMIN data? Is it eno=
ugh to make<br>
&gt;&gt;&gt; a pointer towards those datasets somehow?<br>
&gt;&gt;&gt; I would say URL&#39;s or URIs here, but we have seen how the W=
eb is dynamic<br>
&gt;&gt;&gt; and sites disappear and links change.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Its worth saying that in the UK there is a lot of effort in th=
is space.<br>
&gt;&gt;&gt; The Research Councils there mandated that if they fund researc=
h the data<br>
&gt;&gt;&gt; must be retained for N years (I forget N)<br>
&gt;&gt;&gt; So many Universities now have specific services for research d=
ata, for<br>
&gt;&gt;&gt; instance:<br>
&gt;&gt;&gt; <a href=3D"http://www.ucl.ac.uk/research-it-services/research-=
data-service" rel=3D"noreferrer noreferrer" target=3D"_blank">http://www.uc=
l.ac.uk/research-<wbr>it-services/research-data-<wbr>service</a><br>
&gt;&gt;&gt; <a href=3D"https://www.ukdataservice.ac.uk/" rel=3D"noreferrer=
 noreferrer" target=3D"_blank">https://www.ukdataservice.ac.<wbr>uk/</a><br=
>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; Arkivum <a href=3D"https://arkivum.com/" rel=3D"noreferrer nor=
eferrer" target=3D"_blank">https://arkivum.com/</a> works closely with the =
UK academic network<br>
&gt;&gt;&gt; to provide large data storage. I just found this blog on their=
 website -<br>
&gt;&gt;&gt; well worth reading.<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; <a href=3D"https://arkivum.com/articles/blog-series-part-1-fou=
r-economic-factors-make-cost-nothing-expensive-something/" rel=3D"noreferre=
r noreferrer" target=3D"_blank">https://arkivum.com/articles/<wbr>blog-seri=
es-part-1-four-<wbr>economic-factors-make-cost-<wbr>nothing-expensive-somet=
hing/</a><br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; <a href=3D"https://arkivum.com/pharma/blog-series-part-4-final=
-economic-fallacy-long-term-data-temporarily-dynamic-path-dependent/" rel=
=3D"noreferrer noreferrer" target=3D"_blank">https://arkivum.com/pharma/<wb=
r>blog-series-part-4-final-<wbr>economic-fallacy-long-term-<wbr>data-tempor=
arily-dynamic-path-<wbr>dependent/</a><br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; To end up, I guess what we are aiming towards is an S3 compati=
ble storage<br>
&gt;&gt;&gt; bucket, whether this is hosted in-house, by Amazon or by a com=
patible<br>
&gt;&gt;&gt; provider.<br>
&gt;&gt;&gt; Such a bucket would have to be locked, and signed.=C2=A0 Ideas=
??<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt; On 28 June 2018 at 03:44, v &lt;<a href=3D"mailto:vso...@gmail=
.com" rel=3D"noreferrer" target=3D"_blank">vso...@gmail.com</a>&gt; wrote:<=
br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Your description of the different components is on point.<=
br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; Finding hosting for large data is, and will continue to be=
, always one<br>
&gt;&gt;&gt;&gt; of the biggest problems. It&#39;s expensive. Someone has t=
o pay for it. Nobody<br>
&gt;&gt;&gt;&gt; will do it for you for free. We are lucky to have things l=
ike Github repos,<br>
&gt;&gt;&gt;&gt; Google Drive, Dropbox, that gives some (mediocre) access t=
o small data. For<br>
&gt;&gt;&gt;&gt; large data, everyone is pretty much on their own. Most aca=
demics have a<br>
&gt;&gt;&gt;&gt; university that provides some sort of web space / library =
data archive, and<br>
&gt;&gt;&gt;&gt; if you are publishing, some journals will support it too -=
-&gt;<br>
&gt;&gt;&gt;&gt; <a href=3D"https://www.nature.com/sdata/policies/repositor=
ies" rel=3D"noreferrer noreferrer" target=3D"_blank">https://www.nature.com=
/sdata/<wbr>policies/repositories</a>. I try to figure out<br>
&gt;&gt;&gt;&gt; hacks to get everything hosted, for free, in version contr=
ol, but that<br>
&gt;&gt;&gt;&gt; breaks when anything gets large.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; The entity that manages a data respository, if this is a t=
hing, must<br>
&gt;&gt;&gt;&gt; have incentive to do it. The datasets have to bring in mon=
ey in some way, or<br>
&gt;&gt;&gt;&gt; someone has to value it enough to pay for it. That&#39;s s=
ort of what most<br>
&gt;&gt;&gt;&gt; things come down to, unfortunately.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; On Wed, Jun 27, 2018 at 6:38 PM Maxime Hebrard<br>
&gt;&gt;&gt;&gt; &lt;<a href=3D"mailto:maxime...@gmail.com" rel=3D"noreferr=
er" target=3D"_blank">maxime...@gmail.com</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; I start to use singularity / containers and obviously =
I ran into the<br>
&gt;&gt;&gt;&gt;&gt; same question ...<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; a half solution that I found by exploring existing sol=
ution (thanks to<br>
&gt;&gt;&gt;&gt;&gt; nf-core and SciLifeLab to share their workflow / conta=
iners) is ( as<br>
&gt;&gt;&gt;&gt;&gt; far I understand ):<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; the container encapsulate only the sorftware.<br>
&gt;&gt;&gt;&gt;&gt; the data are store in external repositories.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; the user receive the container.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; case 1:<br>
&gt;&gt;&gt;&gt;&gt; the user download the data by himself and point his fi=
les to the<br>
&gt;&gt;&gt;&gt;&gt; container<br>
&gt;&gt;&gt;&gt;&gt; the container use local files as resources<br>
&gt;&gt;&gt;&gt;&gt; pros:<br>
&gt;&gt;&gt;&gt;&gt;=C2=A0 * the container is slim<br>
&gt;&gt;&gt;&gt;&gt;=C2=A0 * user can store the data on machine A (data ser=
ver) and run the<br>
&gt;&gt;&gt;&gt;&gt; software on machine B (analyse server)<br>
&gt;&gt;&gt;&gt;&gt; cons:<br>
&gt;&gt;&gt;&gt;&gt; * user is involved in downloading the right data<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; case 2:<br>
&gt;&gt;&gt;&gt;&gt; the user do not have the data<br>
&gt;&gt;&gt;&gt;&gt; the container download the data from the external repo=
sitory<br>
&gt;&gt;&gt;&gt;&gt; the container use the data it just download<br>
&gt;&gt;&gt;&gt;&gt; pro:<br>
&gt;&gt;&gt;&gt;&gt; * the container manage everything<br>
&gt;&gt;&gt;&gt;&gt; cons:<br>
&gt;&gt;&gt;&gt;&gt; * the step of downloading the data require bandwith + =
disk space =3D<br>
&gt;&gt;&gt;&gt;&gt; time and resources<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; a general worry for both scenarii is:<br>
&gt;&gt;&gt;&gt;&gt; who manage the data repository ? can we ensure the ver=
sion of the data<br>
&gt;&gt;&gt;&gt;&gt; package will be maintain ?<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; Waiting for your feedback ;)<br>
&gt;&gt;&gt;&gt;&gt; Maxime<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; On Thu, Jun 28, 2018 at 8:15 AM, &#39;Chris Hines&#39;=
 via singularity<br>
&gt;&gt;&gt;&gt;&gt; &lt;<a href=3D"mailto:singu...@lbl.gov" rel=3D"norefer=
rer" target=3D"_blank">singu...@lbl.gov</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt; &gt; To quote 90&#39;s band &quot;The Offspring&quot; =
IMHO &quot;You gotta keep &#39;em<br>
&gt;&gt;&gt;&gt;&gt; &gt; separated&quot;<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; Personally I think this is a larger question: How=
 do we (as research<br>
&gt;&gt;&gt;&gt;&gt; &gt; software engineers, or whatever you would like to=
 call us today)<br>
&gt;&gt;&gt;&gt;&gt; &gt; catalog and<br>
&gt;&gt;&gt;&gt;&gt; &gt; attach references (DOI&#39;s I guess) to larger d=
ata sets. Does it make<br>
&gt;&gt;&gt;&gt;&gt; &gt; sense to<br>
&gt;&gt;&gt;&gt;&gt; &gt; mksquashfs or tar.bz2? What if they are already i=
n a single hdf5<br>
&gt;&gt;&gt;&gt;&gt; &gt; file? And<br>
&gt;&gt;&gt;&gt;&gt; &gt; what about the output data set? we obviously want=
 that to land<br>
&gt;&gt;&gt;&gt;&gt; &gt; outside the<br>
&gt;&gt;&gt;&gt;&gt; &gt; computational container, but how should we packag=
e the output so it<br>
&gt;&gt;&gt;&gt;&gt; &gt; can be<br>
&gt;&gt;&gt;&gt;&gt; &gt; referenced directly? How do we make that whole th=
ing discoverable and<br>
&gt;&gt;&gt;&gt;&gt; &gt; encourage researchers to attach sufficient metada=
ta to make it<br>
&gt;&gt;&gt;&gt;&gt; &gt; searchable?<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; I&#39;m wondering if part of the solution is some=
 sort of &quot;meta<br>
&gt;&gt;&gt;&gt;&gt; &gt; container&quot; that<br>
&gt;&gt;&gt;&gt;&gt; &gt; downloads a set of versioned data with specific c=
hecksums, and a<br>
&gt;&gt;&gt;&gt;&gt; &gt; versioned<br>
&gt;&gt;&gt;&gt;&gt; &gt; tool container with a specific checksum, and atta=
ches them in a<br>
&gt;&gt;&gt;&gt;&gt; &gt; reproducible<br>
&gt;&gt;&gt;&gt;&gt; &gt; way.<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; To address Dominque&#39;s question directly: I&#3=
9;d keep the<br>
&gt;&gt;&gt;&gt;&gt; &gt; &quot;semi-separated&quot;.<br>
&gt;&gt;&gt;&gt;&gt; &gt; Whatever your researchers use for archiving/catal=
oging/managing their<br>
&gt;&gt;&gt;&gt;&gt; &gt; data<br>
&gt;&gt;&gt;&gt;&gt; &gt; sets, keep that in place and add the singularity =
container to the<br>
&gt;&gt;&gt;&gt;&gt; &gt; data set<br>
&gt;&gt;&gt;&gt;&gt; &gt; (rather than adding the data set to the singulari=
ty container).<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; Regards,<br>
&gt;&gt;&gt;&gt;&gt; &gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt; Chris.<br>
&gt;&gt;&gt;&gt;&gt; &gt; Monash eResearch Centre, Monash University, Austr=
alia<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; On Thu, 28 Jun 2018 at 01:19, v &lt;<a href=3D"ma=
ilto:vso...@gmail.com" rel=3D"noreferrer" target=3D"_blank">vso...@gmail.co=
m</a>&gt; wrote:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; If you are making containers with singularity=
 (and using Squashfs<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; anyway)<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; it wouldn&#39;t be so nutty to just compress =
with mksquashfs and then<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; mount<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; where needed - I did this with a huge dataset=
 and it worked pretty<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; nicely<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; :_) It relies on FUSE then and all the issues=
 around that, but it&#39;s<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; an<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; option!<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; This is good showing of how use use mksquashf=
s (it&#39;s really<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; simple,actually!) --&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; <a href=3D"http://tldp.org/HOWTO/SquashFS-HOW=
TO/creatingandusing.html" rel=3D"noreferrer noreferrer" target=3D"_blank">h=
ttp://tldp.org/HOWTO/<wbr>SquashFS-HOWTO/<wbr>creatingandusing.html</a><br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; And then mount --&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; <a href=3D"https://vsoch.github.io/datasets/2=
018/zenodo/#mount-with-sudo" rel=3D"noreferrer noreferrer" target=3D"_blank=
">https://vsoch.github.io/<wbr>datasets/2018/zenodo/#mount-<wbr>with-sudo</=
a><br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; On Wed, Jun 27, 2018 at 8:14 AM Brandon Barke=
r<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; &lt;<a href=3D"mailto:brando...@cornell.edu" =
rel=3D"noreferrer" target=3D"_blank">brando...@cornell.edu</a>&gt; wrote:<b=
r>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; I seem to recall code ocean may have expl=
ored this idea. Sorry I<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; can&#39;t<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; say more, at the moment.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; On Wed, Jun 27, 2018, 8:50 AM Dominique H=
ansen<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; &lt;<a href=3D"mailto:dominiqu...@gmail.c=
om" rel=3D"noreferrer" target=3D"_blank">dominiqu...@gmail.com</a>&gt; wrot=
e:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Hello everyone,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; I am seeking for tips and experience =
on how to handle research<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; data,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; especially bigger sets of data (insid=
e the GB range), in<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; combination with<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; containers.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; I am a student assistant working in t=
he IT department of a<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; research<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; institute. And I am involved in build=
ing the infrastructure for<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; singularity<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; containerization and introducing rese=
archers to the technology. We<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; have<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; already build a few base images conta=
ining frequently used tools.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Recently a<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; research group approached us, wishing=
 to integrate data, they<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; created for<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; one tool, into a container with the t=
ool. The data takes up<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; several GB of<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; disk space and we are unsure how to h=
andle this and similar future<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; use<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; cases.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Does anyone have a set of best practi=
ces or is there an intended<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; way to<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; use singularity with big research dat=
a?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; The options we considered are:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Moving the data into the container at=
 build time.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Keeps the whole thing mobile<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Keeps work away from the researchers<=
br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Can be referenced as a single entity =
in a publication.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Where would you store such big contai=
ners, especially several of<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; them?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; What would happen, if separate versio=
ns of the tool are needed?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Keep the<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; old and accumulate redundant data? De=
lete the old and risk<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; reproducibility<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; problems? (Maybe container Apps can b=
e used to minimize this.)<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Let the researchers mount the data in=
to the container at startup.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Keeps the containers slimmer, the too=
ls more modular.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Adds to the workload and the things t=
he researchers have to keep<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; track<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; of.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Spreads the parts needed for reproduc=
tion over at least two<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; points.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Hampers mobility.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Mounting during early phases and publ=
ish with a container,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; containing<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; the data.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Pro:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Reduces amount of containers with red=
undant and deprecated=C2=A0 data.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Makes reproduction of results easier =
after publication.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Con:<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Ads to the workload.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; When is the point when its time to &q=
uot;freeze&quot; the data inside the<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; container?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Storage of the container is still pro=
blematic.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Might introduce reproducibility probl=
ems, since you change the<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; original<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; container to put the data into it.<br=
>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Are there any recommendations from ex=
perience?<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Thank you and best regards,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Dominique<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; You received this message because you=
 are subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.=
<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; To unsubscribe from this group and st=
op receiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; send<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;&gt; an email to <a href=3D"mailto:singula=
rity%...@lbl.gov" rel=3D"noreferrer" target=3D"_blank">singularity+unsubscr=
ibe@lbl.<wbr>gov</a>.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; You received this message because you are=
 subscribed to the Google<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; Groups<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; To unsubscribe from this group and stop r=
eceiving emails from it,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; send an<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; email to <a href=3D"mailto:singularity%..=
.@lbl.gov" rel=3D"noreferrer" target=3D"_blank">singularity+unsubscribe@lbl=
.<wbr>gov</a>.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; Vanessa Villamia Sochat<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; Stanford University &#39;16<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;&gt; (603) 321-0676<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; You received this message because you are sub=
scribed to the Google<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; Groups<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; To unsubscribe from this group and stop recei=
ving emails from it,<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; send an<br>
&gt;&gt;&gt;&gt;&gt; &gt;&gt; email to <a href=3D"mailto:singularity%...@lb=
l.gov" rel=3D"noreferrer" target=3D"_blank">singularity+unsubscribe@lbl.<wb=
r>gov</a>.<br>
&gt;&gt;&gt;&gt;&gt; &gt;<br>
&gt;&gt;&gt;&gt;&gt; &gt; --<br>
&gt;&gt;&gt;&gt;&gt; &gt; You received this message because you are subscri=
bed to the Google<br>
&gt;&gt;&gt;&gt;&gt; &gt; Groups<br>
&gt;&gt;&gt;&gt;&gt; &gt; &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; &gt; To unsubscribe from this group and stop receiving=
 emails from it,<br>
&gt;&gt;&gt;&gt;&gt; &gt; send an<br>
&gt;&gt;&gt;&gt;&gt; &gt; email to <a href=3D"mailto:singularity%...@lbl.go=
v" rel=3D"noreferrer" target=3D"_blank">singularity+unsubscribe@lbl.<wbr>go=
v</a>.<br>
&gt;&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt;&gt; You received this message because you are subscribed t=
o the Google<br>
&gt;&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emai=
ls from it, send<br>
&gt;&gt;&gt;&gt;&gt; an email to <a href=3D"mailto:singularity%...@lbl.gov"=
 rel=3D"noreferrer" target=3D"_blank">singularity+unsubscribe@lbl.<wbr>gov<=
/a>.<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt; Vanessa Villamia Sochat<br>
&gt;&gt;&gt;&gt; Stanford University &#39;16<br>
&gt;&gt;&gt;&gt; (603) 321-0676<br>
&gt;&gt;&gt;&gt;<br>
&gt;&gt;&gt;&gt; --<br>
&gt;&gt;&gt;&gt; You received this message because you are subscribed to th=
e Google<br>
&gt;&gt;&gt;&gt; Groups &quot;singularity&quot; group.<br>
&gt;&gt;&gt;&gt; To unsubscribe from this group and stop receiving emails f=
rom it, send<br>
&gt;&gt;&gt;&gt; an email to <a href=3D"mailto:singularity%...@lbl.gov" rel=
=3D"noreferrer" target=3D"_blank">singularity+unsubscribe@lbl.<wbr>gov</a>.=
<br>
&gt;&gt;&gt;<br>
&gt;&gt;&gt;<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; You received this message because you are subscribed to the Google=
 Groups<br>
&gt;&gt; &quot;singularity&quot; group.<br>
&gt;&gt; To unsubscribe from this group and stop receiving emails from it, =
send an<br>
&gt;&gt; email to <a href=3D"mailto:singularity%...@lbl.gov" rel=3D"norefer=
rer" target=3D"_blank">singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
&gt;&gt;<br>
&gt;&gt; --<br>
&gt;&gt; Vanessa Villamia Sochat<br>
&gt;&gt; Stanford University &#39;16<br>
&gt;&gt; (603) 321-0676<br>
&gt;<br>
&gt; --<br>
&gt; You received this message because you are subscribed to the Google Gro=
ups<br>
&gt; &quot;singularity&quot; group.<br>
&gt; To unsubscribe from this group and stop receiving emails from it, send=
 an<br>
&gt; email to <a href=3D"mailto:singularity%...@lbl.gov" rel=3D"noreferrer"=
 target=3D"_blank">singularity+unsubscribe@lbl.<wbr>gov</a>.<br>
<br>
-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singularity%...@lbl.gov" rel=3D"noreferrer" targe=
t=3D"_blank">singularity+unsubscribe@lbl.<wbr>gov</a>.<br clear=3D"all"><di=
v><br></div>-- <br><div dir=3D"ltr" class=3D"m_4101311823605881321m_9222356=
217056320682m_1012473880129367663gmail_signature" data-smartmail=3D"gmail_s=
ignature"><div class=3D"m_4101311823605881321m_9222356217056320682m_1012473=
880129367663gmail_signature" data-smartmail=3D"gmail_signature">Vanessa Vil=
lamia Sochat<br>Stanford University &#39;16<br><div><div><div>(603) 321-067=
6<br clear=3D"all"><div><br></div>-- <br><div dir=3D"ltr" class=3D"m_410131=
1823605881321m_9222356217056320682gmail_signature" data-smartmail=3D"gmail_=
signature"><div class=3D"m_4101311823605881321m_9222356217056320682gmail_si=
gnature" data-smartmail=3D"gmail_signature">Vanessa Villamia Sochat<br>Stan=
ford University &#39;16<br><div><div><div>(603) 321-0676</div></div></div><=
/div></div></div></div></div></div></div></blockquote></div></blockquote></=
div>
</blockquote></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><br>-- <br><div class=
=3D"gmail_signature" data-smartmail=3D"gmail_signature"><div dir=3D"ltr">Br=
andon E. Barker<br><a href=3D"http://www.cac.cornell.edu/barker/" target=3D=
"_blank">http://www.cac.cornell.edu/barker/</a><br></div></div>
</div>

--000000000000251ee1057019e6a5--

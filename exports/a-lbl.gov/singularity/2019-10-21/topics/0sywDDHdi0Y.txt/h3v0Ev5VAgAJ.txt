X-Received: by 10.36.76.139 with SMTP id a133mr4100909itb.8.1466528897357;
        Tue, 21 Jun 2016 10:08:17 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.130.202 with SMTP id m71ls697734ioi.68.gmail; Tue, 21 Jun
 2016 10:08:16 -0700 (PDT)
X-Received: by 10.98.208.197 with SMTP id p188mr21358281pfg.152.1466528896787;
        Tue, 21 Jun 2016 10:08:16 -0700 (PDT)
Return-Path: <bge...@riken.jp>
Received: from fe4.lbl.gov (fe4.lbl.gov. [128.3.41.71])
        by mx.google.com with ESMTPS id bc14si11070065pac.238.2016.06.21.10.08.16
        for <singu...@lbl.gov>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Tue, 21 Jun 2016 10:08:16 -0700 (PDT)
Received-SPF: pass (google.com: domain of bge...@riken.jp designates 134.160.33.85 as permitted sender) client-ip=134.160.33.85;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of bge...@riken.jp designates 134.160.33.85 as permitted sender) smtp.mailfrom=bge...@riken.jp
X-Ironport-SBRS: 3.5
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A0D+AQDQc2lXh1UhoIZdHAEBglKCIQaDNqs4hwGGcwgXAYV/AoEwQxABAQEBAQEBEgEBAQoLCQkhL4RLAQEBAQIBEhErMAsLCw0qAgIhAQ8DAQUBHA4HBAEcBAGHdAMPCAWjUIExPjGLO4Ykhi0Ng3UBCgEBASOGJ4NKgQOCQ4FPEQGDHYJaBY5piVw0jDKBeo8jiAuGLhIegQ81gjiBd04HiQyBNQEBAQ
X-IPAS-Result: A0D+AQDQc2lXh1UhoIZdHAEBglKCIQaDNqs4hwGGcwgXAYV/AoEwQxABAQEBAQEBEgEBAQoLCQkhL4RLAQEBAQIBEhErMAsLCw0qAgIhAQ8DAQUBHA4HBAEcBAGHdAMPCAWjUIExPjGLO4Ykhi0Ng3UBCgEBASOGJ4NKgQOCQ4FPEQGDHYJaBY5piVw0jDKBeo8jiAuGLhIegQ81gjiBd04HiQyBNQEBAQ
X-IronPort-AV: E=Sophos;i="5.26,505,1459839600"; 
   d="scan'208,217";a="27002002"
Received: from postman3.riken.jp (HELO postman.riken.jp) ([134.160.33.85])
  by fe4.lbl.gov with ESMTP; 21 Jun 2016 10:08:14 -0700
Received: from postman.riken.jp (localhost.localdomain [127.0.0.1])
	by postman.riken.jp (Postfix) with SMTP id 1E82F9411D
	for <singu...@lbl.gov>; Wed, 22 Jun 2016 02:08:14 +0900 (JST)
Received: from mail-it0-f43.google.com (mail-it0-f43.google.com [209.85.214.43])
	by postman.riken.jp (Postfix) with ESMTPA id 103159411B
	for <singu...@lbl.gov>; Wed, 22 Jun 2016 02:08:13 +0900 (JST)
Received: by mail-it0-f43.google.com with SMTP id a5so78756749ita.1
        for <singu...@lbl.gov>; Tue, 21 Jun 2016 10:08:12 -0700 (PDT)
X-Gm-Message-State: ALyK8tIrPuUmuQfjLLDdVpcTYnD/luuQP8YzlrRA/tjWyIaslMAX5Ev+dfHczoScdgcrgKwzCqHmXgS3XJYgsA==
X-Received: by 10.36.105.77 with SMTP id e74mr7134683itc.17.1466528892228;
 Tue, 21 Jun 2016 10:08:12 -0700 (PDT)
MIME-Version: 1.0
Reply-To: bge...@riken.jp
Received: by 10.50.18.103 with HTTP; Tue, 21 Jun 2016 10:08:11 -0700 (PDT)
In-Reply-To: <90C46E72-DE5B-491A-A596-87D4B65DBCB2@open-mpi.org>
References: <6247ec64-6881-4978-82a0-f7d6e24039e9@lbl.gov> <244D668A-1EB7-412D-9303-E52F5412409C@open-mpi.org>
 <CAPqNE2WY31aOinCS12uqJD-wXQNUGBaEr6irHuSQMGGp=47SDQ@mail.gmail.com>
 <CAHCZMOGATFSE2HmNoi=XocaxC6g=V2yeaiegi04RU07j792U0g@mail.gmail.com>
 <CAPVZOdEgH-K-ieiMaA62TOXqGF2+hRNCexK6v8ZrBfXCcj_F0g@mail.gmail.com> <90C46E72-DE5B-491A-A596-87D4B65DBCB2@open-mpi.org>
From: Balazs Gerofi <bge...@riken.jp>
Date: Tue, 21 Jun 2016 10:08:11 -0700
X-Gmail-Original-Message-ID: <CAPVZOdEOXEOj_fLKAEzhH...@mail.gmail.com>
Message-ID: <CAPVZOdEOXEOj_fLKAEzhHrwRwjmvr0K8yHmNh2bXKMFe+6MDCA@mail.gmail.com>
Subject: Re: [Singularity] Communication between singularity containers
To: singularity@lbl.gov
Content-Type: multipart/alternative; boundary=001a1145302eac9d8f0535ccdd03
X-PMX-Version: 6.1.1.2430161, Antispam-Engine: 2.7.2.2107409, Antispam-Data: 2016.6.21.170018

--001a1145302eac9d8f0535ccdd03
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

Ralph,

I think Intel MPI uses dlopen() internally based on what you specify as the
I_MPI_FABRICS environment variable, if you don't use IB it doesn't need
those libraries.
Of course the files need to be in your LD_PRELOAD_PATH or in the
ld.so.cache.

Balazs

On Tue, Jun 21, 2016 at 9:59 AM, Ralph Castain <r...@open-mpi.org> wrote:

> I=E2=80=99m a little surprised that those dependencies wouldn=E2=80=99t b=
e =E2=80=9Cdiscoverable=E2=80=9D
> - the linker must be able to find them, yes? How are they communicated to
> the linker?
>
> On Jun 21, 2016, at 9:49 AM, Balazs Gerofi <bge...@riken.jp> wrote:
>
> Hello Greg,
>
> I've tested Intel MPI and it works fine.
> One caveat: if you run over IB you will need to add the network drivers
> (libdapl* and friends) to the container image.
> Unfortunately these don't get displayed just by inspecting your binary
> with ldd, but you can figure them out during runtime.
>
> Best,
> Balazs
>
> On Tue, Jun 21, 2016 at 9:39 AM, Greg Keller <gregw...@gmail.com>
> wrote:
>
>> Any chance IntelMPI will, "just work"?
>>
>> On Tue, Jun 21, 2016 at 10:46 AM, 'John Hearns' via singularity <
>> singu...@lbl.gov> wrote:
>>
>>> > We=E2=80=99ll take care of the rest. Our initial studies showed zero
>>> performance degradation by running inside Singularity, and the launch
>>> penalty is near-zero as well
>>>
>>> May I just say - I haz a happee. Lolz.
>>> Sorry - normal service will be resumed as soon as possible.  And yes I
>>> am a sad person when the thought of running MPI processes in containers
>>> makes me happy.
>>>
>>> On 21 June 2016 at 15:49, Ralph Castain <r...@open-mpi.org> wrote:
>>>
>>>> Singularity is fully supported by OMPI (and vice versa). If you grab a
>>>> copy of the OMPI master and build it
>>>> =E2=80=94with-singularity=3D<path-to-singularity> (or have the singula=
rity path in
>>>> your default path), then all you have to do is use mpirun as you norma=
lly
>>>> do, but provide the container as your =E2=80=9Capp=E2=80=9D.
>>>>
>>>> We=E2=80=99ll take care of the rest. Our initial studies showed zero
>>>> performance degradation by running inside Singularity, and the launch
>>>> penalty is near-zero as well (and gets better when compared against
>>>> dl_open=E2=80=99d dynamic jobs running at scale). I=E2=80=99ll let Gre=
g answer the question
>>>> of how to address the running container.
>>>>
>>>>
>>>> On Jun 21, 2016, at 7:37 AM, Raimon Bosch <raimo...@gmail.com>
>>>> wrote:
>>>>
>>>>
>>>>
>>>> Hi,
>>>>
>>>> We are trying to run experiments using singularity containers. The ide=
a
>>>> is to run OpenMPI among several containers and check performance resul=
ts.
>>>>
>>>> How can I communicate with another container? In docker this is clear
>>>> because every container gets an assigned IP and you can ping there, bu=
t
>>>> what is the situation in the case of singularity? Is it possible to as=
sign
>>>> an IP to each container? Can I connect via ssh to them?
>>>>
>>>> Thanks in advance,
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>>
>>>>
>>>> --
>>>> You received this message because you are subscribed to the Google
>>>> Groups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>> an email to singu...@lbl.gov.
>>>>
>>>
>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>>
>> --
>> You received this message because you are subscribed to the Google Group=
s
>> "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n
>> email to singu...@lbl.gov.
>>
>
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>
>
> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>

--001a1145302eac9d8f0535ccdd03
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr"><div>Ralph,</div><div><br></div>I think Intel MPI uses dlo=
pen() internally based on what you specify as the I_MPI_FABRICS environment=
 variable, if you don&#39;t use IB it doesn&#39;t need those libraries.<div=
>Of course the files need to be in your LD_PRELOAD_PATH or in the ld.so.cac=
he.</div><div><br></div><div>Balazs</div><div class=3D"gmail_extra"><br><di=
v class=3D"gmail_quote">On Tue, Jun 21, 2016 at 9:59 AM, Ralph Castain <spa=
n dir=3D"ltr">&lt;<a href=3D"mailto:r...@open-mpi.org" target=3D"_blank">r.=
..@open-mpi.org</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" =
style=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><di=
v style=3D"word-wrap:break-word">I=E2=80=99m a little surprised that those =
dependencies wouldn=E2=80=99t be =E2=80=9Cdiscoverable=E2=80=9D - the linke=
r must be able to find them, yes? How are they communicated to the linker?<=
div><div class=3D"h5"><div><br><div><blockquote type=3D"cite"><div>On Jun 2=
1, 2016, at 9:49 AM, Balazs Gerofi &lt;<a href=3D"mailto:bge...@riken.jp" t=
arget=3D"_blank">bge...@riken.jp</a>&gt; wrote:</div><br><div><div dir=3D"l=
tr">Hello Greg,<div><br></div><div>I&#39;ve tested Intel MPI and it works f=
ine.</div><div>One caveat: if you run over IB you will need to add the netw=
ork drivers (libdapl* and friends) to the container image.</div><div>Unfort=
unately these don&#39;t get displayed just by inspecting your binary with l=
dd, but you can figure them out during runtime.=C2=A0</div><div><br></div><=
div>Best,</div><div>Balazs=C2=A0</div><div class=3D"gmail_extra"><br><div c=
lass=3D"gmail_quote">On Tue, Jun 21, 2016 at 9:39 AM, Greg Keller <span dir=
=3D"ltr">&lt;<a href=3D"mailto:gregw...@gmail.com" target=3D"_blank">gregw.=
..@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" sty=
le=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div d=
ir=3D"ltr">Any chance IntelMPI will, &quot;just work&quot;?</div><div><div>=
<div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Tue, Jun 21, 2=
016 at 10:46 AM, &#39;John Hearns&#39; via singularity <span dir=3D"ltr">&l=
t;<a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.gov</a=
>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 =
0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr"><spa=
n><span style=3D"font-size:12.8px">&gt; We=E2=80=99ll take care of the rest=
. Our initial studies showed zero performance degradation by running inside=
 Singularity, and the launch penalty is near-zero as well</span><br><div><s=
pan style=3D"font-size:12.8px"><br></span></div></span><div><span style=3D"=
font-size:12.8px">May I just say - I haz a happee. Lolz.</span></div><div><=
span style=3D"font-size:12.8px">Sorry - normal service will be resumed as s=
oon as possible.=C2=A0 And yes I am a sad person when the thought of runnin=
g MPI processes in containers makes me happy.</span><br></div></div><div><d=
iv><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On 21 June 201=
6 at 15:49, Ralph Castain <span dir=3D"ltr">&lt;<a href=3D"mailto:r...@open=
-mpi.org" target=3D"_blank">r...@open-mpi.org</a>&gt;</span> wrote:<br><blo=
ckquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #c=
cc solid;padding-left:1ex"><div style=3D"word-wrap:break-word">Singularity =
is fully supported by OMPI (and vice versa). If you grab a copy of the OMPI=
 master and build it =E2=80=94with-singularity=3D&lt;path-to-singularity&gt=
; (or have the singularity path in your default path), then all you have to=
 do is use mpirun as you normally do, but provide the container as your =E2=
=80=9Capp=E2=80=9D.<div><br></div><div>We=E2=80=99ll take care of the rest.=
 Our initial studies showed zero performance degradation by running inside =
Singularity, and the launch penalty is near-zero as well (and gets better w=
hen compared against dl_open=E2=80=99d dynamic jobs running at scale). I=E2=
=80=99ll let Greg answer the question of how to address the running contain=
er.</div><div><div><div><br></div><div><br><div><blockquote type=3D"cite"><=
div>On Jun 21, 2016, at 7:37 AM, Raimon Bosch &lt;<a href=3D"mailto:raimo..=
.@gmail.com" target=3D"_blank">raimo...@gmail.com</a>&gt; wrote:</div><br><=
div><div dir=3D"ltr"><br><br>Hi,<br><br>We are trying to run experiments us=
ing singularity containers. The idea is to run OpenMPI among several contai=
ners and check performance results. <br><br>How can I communicate with anot=
her container? In docker this is clear because every container gets an assi=
gned IP and you can ping there, but what is the situation in the case of si=
ngularity? Is it possible to assign an IP to each container? Can I connect =
via ssh to them?<br><br>Thanks in advance,<br></div><div><br></div>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></blockquote></div><br></div></div></div></div><div><div><div><br></d=
iv>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div><div><br></div>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div><div><br></div>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div></div><div><br></div>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></blockquote></div><br></div></div></div></div><div class=3D"HOEnZb">=
<div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div></div>

--001a1145302eac9d8f0535ccdd03--

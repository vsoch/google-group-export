X-Received: by 10.66.1.136 with SMTP id 8mr495969pam.14.1476292700865;
        Wed, 12 Oct 2016 10:18:20 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.36.111.201 with SMTP id x192ls4805514itb.14.canary; Wed, 12
 Oct 2016 10:18:20 -0700 (PDT)
X-Received: by 10.66.94.163 with SMTP id dd3mr2822821pab.194.1476292700285;
        Wed, 12 Oct 2016 10:18:20 -0700 (PDT)
Return-Path: <gmku...@lbl.gov>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTP id x191si6821999pgd.120.2016.10.12.10.18.20
        for <singu...@lbl.gov>;
        Wed, 12 Oct 2016 10:18:20 -0700 (PDT)
Received-SPF: pass (google.com: domain of gmku...@lbl.gov designates 209.85.215.69 as permitted sender) client-ip=209.85.215.69;
Authentication-Results: mx.google.com;
       spf=pass (google.com: domain of gmku...@lbl.gov designates 209.85.215.69 as permitted sender) smtp.mailfrom=gmku...@lbl.gov
IronPort-PHdr: 9a23:GIEM1x0uu2icdM20smDT+DRfVm0co7zxezQtwd8ZsekXK/ad9pjvdHbS+e9qxAeQG96KsbQY0aGP6/CocFdDyK7JiGoFfp1IWk1NouQttCtkPvS4D1bmJuXhdS0wEZcKflZk+3amLRodQ56mNBXsq3G/pQQfBg/4fVIsYL+kQMiO1Y/uj7D60qaQSj0AvCC6b7J2IUf+hiTqne5Sv7FfLL0swADCuHpCdrce72ppIVWOg0S0vZ/or9Ze6SAYh9YNv44FD+SpN5k+VqFSWTEvMmQp45/wtB/MUA+G/HoAQyYLlAFVCRPO9hDwU7/1uC+8ue1jixWdaNb3S78pXT247rt6AEvziSEIKjow6mDLm+R0hqYdrxW/8U9R2YnRNcu6LvdxebnMNfZcDUlcRNpDWjYLStezaogSFfYTMPxwq4P54VQJs03tVkGXGOrzx2oQ1TfN1qog3rFkTww=
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2FgAAAjcP5XhkXXVdFcGgEBAQECAQEBAQgBAQEBFgEBAQMBAQEJAQEBglw1AQEBAQF0bQ8HgziJdJcFglaFBYxZgUobJAMbAQaBdIIwgVoCgW8HOBQBAQEBAQEBAQEBAQIQAQEBCAsLCRkvgjIEAgECEQUEATkKMQEBAQEBAQEBAQEBAQEBAQEaAggFIg8DDwIZAQEBAwESCAkrMAsJAgsNIAoCAiEBDwMBBQELEQYIBwQBBxUEAYdKSgMPCAWZH49NgTI+MotCiQoNg2wBAQEHAQEBAQEBAQEgEIsCgkeBUhEBgyCCWwWIPGSGFYRzhSU1AYYmhkuDC4FuToQZgzeFaYhlhBSCPRMegREPD1uCYTsRC4FzHjQHhj1HMYEoAQEB
X-IronPort-AV: E=Sophos;i="5.31,336,1473145200"; 
   d="scan'208,217";a="43570297"
Received: from mail-lf0-f69.google.com ([209.85.215.69])
  by fe3.lbl.gov with ESMTP; 12 Oct 2016 10:17:51 -0700
Received: by mail-lf0-f69.google.com with SMTP id b75so31170508lfg.3
        for <singu...@lbl.gov>; Wed, 12 Oct 2016 10:17:51 -0700 (PDT)
X-Gm-Message-State: AA6/9Rm6dyyaoNe0nq+rOQNUJZKaN27KPtRvEre5KcCgInXke/BggHYTV0j8/6+Llbo4xklT9Z553F9rwl6mOUURKTTc7Xt6ruqCIaBe2TnRcUET0eERqhTTrVBRfGPTPpMqdLRQB2fIAOA7xuWHMxyKq64=
X-Received: by 10.25.66.18 with SMTP id p18mr2829499lfa.82.1476292669991;
        Wed, 12 Oct 2016 10:17:49 -0700 (PDT)
X-Received: by 10.25.66.18 with SMTP id p18mr2829466lfa.82.1476292669680; Wed,
 12 Oct 2016 10:17:49 -0700 (PDT)
MIME-Version: 1.0
Received: by 10.25.167.67 with HTTP; Wed, 12 Oct 2016 10:17:49 -0700 (PDT)
In-Reply-To: <8689886f-9da7-4f40-8769-06dbfc0a547f@lbl.gov>
References: <04cccf38-72fb-49ef-b010-15fb80e71e8e@lbl.gov> <CAN7etTyY_+ytGXpY4Te-=xED4zHNzz4Pg7xkB4ULj2sZ=gk2WA@mail.gmail.com>
 <6e2a6338-f64e-4f2a-894b-d40f1f646113@lbl.gov> <CAN7etTzk47mf9bCo2S6Wp-9sYpS6u3JfwVgN2koRpKcamDtRWw@mail.gmail.com>
 <8689886f-9da7-4f40-8769-06dbfc0a547f@lbl.gov>
From: "Gregory M. Kurtzer" <gmku...@lbl.gov>
Date: Wed, 12 Oct 2016 10:17:49 -0700
Message-ID: <CAN7etTz0wBEjGweZXC_pcOzEULW7hmeBr7zY5ndtsXOL88jSdA@mail.gmail.com>
Subject: Re: [Singularity] Using singularity with MPI jobs
To: singularity <singu...@lbl.gov>
Content-Type: multipart/alternative; boundary=94eb2c1a094a293b35053eae2c0e

--94eb2c1a094a293b35053eae2c0e
Content-Type: text/plain; charset=UTF-8

Can you create a file in /dev/shm/... on the host, and then start a
Singularity container and confirm that you can see that file from within
the container please?

Thanks!

On Wed, Oct 12, 2016 at 9:45 AM, Steve Mehlberg <sgmeh...@gmail.com>
wrote:

> Wow, that was very interesting.  I indeed get the same problem with the
> singularity -n1 (srun - one task).  I created the strace, then wanted to
> compare the output to a non-singularity run.  But when I change the
> non-singularity run to use anything other than the required number of tasks
> I get the same error!  That seems to indicate that in the singularity run
> (srun with the correct number of tasks) for some reason the MPI processes
> can't communicate with one another.
>
> The strace doesn't show much - or at least not much that means something
> to me.  The program seems to be going along outputting data then aborts
> with exit 6:
>
> [pid 13573] write(27, "                    suppress iso"..., 56) = 56
> [pid 13573] write(27, "                    ------------"..., 56) = 56
> [pid 13573] write(27, "      no isolated ocean grid poi"..., 36) = 36
> [pid 13573] open("/opt/mpi/openmpi-icc/2.0.0/share/openmpi/help-mpi-errors.txt",
> O_RDONLY) = 28
> [pid 13573] ioctl(28, SNDCTL_TMR_TIMEBASE or SNDRV_TIMER_IOCTL_NEXT_DEVICE
> or TCGETS, 0x7ffec31d4d80) = -1 ENOTTY (Inappropriate ioctl for device)
> [pid 13573] fstat(28, {st_mode=S_IFREG|0644, st_size=1506, ...}) = 0
> [pid 13573] mmap(NULL, 4096, PROT_READ|PROT_WRITE,
> MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f4b65f45000
> [pid 13573] read(28, "# -*- text -*-\n#\n# Copyright (c)"..., 8192) = 1506
> [pid 13573] read(28, "", 4096)          = 0
> [pid 13573] close(28)                   = 0
> [pid 13573] munmap(0x7f4b65f45000, 4096) = 0
> [pid 13573] write(1, "[node9:13573] *** An error occ"..., 361) = 361
> [pid 13573] stat("/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0",
> {st_mode=S_IFDIR|0700, st_size=40, ...}) = 0
> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0",
> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
> [pid 13573] getdents(28, /* 2 entries */, 32768) = 48
> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
> [pid 13573] close(28)                   = 0
> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0",
> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
> [pid 13573] getdents(28, /* 2 entries */, 32768) = 48
> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
> [pid 13573] close(28)                   = 0
> [pid 13573] rmdir("/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0") = 0
> [pid 13573] stat("/dev/shm/openmpi-sessions-50342@node9_0/37255/1",
> {st_mode=S_IFDIR|0700, st_size=40, ...}) = 0
> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1",
> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
> [pid 13573] getdents(28, /* 2 entries */, 32768) = 48
> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
> [pid 13573] close(28)                   = 0
> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1",
> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
> [pid 13573] getdents(28, /* 2 entries */, 32768) = 48
> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
> [pid 13573] close(28)                   = 0
> [pid 13573] rmdir("/dev/shm/openmpi-sessions-50342@node9_0/37255/1") = 0
> [pid 13573] stat("/dev/shm/openmpi-sessions-50342@node9_0",
> {st_mode=S_IFDIR|0700, st_size=11080, ...}) = 0
> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0",
> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
> [pid 13573] getdents(28, /* 554 entries */, 32768) = 17424
> [pid 13573] getdents(28, /* 0 entries */, 32768) = 0
> [pid 13573] close(28)                   = 0
> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0",
> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = 28
> [pid 13573] getdents(28, /* 554 entries */, 32768) = 17424
> [pid 13573] close(28)                   = 0
> [pid 13573] openat(AT_FDCWD, "/dev/shm/openmpi-sessions-50342@node9_0/37255/1/0",
> O_RDONLY|O_NONBLOCK|O_DIRECTORY|O_CLOEXEC) = -1 ENOENT (No such file or
> directory)
> [pid 13573] exit_group(6)               = ?
> [pid 13574] +++ exited with 6 +++
> +++ exited with 6 +++
> srun: error: node9: task 0: Exited with exit code 6
>
>
>
> On Wednesday, October 12, 2016 at 8:53:12 AM UTC-6, Gregory M. Kurtzer
> wrote:
>>
>> Can you replicate the problem with a -np 1? If so can you strace it from
>> within the container:
>>
>> mpirun -np 1 singularity exec container.img strace -ff /path/to/mpi.exe
>> (opts)
>>
>> Yes you can try Singularity 2.2. Please install it to a different path so
>> we can test side by side if you don't mind (if really like to debug this).
>>
>> Thanks!
>>
>>
>>
>> On Wednesday, October 12, 2016, Steve Mehlberg <sg...@gmail.com>
>> wrote:
>>
>>> Greg,
>>>
>>> I put a bind to /opt in the singularity.conf file so that /opt/intel is
>>> available in the container.
>>>
>>> All the tasks (16) immediately exit code 6.  The job exits after about 4
>>> seconds.  It normally takes about 16 minutes to run with the configuration
>>> I'm using and I do see the start of some output.
>>>
>>> I am using openmpi 2.0.0.
>>>
>>> I tried an "export SINGULARITY_NO_NAMESPACE_PID=1" in the bash script
>>> that runs all of this for each process and I still get the problem.
>>>
>>> [node12:9779] *** An error occurred in MPI_Isend
>>> [node12:9779] *** reported by process [3025076225,0]
>>> [node12:9779] *** on communicator MPI COMMUNICATOR 3 DUP FROM 0
>>> [node12:9779] *** MPI_ERR_RANK: invalid rank
>>> [node12:9779] *** MPI_ERRORS_ARE_FATAL (processes in this communicator
>>> will now abort,
>>> [node12:9779] ***    and potentially your MPI job)
>>>
>>> I can try 2.2 - do you think it might behave differently?
>>>
>>> Thanks for the ideas and help.
>>>
>>> Regards,
>>>
>>> Steve
>>>
>>> On Tuesday, October 11, 2016 at 8:19:47 PM UTC-6, Gregory M. Kurtzer
>>> wrote:
>>>>
>>>> Hi Steve,
>>>>
>>>> I'm not sure at first glance, but just to touch on the basics... Is
>>>> /opt/intel available from within the container? Do all tasks exit code 6,
>>>> or just some of them?
>>>>
>>>> What version of OMPI are you using?
>>>>
>>>> I wonder if the PID namespace is causing a problem here... I'm not sure
>>>> it gets effectively disabled when running via srun and pmi. Can you export
>>>> the environment variable "SINGULARITY_NO_NAMESPACE_PID=1" in a place
>>>> where Singularity will pick it up definitively by all ranks? That will
>>>> ensure that the PID namespace is not being exported.
>>>>
>>>> Additionally, you could try version 2.2. I just released it, and by
>>>> default it does not unshare() out the PID namespace. But... It is the first
>>>> release in the 2.2 series so it may bring with it other issues that still
>>>> need resolving.... But we should debug those too! :)
>>>>
>>>> Greg
>>>>
>>>>
>>>>
>>>> On Tue, Oct 11, 2016 at 2:40 PM, Steve Mehlberg <sg...@gmail.com>
>>>> wrote:
>>>>
>>>>> Does singularity support MPI PMI-2 jobs?  I've had mixed success
>>>>> testing benchmark applications using a singularity container.
>>>>>
>>>>> Currently I'm struggling to get the NEMO benchmark to run using slurm
>>>>> 16.05 and pmi2.  I can run the exact same executable on bare metal with the
>>>>> same slurm, but I get Rank errors when I run using "srun --mpi=pmi2
>>>>> singularity...".  The application aborts with an exit code 6.
>>>>>
>>>>> I tried pmix too, but that gets mpi aborts for both bare metal and
>>>>> singularity.
>>>>>
>>>>> The only way I could get the NEMO application to compile was to use
>>>>> the intel compilers and mpi:
>>>>>
>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/compilervars.sh
>>>>> intel64
>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/ifortvars.sh
>>>>> intel64
>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/iccvars.sh
>>>>> intel64
>>>>> source /opt/mpi/openmpi-icc/2.0.0/bin/mpivars.sh
>>>>>
>>>>> It runs fine when I use mpirun with or without singularity.
>>>>>
>>>>> Example run/error:
>>>>>
>>>>> sbatch ...
>>>>> srun --mpi=pmi2 -n16 singularity exec c7.img run.it > out_now
>>>>>
>>>>> .......
>>>>> srun: error: node11: tasks 0-7: Exited with exit code 6
>>>>> srun: error: node12: tasks 8-15: Exited with exit code 6
>>>>>
>>>>> $ cat run.it
>>>>> #!/bin/sh
>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/compilervars.sh
>>>>> intel64
>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/ifortvars.sh
>>>>> intel64
>>>>> source /opt/intel/compilers_and_libraries_2016.3.210/linux/bin/iccvars.sh
>>>>> intel64
>>>>> source /opt/mpi/openmpi-icc/2.0.0/bin/mpivars.sh
>>>>> source env_bench
>>>>> export PATH=/opt/mpi/openmpi-icc/2.0.0/bin:/opt/pmix/1.1.5/bin:$PATH
>>>>> export LD_LIBRARY_PATH=/opt/openmpi-icc/2.0.0/lib:/opt/pmix/1.1.5/l
>>>>> ib:$LD_LIBRARY_PATH
>>>>> export OMPI_MCA_btl=self,sm,openib
>>>>>
>>>>> ./opa_8_2 namelist >out_now
>>>>>
>>>>> $ cat out_now
>>>>> [node12:29725] *** An error occurred in MPI_Isend
>>>>> [node12:29725] *** reported by process [3865116673,0]
>>>>> [node12:29725] *** on communicator MPI COMMUNICATOR 3 DUP FROM 0
>>>>> [node12:29725] *** MPI_ERR_RANK: invalid rank
>>>>> [node12:29725] *** MPI_ERRORS_ARE_FATAL (processes in this
>>>>> communicator will now abort,
>>>>> [node12:29725] ***    and potentially your MPI job)
>>>>>
>>>>> I am running singularity 2.1 - any ideas?
>>>>>
>>>>> -Steve
>>>>>
>>>>> --
>>>>> You received this message because you are subscribed to the Google
>>>>> Groups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, send
>>>>> an email to singu...@lbl.gov.
>>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> Gregory M. Kurtzer
>>>> HPC Systems Architect and Technology Developer
>>>> Lawrence Berkeley National Laboratory HPCS
>>>> University of California Berkeley Research IT
>>>> Singularity Linux Containers (http://singularity.lbl.gov/)
>>>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>>>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>>>> er.com/gmkurtzer
>>>>
>>> --
>>> You received this message because you are subscribed to the Google
>>> Groups "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send
>>> an email to singu...@lbl.gov.
>>>
>>
>>
>> --
>> Gregory M. Kurtzer
>> HPC Systems Architect and Technology Developer
>> Lawrence Berkeley National Laboratory HPCS
>> University of California Berkeley Research IT
>> Singularity Linux Containers (http://singularity.lbl.gov/)
>> Warewulf Cluster Management (http://warewulf.lbl.gov/)
>> GitHub: https://github.com/gmkurtzer, Twitter: https://twitt
>> er.com/gmkurtzer
>>
>> --
> You received this message because you are subscribed to the Google Groups
> "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an
> email to singu...@lbl.gov.
>



-- 
Gregory M. Kurtzer
HPC Systems Architect and Technology Developer
Lawrence Berkeley National Laboratory HPCS
University of California Berkeley Research IT
Singularity Linux Containers (http://singularity.lbl.gov/)
Warewulf Cluster Management (http://warewulf.lbl.gov/)
GitHub: https://github.com/gmkurtzer, Twitter: https://twitter.com/gmkurtzer

--94eb2c1a094a293b35053eae2c0e
Content-Type: text/html; charset=UTF-8
Content-Transfer-Encoding: quoted-printable

<div dir=3D"ltr">Can you create a file in /dev/shm/... on the host, and the=
n start a Singularity container and confirm that you can see that file from=
 within the container please?<div><br></div><div>Thanks!</div></div><div cl=
ass=3D"gmail_extra"><br><div class=3D"gmail_quote">On Wed, Oct 12, 2016 at =
9:45 AM, Steve Mehlberg <span dir=3D"ltr">&lt;<a href=3D"mailto:sgmeh...@gm=
ail.com" target=3D"_blank">sgmeh...@gmail.com</a>&gt;</span> wrote:<br><blo=
ckquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #c=
cc solid;padding-left:1ex"><div dir=3D"ltr">Wow, that was very interesting.=
=C2=A0 I indeed get the same problem with the singularity -n1 (srun - one t=
ask).=C2=A0 I created the strace, then wanted to compare the output to a no=
n-singularity run.=C2=A0 But when I change the non-singularity run to use a=
nything other than the required number of tasks I get the same error!=C2=A0=
 That seems to indicate that in the singularity run (srun with the correct =
number of tasks) for some reason the MPI processes can&#39;t communicate wi=
th one another. <br><br>The strace doesn&#39;t show much - or at least not =
much that means something to me.=C2=A0 The program seems to be going along =
outputting data then aborts with exit 6:<br><br><span style=3D"font-family:=
courier new,monospace">[pid 13573] write(27, &quot;=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0 suppress iso&quot;..., 56) =3D 56<br>[pid 13573] write(27, =
&quot;=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 ------------&quot;..., 56) =
=3D 56<br>[pid 13573] write(27, &quot;=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 no iso=
lated ocean grid poi&quot;..., 36) =3D 36<br>[pid 13573] open(&quot;/opt/mp=
i/openmpi-icc/2.<wbr>0.0/share/openmpi/help-mpi-<wbr>errors.txt&quot;, O_RD=
ONLY) =3D 28<br>[pid 13573] ioctl(28, SNDCTL_TMR_TIMEBASE or SNDRV_TIMER_IO=
CTL_NEXT_DEVICE or TCGETS, 0x7ffec31d4d80) =3D -1 ENOTTY (Inappropriate ioc=
tl for device)<br>[pid 13573] fstat(28, {st_mode=3DS_IFREG|0644, st_size=3D=
1506, ...}) =3D 0<br>[pid 13573] mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP=
_PRIVATE|MAP_ANONYMOUS, -1, 0) =3D 0x7f4b65f45000<br>[pid 13573] read(28, &=
quot;# -*- text -*-\n#\n# Copyright (c)&quot;..., 8192) =3D 1506<br>[pid 13=
573] read(28, &quot;&quot;, 4096)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0 =3D 0<br>[pid 13573] close(28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0 =3D 0<br>[pid 13573] munmap(0x7f4b65f45000, 4096) =3D 0<br>[pid 13573] =
write(1, &quot;[node9:13573] *** An error occ&quot;..., 361) =3D 361<br>[pi=
d 13573] stat(&quot;/dev/shm/openmpi-<wbr>sessions-50342@node9_0/37255/<wbr=
>1/0&quot;, {st_mode=3DS_IFDIR|0700, st_size=3D40, ...}) =3D 0<br>[pid 1357=
3] openat(AT_FDCWD, &quot;/dev/shm/openmpi-sessions-<wbr>50342@node9_0/3725=
5/1/0&quot;, O_RDONLY|O_NONBLOCK|O_<wbr>DIRECTORY|O_CLOEXEC) =3D 28<br>[pid=
 13573] getdents(28, /* 2 entries */, 32768) =3D 48<br>[pid 13573] getdents=
(28, /* 0 entries */, 32768) =3D 0<br>[pid 13573] close(28)=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573] openat(AT_FDCWD, &quot;/dev/shm/ope=
nmpi-sessions-<wbr>50342@node9_0/37255/1/0&quot;, O_RDONLY|O_NONBLOCK|O_<wb=
r>DIRECTORY|O_CLOEXEC) =3D 28<br>[pid 13573] getdents(28, /* 2 entries */, =
32768) =3D 48<br>[pid 13573] getdents(28, /* 0 entries */, 32768) =3D 0<br>=
[pid 13573] close(28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573]=
 rmdir(&quot;/dev/shm/openmpi-<wbr>sessions-50342@node9_0/37255/<wbr>1/0&qu=
ot;) =3D 0<br>[pid 13573] stat(&quot;/dev/shm/openmpi-<wbr>sessions-50342@n=
ode9_0/37255/<wbr>1&quot;, {st_mode=3DS_IFDIR|0700, st_size=3D40, ...}) =3D=
 0<br>[pid 13573] openat(AT_FDCWD, &quot;/dev/shm/openmpi-sessions-<wbr>503=
42@node9_0/37255/1&quot;, O_RDONLY|O_NONBLOCK|O_<wbr>DIRECTORY|O_CLOEXEC) =
=3D 28<br>[pid 13573] getdents(28, /* 2 entries */, 32768) =3D 48<br>[pid 1=
3573] getdents(28, /* 0 entries */, 32768) =3D 0<br>[pid 13573] close(28)=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573] openat(AT_FDCWD, &qu=
ot;/dev/shm/openmpi-sessions-<wbr>50342@node9_0/37255/1&quot;, O_RDONLY|O_N=
ONBLOCK|O_<wbr>DIRECTORY|O_CLOEXEC) =3D 28<br>[pid 13573] getdents(28, /* 2=
 entries */, 32768) =3D 48<br>[pid 13573] getdents(28, /* 0 entries */, 327=
68) =3D 0<br>[pid 13573] close(28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0=
<br>[pid 13573] rmdir(&quot;/dev/shm/openmpi-<wbr>sessions-50342@node9_0/37=
255/<wbr>1&quot;) =3D 0<br>[pid 13573] stat(&quot;/dev/shm/openmpi-<wbr>ses=
sions-50342@node9_0&quot;, {st_mode=3DS_IFDIR|0700, st_size=3D11080, ...}) =
=3D 0<br>[pid 13573] openat(AT_FDCWD, &quot;/dev/shm/openmpi-sessions-<wbr>=
50342@node9_0&quot;, O_RDONLY|O_NONBLOCK|O_<wbr>DIRECTORY|O_CLOEXEC) =3D 28=
<br>[pid 13573] getdents(28, /* 554 entries */, 32768) =3D 17424<br>[pid 13=
573] getdents(28, /* 0 entries */, 32768) =3D 0<br>[pid 13573] close(28)=C2=
=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0 =3D 0<br>[pid 13573] openat(AT_FDCWD, &quot;=
/dev/shm/openmpi-sessions-<wbr>50342@node9_0&quot;, O_RDONLY|O_NONBLOCK|O_<=
wbr>DIRECTORY|O_CLOEXEC) =3D 28<br>[pid 13573] getdents(28, /* 554 entries =
*/, 32768) =3D 17424<br>[pid 13573] close(28)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=
=A0 =3D 0<br>[pid 13573] openat(AT_FDCWD, &quot;/dev/shm/openmpi-sessions-<=
wbr>50342@node9_0/37255/1/0&quot;, O_RDONLY|O_NONBLOCK|O_<wbr>DIRECTORY|O_C=
LOEXEC) =3D -1 ENOENT (No such file or directory)<br>[pid 13573] exit_group=
(6)=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=C2=A0=
=C2=A0=C2=A0 =3D ?<br>[pid 13574] +++ exited with 6 +++<br>+++ exited with =
6 +++<br>srun: error: node9: task 0: Exited with exit code 6</span><span cl=
ass=3D""><br><br><br><br>On Wednesday, October 12, 2016 at 8:53:12 AM UTC-6=
, Gregory M. Kurtzer wrote:</span><blockquote class=3D"gmail_quote" style=
=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding-left:1ex"=
><span class=3D"">Can you replicate the problem with a -np 1? If so can you=
 strace it from within the container:<div><br></div><div>mpirun -np 1 singu=
larity exec container.img strace -ff /path/to/mpi.exe (opts)<span></span></=
div><div><br></div><div>Yes you can try Singularity 2.2. Please install it =
to a different path so we can test side by side if you don&#39;t mind (if r=
eally like to debug this).=C2=A0</div><div><br></div><div>Thanks!</div><div=
><br></div></span><div><div class=3D"h5"><div><br><br>On Wednesday, October=
 12, 2016, Steve Mehlberg &lt;<a rel=3D"nofollow">sg...@gmail.com</a>&gt; w=
rote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;borde=
r-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Greg,<br><br>I put=
 a bind to /opt in the singularity.conf file so that /opt/intel is availabl=
e in the container.<br><br>All the tasks (16) immediately exit code 6.=C2=
=A0 The job exits after about 4 seconds.=C2=A0 It normally takes about 16 m=
inutes to run with the configuration I&#39;m using and I do see the start o=
f some output.<br><br>I am using openmpi 2.0.0.<br><br>I tried an &quot;exp=
ort <span>SINGULARITY_NO_NAMESPACE_</span><span>PID=3D1<wbr>&quot; in the b=
ash script that runs all of this for each process and I still get the probl=
em.</span><br><br>[node12:9779] *** An error occurred in MPI_Isend<br>[node=
12:9779] *** reported by process <a href=3D"tel:%5B3025076225" value=3D"+13=
025076225" target=3D"_blank">[3025076225</a>,0]<br>[node12:9779] *** on com=
municator MPI COMMUNICATOR 3 DUP FROM 0<br>[node12:9779] *** MPI_ERR_RANK: =
invalid rank<br>[node12:9779] *** MPI_ERRORS_ARE_FATAL (processes in this c=
ommunicator will now abort,<br>[node12:9779] ***=C2=A0=C2=A0=C2=A0 and pote=
ntially your MPI job)<br><br>I can try 2.2 - do you think it might behave d=
ifferently?<br><br>Thanks for the ideas and help.<br><br>Regards,<br><br>St=
eve<br><br>On Tuesday, October 11, 2016 at 8:19:47 PM UTC-6, Gregory M. Kur=
tzer wrote:<blockquote class=3D"gmail_quote" style=3D"margin:0;margin-left:=
0.8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Stev=
e,<div><br></div><div>I&#39;m not sure at first glance, but just to touch o=
n the basics... Is /opt/intel available from within the container? Do all t=
asks exit code 6, or just some of them?</div><div><br></div><div>What versi=
on of OMPI are you using?</div><div><br></div><div>I wonder if the PID name=
space is causing a problem here... I&#39;m not sure it gets effectively dis=
abled when running via srun and pmi. Can you export the environment variabl=
e &quot;<span>SINGULARITY_NO_NAMESPACE_</span><span>PID=3D<wbr>1&quot; in a=
 place where Singularity will pick it up definitively by all ranks? That wi=
ll ensure that the PID namespace is not being exported.</span></div><div><s=
pan><br></span></div><div><span>Additionally, you could try version 2.2. I =
just released it, and by default it does not unshare() out the PID namespac=
e. But... It is the first release in the 2.2 series so it may bring with it=
 other issues that still need resolving.... But we should debug those too! =
:)</span></div><div><span><br></span></div><div>Greg</div><div><br></div><d=
iv><br></div>







</div><div><br><div class=3D"gmail_quote">On Tue, Oct 11, 2016 at 2:40 PM, =
Steve Mehlberg <span dir=3D"ltr">&lt;<a rel=3D"nofollow">sg...@gmail.com</a=
>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 =
0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Does=
 singularity support MPI PMI-2 jobs?=C2=A0 I&#39;ve had mixed success testi=
ng benchmark applications using a singularity container.=C2=A0 <br><br>Curr=
ently I&#39;m struggling to get the NEMO benchmark to run using slurm 16.05=
 and pmi2.=C2=A0 I can run the exact same executable on bare metal with the=
 same slurm, but I get Rank errors when I run using &quot;srun --mpi=3Dpmi2=
 singularity...&quot;.=C2=A0 The application aborts with an exit code 6.<br=
><br>I tried pmix too, but that gets mpi aborts for both bare metal and sin=
gularity.<br><br>The only way I could get the NEMO application to compile w=
as to use the intel compilers and mpi:<br><br><span style=3D"font-size:12.0=
pt;font-family:&quot;Times New Roman&quot;,&quot;serif&quot;;color:black">s=
ource
/opt/intel/compilers_and_libra<wbr>ries_2016.3.210/linux/bin/<wbr>compilerv=
ars.sh intel64<br>
source /opt/intel/compilers_and_libra<wbr>ries_2016.3.210/linux/bin/<wbr>if=
ortvars.sh
intel64<br>
source /opt/intel/compilers_and_libra<wbr>ries_2016.3.210/linux/bin/<wbr>ic=
cvars.sh
intel64<br>
source /opt/mpi/openmpi-icc/2.0.0/bin<wbr>/mpivars.sh<br><br></span>It runs=
 fine when I use mpirun with or without singularity.<br><br>Example run/err=
or:<br><br>sbatch ...<br>srun --mpi=3Dpmi2 -n16 singularity exec c7.img <a =
href=3D"http://run.it" rel=3D"nofollow" target=3D"_blank">run.it</a> &gt; o=
ut_now<br><br>.......<br>srun: error: node11: tasks 0-7: Exited with exit c=
ode 6<br>srun: error: node12: tasks 8-15: Exited with exit code 6<br><br>$ =
cat <a href=3D"http://run.it" rel=3D"nofollow" target=3D"_blank">run.it</a>=
<br>#!/bin/sh<br>source /opt/intel/compilers_and_libra<wbr>ries_2016.3.210/=
linux/bin/<wbr>compilervars.sh intel64<br>source /opt/intel/compilers_and_l=
ibra<wbr>ries_2016.3.210/linux/bin/<wbr>ifortvars.sh intel64<br>source /opt=
/intel/compilers_and_libra<wbr>ries_2016.3.210/linux/bin/<wbr>iccvars.sh in=
tel64<br>source /opt/mpi/openmpi-icc/2.0.0/bin<wbr>/mpivars.sh<br>source en=
v_bench<br>export PATH=3D/opt/mpi/openmpi-icc/2.0.<wbr>0/bin:/opt/pmix/1.1.=
5/bin:$PAT<wbr>H<br>export LD_LIBRARY_PATH=3D/opt/openmpi-i<wbr>cc/2.0.0/li=
b:/opt/pmix/1.1.5/l<wbr>ib:$LD_LIBRARY_PATH<br>export OMPI_MCA_btl=3Dself,s=
m,openib<br><br>./opa_8_2 namelist &gt;out_now<br><br>$ cat out_now<br>[nod=
e12:29725] *** An error occurred in MPI_Isend<br>[node12:29725] *** reporte=
d by process <a value=3D"+13865116673">[3865116673</a>,0]<br>[node12:29725]=
 *** on communicator MPI COMMUNICATOR 3 DUP FROM 0<br>[node12:29725] *** MP=
I_ERR_RANK: invalid rank<br>[node12:29725] *** MPI_ERRORS_ARE_FATAL (proces=
ses in this communicator will now abort,<br>[node12:29725] ***=C2=A0=C2=A0=
=C2=A0 and potentially your MPI job)<br><br>I am running singularity 2.1 - =
any ideas?<span><font color=3D"#888888"><br><br>-Steve<br><br></font></span=
></div><span><font color=3D"#888888">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a rel=3D"nofollow">singu...@lbl.gov</a>.<br>
</font></span></blockquote></div><br><br clear=3D"all"><div><br></div>-- <b=
r><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><d=
iv dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtzer</d=
iv><div>HPC Systems Architect and Technology Developer</div><div>Lawrence B=
erkeley National Laboratory HPCS<br>University of California Berkeley Resea=
rch IT<br>Singularity Linux Containers=C2=A0(<a href=3D"http://singularity.=
lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://singularity<wbr>.lbl.go=
v/</a>)</div><div>Warewulf Cluster Management=C2=A0(<a href=3D"http://warew=
ulf.lbl.gov/" rel=3D"nofollow" target=3D"_blank">http://warewulf.lb<wbr>l.g=
ov/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.com/gmkurtzer" re=
l=3D"nofollow" target=3D"_blank">https://github.com/gmk<wbr>urtzer</a>,=C2=
=A0<span style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"https:/=
/twitter.com/gmkurtzer" style=3D"font-size:12.8px" rel=3D"nofollow" target=
=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</a></div></div></div></div><=
/div></div></div></div></div></div></div>
</div>
</blockquote></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singularity+unsubscribe@lbl.go<wbr>v</a>.<br>
</blockquote></div><br><br>-- <br><div dir=3D"ltr"><div><div dir=3D"ltr"><d=
iv><div dir=3D"ltr"><div><div dir=3D"ltr"><div dir=3D"ltr"><div dir=3D"ltr"=
><div>Gregory M. Kurtzer</div><div>HPC Systems Architect and Technology Dev=
eloper</div><div>Lawrence Berkeley National Laboratory HPCS<br>University o=
f California Berkeley Research IT<br>Singularity Linux Containers=C2=A0(<a =
href=3D"http://singularity.lbl.gov/" rel=3D"nofollow" target=3D"_blank">htt=
p://singularity<wbr>.lbl.gov/</a>)</div><div>Warewulf Cluster Management=C2=
=A0(<a href=3D"http://warewulf.lbl.gov/" rel=3D"nofollow" target=3D"_blank"=
>http://warewulf.lb<wbr>l.gov/</a>)</div><div>GitHub:=C2=A0<a href=3D"https=
://github.com/gmkurtzer" rel=3D"nofollow" target=3D"_blank">https://github.=
com/gmk<wbr>urtzer</a>,=C2=A0<span style=3D"font-size:12.8px">Twitter:=C2=
=A0</span><a href=3D"https://twitter.com/gmkurtzer" style=3D"font-size:12.8=
px" rel=3D"nofollow" target=3D"_blank">https://twitt<wbr>er.com/gmkurtzer</=
a></div></div></div></div></div></div></div></div></div></div><br>
</div></div></blockquote></div><div class=3D"HOEnZb"><div class=3D"h5">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups &=
quot;singularity&quot; group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singularity+u=
nsubscribe@lbl.<wbr>gov</a>.<br>
</div></div></blockquote></div><br><br clear=3D"all"><div><br></div>-- <br>=
<div class=3D"gmail_signature" data-smartmail=3D"gmail_signature"><div dir=
=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr"><div><div dir=3D"ltr">=
<div dir=3D"ltr"><div dir=3D"ltr"><div>Gregory M. Kurtzer</div><div>HPC Sys=
tems Architect and Technology Developer</div><div>Lawrence Berkeley Nationa=
l Laboratory HPCS<br>University of California Berkeley Research IT<br>Singu=
larity Linux Containers=C2=A0(<a href=3D"http://singularity.lbl.gov/" targe=
t=3D"_blank">http://singularity.lbl.gov/</a>)</div><div>Warewulf Cluster Ma=
nagement=C2=A0(<a href=3D"http://warewulf.lbl.gov/" target=3D"_blank">http:=
//warewulf.lbl.gov/</a>)</div><div>GitHub:=C2=A0<a href=3D"https://github.c=
om/gmkurtzer" target=3D"_blank">https://github.com/gmkurtzer</a>,=C2=A0<spa=
n style=3D"font-size:12.8px">Twitter:=C2=A0</span><a href=3D"https://twitte=
r.com/gmkurtzer" style=3D"font-size:12.8px" target=3D"_blank">https://twitt=
er.com/gmkurtzer</a></div></div></div></div></div></div></div></div></div><=
/div></div>
</div>

--94eb2c1a094a293b35053eae2c0e--

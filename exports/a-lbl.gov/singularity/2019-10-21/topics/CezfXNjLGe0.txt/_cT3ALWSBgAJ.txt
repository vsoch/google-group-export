X-Received: by 10.13.204.198 with SMTP id o189mr46196213ywd.35.1470030240271;
        Sun, 31 Jul 2016 22:44:00 -0700 (PDT)
X-BeenThere: singularity@lbl.gov
Received: by 10.107.151.10 with SMTP id z10ls3704815iod.31.gmail; Sun, 31 Jul
 2016 22:43:59 -0700 (PDT)
X-Received: by 10.98.104.71 with SMTP id d68mr93100818pfc.163.1470030239728;
        Sun, 31 Jul 2016 22:43:59 -0700 (PDT)
Return-Path: <richard...@gmail.com>
Received: from fe3.lbl.gov (fe3.lbl.gov. [128.3.41.68])
        by mx.google.com with ESMTPS id c69si33279316pfj.224.2016.07.31.22.43.59
        for <singu...@lbl.gov>
        (version=TLS1_2 cipher=ECDHE-RSA-AES128-GCM-SHA256 bits=128/128);
        Sun, 31 Jul 2016 22:43:59 -0700 (PDT)
Received-SPF: pass (google.com: domain of richard...@gmail.com designates 209.85.192.172 as permitted sender) client-ip=209.85.192.172;
Authentication-Results: mx.google.com;
       dkim=pass head...@gmail.com;
       spf=pass (google.com: domain of richard...@gmail.com designates 209.85.192.172 as permitted sender) smtp.mailfrom=richard...@gmail.com
X-Ironport-SBRS: 3.4
X-IronPort-Anti-Spam-Filtered: true
X-IronPort-Anti-Spam-Result: A2HYAAAW4Z5XhqzAVdFdhBt8gz6BDKMoiS2GfHaBPUAmgWxUgVxLAYEPAiWBADgUAQEBAQEBAQMPAQEBCAsLCRkvglM5CgYrAQEBAQEBAQEBAQEBAQEBARoCKwQWCxsBAQQBEggBCB0BDQ4eAwELBgULDSABCQICIQIOAwEFARwOBwQBHAQBh3QBAw8IBQmjFIEyPjGLO4FqgloFhh8KGScNVINAAQEBAQEFAQEBAQEBAQEBAQEUAgYQiBIIgUqBA4JDgU8RARwZgmgrgi8FgUWGWAdghRILaj+JNTSGGIJ8gnNDgjWBaxc3hwwOI4VJiCuEBYI4MIEPHoJIEQuBbE4BAQEBA4cUgTYBAQE
X-IronPort-AV: E=Sophos;i="5.28,453,1464678000"; 
   d="scan'208,217";a="31870058"
Received: from mail-pf0-f172.google.com ([209.85.192.172])
  by fe3.lbl.gov with ESMTP; 31 Jul 2016 22:43:57 -0700
Received: by mail-pf0-f172.google.com with SMTP id p64so51670123pfb.1
        for <singu...@lbl.gov>; Sun, 31 Jul 2016 22:43:57 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20120113;
        h=subject:references:from:in-reply-to:message-id:date:to
         :content-transfer-encoding:mime-version;
        bh=5aGjZitb4ntNIRB7KP7yrkZx76xByBpvu96/WmZrff0=;
        b=Jzfy56zSyVYN+r+2V3Oxc4wfsV+M7RSpGbMKZ207LCVH6BFdX0AReKMhEMUfP5h4o2
         fVBWekl938h2Hah1GT1U34oEOJkcl/wwCMMOyefUxq29W5PPV3l8rTFTj60i4ju+JqbK
         zuDeXv8T05kfJn7S0VPhVp+0THSUQG9t1Wfv7bp2dw/IdQUNUkYdMciWTKj/TqpJ7EU0
         ts4G0TkatDe/LvWRkXMGyOpOH8KIImu7NoxZVtlqHvHH63i40057rfskD8FHnYSPhaWg
         Qzn0RYa3bi4i4hGTwrlC2svrLWbMdX+cvqIg79I8j/TpJ546zA1rh9A3H/oYQVJFgefP
         gyKw==
X-Gm-Message-State: AEkoouvZkbtkAxq3pMCGd5a+T40x9IssmDw5qE7vCWTWzA2wNeSlxS5McaTXuY4yUpJDJQ==
X-Received: by 10.98.94.6 with SMTP id s6mr74198900pfb.31.1470030237067;
        Sun, 31 Jul 2016 22:43:57 -0700 (PDT)
Return-Path: <richard...@gmail.com>
Received: from [192.168.1.21] (108-66-116-252.lightspeed.sndgca.sbcglobal.net. [108.66.116.252])
        by smtp.gmail.com with ESMTPSA id l81sm41838629pfi.50.2016.07.31.22.43.54
        for <singu...@lbl.gov>
        (version=TLS1 cipher=ECDHE-RSA-AES128-SHA bits=128/128);
        Sun, 31 Jul 2016 22:43:56 -0700 (PDT)
Subject: Re: [Singularity] How to use GPU in singularity?
References: <02b27dd5-dcc4-4800-97f6-7dcfcc85afd8@lbl.gov> <CAA8GL6Bsyt5oHK8O9GrDS6F=USv-aP0K9a+m8Q+jfOJ8kpxrhA@mail.gmail.com> <CAA8GL6DP3KhfbWV7nK5JGxNn4S+=M0=vEV0mACsoRrd6Ag2GpQ@mail.gmail.com> <718cb7c4-524f-4b08-bde9-3a36013fba59@lbl.gov> <4e52c56a-5475-4075-a3c7-2ae22191b544@lbl.gov> <CAA8GL6BdE1TRBaPD-oM7qcj8QK1cBsmJsUzYyrvkRPBP9CX+hQ@mail.gmail.com> <CAMfmYehdPLtiouQqMGqOx4ZbEXFbbPRL5QOxsP_vQo0us1QLuA@mail.gmail.com> <B927B7F6-3CFB-452D-92AB-866F9B8024E4@gmail.com> <CAMfmYeiSvcReO4jvSGJkavnex64wGZ8Phxva2kAxJ7pcp48YiA@mail.gmail.com> <CAMfmYeiaTxVQSNqwprHe5ckcDHPcJXy3imdepiRL+KkDh12TCQ@mail.gmail.com> <65CD778F-6CD1-4DB4-9668-4D89839B7053@gmail.com> <CAMfmYeg_pnJcyKGetK7WVChToaWCgGYH-nrYY9v=2+RSkuWZuQ@mail.gmail.com> <C5AE54CB-2BA1-4E59-88FC-D20224A46086@gmail.com> <CAMfmYeg2rR9-U-zyviCeDXRt_QgKv_K0p9pf-+qgoGPQAjxjXA@mail.gmail.com>
From: Rick Wagner <richard...@gmail.com>
Content-Type: multipart/alternative;
	boundary=Apple-Mail-8489228D-7BD0-4D7F-98F0-E69C475F0ECF
X-Mailer: iPad Mail (13F69)
In-Reply-To: <CAMfmYeg2rR9-U-zyviCeDXRt_QgKv_K0p9pf-+qgoGPQAjxjXA@mail.gmail.com>
Message-Id: <95039222-908B-4AE8-8844-551646C9733C@gmail.com>
Date: Sun, 31 Jul 2016 22:43:53 -0700
To: singularity@lbl.gov
Content-Transfer-Encoding: 7bit
Mime-Version: 1.0 (1.0)

--Apple-Mail-8489228D-7BD0-4D7F-98F0-E69C475F0ECF
Content-Type: text/plain;
	charset=us-ascii
Content-Transfer-Encoding: quoted-printable

Igor,

If you had a chance to post your definition file or the steps you took, I k=
now several of us would appreciate it. Getting TensorFlow running on CentOS=
 was a huge effort for our support staff. And that's just one of many GPU-e=
nabled applications.

--Rick

> On Jul 31, 2016, at 10:20 PM, Igor Yakushin <igor...@gmail.com> wrote:
>=20
> Thank you, Nathan. It finally works!
>=20
>> On Sun, Jul 31, 2016 at 5:17 PM, Nathan Lin <nathan...@gmail.com> wrote:
>> Yes I do
>>=20
>>> On Jul 31, 2016, at 5:03 PM, Igor Yakushin <igor...@gmail.com> wrote:
>>>=20
>>> Nathan,
>>> When you import tensorflow in python, does it tell you what cuda librar=
ies it is loading or not?
>>> Do you see these messages:
>>> =3D=3D=3D=3D=3D=3D
>>> >>> import tensorflow as tf=20
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcublas.so locally=20
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcudnn.so locally=20
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcufft.so locally=20
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcuda.so locally=20
>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcurand.so locally=20
>>> =3D=3D=3D=3D=3D=3D
>>> Thank you,
>>> Igor
>>>=20
>>>> On Sun, Jul 31, 2016 at 1:26 PM, Nathan Lin <nathan...@gmail.com> wrot=
e:
>>>> Hi Igor,
>>>>=20
>>>> In regards to your first questions, the OS/drivers of your building co=
mputer should not matter. I built an Ubuntu 14.04 image on my RHEL 7 box fo=
r our RHEL 6 cluster. I'm not sure that the toolkit is that version specifi=
c, my image seems to work fine and it's running 353.63. There is one thing =
that I do that may be helpful. I read it somewhere online and am not actual=
ly sure if it does anything, but I've included it in my image definitions j=
ust in case. Apparently there is something about initializing the CUDA Tool=
kit. As part of my definition file I run 'make' on the CUDA sample 'deviceQ=
uery'. Maybe that will help?
>>>>=20
>>>> Best,
>>>> Nathan
>>>>=20
>>>>> On Jul 31, 2016, at 1:51 PM, Igor Yakushin <igor...@gmail.com> wrote:
>>>>>=20
>>>>> Hi Nathan,
>>>>> I got a little bit further: nvidia-smi is working now but tensorflow =
still complains:
>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>>>=20
>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>>> Singularity/ubuntu_14.04.img> nvidia-smi=20
>>>>> Sun Jul 31 17:33:44 2016       =20
>>>>> +------------------------------------------------------+             =
          =20
>>>>> | NVIDIA-SMI 352.55     Driver Version: 352.55         |             =
          =20
>>>>> |-------------------------------+----------------------+-------------=
---------+=20
>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Unc=
orr. ECC |=20
>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Co=
mpute M. |=20
>>>>> |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D|=20
>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |             =
       0 |=20
>>>>> | N/A   45C    P0    79W / 235W |    158MiB / 11519MiB |     45%     =
 Default |=20
>>>>> +-------------------------------+----------------------+-------------=
---------+=20
>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |             =
       0 |=20
>>>>> | N/A   23C    P8    18W / 235W |     61MiB / 11519MiB |      0%     =
 Default |=20
>>>>> +-------------------------------+----------------------+-------------=
---------+=20
>>>>>                                                                      =
         =20
>>>>> +--------------------------------------------------------------------=
---------+=20
>>>>> | Processes:                                                       GP=
U Memory |=20
>>>>> |  GPU       PID  Type  Process name                               Us=
age      |=20
>>>>> |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D|=20
>>>>> +--------------------------------------------------------------------=
---------+=20
>>>>> Singularity/ubuntu_14.04.img> python=20
>>>>> Python 2.7.6 (default, Mar 22 2014, 22:59:56) =20
>>>>> [GCC 4.8.2] on linux2=20
>>>>> Type "help", "copyright", "credits" or "license" for more information=
.=20
>>>>> >>> import tensorflow=20
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened C=
UDA library libcublas.so locally=20
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened C=
UDA library libcudnn.so locally=20
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened C=
UDA library libcufft.so locally=20
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened C=
UDA library libcuda.so.1 locally=20
>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened C=
UDA library libcurand.so locally=20
>>>>> >>> ss =3D tensorflow.Session()=20
>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to =
cuInit: CUDA_ERROR_NO_DEVICE=20
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving=
 CUDA diagnostic information for host: midway-l34-02=20
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: =
midway-l34-02=20
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda re=
ported version is: 352.93.0=20
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver ver=
sion file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.=
55  Thu Oct  8 15:18:00 PDT 2015=20
>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =20
>>>>> """=20
>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel rep=
orted version is: 352.55.0=20
>>>>> E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:296] kernel ver=
sion 352.55.0 does not match DSO version 352.93.0 -- cannot find working de=
vices in this configuration=20
>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices a=
vailable on machine.=20
>>>>> >>>=20
>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>>> As far as I understand the problem is that cuda-7.5 was built or reli=
es on nvidia 352.93 while I have NVIDIA driver 352.55 both on the host and =
container. So far I could not find cuda-7.5 built with 352.55.
>>>>> cuda-7.5 has stabs directory in which there is libcuda.so. The proble=
m is probably coming from there. However, I doubt I can just replace libcud=
a.so in the stubs directory by a different version or turn it into symbolic=
 link to a different version in the driver? Because its size is much smalle=
r than the size of the real libcuda.so in the driver. So I suspect, it is r=
eally only some kind of interface to the real library?
>>>>>=20
>>>>> Thank you,
>>>>> Igor
>>>>>=20
>>>>>=20
>>>>>> On Sun, Jul 31, 2016 at 9:36 AM, Igor Yakushin <igor...@gmail.com> w=
rote:
>>>>>> Hi Nathan,
>>>>>> When installing cuda libraries and tensorflow into the singularity i=
mage, is it important to be on the same host with the same version of CUDA/=
OS on which you are going to run later?
>>>>>> I do not have root on the machine I am going to run later and prepar=
e the image on a different machine with a different version of nvidia drive=
r and a different flavor of Linux.
>>>>>> Thank you,
>>>>>> Igor
>>>>>>=20
>>>>>>=20
>>>>>>> On Sun, Jul 31, 2016 at 8:39 AM, Nathan Lin <nathan...@gmail.com> w=
rote:
>>>>>>> Hi Igor,
>>>>>>>=20
>>>>>>> I don't necessarily have a great answer for you. If seems like you =
are doing everything right, yet it is still not working. In my case, yes nv=
idia-smi as well as TensorFlow both work correctly. I feel like your error =
still has to do with the version of libcuda.so you are using. Notice how Py=
thon seems to correctly load libcuda.so, yet there is later an error that i=
s unable to find libcuda.so. My first suspicion is that there is still a ve=
rsion mismatch between the drivers installed on the image and on the host. =
If you are sure that is not true, it may be possible that the version of th=
e driver that is installed on the machine isn't new enough for the GPU. Tha=
t actually occurred on our cluster, and after a sysadmin updated the driver=
, it worked. Barring that I am not too sure. Maybe if you provide me with t=
he full details of your installation (the versions of the packages that you=
 have installed, the OS of your image and host), I might be able to think a=
bout something, but my suspicion is that the driver version on your host ma=
chine may not be new enough.=20
>>>>>>>=20
>>>>>>> Best,
>>>>>>> Nathan=20
>>>>>>>=20
>>>>>>>> On Jul 31, 2016, at 12:17 AM, Igor Yakushin <igor...@gmail.com> wr=
ote:
>>>>>>>>=20
>>>>>>>> Hi Nathan,
>>>>>>>>=20
>>>>>>>> I have found exactly the same version of NVIDIA driver and extract=
ed from it the libraries and nvidia executables and copied them in /usr/lib=
64/nvidia and /usr/bin and created the corresponding symbolic links. Howeve=
r, I still cannot use GPU inside singularity: nvidia-smi says "GPU access b=
locked by the operating system" (does it work in your case?) and when tenso=
rflow session starts it also complains that "No GPU devices available on ma=
chine". However, notice that tensorflow seems to think that a different ver=
sion of NVIDIA driver is used. Not sure where it is coming from. The machin=
e on which the image was built has version 361.42
>>>>>>>>=20
>>>>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24) =20
>>>>>>>> [GCC 5.4.0 20160609] on linux2=20
>>>>>>>> Type "help", "copyright", "credits" or "license" for more informat=
ion.=20
>>>>>>>> >>> import tensorflow=20
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opene=
d CUDA library libcublas.so locally=20
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opene=
d CUDA library libcudnn.so locally=20
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opene=
d CUDA library libcufft.so locally=20
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opene=
d CUDA library libcuda.so locally=20
>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully opene=
d CUDA library libcurand.so locally=20
>>>>>>>> >>> ss =3D tensorflow.Session()=20
>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call =
to cuInit: CUDA_ERROR_UNKNOWN=20
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retriev=
ing CUDA diagnostic information for host: midway230=20
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostnam=
e: midway230=20
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda=
 reported version is: Not found: was unable to find libcuda.so DSO loaded i=
nto this program=20
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver =
version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  3=
52.55  Thu Oct  8 15:18:00 PDT 2015=20
>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =
=20
>>>>>>>> """=20
>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel =
reported version is: 352.55.0=20
>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU device=
s available on machine.=20
>>>>>>>> >>> =20
>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi=20
>>>>>>>> Failed to initialize NVML: GPU access blocked by the operating sys=
tem
>>>>>>>> =3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D
>>>>>>>>=20
>>>>>>>> Thank you,
>>>>>>>> Igor
>>>>>>>>=20
>>>>>>>>=20
>>>>>>>>> On Thu, Jul 28, 2016 at 9:34 PM, Nathan Lin <nathan...@gmail.com>=
 wrote:
>>>>>>>>> I am not sure how to find the correct driver version, but from my=
 testing, the version must match exactly. I will admit that I have had prob=
lems finding specific versions of the driver from NVIDIA's website. I had t=
o ask a sysadmin for the installer that they used. In order to extract the =
files, you need to use the --extract-only option. For instance, you will ha=
ve to run something like ' sh /NVIDIA-Linux-x86_64-352.63.run --extract-onl=
y'/ . You will then be given a directory with all the libraries that would =
have been installed. You will need to copy the libcuda.so.###.## library (a=
nd you can copy any NVIDIA executables that you want such as nvidia-smi). G=
ood luck!
>>>>>>>>>=20
>>>>>>>>>> On Thu, Jul 28, 2016 at 8:51 PM, Igor <igor...@gmail.com> wrote:
>>>>>>>>>> I mean I am using this file from NVIDIA website cuda_7.5.18_linu=
x.run to install the driver, opengl, cuda. Driver installation fails, cuda =
succeeds.=20
>>>>>>>>>> Also, when I run=20
>>>>>>>>>> sh cuda_7.5.18_linux.run
>>>>>>>>>> I am offered to install the driver version 352.39 while on the h=
ost it is 346.47. I cannot upgrade the host. Any idea where I can get 346.1=
7?
>>>>>>>>>> I tried using the same link just substitute 18 for something els=
e but have not found the files:
>>>>>>>>>> wget http://developer.download.nvidia.com/compute/cuda/7.5/Prod/=
local_installers/cuda_7.5.1X_linux.run
>>>>>>>>>>=20
>>>>>>>>>>=20
>>>>>>>>>>=20
>>>>>>>>>>> On Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:
>>>>>>>>>>> Hi Nathan,
>>>>>>>>>>> When I try to install the driver by running NVIDIA*.run script =
inside the image, it fails, probably because it tries to modify kernel that=
 belongs to host?
>>>>>>>>>>> How do I extract just libcuda.so.345.67 without installing the =
driver (which is obviously problematic) and why would copying the library f=
rom the host would not work?
>>>>>>>>>>> Thank you,
>>>>>>>>>>> Igor
>>>>>>>>>>>=20
>>>>>>>>>>>> On Thursday, July 28, 2016 at 7:18:26 PM UTC-5, Nathan Lin wro=
te:
>>>>>>>>>>>> Also if you are using the binary installation of TensorFlow yo=
u need CUDA toolkit 7.5 and cuDNN v4. These only need to be installed on ou=
r image. As I mentioned earlier you will need the libcuda.so.###.## library=
 on your image. It is very important that this is the same version of the N=
VIDIA driver as you have on your nose (seemingly 346.67 for you). I should'=
ve have also mentioned that you want the libcuda.so.345.67 library that you=
 get from extracting the NVIDIA installer. It will not work if you try to c=
opy the libcuda.so library that from you node.=20
>>>>>>>>>>>>=20
>>>>>>>>>>>> Let me know if you have any more questions.=20
>>>>>>>>>>>>=20
>>>>>>>>>>>> Best,
>>>>>>>>>>>> Nathan
>>>>>>>>>>>>=20
>>>>>>>>>>>>> On Thursday, July 28, 2016, Nathan Lin <nat...@gmail.com> wro=
te:
>>>>>>>>>>>>> Hello,
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> Yes you are correct. The NVIDIA driver must be installed on y=
our image as well. However, you honestly only need the libcuda.so.###.## li=
brary and the appropriate links for that library. Once you have those insta=
lled in your image, it should work.=20
>>>>>>>>>>>>>=20
>>>>>>>>>>>>> Best,
>>>>>>>>>>>>> Nathan=20
>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> On Thursday, July 28, 2016, Igor <igor...@gmail.com> wrote:
>>>>>>>>>>>>>> Hi All,
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> I am trying to use GPU-enabled tensorflow and it cannot find=
 GPU card from inside the container.
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> On the host:
>>>>>>>>>>>>>> $ lspci | grep -i nvidia=20
>>>>>>>>>>>>>> 20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K4=
0m] (rev a1)=20
>>>>>>>>>>>>>> 8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K4=
0m] (rev a1)
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> $ nvidia-smi=20
>>>>>>>>>>>>>> Thu Jul 28 19:01:42 2016       =20
>>>>>>>>>>>>>> +------------------------------------------------------+    =
                   =20
>>>>>>>>>>>>>> | NVIDIA-SMI 346.47     Driver Version: 346.47         |    =
                   =20
>>>>>>>>>>>>>> |-------------------------------+----------------------+----=
------------------+=20
>>>>>>>>>>>>>> | GPU  Name        Persistence-M| Bus-Id        Disp.A | Vol=
atile Uncorr. ECC |=20
>>>>>>>>>>>>>> | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU=
-Util  Compute M. |=20
>>>>>>>>>>>>>> |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D|=20
>>>>>>>>>>>>>> |   0  Tesla K40m          Off  | 0000:20:00.0     Off |    =
                0 |=20
>>>>>>>>>>>>>> | N/A   30C    P8    20W / 235W |     66MiB / 11519MiB |    =
  0%      Default |=20
>>>>>>>>>>>>>> +-------------------------------+----------------------+----=
------------------+=20
>>>>>>>>>>>>>> |   1  Tesla K40m          Off  | 0000:8B:00.0     Off |    =
                0 |=20
>>>>>>>>>>>>>> | N/A   26C    P8    19W / 235W |     60MiB / 11519MiB |    =
  0%      Default |=20
>>>>>>>>>>>>>> +-------------------------------+----------------------+----=
------------------+=20
>>>>>>>>>>>>>>                                                             =
                  =20
>>>>>>>>>>>>>> +-----------------------------------------------------------=
------------------+=20
>>>>>>>>>>>>>> | Processes:                                                =
       GPU Memory |=20
>>>>>>>>>>>>>> |  GPU       PID  Type  Process name                        =
       Usage      |=20
>>>>>>>>>>>>>> |=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D|=20
>>>>>>>>>>>>>> |    0     11671    G   /usr/bin/X                          =
             9MiB |=20
>>>>>>>>>>>>>> |    1     11671    G   /usr/bin/X                          =
             3MiB |
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> Inside singularity:
>>>>>>>>>>>>>> $ singularity shell /software/src/singularity_images/tensorf=
low_0.9.img
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> lspci | grep -i nvidia=20
>>>>>>>>>>>>>> bash: lspci: command not found=20
>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> nvidia-smi=20
>>>>>>>>>>>>>> bash: nvidia-smi: command not found=20
>>>>>>>>>>>>>> Singularity/tensorflow_0.9.img> python=20
>>>>>>>>>>>>>> Python 2.7.12 (default, Jul  1 2016, 15:12:24) =20
>>>>>>>>>>>>>> [GCC 5.4.0 20160609] on linux2=20
>>>>>>>>>>>>>> Type "help", "copyright", "credits" or "license" for more in=
formation.=20
>>>>>>>>>>>>>> >>> import tensorflow as tf=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened CUDA library libcublas.so locally=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened CUDA library libcudnn.so locally=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened CUDA library libcufft.so locally=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened CUDA library libcuda.so locally=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/dso_loader.cc:108] successfully=
 opened CUDA library libcurand.so locally=20
>>>>>>>>>>>>>> >>> sess =3D tf.Session()=20
>>>>>>>>>>>>>> E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed=
 call to cuInit: CUDA_ERROR_UNKNOWN=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] r=
etrieving CUDA diagnostic information for host: midway-l34-01=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] h=
ostname: midway-l34-01=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] l=
ibcuda reported version is: Not found: was unable to find libcuda.so DSO lo=
aded into this program=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] d=
river version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Mod=
ule  346.47  Thu Feb 19 18:56:03 PST 2015=20
>>>>>>>>>>>>>> GCC version:  gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) =
(GCC) =20
>>>>>>>>>>>>>> """=20
>>>>>>>>>>>>>> I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] k=
ernel reported version is: 346.47.0=20
>>>>>>>>>>>>>> I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU =
devices available on machine.
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> Must there be nvidia driver installed inside the container? =
Outside? The container shares the same kernel with the host and nvidia kern=
el module needs to be loaded... How this is handled? Any requirements on nv=
idia driver and cuda versions inside and outside of the container?
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> Thank you,
>>>>>>>>>>>>>> Igor
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>>=20
>>>>>>>>>>>>>> --=20
>>>>>>>>>>>>>> You received this message because you are subscribed to the =
Google Groups "singularity" group.
>>>>>>>>>>>>>> To unsubscribe from this group and stop receiving emails fro=
m it, send an email to singu...@lbl.gov.
>>>>>>>>>>=20
>>>>>>>>>> --=20
>>>>>>>>>> You received this message because you are subscribed to the Goog=
le Groups "singularity" group.
>>>>>>>>>> To unsubscribe from this group and stop receiving emails from it=
, send an email to singu...@lbl.gov.
>>>>>>>>>=20
>>>>>>>>> --=20
>>>>>>>>> You received this message because you are subscribed to the Googl=
e Groups "singularity" group.
>>>>>>>>> To unsubscribe from this group and stop receiving emails from it,=
 send an email to singu...@lbl.gov.
>>>>>>>>=20
>>>>>>>> --=20
>>>>>>>> You received this message because you are subscribed to the Google=
 Groups "singularity" group.
>>>>>>>> To unsubscribe from this group and stop receiving emails from it, =
send an email to singu...@lbl.gov.
>>>>>>>=20
>>>>>>> --=20
>>>>>>> You received this message because you are subscribed to the Google =
Groups "singularity" group.
>>>>>>> To unsubscribe from this group and stop receiving emails from it, s=
end an email to singu...@lbl.gov.
>>>>>>=20
>>>>>=20
>>>>> --=20
>>>>> You received this message because you are subscribed to the Google Gr=
oups "singularity" group.
>>>>> To unsubscribe from this group and stop receiving emails from it, sen=
d an email to singu...@lbl.gov.
>>>>=20
>>>> --=20
>>>> You received this message because you are subscribed to the Google Gro=
ups "singularity" group.
>>>> To unsubscribe from this group and stop receiving emails from it, send=
 an email to singu...@lbl.gov.
>>>=20
>>> --=20
>>> You received this message because you are subscribed to the Google Grou=
ps "singularity" group.
>>> To unsubscribe from this group and stop receiving emails from it, send =
an email to singu...@lbl.gov.
>>=20
>> --=20
>> You received this message because you are subscribed to the Google Group=
s "singularity" group.
>> To unsubscribe from this group and stop receiving emails from it, send a=
n email to singu...@lbl.gov.
>=20
> --=20
> You received this message because you are subscribed to the Google Groups=
 "singularity" group.
> To unsubscribe from this group and stop receiving emails from it, send an=
 email to singu...@lbl.gov.

--Apple-Mail-8489228D-7BD0-4D7F-98F0-E69C475F0ECF
Content-Type: text/html;
	charset=utf-8
Content-Transfer-Encoding: quoted-printable

<html><head><meta http-equiv=3D"content-type" content=3D"text/html; charset=
=3Dutf-8"></head><body dir=3D"auto"><div></div><div>Igor,</div><div><br></d=
iv><div>If you had a chance to post your definition file or the steps you t=
ook, I know several of us would appreciate it. Getting TensorFlow running o=
n CentOS was a huge effort for our support staff. And that's just one of ma=
ny GPU-enabled applications.</div><div><br></div><div>--Rick</div><div><br>=
On Jul 31, 2016, at 10:20 PM, Igor Yakushin &lt;<a href=3D"mailto:igor...@g=
mail.com">igor...@gmail.com</a>&gt; wrote:<br><br></div><blockquote type=3D=
"cite"><div><div dir=3D"ltr">Thank you, Nathan. It finally works!</div><div=
 class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, Jul 31, 2016 =
at 5:17 PM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mailto:nathan...@gm=
ail.com" target=3D"_blank">nathan...@gmail.com</a>&gt;</span> wrote:<br><bl=
ockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #=
ccc solid;padding-left:1ex"><div dir=3D"auto"><div></div><div>Yes I do</div=
><div><div class=3D"h5"><div><br>On Jul 31, 2016, at 5:03 PM, Igor Yakushin=
 &lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">igor...@gmail.c=
om</a>&gt; wrote:<br><br></div><blockquote type=3D"cite"><div><div dir=3D"l=
tr">Nathan,<div>When you import tensorflow in python, does it tell you what=
 cuda libraries it is loading or not?</div><div>Do you see these messages:<=
/div><div>=3D=3D=3D=3D=3D=3D</div><div><div>&gt;&gt;&gt; import tensorflow =
as tf&nbsp;</div><div>I tensorflow/stream_executor/dso_loader.cc:108] succe=
ssfully opened CUDA library libcublas.so locally&nbsp;</div><div>I tensorfl=
ow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libc=
udnn.so locally&nbsp;</div><div>I tensorflow/stream_executor/dso_loader.cc:=
108] successfully opened CUDA library libcufft.so locally&nbsp;</div><div>I=
 tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA lib=
rary libcuda.so locally&nbsp;</div><div>I tensorflow/stream_executor/dso_lo=
ader.cc:108] successfully opened CUDA library libcurand.so locally&nbsp;</d=
iv></div><div>=3D=3D=3D=3D=3D=3D</div><div>Thank you,</div><div>Igor</div><=
/div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, Jul =
31, 2016 at 1:26 PM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mailto:nat=
han...@gmail.com" target=3D"_blank">nathan...@gmail.com</a>&gt;</span> wrot=
e:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-l=
eft:1px #ccc solid;padding-left:1ex"><div dir=3D"auto"><div></div><div>Hi I=
gor,</div><div><br></div><div>In regards to your first questions, the OS/dr=
ivers of your building computer should not matter. I built an Ubuntu 14.04 =
image on my RHEL 7 box for our RHEL 6 cluster. I'm not sure that the toolki=
t is that version specific, my image seems to work fine and it's running 35=
3.63. There is one thing that I do that may be helpful. I read it somewhere=
 online and am not actually sure if it does anything, but I've included it =
in my image definitions just in case. Apparently there is something about i=
nitializing the CUDA Toolkit. As part of my definition file I run 'make' on=
 the CUDA sample 'deviceQuery'. Maybe that will help?</div><div><br></div><=
div>Best,</div><div>Nathan</div><div><div><div><br>On Jul 31, 2016, at 1:51=
 PM, Igor Yakushin &lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blan=
k">igor...@gmail.com</a>&gt; wrote:<br><br></div><blockquote type=3D"cite">=
<div><div dir=3D"ltr">Hi Nathan,<div>I got a little bit further: nvidia-smi=
 is working now but tensorflow still complains:</div><div>=3D=3D=3D=3D=3D=
=3D=3D=3D=3D</div><div><br></div><div>=3D=3D=3D=3D=3D=3D=3D=3D=3D</div><div=
><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">Sin=
gularity/ubuntu_14.04.img&gt; nvidia-smi
</span><br>Sun Jul 31 17:33:44 2016 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;<br>+------------------------------------------------------+ &nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>| NVIDIA-SMI 352.55=
 &nbsp;&nbsp;&nbsp;&nbsp;Driver Version: 352.55 &nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;<br>|-------------------------------+----------------------+----=
------------------+
<br>| GPU &nbsp;Name &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Persistence-=
M| Bus-Id &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan &nbsp;Temp &nbsp;Perf &nbsp;Pwr:Usage/Cap| &nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;Memory-Usage | GPU-Util &nbsp;Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D|
<br>| &nbsp;&nbsp;0 &nbsp;Tesla K40m &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;Off &nbsp;| 0000:20:00.0 &nbsp;&nbsp;&nbsp;&nbsp;Off | &nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 |
<br>| N/A &nbsp;&nbsp;45C &nbsp;&nbsp;&nbsp;P0 &nbsp;&nbsp;&nbsp;79W / 235W=
 | &nbsp;&nbsp;&nbsp;158MiB / 11519MiB | &nbsp;&nbsp;&nbsp;&nbsp;45% &nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;Default |
<br>+-------------------------------+----------------------+---------------=
-------+
<br>| &nbsp;&nbsp;1 &nbsp;Tesla K40m &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;Off &nbsp;| 0000:8B:00.0 &nbsp;&nbsp;&nbsp;&nbsp;Off | &nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 |
<br>| N/A &nbsp;&nbsp;23C &nbsp;&nbsp;&nbsp;P8 &nbsp;&nbsp;&nbsp;18W / 235W=
 | &nbsp;&nbsp;&nbsp;&nbsp;61MiB / 11519MiB | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default |
<br>+-------------------------------+----------------------+---------------=
-------+
<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>+-----------------------------------------=
------------------------------------+
<br>| Processes: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GPU Memory |
<br>| &nbsp;GPU &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PID &nbsp;Type &nbsp;Pr=
ocess name &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Usage &nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D|
<br>+----------------------------------------------------------------------=
-------+
<br>Singularity/ubuntu_14.04.img&gt; python
<br>Python 2.7.6 (default, Mar 22 2014, 22:59:56) &nbsp;<br>[GCC 4.8.2] on =
linux2
<br>Type "help", "copyright", "credits" or "license" for more information.
<br>&gt;&gt;&gt; import tensorflow
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcublas.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcudnn.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcufft.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcuda.so.1 locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcurand.so locally
<br>&gt;&gt;&gt; ss =3D tensorflow.Session()
<br>E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cu=
Init: CUDA_ERROR_NO_DEVICE
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving C=
UDA diagnostic information for host: midway-l34-02
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: mi=
dway-l34-02
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda repo=
rted version is: 352.93.0
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver versi=
on file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module &nbsp;3=
52.55 &nbsp;Thu Oct &nbsp;8 15:18:00 PDT 2015
<br>GCC version: &nbsp;gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =
&nbsp;<br>"""
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel repor=
ted version is: 352.55.0
<br>E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:296] kernel versi=
on 352.55.0 does not match DSO version 352.93.0 -- cannot find working devi=
ces in this configuration
<br>I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices ava=
ilable on machine.
<br>&gt;&gt;&gt; <br>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span></div><div><span =
style=3D"font-family:monospace">As far as I understand the problem is that =
cuda-7.5 was built or relies on nvidia 352.93 while I have NVIDIA driver 35=
2.55 both on the host and container. So far I could not find cuda-7.5 built=
 with 352.55.</span></div><div><span style=3D"font-family:monospace">cuda-7=
.5 has stabs directory in which there is libcuda.so. The problem is probabl=
y coming from there. However, I doubt I can just replace libcuda.so in the =
stubs directory by a different version or turn it into symbolic link to a d=
ifferent version in the driver? Because its size is much smaller than the s=
ize of the real libcuda.so in the driver. So I suspect, it is really only s=
ome kind of interface to the real library?</span></div><div><span style=3D"=
font-family:monospace"><br></span></div><div><span style=3D"font-family:mon=
ospace">Thank you,</span></div><div><span style=3D"font-family:monospace">I=
gor</span></div><div><span style=3D"font-family:monospace"><br></span></div=
></div><div class=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, Ju=
l 31, 2016 at 9:36 AM, Igor Yakushin <span dir=3D"ltr">&lt;<a href=3D"mailt=
o:igor...@gmail.com" target=3D"_blank">igor...@gmail.com</a>&gt;</span> wro=
te:<br><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-=
left:1px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi Nathan,<div>When =
installing cuda libraries and tensorflow into the singularity image, is it =
important to be on the same host with the same version of CUDA/OS on which =
you are going to run later?</div><div>I do not have root on the machine I a=
m going to run later and prepare the image on a different machine with a di=
fferent version of nvidia driver and a different flavor of Linux.</div><div=
>Thank you,</div><div>Igor</div><div><br></div></div><div><div><div class=
=3D"gmail_extra"><br><div class=3D"gmail_quote">On Sun, Jul 31, 2016 at 8:3=
9 AM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mailto:nathan...@gmail.co=
m" target=3D"_blank">nathan...@gmail.com</a>&gt;</span> wrote:<br><blockquo=
te class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc so=
lid;padding-left:1ex"><div dir=3D"auto"><div></div><div>Hi Igor,</div><div>=
<br></div><div>I don't necessarily have a great answer for you. If seems li=
ke you are doing everything right, yet it is still not working. In my case,=
 yes nvidia-smi as well as TensorFlow both work correctly. I feel like your=
 error still has to do with the version of libcuda.so you are using. Notice=
 how Python seems to correctly load libcuda.so, yet there is later an error=
 that is unable to find libcuda.so. My first suspicion is that there is sti=
ll a version mismatch between the drivers installed on the image and on the=
 host. If you are sure that is not true, it may be possible that the versio=
n of the driver that is installed on the machine isn't new enough for the G=
PU. That actually occurred on our cluster, and after a sysadmin updated the=
 driver, it worked. Barring that I am not too sure. Maybe if you provide me=
 with the full details of your installation (the versions of the packages t=
hat you have installed, the OS of your image and host), I might be able to =
think about something, but my suspicion is that the driver version on your =
host machine may not be new enough.&nbsp;</div><div><br></div><div>Best,</d=
iv><div>Nathan&nbsp;</div><div><div><div><br>On Jul 31, 2016, at 12:17 AM, =
Igor Yakushin &lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">ig=
or...@gmail.com</a>&gt; wrote:<br><br></div><blockquote type=3D"cite"><div>=
<div dir=3D"ltr"><div><span style=3D"font-family:monospace"><span style=3D"=
color:rgb(0,0,0)">Hi Nathan,</span></span></div><div><span style=3D"font-fa=
mily:monospace"><span style=3D"color:rgb(0,0,0)"><br></span></span></div><d=
iv><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">I=
 have found exactly the same version of NVIDIA driver and extracted from it=
 the libraries and nvidia executables and copied them in /usr/lib64/nvidia =
and /usr/bin and created the corresponding symbolic links. However, I still=
 cannot use GPU inside singularity: nvidia-smi says "GPU access blocked by =
the operating system" (does it work in your case?) and when tensorflow sess=
ion starts it also complains that "No GPU devices available on machine". Ho=
wever, notice that tensorflow seems to think that a different version of NV=
IDIA driver is used. Not sure where it is coming from. The machine on which=
 the image was built has version&nbsp;</span></span><span style=3D"color:rg=
b(0,0,0);font-family:monospace">361.42</span></div><span style=3D"font-fami=
ly:monospace"><span style=3D"color:rgb(0,0,0)"><div><span style=3D"font-fam=
ily:monospace"><span style=3D"color:rgb(0,0,0)"><br></span></span></div><di=
v><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span></span></div>Python 2.7.12 (defa=
ult, Jul &nbsp;1 2016, 15:12:24) &nbsp;</span><br>[GCC 5.4.0 20160609] on l=
inux2
<br>Type "help", "copyright", "credits" or "license" for more information.
<br>&gt;&gt;&gt; import tensorflow
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcublas.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcudnn.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcufft.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcuda.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcurand.so locally
<br>&gt;&gt;&gt; ss =3D tensorflow.Session()
<br>E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cu=
Init: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving C=
UDA diagnostic information for host: midway230
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: mi=
dway230
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda repo=
rted version is: Not found: was unable to find libcuda.so DSO loaded into t=
his program
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver versi=
on file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module &nbsp;3=
52.55 &nbsp;Thu Oct &nbsp;8 15:18:00 PDT 2015
<br>GCC version: &nbsp;gcc version 4.4.7 20120313 (Red Hat 4.4.7-16) (GCC) =
&nbsp;<br>"""
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel repor=
ted version is: 352.55.0
<br>I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices ava=
ilable on machine.
<br>&gt;&gt;&gt; &nbsp;<br>Singularity/tensorflow_0.9.img&gt; nvidia-smi
<br>Failed to initialize NVML: GPU access blocked by the operating system<b=
r>
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D</span><div><span style=3D"font-family:mon=
ospace"><br></span></div><div><span style=3D"font-family:monospace">Thank y=
ou,</span></div><div><span style=3D"font-family:monospace">Igor</span></div=
><div><span style=3D"font-family:monospace"><br></span></div></div><div cla=
ss=3D"gmail_extra"><br><div class=3D"gmail_quote">On Thu, Jul 28, 2016 at 9=
:34 PM, Nathan Lin <span dir=3D"ltr">&lt;<a href=3D"mailto:nathan...@gmail.=
com" target=3D"_blank">nathan...@gmail.com</a>&gt;</span> wrote:<br><blockq=
uote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc =
solid;padding-left:1ex"><div dir=3D"ltr">I am no<font face=3D"arial, helvet=
ica, sans-serif">t sure how to find the correct driver version, but from my=
 testing, the version must match exactly. I will admit that I have had prob=
lems finding specific versions of the driver from NVIDIA's website. I had t=
o ask a sysadmin for the installer that they used. In order to extract the =
files, you need to use the --extract-only option. For instance, you will ha=
ve to run something like '

















sh /NVIDIA-Linux-x86_64-352.63.run
--extract-only'/ . You will then be given a directory with all the librarie=
s that would have been installed. You will need to copy the libcuda.so.###.=
## library (and you can copy any NVIDIA executables that you want such as n=
vidia-smi). Good luck!</font></div><div><div><div class=3D"gmail_extra"><br=
><div class=3D"gmail_quote">On Thu, Jul 28, 2016 at 8:51 PM, Igor <span dir=
=3D"ltr">&lt;<a href=3D"mailto:igor...@gmail.com" target=3D"_blank">igor...=
@gmail.com</a>&gt;</span> wrote:<br><blockquote class=3D"gmail_quote" style=
=3D"margin:0 0 0 .8ex;border-left:1px #ccc solid;padding-left:1ex"><div dir=
=3D"ltr"><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,0=
,0)">I mean I am using this file from NVIDIA website cuda_7.5.18_linux.run =
to install the driver, opengl, cuda. Driver installation fails, cuda succee=
ds.&nbsp;</span></span><div><span style=3D"font-family:monospace"><font col=
or=3D"#000000">Also, when I run&nbsp;</font></span></div><div><span style=
=3D"font-family:monospace"><font color=3D"#000000">sh&nbsp;</font></span><f=
ont color=3D"#000000" face=3D"monospace">cuda_7.5.18_linux.run</font></div>=
<div><span style=3D"font-family:monospace"><font color=3D"#000000">I am off=
ered to install the driver version&nbsp;</font></span><span style=3D"font-f=
amily:monospace"><span style=3D"color:rgb(0,0,0)">352.39 while on the host =
it is&nbsp;</span></span><span style=3D"font-family:monospace"><span style=
=3D"color:rgb(0,0,0)">346.47. I cannot upgrade the host. Any idea where I c=
an get 346.17?</span></span></div><div><span style=3D"font-family:monospace=
"><font color=3D"#000000">I tried using the same link just substitute 18 fo=
r something else but have not found the files:</font></span></div><div><spa=
n style=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">wget <a =
href=3D"http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_in=
stallers/cuda_7.5.1X_linux.run" target=3D"_blank">http://developer.download=
.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.1X_linux.run</a=
></span><br></span><br></div><div><div><div><br></div><div><br></div><div>O=
n Thursday, July 28, 2016 at 7:34:55 PM UTC-5, Igor wrote:<blockquote class=
=3D"gmail_quote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc s=
olid;padding-left:1ex"><div dir=3D"ltr">Hi Nathan,<div>When I try to instal=
l the driver by running NVIDIA*.run script inside the image, it fails, prob=
ably because it tries to modify kernel that belongs to host?</div><div>How =
do I extract just libcuda.so.345.67 without installing the driver (which is=
 obviously problematic) and why would copying the library from the host wou=
ld not work?</div><div>Thank you,</div><div>Igor<br><br>On Thursday, July 2=
8, 2016 at 7:18:26 PM UTC-5, Nathan Lin wrote:<blockquote class=3D"gmail_qu=
ote" style=3D"margin:0;margin-left:0.8ex;border-left:1px #ccc solid;padding=
-left:1ex">Also if you are using the binary installation of TensorFlow you =
need CUDA toolkit 7.5 and cuDNN v4. These only need to be installed on our =
image. As I mentioned earlier you will need the libcuda.so.###.## library o=
n your image. It is very important that this is the same version of the NVI=
DIA driver as you have on your nose (seemingly 346.67 for you). I should've=
 have also mentioned that you want the libcuda.so.345.67 library that you g=
et from extracting the NVIDIA installer. It will not work if you try to cop=
y&nbsp;the libcuda.so library that from you node.&nbsp;<div><br></div><div>=
Let me know if you have any more questions.&nbsp;</div><div><br></div><div>=
Best,</div><div>Nathan<span></span><br><br>On Thursday, July 28, 2016, Nath=
an Lin &lt;<a rel=3D"nofollow">nat...@gmail.com</a>&gt; wrote:<br><blockquo=
te class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1px #ccc so=
lid;padding-left:1ex">Hello,<div><br></div><div>Yes you are correct. The NV=
IDIA driver must be installed on your image as well. However, you honestly =
only need the libcuda.so.###.## library and the appropriate links for that =
library. Once you have those installed in your image, it should work.&nbsp;=
</div><div><br></div><div>Best,</div><div>Nathan&nbsp;<span></span><br><br>=
On Thursday, July 28, 2016, Igor &lt;<a>igor...@gmail.com</a>&gt; wrote:<br=
><blockquote class=3D"gmail_quote" style=3D"margin:0 0 0 .8ex;border-left:1=
px #ccc solid;padding-left:1ex"><div dir=3D"ltr">Hi All,<div><br><div>I am =
trying to use GPU-enabled tensorflow and it cannot find GPU card from insid=
e the container.</div><div><br></div><div>On the host:</div><div><span styl=
e=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ lspci | grep=
 -i nvidia
</span><br>20:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] =
(rev a1)
<br>8b:00.0 3D controller: NVIDIA Corporation GK110BGL [Tesla K40m] (rev a1=
)<br>
<br></span></div><div><span style=3D"font-family:monospace"><span style=3D"=
color:rgb(0,0,0)">$ nvidia-smi
</span><br>Thu Jul 28 19:01:42 2016 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;<br>+------------------------------------------------------+ &nbsp;&nbsp=
;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>| NVIDIA-SMI 346.47=
 &nbsp;&nbsp;&nbsp;&nbsp;Driver Version: 346.47 &nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;| &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;<br>|-------------------------------+----------------------+----=
------------------+
<br>| GPU &nbsp;Name &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Persistence-=
M| Bus-Id &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Disp.A | Volatile Uncor=
r. ECC |
<br>| Fan &nbsp;Temp &nbsp;Perf &nbsp;Pwr:Usage/Cap| &nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;Memory-Usage | GPU-Util &nbsp;Compute M. |
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D+=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D|
<br>| &nbsp;&nbsp;0 &nbsp;Tesla K40m &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;Off &nbsp;| 0000:20:00.0 &nbsp;&nbsp;&nbsp;&nbsp;Off | &nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 |
<br>| N/A &nbsp;&nbsp;30C &nbsp;&nbsp;&nbsp;P8 &nbsp;&nbsp;&nbsp;20W / 235W=
 | &nbsp;&nbsp;&nbsp;&nbsp;66MiB / 11519MiB | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default |
<br>+-------------------------------+----------------------+---------------=
-------+
<br>| &nbsp;&nbsp;1 &nbsp;Tesla K40m &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&n=
bsp;&nbsp;&nbsp;Off &nbsp;| 0000:8B:00.0 &nbsp;&nbsp;&nbsp;&nbsp;Off | &nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0 |
<br>| N/A &nbsp;&nbsp;26C &nbsp;&nbsp;&nbsp;P8 &nbsp;&nbsp;&nbsp;19W / 235W=
 | &nbsp;&nbsp;&nbsp;&nbsp;60MiB / 11519MiB | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp=
;0% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Default |
<br>+-------------------------------+----------------------+---------------=
-------+
<br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>+-----------------------------------------=
------------------------------------+
<br>| Processes: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;GPU Memory |
<br>| &nbsp;GPU &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PID &nbsp;Type &nbsp;Pr=
ocess name &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&=
nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Usage &nbsp;&nbsp;&nbsp;&nbsp;&nbs=
p;|
<br>|=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=3D=
=3D=3D=3D=3D|
<br>| &nbsp;&nbsp;&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;11671 &nbsp;&nbsp;&nbsp;G=
 &nbsp;&nbsp;/usr/bin/X &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;9MiB |
<br>| &nbsp;&nbsp;&nbsp;1 &nbsp;&nbsp;&nbsp;&nbsp;11671 &nbsp;&nbsp;&nbsp;G=
 &nbsp;&nbsp;/usr/bin/X &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;=
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nb=
sp;&nbsp;&nbsp;&nbsp;&nbsp;3MiB |<br>
<br></span></div></div><div><font face=3D"monospace"><br></font></div><div>=
<font face=3D"monospace">Inside singularity:</font></div><div><span style=
=3D"font-family:monospace"><span style=3D"color:rgb(0,0,0)">$ singularity s=
hell /software/src/singularity_images/tensorflow_0.9.img</span><br></span><=
/div><div><span style=3D"font-family:monospace"><span style=3D"color:rgb(0,=
0,0)"><br></span></span></div><div><span style=3D"font-family:monospace"><s=
pan style=3D"color:rgb(0,0,0)">Singularity/tensorflow_0.9.img&gt; lspci | g=
rep -i nvidia
</span><br>bash: lspci: command not found
<br>Singularity/tensorflow_0.9.img&gt; nvidia-smi
<br>bash: nvidia-smi: command not found
<br>Singularity/tensorflow_0.9.img&gt; python
<br>Python 2.7.12 (default, Jul &nbsp;1 2016, 15:12:24) &nbsp;<br>[GCC 5.4.=
0 20160609] on linux2
<br>Type "help", "copyright", "credits" or "license" for more information.
<br>&gt;&gt;&gt; import tensorflow as tf
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcublas.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcudnn.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcufft.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcuda.so locally
<br>I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUD=
A library libcurand.so locally
<br>&gt;&gt;&gt; sess =3D tf.Session()
<br>E tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cu=
Init: CUDA_ERROR_UNKNOWN
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving C=
UDA diagnostic information for host: midway-l34-01
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: mi=
dway-l34-01
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda repo=
rted version is: Not found: was unable to find libcuda.so DSO loaded into t=
his program
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver versi=
on file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module &nbsp;3=
46.47 &nbsp;Thu Feb 19 18:56:03 PST 2015
<br>GCC version: &nbsp;gcc version 4.4.7 20120313 (Red Hat 4.4.7-11) (GCC) =
&nbsp;<br>"""
<br>I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel repor=
ted version is: 346.47.0
<br>I tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices ava=
ilable on machine.<br>
<br></span></div><div><span style=3D"font-family:monospace">Must there be n=
vidia driver installed inside the container? Outside? The container shares =
the same kernel with the host and nvidia kernel module needs to be loaded..=
. How this is handled? Any requirements on nvidia driver and cuda versions =
inside and outside of the container?</span></div><div><span style=3D"font-f=
amily:monospace"><br></span></div><div><span style=3D"font-family:monospace=
">Thank you,</span></div><div><span style=3D"font-family:monospace">Igor</s=
pan></div><div><span style=3D"font-family:monospace"><br></span></div><div>=
<font face=3D"monospace"><br></font></div></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a>singu...@lbl.gov</a>.<br>
</blockquote></div>
</blockquote></div>
</blockquote></div></div></blockquote></div></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></blockquote></div></div></div><div><div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></blockquote></div></div></div><div class=3D"HOEnZb"><div class=3D"h5=
">

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov" target=3D"_blank">singu...@lbl.=
gov</a>.<br>
</div></div></blockquote></div><br></div>

<p></p>

-- <br>
You received this message because you are subscribed to the Google Groups "=
singularity" group.<br>
To unsubscribe from this group and stop receiving emails from it, send an e=
mail to <a href=3D"mailto:singu...@lbl.gov">singu...@lbl.gov</a>.<br>
</div></blockquote></body></html>
--Apple-Mail-8489228D-7BD0-4D7F-98F0-E69C475F0ECF--
